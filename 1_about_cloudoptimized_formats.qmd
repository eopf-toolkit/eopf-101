---
title: "About Cloud Optimised Formats"
format: html
---
::: {.justify}


## Why do we need to cloud-optimise geospatial data formats? {.unnumbered}

The volume of EO data has grown exponentially in recent years. For ESA, Copernicus alone generates ~16TB daily from the Sentinel missions alone. Traditional file formats, like SAFE (where each file can be hundreds of megabytes), make it slow to get just the specific information needed (for example, data for a single city over a decade). We have to download the entire asset, even if only a small part of it is needed. This might not a problem when you work close to the data.


When moving your Earth Observation processing workflow to the cloud however, your data  




Cloud-optimised formats make working with this data much more efficient by allowing:

- **Subsetting extraction**: Avoiding full downloads (optimised Extract-Load-Transform (ELT) operations)
- **Parallel processing**: by working with many parts of the data at the same time.
- **Scalable storage**: Using cloud-native storage systems that can grow as needed.
- **Optimised data latency**: Reducing delays when processing and visualising data.

## What is Data Latency?

**Data latency** in cloud computing refers to the time it takes for data to be available for processing once requested from cloud storage. For satellite data, this includes the time from when the satellite captures the data to when it is possible to work with it. 
Reducing latency enables faster access for users without powerful computers, making Sentinel data more accessible to everyone, no matter where they are. It also allows for more detailed analysis, leading to more accurate results because the analysis can use more relevant data.

Minimising latency benefits:

- We can access the data in less time.
- Decisions are made more quickly.
- Combining and analysing different datasets in an efficient way, reducing computing costs.

Modern cloud architectures reduce latency through:

- Storing and processing data in different geographic locations (e.g., AWS regions co-located with ESA ground stations)
- Caching high-demand products, so they are readily available.
- Utilising flexible computing resources that can quickly handle large processing tasks during emergencies

::: {.callout-note}
When accessing data over the internet (e.g., cloud storage), latency is high compared to local storage, so it's preferable to fetch lots of data in fewer reads.
:::

## Cloud-Optimised Geospatial Raster Formats

Initiatives like the [Cloud Native Geospatial Forum (CNG)](https://cloudnativegeo.org/) help develop ways to use geospatial data efficiently in the cloud, using standard cloud technologies and encouraging open collaboration on data formats. Two of the most important formats for storing and accessing geospatial data efficiently are Cloud-Optimised GeoTIFFs (COGs) and Zarr.

### Cloud-optimised GeoTIFF (COG)

COGs are like snapshots of raster data (such as satellite images or elevation maps). This widely used format improves the standard GeoTIFF format by:

- Organising data into **tiles**: Dividing the data into smaller, manageable squares (like 512x512 pixels).
- Including lower-resolution previews: Having pre-generated, less detailed versions of the data.

![COG structure. Retrieved from CNG documentation](img/cogtiff.png)

A key feature is the **Internal File Directory** (IFD), which acts like an internal index. This allows:

- Retrieving only the parts of the data needed using simple web requests.
- For example, it is possible to access just the tiles covering Paris from a large Sentinel-2 image of Europe.

### Zarr

This format is designed for handling large, multi-dimensional datasets (often called "data cubes"). Zarr, developed and maintained by the community, works by:

- Storing data as compressed **chunks** in a flexible way.
- Allowing for efficient indexing and processing of the data in parallel.
- Enabling specific descriptions (metadata) for each part of the data.

![Zarr structure. Retrieved from CNG documentation.](img/zarr1.png)

For example, Zarr makes it possible to extract temperature data for the summer of 2023 from a climate dataset spanning 50 years without needing to load the entire dataset.

The table below compares some features of COG and Zarr:

| Feature | Zarr | COG |
|---------|------|-----|
| Structure | Multi-file chunks | Single file |
| Access | Parallel | Sequential |
| Compression | Differently per-chunk | Whole-file |
| Scales | Multi-scale in single file | Separate, pre-generated lower-resolution files |


## When to use COGs versus Zarr?

Based on the structure and capabilities for each format, it is advised to use COGs when:

- Working with raster data (like images or elevation models) that does has sudden changes.
- It is needed to easily visualise or access specific geographic areas without loading the entire dataset.
- Interoperability with existing GIS software is important, as COG is a widely adopted standard.

On the other hand, it is advised to use Zarr when:

- Dealing with large, multi-dimensional datasets that might be updated or modified.
- Performing complex analyses that involve accessing different parts of the data in parallel.
- Efficiently handling different resolutions or variables within a single dataset is required.
- Working in cloud environments that benefit from chunked data storage for parallel processing.

## What's next?
Now that we have an idea of the available cloud-optimised formats and what cloud-optimised means, we will explore the available data sets inside the EOPF available products.

:::