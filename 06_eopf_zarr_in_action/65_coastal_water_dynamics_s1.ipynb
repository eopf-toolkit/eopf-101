{
 "cells": [
  {
   "cell_type": "raw",
   "id": "98baf096",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Surface Water Dynamics - Time Series Analysis with Sentinel-1\"\n",
    "execute:\n",
    "  enabled: true\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a81794",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "- **Walid Ghariani** - [GitHub Profile](https://github.com/WalidGharianiEAGLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd19370",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80910271",
   "metadata": {},
   "source": [
    "Water is a vital part of Earth ecosystems and life, supporting biodiversity, and sustaining human livelihoods. Monitoring surface water dynamics (occurence, frequency and change) is important for managing resources, and mitigating natural hazards such as floods and droughts. Wetlands in particular are unique ecosystems under the influence of precipitaion, hydrological processes and coastal dynamics, which contribute in shaping the habitats, and species diversity. Within this context, the [Keta](https://rsis.ramsar.org/ris/567) and [Songor](https://rsis.ramsar.org/ris/566) [Ramsar](https://www.ramsar.org/) Sites in southeastern Ghana present a dynamic coastal wetland system where water levels fluctuate due to rainfall, tidal influence, and lagoon-river interactions. \n",
    "\n",
    "These ramsar sites consists of different wetlands classes such as marshes, floodplains, mangroves, and seasonally inundated grasslands. These unique sites are also critical habitats for thousands of resident and migratory birds, fish, and sea turtles, while supporting local livelihoods through fishing, agriculture, and salt production. Threfore an effective monitoring of water dynamics of these ecosystems is essential for conserving biodiversity and sustaining community resources.\n",
    "\n",
    "Sentinel-1 Synthetic Aperture Radar (SAR) can detect water under all weather conditions, overcoming limitations of optical imagery caused by cloud cover. By processing and analyzing Sentinel-1 time series and its radar backscatter (VH, VV), water occurrence, frequency and dynamics in Ramsar wetlands could be detected and monitored providing valuable insights of these complex wetlands sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f59be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, NamedTuple\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import fsspec\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pystac_client import Client\n",
    "from odc.geo.geobox import GeoBox\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import uniform_filter\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "import session_info\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pkg_resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5283645",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858bae0d",
   "metadata": {},
   "source": [
    "## Data search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b4d525",
   "metadata": {},
   "source": [
    "- Search for Sentinel-1 GRD data using pystac-client and EODC STAC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08755b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for the Area Of Interest (AOI), time range and Polarization\n",
    "aoi_bounds = [0.60912065235268, 5.759873096746288, 0.714565658530316, 5.837736228130655]\n",
    "date_start = dt.datetime(2024, 1, 1)\n",
    "date_end = dt.datetime(2025, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0101aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Client.open(\"https://stac.core.eopf.eodc.eu\")\n",
    "search = catalog.search(\n",
    "    collections=[\"sentinel-1-l1-grd\"],\n",
    "    bbox=aoi_bounds,\n",
    "    datetime=f\"{date_start:%Y-%m-%d}/{date_end:%Y-%m-%d}\",\n",
    ")\n",
    "items = search.item_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de6ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets inspect the first item\n",
    "items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b956a",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb2b54",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf08903",
   "metadata": {},
   "source": [
    "Lets open the first item of Sentinel-1 Zarr product, navigates its hierarchical structure, and extracts measurement data, geolocation conditions, and calibration metadata for a specific polarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc287c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarization = \"VH\"  # or \"VV\"\n",
    "\n",
    "url = items[0].assets[\"product\"].href\n",
    "store = fsspec.get_mapper(url)\n",
    "datatree = xr.open_datatree(store, engine=\"zarr\", chunks={})\n",
    "group = [x for x in datatree.children if f\"{polarization}\" in x][0]\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664450bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd = datatree[group][\"measurements/grd\"]\n",
    "gcp = datatree[group][\"conditions/gcp\"].to_dataset()\n",
    "calibration = datatree[group][\"quality/calibration\"].to_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ed055",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b9143e",
   "metadata": {},
   "source": [
    "## Spatial subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66365bb7",
   "metadata": {},
   "source": [
    "To focus our analysis over the chosen AOI, we can efficiently crop our dataset using a spatial subset. The following functions determine the slices in azimuth_time and ground_range that cover the AOI, and then extract and mask the corresponding portion of the GDR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9490b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoi_slices(\n",
    "    gcp_ds: xr.Dataset,\n",
    "    aoi_bounds: list[float] | tuple[float, float, float, float],\n",
    "    offset: int = 2,\n",
    ") -> dict[str, slice]:\n",
    "    \"\"\"\n",
    "    Get the azimuth_time and ground_range slices for cropping around an AOI.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gcp_ds : xarray.Dataset\n",
    "        Dataset with 'latitude' and 'longitude' variables.\n",
    "    aoi_bounds : list or tuple\n",
    "        [min_lon, min_lat, max_lon, max_lat]\n",
    "    offset : int\n",
    "        Number of GCP grid cells to include around the nearest point.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        {\"azimuth_time\": az_slice, \"ground_range\": gr_slice}\n",
    "    \"\"\"\n",
    "    min_lon, min_lat, max_lon, max_lat = aoi_bounds\n",
    "    lat_c = (min_lat + max_lat) / 2\n",
    "    lon_c = (min_lon + max_lon) / 2\n",
    "\n",
    "    dist = (gcp_ds.latitude - lat_c) ** 2 + (gcp_ds.longitude - lon_c) ** 2\n",
    "\n",
    "    flat_index = dist.argmin().values\n",
    "    i, j = np.unravel_index(flat_index, gcp_ds.latitude.shape)\n",
    "\n",
    "    def clamp(index, dim):\n",
    "        start = max(0, index - offset)\n",
    "        end = min(dim - 1, index + offset)\n",
    "        return slice(start, end + 1)\n",
    "\n",
    "    az_slice = clamp(i, gcp_ds.sizes[\"azimuth_time\"])\n",
    "    gr_slice = clamp(j, gcp_ds.sizes[\"ground_range\"])\n",
    "\n",
    "    return {\"azimuth_time\": az_slice, \"ground_range\": gr_slice}\n",
    "\n",
    "\n",
    "def subset(\n",
    "    gdr: xr.Dataset,\n",
    "    gcp_ds: xr.Dataset,\n",
    "    aoi_bounds: list[float] | tuple[float, float, float, float],\n",
    "    offset=2,\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Crop GDR to AOI and return the subset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdr : xarray.DataArray or Dataset\n",
    "        GDR data to crop.\n",
    "    gcp_ds : xarray.Dataset\n",
    "        GCP dataset for slicing.\n",
    "    aoi_bounds : list or tuple\n",
    "        [min_lon, min_lat, max_lon, max_lat]\n",
    "    offset : int\n",
    "        Number of GCP grid cells to include around the nearest point.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.DataArray or Dataset\n",
    "        Cropped and masked GDR subset.\n",
    "    \"\"\"\n",
    "    slices = aoi_slices(gcp_ds, aoi_bounds, offset)\n",
    "    gcp_crop = gcp_ds.isel(**slices)\n",
    "\n",
    "    az_min, az_max = (\n",
    "        gcp_crop.azimuth_time.min().values,\n",
    "        gcp_crop.azimuth_time.max().values,\n",
    "    )\n",
    "    gr_min, gr_max = (\n",
    "        gcp_crop.ground_range.min().values,\n",
    "        gcp_crop.ground_range.max().values,\n",
    "    )\n",
    "    gdr_crop = gdr.sel(\n",
    "        azimuth_time=slice(az_min, az_max),\n",
    "        ground_range=slice(gr_min, gr_max),\n",
    "    )\n",
    "\n",
    "    gcp_interp = gcp_crop.interp_like(gdr_crop)\n",
    "    gdr_crop = gdr_crop.assign_coords(\n",
    "        latitude=gcp_interp.latitude,\n",
    "        longitude=gcp_interp.longitude,\n",
    "    )\n",
    "\n",
    "    minx, miny, maxx, maxy = aoi_bounds\n",
    "    mask = (\n",
    "        (gdr_crop.latitude >= miny)\n",
    "        & (gdr_crop.latitude <= maxy)\n",
    "        & (gdr_crop.longitude >= minx)\n",
    "        & (gdr_crop.longitude <= maxx)\n",
    "    )\n",
    "    mask = mask.compute()\n",
    "\n",
    "    return gdr_crop.where(mask, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdr_subset = subset(grd, gcp, aoi_bounds, offset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b293992",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdr_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb89281",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdr_subset.plot(robust=True, cmap=\"cividis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00cc1fd",
   "metadata": {},
   "source": [
    "## Radiometric calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680401ce",
   "metadata": {},
   "source": [
    "In order to get a meanigful physical properties of features in the SAR scene that could be used for quantitative analysis, we need to apply a radiometric calibration on the backscatter values. This step converts the backscatter into a calibrated normalized radar cross section, correcting for incidence angle and sensor characteristics ensuring SAR images from different dates or viewing geometries are directly comparable. \n",
    "\n",
    "- Reference: https://step.esa.int/docs/tutorials/S1TBX%20SAR%20Basics%20Tutorial.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiometric_calibration(\n",
    "    gdr: xr.DataArray,\n",
    "    calibration_ds: xr.Dataset,\n",
    "    calibration_type=\"sigma_nought\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform radiometric calibration on a grd data array.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdr : xarray.DataArray\n",
    "        The data array to calibrate.\n",
    "    calibration_ds : xarray.Dataset\n",
    "        The calibration dataset.\n",
    "    calibration_type : str, optional\n",
    "        The name of the calibration type in the calibration dataset.\n",
    "        Default is \"sigma_nought\".\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    xarray.DataArray\n",
    "        The calibrated GRD data.\n",
    "    \"\"\"\n",
    "    calibration_matrix = calibration_ds.interp_like(gdr)\n",
    "    return (gdr / calibration_matrix[calibration_type]) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc7f9d5",
   "metadata": {},
   "source": [
    "- Check the availble data vars in the calibration dataset that could be used for the radiometric calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration.data_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0 = radiometric_calibration(\n",
    "    gdr_subset, calibration, calibration_type=\"sigma_nought\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22dfe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0.plot(robust=True, cmap=\"cividis\", cbar_kwargs={\"label\": \"Sigma Nought\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fcd69b",
   "metadata": {},
   "source": [
    "## Speckel filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756bd71",
   "metadata": {},
   "source": [
    "Raw SAR imegery are characaterized by grainy or salt and pepper effect caused by random constructive and destructive interference, known as speckle. In order to reduce this effect and noise, we apply a spatial filter called **Lee Filter** [Lee et al. (2009)](https://doi.org/10.1080/02757259409532206) that averages the pixel values while preserving edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lee_filter(img: np.ndarray, size: int = 5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Numpy-based Lee filter for a single 2D array.\n",
    "    (Internal helper used by lee_filter_dask)\n",
    "    Adapted from reference: https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\n",
    "    \"\"\"\n",
    "    img = img.astype(np.float32)\n",
    "    mask_valid = np.isfinite(img)\n",
    "    img_filled = np.where(mask_valid, img, 0)\n",
    "\n",
    "    img_mean = uniform_filter(img_filled, size)\n",
    "    img_sqr_mean = uniform_filter(img_filled**2, size)\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "    img_variance = np.maximum(img_variance, 0)\n",
    "\n",
    "    valid_pixels = img[mask_valid]\n",
    "    overall_variance = np.var(valid_pixels) if valid_pixels.size > 0 else 0.0\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance + 1e-6)\n",
    "    img_output = img_mean + img_weights * (img_filled - img_mean)\n",
    "    img_output[~mask_valid] = np.nan\n",
    "    return img_output\n",
    "\n",
    "\n",
    "def lee_filter_dask(da: xr.DataArray, size: int = 5) -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Apply a Lee speckle filter to an xarray.DataArray (Dask-compatible).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : xr.DataArray\n",
    "        Input DataArray (float32 preferred). May be Dask-backed.\n",
    "    size : int\n",
    "        Window size (odd number recommended)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        Filtered DataArray (Dask-backed if input was Dask-backed)\n",
    "    \"\"\"\n",
    "    filtered = xr.apply_ufunc(\n",
    "        lee_filter,\n",
    "        da,\n",
    "        kwargs={\"size\": size},\n",
    "        input_core_dims=[[\"azimuth_time\", \"ground_range\"]],\n",
    "        output_core_dims=[[\"azimuth_time\", \"ground_range\"]],\n",
    "        vectorize=False,\n",
    "        dask=\"parallelized\",\n",
    "        output_dtypes=[np.float32],\n",
    "        dask_gufunc_kwargs={\"allow_rechunk\": True},  \n",
    "    )\n",
    "    filtered.attrs.update(da.attrs)\n",
    "    filtered.attrs.update(attrs={\"speckle filter method\": \"lee\"})\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b134f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk = lee_filter_dask(sigma_0, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3004b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk.plot(robust=True, cmap=\"cividis\", cbar_kwargs={\"label\": \"Sigma Nought\"})\n",
    "plt.title(\"Sigma Nought after Lee Filter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505082c1",
   "metadata": {},
   "source": [
    "## Georefrecing and regredding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d98b0",
   "metadata": {},
   "source": [
    "Sentinel-1 GRD ZARR comes in irregular image geometry that does not align with common geographic grids. In order to conduct spatial analysis, and scenes comparison, and mapping, we need to georefrence and resample the data onto a regular grid. We will use an [ODC GeoBox](https://odc-geo.readthedocs.io/en/latest/intro-geobox.html) along with with [scipy.griddata](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.griddata.html) to interpolate the SAR values onto a consistent latitude-longitude grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridInfo(NamedTuple):\n",
    "    \"\"\"Container for grid information.\"\"\"\n",
    "\n",
    "    gbox: GeoBox\n",
    "    xs: np.ndarray  # -> 1D longitude array\n",
    "    ys: np.ndarray  # -> 1D latitude array\n",
    "    xg: np.ndarray  # -->2D meshgrid longitude\n",
    "    yg: np.ndarray  # --> 2D meshgrid latitude\n",
    "\n",
    "\n",
    "def _extract_valid_data(\n",
    "    sar_da: xr.DataArray,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts valid longitude, latitude, and data values from a DataArray.\n",
    "    \"\"\"\n",
    "    lon = sar_da.longitude.values.flatten()\n",
    "    lat = sar_da.latitude.values.flatten()\n",
    "    data = sar_da.values.flatten()\n",
    "    mask = np.isfinite(lon) & np.isfinite(lat) & np.isfinite(data)\n",
    "    return lon[mask], lat[mask], data[mask]\n",
    "\n",
    "\n",
    "def _build_geobox(\n",
    "    bounds: list[float] | Tuple[float, float, float, float],\n",
    "    resolution: Tuple[float, float],\n",
    "    crs: str = \"EPSG:4326\",\n",
    ") -> GridInfo:\n",
    "    \"\"\"\n",
    "    Creates a GeoBox and returns grid information for interpolation.\n",
    "    \"\"\"\n",
    "    gbox = GeoBox.from_bbox(bounds, crs=crs, resolution=resolution)\n",
    "    coords = gbox.coordinates\n",
    "    xs = coords[\"longitude\"].values\n",
    "    ys = coords[\"latitude\"].values\n",
    "    xg, yg = np.meshgrid(xs, ys)\n",
    "    return GridInfo(gbox, xs, ys, xg, yg)\n",
    "\n",
    "\n",
    "def _interpolate_to_grid(\n",
    "    lon: np.ndarray,\n",
    "    lat: np.ndarray,\n",
    "    data: np.ndarray,\n",
    "    grid_info: GridInfo,\n",
    "    method: str = \"nearest\",\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Interpolates scattered data onto a regular grid and returns a DataArray with CRS and GeoBox.\n",
    "    \"\"\"\n",
    "    data_interp = griddata(\n",
    "        (lon, lat), data, (grid_info.xg, grid_info.yg), method=method\n",
    "    )\n",
    "    da = xr.DataArray(\n",
    "        data_interp,\n",
    "        dims=(\"y\", \"x\"),\n",
    "        coords={\"x\": grid_info.xs, \"y\": grid_info.ys},\n",
    "        attrs={\"interpolation\": method},\n",
    "    )\n",
    "    da = da.rio.write_crs(grid_info.gbox.crs)\n",
    "    da = da.rio.write_transform(grid_info.gbox.transform)\n",
    "    # Attach the GeoBox to the DataArray\n",
    "    da.attrs[\"odcgeobox\"] = grid_info.gbox\n",
    "    return da\n",
    "\n",
    "\n",
    "def regrid(\n",
    "    da: xr.DataArray,\n",
    "    bounds: list[float] | Tuple[float, float, float, float],\n",
    "    resolution: Tuple[float, float],\n",
    "    crs: str = \"EPSG:4326\",\n",
    "    method: str = \"nearest\",\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Regrids DataArray to a regular grid using ODC GeoBox and scipy griddata.\n",
    "    \"\"\"\n",
    "    lon, lat, data = _extract_valid_data(da)\n",
    "    grid_info = _build_geobox(bounds, resolution, crs)\n",
    "    da_out = _interpolate_to_grid(lon, lat, data, grid_info, method)\n",
    "    return da_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86110ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 10 / 111320  # approx 10 meters in degrees\n",
    "crs = \"epsg:4326\"\n",
    "\n",
    "sigma_0_spk_geo = regrid(\n",
    "    da=sigma_0_spk,\n",
    "    bounds=aoi_bounds,\n",
    "    resolution=resolution,\n",
    "    crs=crs,\n",
    "    method=\"nearest\",  # \"linear\" or \"cubic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2911f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo.odcgeobox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo.plot(robust=True, cmap=\"cividis\", cbar_kwargs={\"label\": \"Sigma Nought\"})\n",
    "plt.title(\"Regridded Sigma Nought after Lee Filter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a805f",
   "metadata": {},
   "source": [
    "## Convert backscatter to dB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd48ee",
   "metadata": {},
   "source": [
    "We convert the regridded sigma_0 backscatter intensity from Linear scale to decibels (dB) using a logarithmic transformation. This enhances contrast and simplifies statistical analysis and interpretation of the image. It is considered a standard approach for representing SAR intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76077baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo_db = 10 * np.log10(sigma_0_spk_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e62200",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo_db.plot(\n",
    "    robust=True, cmap=\"cividis\", cbar_kwargs={\"label\": \"Sigma Nought dB\"}\n",
    ")\n",
    "plt.title(\"Calibrated Sigma Nought in dB\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf55964",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_0_spk_geo_db.hvplot.image(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    robust=True,\n",
    "    cmap=\"cividis\",\n",
    "    title=\"SAR GRD\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e999d",
   "metadata": {},
   "source": [
    "## Water mask "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed39db8",
   "metadata": {},
   "source": [
    "To separate water from non-water surfaces, we first inspect the distribution of backscatter values using a histogram. In the following histogram we could choose -19 as therhold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e227fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sigma_0_spk_geo_db.values.ravel(), bins=50, alpha=0.7)\n",
    "plt.title(\"Histogram of Sigma Nought (dB) Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9bf9b",
   "metadata": {},
   "source": [
    "Since SAR water thresholds vary across scenes and times, a fixed cutoff is unreliable. Threfore, we apply an adaptative thresholding method using Otsu algorithm provided by [skimage](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_otsu), which automatically determines an optimal threshold from the intensity distribution and create a water mask accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf65388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_threshold_otsu(\n",
    "    da: xr.DataArray,\n",
    "    mask_nan: bool = True,\n",
    "    return_threshold: bool = False,\n",
    "    mask_name: str = None,\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Compute Otsu's threshold and generate a binary mask from a DataArray.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : xr.DataArray\n",
    "        Input DataArray with values to threshold.\n",
    "    mask_nan : bool, optional\n",
    "        If True, mask NaN values before thresholding.\n",
    "    return_threshold : bool, optional\n",
    "        If True, return the threshold value as an attribute.\n",
    "    mask_name : str, optional\n",
    "        Name for the binary mask DataArray (useful for metadata).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        A binary mask DataArray with the same spatial metadata as the input.\n",
    "        If return_threshold is True, the threshold value is stored in attrs.\n",
    "    \"\"\"\n",
    "    values = da.values\n",
    "    if mask_nan:\n",
    "        values = values[~np.isnan(values)]\n",
    "\n",
    "    threshold = threshold_otsu(values)\n",
    "    mask = (da > threshold).astype(np.uint8)\n",
    "\n",
    "    mask_da = xr.DataArray(\n",
    "        mask,\n",
    "        dims=da.dims,\n",
    "        coords=da.coords,\n",
    "        name=mask_name,\n",
    "        attrs={\"threshold\": threshold} if return_threshold else {},\n",
    "    )\n",
    "    return mask_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_mask = xr_threshold_otsu(\n",
    "    sigma_0_spk_geo_db, return_threshold=True, mask_name=\"water_mask\"\n",
    ")\n",
    "print(f\"Otsu threshold: {water_mask.attrs['threshold']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e837fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54586b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - water_mask).plot(cmap=\"Blues\")\n",
    "plt.title(\"Water Mask (1 = Water, 0 = Non-Water)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b33a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - water_mask).hvplot.image(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    cmap=\"Blues\",\n",
    "    robust=True,\n",
    "    title=\"Water Mask\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94aa5b",
   "metadata": {},
   "source": [
    "# Time series analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea5659",
   "metadata": {},
   "source": [
    "So far we have walked through each processing step separately. To automate the workflow and apply it efficiently across Sentinel-1 acquisitions, we could now wrap all these operations into a single processing function. This allows us to automatically generate water masks for every item in our STAC collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b810f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_item(\n",
    "    item, aoi_bounds, polarization=\"VH\", resolution=10 / 111320, crs=\"epsg:4326\"\n",
    "):\n",
    "    \"\"\"Process a STAC item to generate water mask and timestamp.\"\"\"\n",
    "    url = item.assets[\"product\"].href\n",
    "    store = fsspec.get_mapper(url)\n",
    "    datatree = xr.open_datatree(store, engine=\"zarr\", chunks={})\n",
    "\n",
    "    group_VH = [x for x in datatree.children if f\"{polarization}\" in x][0]\n",
    "\n",
    "    grd = datatree[group_VH][\"measurements/grd\"]\n",
    "    gcp = datatree[group_VH][\"conditions/gcp\"].to_dataset()\n",
    "    calibration = datatree[group_VH][\"quality/calibration\"].to_dataset()\n",
    "\n",
    "    gdr_subset = subset(grd, gcp, aoi_bounds, offset=1)\n",
    "    sigma_0 = radiometric_calibration(\n",
    "        gdr_subset, calibration, calibration_type=\"sigma_nought\"\n",
    "    )\n",
    "    sigma_0_spk = lee_filter_dask(sigma_0, size=5)\n",
    "    sigma_0_spk_geo = regrid(\n",
    "        da=sigma_0_spk,\n",
    "        bounds=aoi_bounds,\n",
    "        resolution=resolution,\n",
    "        crs=crs,\n",
    "        method=\"nearest\",\n",
    "    )\n",
    "    sigma_0_spk_geo_db = 10 * np.log10(sigma_0_spk_geo)\n",
    "    water_mask = xr_threshold_otsu(\n",
    "        sigma_0_spk_geo_db, return_threshold=True, mask_name=\"water_mask\"\n",
    "    )\n",
    "\n",
    "    t = np.datetime64(item.properties[\"datetime\"][:-2], \"ns\")\n",
    "    water_mask = water_mask.assign_coords(time=t)\n",
    "\n",
    "    return water_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08edc66e",
   "metadata": {},
   "source": [
    "Now we loop through all STAC items and use the `process_item` to build the full water-mask dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_masks = []\n",
    "thresholds = []\n",
    "\n",
    "for item in tqdm(items):\n",
    "    water_mask = process_item(item, aoi_bounds)\n",
    "    water_masks.append(1 - water_mask)  # invert mask to have 1 = water\n",
    "    thresholds.append(water_mask.attrs[\"threshold\"])\n",
    "\n",
    "water_mask_ds = xr.concat(water_masks, dim=\"time\")\n",
    "water_mask_ds = water_mask_ds.assign_coords(threshold=(\"time\", thresholds)).sortby(\n",
    "    \"time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bddf886",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_mask_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06327040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the water mask thresholds over time\n",
    "plt.plot(water_mask_ds.time, water_mask_ds.threshold, marker=\"o\")\n",
    "plt.title(\"Water Mask Thresholds over Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbadc61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = water_mask_ds.time\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1830a8",
   "metadata": {},
   "source": [
    "Lets inspect the water mask for the first 4 dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b65668",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_mask_ds.sel(time=dates[:4]).plot(col=\"time\", cmap=\"Blues\", vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d87450",
   "metadata": {},
   "source": [
    "We found out that the RAW Sentinel-1 GRD scene for 2024-06-07 has issues and artificat that will lead to incorrect water classification. Therefore, we will exclude it from our water frequency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_date = pd.to_datetime(\"2024-06-07\").date()\n",
    "filtered_water_ds = water_mask_ds.sel(\n",
    "    time=water_mask_ds.time.to_index().date != bad_date\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_water_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49729069",
   "metadata": {},
   "source": [
    "## Monthly surface water frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550e768",
   "metadata": {},
   "source": [
    "Now that we have the water masks, we can group them by month, compute the average water presence for each pixel, and convert it to a percentage (%) to represent monthly water frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72219698",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_water_frequency = filtered_water_ds.groupby(\"time.month\").mean(\"time\") * 100\n",
    "\n",
    "monthly_water_frequency.name = \"SWF\"\n",
    "month_names = pd.date_range(start=\"2024-01-01\", periods=12, freq=\"ME\").strftime(\"%B\")\n",
    "monthly_water_frequency.coords[\"month\"] = (\"month\", month_names)\n",
    "monthly_water_frequency = monthly_water_frequency.assign_attrs(\n",
    "    long_name=\"Surface Water Frequency\"\n",
    ")\n",
    "monthly_water_frequency = monthly_water_frequency.assign_attrs(units=\"%\")\n",
    "monthly_water_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_water_frequency.plot(col=\"month\", col_wrap=4, cmap=\"Blues\", robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b9fc3",
   "metadata": {},
   "source": [
    "## Annual surface water frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d46b8a",
   "metadata": {},
   "source": [
    "Lets calculates the average water occurence across the entire time series over the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_frequency = filtered_water_ds.mean(\"time\") * 100\n",
    "annual_water_frequency = annual_water_frequency.assign_attrs(\n",
    "    long_name=\"Surface Water Frequency\"\n",
    ")\n",
    "annual_water_frequency = annual_water_frequency.assign_attrs(units=\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f702d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_frequency.plot(cmap=\"Blues\")\n",
    "plt.title(\"Annual Surface Water Frequency (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_frequency.hvplot.image(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    robust=True,\n",
    "    cmap=\"Blues\",\n",
    "    title=\"Annual Surface Water Frequency (%)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11beacad",
   "metadata": {},
   "source": [
    "## Annual water change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e355ab",
   "metadata": {},
   "source": [
    "We could also computes the standard deviation of water presence over time. This highlights areas with high water variability (seasonal or dynamic water bodies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c28857",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_change = filtered_water_ds.std(\"time\") * 100\n",
    "annual_water_change = annual_water_change.assign_attrs(\n",
    "    long_name=\"Surface Water Variation\"\n",
    ")\n",
    "annual_water_change = annual_water_change.assign_attrs(units=\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b235786",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_change.plot(cmap=\"magma\")\n",
    "plt.title(\"Annual Surface Water Variation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_water_change.hvplot.image(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    robust=True,\n",
    "    cmap=\"magma\",\n",
    "    title=\"Annual Surface Water Variation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84b8de2",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd2cb0",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrated how to use Sentinel-1 data in `.zarr` format for time-series analysis of surface water dynamics in a wetland coastal and cloudy-prone area. The zarr structure is especially useful for efficient extraction of data over a specific area of interest without loading the full dataset.\n",
    "\n",
    "We developed a streamlined time series workflow using `pystac-client` and the EODC STAC API to preprocess Sentinel-1 GRD data. This included radiometric calibration, speckle filtering, georeferencing, and regridding. We also implemented an automated process for surface water detection and derived surface water occurrence, frequency, and change.\n",
    "\n",
    "**Note**: Although in this notebook we opted to use `VH` polarization to detect the water, users may also experiment with `VV` polarization or combine both polarizations for improved water detection, and implement their own methods for deriving surface water masks. This workflow can also be adapted for other applications, such as monitoring lake dynamic and flood events."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
