{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Creating and Optimizing Multi-temporal EOPF Zarr Datasets\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will create a multi-temporal EOPF Zarr dataset from multiple Sentinel-2 acquisitions, focusing on the 10-meter resolution bands. We will explore different chunking strategies and demonstrate their impact on storage efficiency and access performance. This hands-on approach will help you understand how to optimize Zarr chunking for your specific Earth Observation workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we will learn\n",
    "\n",
    "- üõ∞Ô∏è How to create a reduced EOPF Zarr dataset from multiple Sentinel-2 acquisitions\n",
    "- üìä How to implement different chunking strategies for multi-temporal data\n",
    "- ‚ö° How to measure and compare performance metrics for different chunk sizes\n",
    "- üîß How to optimize chunking for specific access patterns (spatial vs temporal)\n",
    "- üíæ How to evaluate storage efficiency with different compression settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook builds upon the concepts introduced in the [Zarr Chunking Introduction](251_zarr_chunking_intro.qmd). You should be familiar with:\n",
    "- Basic Zarr concepts and structure\n",
    "- STAC catalog navigation\n",
    "- Xarray operations\n",
    "\n",
    "::: {.callout-note}\n",
    "**Note:** This notebook uses utility functions from `zarr_chunking_utils.py` to keep the code focused on the key concepts. You can explore the utility functions to understand the implementation details.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our utility functions\n",
    "from zarr_chunking_utils import (\n",
    "    create_dask_client,\n",
    "    get_sentinel2_data,\n",
    ")\n",
    "\n",
    "# Set up plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the environment\n",
    "\n",
    "First, we will initialize our Dask client for parallel processing and define our area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Dask client for parallel processing\n",
    "client = create_dask_client(n_workers=4, threads_per_worker=2, memory_limit='4GB')\n",
    "print(f\"\\n‚úì Dask client initialized with {len(client.nthreads())} workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define area of interest and time period\n",
    "# Example: Agricultural area in Netherlands\n",
    "bbox = [5.0, 52.0, 5.5, 52.5]  # [min_lon, min_lat, max_lon, max_lat]\n",
    "start_date = \"2025-06-01\"\n",
    "end_date = \"2025-09-30\"\n",
    "\n",
    "print(f\"Area of Interest: {bbox}\")\n",
    "print(f\"Time period: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieving Sentinel-2 data from EOPF STAC\n",
    "\n",
    "We will first attempt to retrieve real Sentinel-2 data from the EOPF STAC catalog. If the connection is not available, we will fall back to sample data for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to retrieve real data from EOPF STAC\n",
    "items = get_sentinel2_data(\n",
    "    bbox=bbox,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    max_items=5,  # Get 5 acquisitions\n",
    "    cloud_cover=20\n",
    ")\n",
    "\n",
    "# Display acquisition information\n",
    "print(\"\\n‚úì Found EOPF data:\")\n",
    "for item in items:\n",
    "    date = pd.to_datetime(item['datetime']).strftime('%Y-%m-%d')\n",
    "    print(f\"  - {item['id']}: {date}\")\n",
    "use_real_data = True\n",
    "\n",
    "# Define the 10m bands we want to work with\n",
    "bands_10m = ['b02', 'b03', 'b04', 'b08']  # Blue, Green, Red, NIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def load_datatree_delayed(path):\n",
    "    return xr.open_datatree(path, consolidated=True, chunks=\"auto\")\n",
    "\n",
    "# Create delayed objects\n",
    "delayed_datatrees = [load_datatree_delayed(item['cloud_storage_url']) for item in items]\n",
    "# Compute in parallel\n",
    "datatrees = dask.compute(*delayed_datatrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examining EOPF Sentinel-2 Zarr Chunking\n",
    "\n",
    "Let's now examine the existing chunking of a Sentinel-2 Zarr dataset.\n",
    "The following cell will visualize the chunk layout of the dataset and draw the bounding box of our area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the first datatree's chunking configuration\n",
    "first_datatree = datatrees[0]\n",
    "\n",
    "# Access the 10m resolution data group\n",
    "data_10m = first_datatree['measurements/reflectance/r10m']\n",
    "\n",
    "# Print chunking information\n",
    "print(\"\\nChunking configuration for 10m bands:\")\n",
    "for var in data_10m.variables:\n",
    "    if var in bands_10m:\n",
    "        chunks = data_10m[var].chunks\n",
    "        print(f\"\\n{var}:\")\n",
    "        print(f\"  Shape: {data_10m[var].shape}\")\n",
    "        print(f\"  Chunks: {chunks}\")\n",
    "        print(f\"  Number of chunks: {len(chunks[0])} x {len(chunks[1])}\")\n",
    "\n",
    "# Create a visual representation of the chunking\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Sentinel-2 10m Band Chunking Layout\")\n",
    "\n",
    "# Plot chunk boundaries\n",
    "var = data_10m[bands_10m[0]]  # Use first band as reference\n",
    "y_chunks = np.cumsum([0] + list(var.chunks[0]))\n",
    "x_chunks = np.cumsum([0] + list(var.chunks[1]))\n",
    "\n",
    "for y in y_chunks:\n",
    "    plt.axhline(y=y, color='blue', linestyle='--', alpha=0.5)\n",
    "for x in x_chunks:\n",
    "    plt.axvline(x=x, color='blue', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Draw the bounding box of our area of interest\n",
    "bbox_patch = plt.Rectangle((bbox[0], bbox[1]), \n",
    "                          bbox[2]-bbox[0], bbox[3]-bbox[1],\n",
    "                          fill=False, color='red', linewidth=2,\n",
    "                          label='Area of Interest')\n",
    "plt.gca().add_patch(bbox_patch)\n",
    "\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics about the chunks\n",
    "chunk_sizes = [c * c2 for c, c2 in zip(var.chunks[0], var.chunks[1])]\n",
    "print(f\"\\nChunk statistics:\")\n",
    "print(f\"  Average chunk size: {np.mean(chunk_sizes):,.0f} pixels\")\n",
    "print(f\"  Min chunk size: {np.min(chunk_sizes):,.0f} pixels\")\n",
    "print(f\"  Max chunk size: {np.max(chunk_sizes):,.0f} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí™ Now it is your turn\n",
    "\n",
    "The following exercises will help you master Zarr chunking strategies for your own Earth Observation workflows.\n",
    "\n",
    "### Task 1: Explore Your Own Chunking Strategy\n",
    "\n",
    "* Define a new chunking strategy that might work better for your specific use case\n",
    "* Add it to the `chunking_strategies` dictionary\n",
    "* Run the comparison again to see how it performs\n",
    "\n",
    "### Task 2: Test with Different Data Dimensions\n",
    "\n",
    "* Modify the `data_shape` to simulate a longer time series (e.g., 20 time steps)\n",
    "* How does this affect the optimal chunking strategy?\n",
    "* Which strategy performs best for time series analysis?\n",
    "\n",
    "### Task 3: Optimize for Your Access Pattern\n",
    "\n",
    "* If you primarily need to extract time series for individual pixels, which strategy would you choose?\n",
    "* If you need to process entire scenes at specific dates, which strategy is optimal?\n",
    "* Create a custom chunking strategy that balances both requirements\n",
    "\n",
    "### Task 4: Experiment with Different Compression Algorithms\n",
    "\n",
    "* Modify the `create_multitemporal_zarr` function call to test different compression algorithms (e.g., 'lz4', 'zlib', 'blosclz')\n",
    "* Compare the trade-offs between compression ratio and read performance\n",
    "* Which algorithm works best for your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your experiments\n",
    "# Example: Add your custom chunking strategy\n",
    "\n",
    "# my_custom_strategy = {\n",
    "#     'time': 3,\n",
    "#     'y': 768,\n",
    "#     'x': 768\n",
    "# }\n",
    "\n",
    "# Add your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have demonstrated how to create multi-temporal EOPF Zarr datasets with different chunking strategies. We explored three main approaches‚Äîspatial-optimized, temporal-optimized, and balanced chunking‚Äîand analyzed their performance characteristics.\n",
    "\n",
    "Key takeaways:\n",
    "- **Spatial-optimized chunking** (large spatial chunks, small temporal chunks) excels for spatial analysis workflows\n",
    "- **Temporal-optimized chunking** (small spatial chunks, large temporal chunks) is ideal for time series extraction\n",
    "- **Balanced chunking** provides reasonable performance for mixed access patterns\n",
    "- Compression level significantly affects storage size but has diminishing returns beyond level 5-7\n",
    "- The optimal strategy depends on your specific access patterns and computational constraints\n",
    "\n",
    "Remember that chunk size selection is one of the most critical optimization decisions in Earth Observation data processing. Always profile your specific workflows to determine the optimal configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "In the next notebook, we will explore advanced Zarr features including hierarchical storage, multi-resolution pyramids, and cloud-optimized access patterns for large-scale Earth Observation analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
