{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "---\n",
    "title: \"Zarr Overviews - Creation\"\n",
    "execute:\n",
    "  enabled: true\n",
    "format: html\n",
    "---"
   ],
   "id": "46388d096a513686"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://jupyterhub.user.eopf.eodc.eu/hub/user-redirect/git-pull?repo=https://github.com/eopf-toolkit/eopf-101&branch=main&urlpath=lab/tree/eopf-101/65_create_overviews.ipynb\" target=\"_blank\">\n",
    "  <button style=\"background-color:#0072ce; color:white; padding:0.6em 1.2em; font-size:1rem; border:none; border-radius:6px; margin-top:1em;\">\n",
    "    üöÄ Launch this notebook in JupyterLab\n",
    "  </button>\n",
    "</a>"
   ],
   "id": "f750d82b4f861cd9"
  },
  {
   "cell_type": "markdown",
   "id": "y4i6lu71mz",
   "source": [
    "### Introduction\n",
    "\n",
    "In this notebook, we will demonstrate how to create **overviews** (also called multiscale pyramids) for large Earth Observation datasets stored in Zarr format. Overviews are downscaled representations of gridded data that optimize visualization and enable scalable access to large datasets.\n",
    "\n",
    "### What we will learn\n",
    "\n",
    "- üóÇÔ∏è How to compute multiscale overview levels from high-resolution satellite data\n",
    "- üìä How to attach GeoZarr-compliant metadata to datasets\n",
    "- üíæ How to write overview pyramids to Zarr storage\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This notebook uses:\n",
    "- **Dataset**: Sentinel-2 L2A reflectance data from EODC object storage\n",
    "- **Resolution**: 10m spatial resolution (10980 √ó 10980 pixels)\n",
    "- **Bands**: Blue (b02), Green (b03), Red (b04), NIR (b08)\n",
    "\n",
    "The workflow follows a **compute-then-write pattern** that separates in-memory computation from disk persistence, allowing validation before committing changes.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import libraries",
   "id": "bb36f1a166d0570e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import warnings\n",
    "import xarray as xr\n",
    "import json\n",
    "from pathlib import Path\n",
    "import zarr\n",
    "import dask\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "3efe6db84af8ac29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Copy Remote Dataset to Local Storage\n",
    "\n",
    "Before we can add overviews, we need to copy the entire remote Zarr dataset to local storage. This creates a local copy that we can modify by adding overview levels and metadata.\n",
    "\n",
    "**Why copy the entire dataset:**\n",
    "- The remote dataset is read-only (object storage) and we need a writable local copy to add new groups (L1-L5)\n",
    "- This preserves the complete original structure\n"
   ],
   "id": "f3da86baae0ba706"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To make sure that we use a convenient scene, we select a source URL from the catalogue.",
   "id": "4b0d2f2ec1c7a8ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#remote_url = (    \"https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:202506-s02msil2a/10/products/cpm_v256/S2C_MSIL2A_20250610T103641_N0511_R008_T32UMD_20250610T132001.zarr\")\n",
    "remote_url = (    \"https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:202508-s02msil2a/31/products/cpm_v256/S2A_MSIL2A_20250831T135741_N0511_R010_T26WPD_20250831T185012.zarr\")\n",
    "local_zarr_path = \"output/S2A_MSIL2A_20250831T135741_N0511_R010_T26WPD_20250831T185012.zarr\""
   ],
   "id": "ccefb8e7b5c23fd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As a first step, we download the remote Zarr dataset, split it into smaller 512-pixel chunks, and saves it as a local Zarr copy ready for exploration.\n",
    "Chunking helps large datasets load faster especially when used in visualisation tools that read data in small spatial tiles."
   ],
   "id": "1e506db3f6fafa2c"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Copying remote Zarr to {local_zarr_path}... (may take several minutes)\")\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "s2l2a_remote = xr.open_datatree(remote_url, engine=\"zarr\")\n",
    "# Rechunk all datasets in the datatree\n",
    "for node in s2l2a_remote.subtree:\n",
    "    if node.has_data:\n",
    "        node.ds = node.ds.chunk({dim: 512 for dim in node.ds.dims})\n",
    "s2l2a_remote.to_zarr(\n",
    "    local_zarr_path,\n",
    "    mode=\"w\",\n",
    "    zarr_version=2,\n",
    "    consolidated=False,\n",
    "    align_chunks=True,\n",
    ")"
   ],
   "id": "dffb1e02b64a6fda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we open the local copy of the dataset and look inside the group that contains the 10-metre reflectance data to understand which variables, dimensions, and coordinates it contains.",
   "id": "35f140264dc5acba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Step 2: Load Local Dataset and Inspect Structure ---\n",
    "variable_group_path = \"measurements/reflectance/r10m\"\n",
    "dataset = xr.open_dataset(f\"{local_zarr_path}/{variable_group_path}\", engine=\"zarr\")\n",
    "dataset"
   ],
   "id": "f3f8d590451e70e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Compute Overviews (In-Memory)\n",
    "\n",
    "Now we compute the overview levels **in memory only** - no data is written to disk at this stage.\n",
    "\n",
    "We extract the reflectance group at 10m resolution and automatically discover variables and dimensions.\n",
    "\n",
    "**Key operations:**\n",
    "- Open the local Zarr dataset as a datatree\n",
    "- Extract the reflectance group and convert to xarray Dataset\n",
    "- Automatically discover all variables and dimensions\n",
    "- Identify spatial coordinate names (x, y)\n"
   ],
   "id": "4094ed73571bbe88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this step, we identify the spatial dimensions and variables in the dataset and define the scale levels that will be used to generate lower-resolution overviews.",
   "id": "85347b2db02f31d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scales = [2, 4, 8, 16, 32, 64, 128]  # Scale factors for each level\n",
    "variables = [var for var in dataset.data_vars]  # Discover variables\n",
    "spatial_dims = [dim for dim in dataset.dims]  # Discover dimensions\n",
    "x_dim = next((d for d in spatial_dims if d in ['x', 'X', 'lon', 'longitude']), 'x')  # Identify x dimension\n",
    "y_dim = next((d for d in spatial_dims if d in ['y', 'Y', 'lat', 'latitude']), 'y')  # Identify y dimension\n",
    "print(f\"Variables: {variables} | Dims: {spatial_dims} | Shape: {dataset[variables[0]].shape} | Using: x_dim='{x_dim}', y_dim='{y_dim}'\\n\")"
   ],
   "id": "937342193664e438",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we generate a series of lower-resolution overview datasets directly in memory.\n",
    "\n",
    "For each scale factor, we use xarray‚Äôs coarsen() function to average groups of pixels along the spatial dimensions (x, y). Each coarsened version is stored under a level name like L1, L2, etc., representing progressively coarser spatial resolutions."
   ],
   "id": "13afa4288409e355"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "overviews = {}  # Generate in-memory overview datasets\n",
    "for i, factor in enumerate(scales):\n",
    "    level_id = f\"L{i+1}\"\n",
    "    coarsened = dataset.coarsen({x_dim: factor, y_dim: factor}, boundary=\"trim\").mean()\n",
    "    overviews[level_id] = coarsened[variables]\n",
    "\n",
    "print(f\"Created {len(overviews)} overview levels:\")\n",
    "for level_id, level_ds in overviews.items():\n",
    "    print(f\"  {level_id}: shape {level_ds[variables[0]].shape}, dims {dict(level_ds.dims)}\")\n",
    "print(\"\\nOverview datasets created successfully (in memory only, not written to disk)\")"
   ],
   "id": "f70fac2c26455380",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "hyrf8kgah4",
   "source": [
    "## Attach Multiscales Metadata\n",
    "\n",
    "With the overviews computed, we now attach **GeoZarr-compliant metadata** to the dataset. This metadata describes:\n",
    "\n",
    "- **Version**: Schema version (\"1.0\")\n",
    "- **Resampling method**: How data was aggregated (\"average\")\n",
    "- **Variables**: Which bands have overviews\n",
    "- **Layout**: The complete hierarchy including L0 (base) and all derived levels\n",
    "\n",
    "The metadata is stored in `dataset.attrs[\"multiscales\"]` following the GeoZarr Overviews specification. This ensures interoperability with GeoZarr-aware tools and libraries."
   ],
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we prepare the information needed to describe the overview hierarchy in the GeoZarr metadata. We set overview_path to indicate where the overview groups will be stored, record the resampling_method (\"average\") used to create them, and compute the base spatial resolutions (x_res and y_res) from the coordinate spacing.",
   "id": "3f008e44e7d0e0ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "overview_path = \"overviews\"  # Where overviews are written (\".\" for direct children)\n",
    "resampling_method = \"average\"\n",
    "x_res = abs(float(dataset['x'].values[1] - dataset['x'].values[0]))\n",
    "y_res = abs(float(dataset['y'].values[1] - dataset['y'].values[0]))"
   ],
   "id": "106d3b893c38728",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we build the multiscales layout metadata that describes how all overview levels relate to the base dataset.\n",
    "\n",
    "The first entry (L0) represents the original data, including its spatial resolution (cell_size). Each subsequent level (L1, L2, ‚Ä¶) is added to the layout with information about its path, the level it was derived from, the scale factors applied, the resampling method, and its corresponding cell size.\n",
    "\n",
    "Finally, this complete structure is stored in dataset.attrs[\"multiscales\"] following the GeoZarr Overviews specification (draft). The printed JSON summary shows the final metadata layout that GeoZarr-aware tools can use to identify and navigate between resolution levels."
   ],
   "id": "75baa6a2bfa850e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "layout = [{\"id\": \"L0\", \"path\": \".\", \"cell_size\": [x_res, y_res]}]  # Base level (native data at current group)\n",
    "for i, factor in enumerate(scales):\n",
    "    level_id = f\"L{i+1}\"\n",
    "    level_path = level_id if overview_path == \".\" else f\"{overview_path}/{level_id}\"\n",
    "    # CHANGE: Calculate level cell_size and add to layout entry\n",
    "    level_cell_size = [x_res * factor, y_res * factor]\n",
    "    layout.append({\"id\": level_id, \"path\": level_path, \"derived_from\": \"L0\" if i == 0 else f\"L{i}\", \"factors\": [factor, factor], \"resampling_method\": resampling_method, \"cell_size\": level_cell_size})\n",
    "dataset.attrs[\"multiscales\"] = {\"version\": \"1.0\", \"resampling_method\": resampling_method, \"variables\": variables, \"layout\": layout}\n",
    "print(\"Metadata structure:\")\n",
    "print(json.dumps(dataset.attrs[\"multiscales\"], indent=2))\n",
    "\n"
   ],
   "id": "3e902e5cb2e4f9a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "un2rac3flq",
   "source": [
    "### Write Overviews to Local Zarr Store\n",
    "\n",
    "Now we add the computed overviews to the local Zarr store without duplicating the native data.\n",
    "\n",
    "**Overview path options:**\n",
    "- `overview_path=\".\"` - Write overviews as direct children (L1, L2, L3, ...)\n",
    "- `overview_path=\"overviews\"` - Write overviews in a subfolder (overviews/L1, overviews/L2, ...)\n",
    "\n",
    "**Write operations:**\n",
    "1. **Write L1-L5** - Add overview levels as subgroups\n",
    "2. **Add metadata** - Update group attributes with multiscales metadata\n",
    "\n",
    "**Key point:** Native data stays at the group level. The multiscales metadata uses `path: \".\"` for L0 to reference the existing native data without duplication.\n",
    "\n",
    "**Result with `overview_path=\".\"`:**\n",
    "```\n",
    "measurements/reflectance/r10m/\n",
    "‚îú‚îÄ‚îÄ b02, b03, b04, b08  # Native data (L0 via path=\".\")\n",
    "‚îú‚îÄ‚îÄ x, y                # Coordinates\n",
    "‚îú‚îÄ‚îÄ L1/                 # Overview levels (direct children)\n",
    "‚îú‚îÄ‚îÄ L2/\n",
    "‚îú‚îÄ‚îÄ L3/\n",
    "‚îú‚îÄ‚îÄ L4/\n",
    "‚îú‚îÄ‚îÄ L5/\n",
    "‚îî‚îÄ‚îÄ .zattrs             # multiscales metadata\n",
    "```\n",
    "\n",
    "**Alternative with `overview_path=\"overviews\"`:**\n",
    "```\n",
    "measurements/reflectance/r10m/\n",
    "‚îú‚îÄ‚îÄ b02, b03, b04, b08  # Native data (L0 via path=\".\")\n",
    "‚îú‚îÄ‚îÄ x, y                # Coordinates\n",
    "‚îú‚îÄ‚îÄ overviews/          # Overview levels in subfolder\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ L1/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ L2/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ L3/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ L4/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ L5/\n",
    "‚îî‚îÄ‚îÄ .zattrs             # multiscales metadata\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "target_group_path = os.path.join(local_zarr_path, variable_group_path)\n",
    "print(f\"Adding overviews to {target_group_path} | Variables: {variables} | Path: '{overview_path}'\\n\")\n",
    "\n",
    "base_path = Path(target_group_path) / overview_path\n",
    "print(f\"Creating Zarr group: {overview_path}/\")\n",
    "zarr.open_group(str(base_path.absolute()), mode='a', zarr_version=2)  # Create proper Zarr group\n",
    "\n",
    "print(f\"Writing {len(overviews)} overview levels...\")\n",
    "for level_id, level_dataset in overviews.items():\n",
    "    level_dataset.to_zarr(str((base_path / level_id).absolute()), mode=\"a\", zarr_version=2)\n",
    "\n",
    "coords_only = xr.Dataset(coords=dataset.coords, attrs=dataset.attrs)  # Metadata update (no data vars)\n",
    "coords_only.to_zarr(str(Path(target_group_path).absolute()), mode=\"a\", zarr_version=2)\n",
    "\n",
    "print(f\"Generating consolidated metadata for {overview_path}/\")\n",
    "zarr.consolidate_metadata(str(base_path.absolute()))  # Create .zmetadata\n",
    "\n",
    "print(f\"\\nSuccessfully added overviews to {target_group_path}\\n\")\n",
    "print(f\"Final structure:\\n  {variable_group_path}/\")\n",
    "print(f\"    ‚îú‚îÄ‚îÄ {', '.join(variables)} (native data - L0 via path '.')\")\n",
    "print(f\"    ‚îú‚îÄ‚îÄ {x_dim}, {y_dim} (coordinates)\")\n",
    "if overview_path == \".\":\n",
    "    for level_id in overviews.keys(): print(f\"    ‚îú‚îÄ‚îÄ {level_id}/\")\n",
    "else:\n",
    "    print(f\"    ‚îú‚îÄ‚îÄ {overview_path}/\")\n",
    "    for level_id in overviews.keys(): print(f\"    ‚îÇ   ‚îú‚îÄ‚îÄ {level_id}/\")\n",
    "print(f\"    ‚îî‚îÄ‚îÄ .zattrs (with multiscales metadata)\")"
   ],
   "id": "1c08c20946520675",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## üí™ Now it is your turn\n",
    "\n",
    "With everything we have learnt so far, you are now able to create multiscale overviews for your own datasets.\n",
    "\n",
    "### Task 1: Experiment with Different Scale Factors\n",
    "\n",
    "Try modifying the `scales` list to create different pyramid structures. For example:\n",
    "- **Fewer levels**: `scales = [2, 4, 8]` for a smaller pyramid\n",
    "- **More aggressive downsampling**: `scales = [4, 16, 64]` for rapid zoom levels\n",
    "- **Fine-grained levels**: `scales = [2, 3, 4, 6, 8]` for smoother transitions\n",
    "\n",
    "### Task 2: Apply to Your Own Dataset\n",
    "\n",
    "Use this notebook as a template for your own Earth Observation data:\n",
    "1. Replace the URL with your own Zarr dataset\n",
    "2. Let the code discover variables and dimensions automatically\n",
    "3. Adjust scale factors based on your data resolution\n",
    "4. Validate and write the results\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This tutorial demonstrated the complete workflow for creating GeoZarr-compliant multiscale overviews:\n",
    "\n",
    "1. ‚úÖ Load and discover dataset structure automatically\n",
    "2. ‚úÖ Compute overview levels in memory (no disk I/O)\n",
    "3. ‚úÖ Attach specification-compliant metadata\n",
    "4. ‚úÖ Write to Zarr storage\n",
    "\n",
    "**Key takeaways:**\n",
    "- The **compute-then-write pattern** separates computation from I/O\n",
    "- **Dynamic discovery** makes code adaptable to different datasets\n",
    "\n",
    "## What's next?\n",
    "\n",
    "- **Visualization**: Use the created overviews with mapping libraries (Leaflet, Mapbox) for progressive rendering\n",
    "- **Performance**: Experiment with different chunking strategies for optimal I/O performance"
   ],
   "id": "5a8e8d222f9856bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
