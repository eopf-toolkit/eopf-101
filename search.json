[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ESA EOPF 101",
    "section": "",
    "text": "Your community guide for working with EOPF Sentinel Zarr data in the cloud\n\nExplore EOPF 101, an open community resource designed to help Sentinel data users explore EOPF Sentinel Zarr data in the cloud. With our step-by-step and hands-on tutorials, you’ll learn how to effectively use EOPF Sentinel Zarr products and build Earth Observation workflows that scale.\n\n🚀 Ready to explore EOPF 101?\n\nEOPF 101 is designed for Sentinel data users who are new to cloud-optimised geospatial formats and cloud-based workflows. It introduces you to fundamental cloud-native geospatial concepts, the Earth Observation Processing Framework (EOPF) activities by ESA, re-processed EOPF Sentinel Zarr data, as well as tools and libraries to work with EOPF Sentinel Zarr data in the cloud.\nAcross five chapters, EOPF 101 gradually introduces you to the EOPF Sentinel Zarr products, how you can search and access these, relevant tools and plugins to use EOPF Sentinel Zarr data in different working environments, as well as practical end-to-end application workflows highlighting the benefits of EOPF Sentinel Zarr data.\n\nChapter 1 - About EOPF\n\nIntroduction to the EOPF\nAbout Cloud-Optimised Formats\nEOPF Sentinel Zarr products\n\nChapter 2 - About EOPF Zarr\n\nOverview of the EOPF Zarr format\nDiscover EOPF Zarr - Sentinel-1 GRD\nOperations with EOPF Zarr - Sentinel-1 GRD\nDiscover EOPF Zarr - Sentinel-2 L2A\nDiscover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST\n\nChapter 3 - About Chunking\n\nAn introduction to Chunking\nBest practices and Chunking optimisation in EOPF\n\nChapter 3 - EOPF and STAC\n\nIntroduction to STAC\nExplore the web interface of the EOPF Zarr STAC Catalog\nAccess the EOPF Zarr STAC API with Python\nFrom STAC to Data: Accessing EOPF Zarr with xarray\n\nChapter 4 - Tools to work with EOPF Zarr – more coming soon!\n\nAccess the EOPF Zarr STAC API with R\n\nChapter 5 - EOPF Zarr in Action\n\nFire in Sardinia 2025 - Part 1\nFire in Sardinia 2025 - Part 2\nFire in Sardinia 2025 - Part 3\nFlood Mapping - Time Series Analysis in Valencia\n\n\n\n💡 How best to use EOPF 101\n\nYou can use EOPF 101 as a reference online resource to get example code and workflows for working with Zarr data, the EOPF STAC Catalogue, and different libraries and plugins facilitating the use of EOPF Sentinel Zarr data. Beyond this browsable version, you can also set up the required environment to execute the notebooks.\nInstructions on local setup and Docker container on CDSE are coming soon.\n\n\n📢 How to get involved\n\nEOPF 101 is an open community resource under active development. Our activities are designed to engage with Sentinel users and to gather feedback on EOPF Sentinel Zarr products. There are different ways you can get involved and engaged:\n\nJoin the EOPF Toolkit Notebook Competition\n\nGet ready and participate in the EOPF Toolkik Notebook Competition! The competition will kick off in October 2025 and run till January 2026. It is your chance to get hands-on with EOPF Zarr products, get expert input and guidance and show the community the great work you do.\nExpress your interest today and do not miss any updates related to the notebook competition.\n\nMore details coming soon.\n\nIdeas & Feedback?\n\nIs there a plugin or library missing that you would like to see integrated? Do you have feedback on EOPF 101? Please submit an issue and we will review your request.\n\nAbout the ESA EOPF Toolkit project\n\nEOPF 101 is a community resource developed as part of the EOPF Toolkit project funded by the European Space Agency. EOPF 101 is brought to you by Development Seed, thriveGEO and SparkGeo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**ESA EOPF 101**</span>"
    ]
  },
  {
    "objectID": "11_about_eopf.html",
    "href": "11_about_eopf.html",
    "title": "Introduction to the EOPF",
    "section": "",
    "text": "Introduction\nIn this chapter, we will introduce the European Space Agency’s (ESA) Earth Observation Processor Framework (EOPF) initiative. This project marks a significant step towards modernising how we handle satellite data, specifically by moving away from the traditional .SAFE data format to a more efficient, cloud-optimised format. We will take a closer look at the new structure ESA has developed for this purpose.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to the EOPF</span>"
    ]
  },
  {
    "objectID": "11_about_eopf.html#what-is-eopf",
    "href": "11_about_eopf.html#what-is-eopf",
    "title": "Introduction to the EOPF",
    "section": "What is EOPF?",
    "text": "What is EOPF?\nThe Earth Observation Processor Framework (EOPF) is an initiative led by the European Space Agency (ESA) designed to modernise and harmonise data from the Copernicus Sentinel Missions.\nWith the upcoming Copernicus Expansion missions in 2028, the amount of data produced daily will significantly increase. EOPF is ESA’s solution to organise Sentinel data in a way that works seamlessly with modern cloud technology. This will make it easier to find, access, and process the information you need. The new approach provides user-friendly access, simplifies maintenance, and helps keep costs down, guaranteeing reliable access to Sentinel data in the long run.\nThe Sentinel-1, Sentinel-2, and Sentinel-3 missions are the first to be updated with this new system.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to the EOPF</span>"
    ]
  },
  {
    "objectID": "11_about_eopf.html#the-eopf-data-model",
    "href": "11_about_eopf.html#the-eopf-data-model",
    "title": "Introduction to the EOPF",
    "section": "The EOPF Data Model",
    "text": "The EOPF Data Model\nThe EOPF data model has been defined by following a set of principles:\n\nOpen standards: Following common and community-approved data standards ensures sustainability and user uptake.\nInteroperability: Harmonised with a clear and organised structure that describes the data itself.\nCloud optimisation: Designed for efficient access and handling in cloud environments.\nConversion flexibility: Providing tools to adjust the data for different applications.\n\nUnder EOPF, there are four key areas of activities: (i) EOPF product structure, (ii) EOPF metadata structure, (iii) EOPF encoding structure and (iv) the EOPF Processor Framework:\n\nEOPF product structure\nAs part of the EOPF, ESA is actively working on a common data structure for Sentinel data products to define a common meta-model that can be used across all Sentinel and other EO missions. This approach ensures that data from several missions is consistent.\nThe EOPF product structure consists of the following components:\n\nMeasurements: The actual sensor readings (like how much light is reflected or the temperature), at different levels of detail.\nQuality indicators: Details that help understand how reliable the measurements are.\nConditions: Information about the environment or technical aspects when the data was collected.\nAttributes: Global metadata, such as when it was acquired and the sensor’s orbit.\n\n\n\n\nEOPF product structure\n\n\n\n\n\n\n\n\nNote\n\n\n\nLearn more about the EOPF Zarr product structure here.\n\n\n\n\nEOPF metadata structure\nMetadata provides all relevant information required to uniquely describe each Sentinel product. The EOPF metadata structure is organised as follows:\n\nDiscovery Metadata: Following the metadata structure defined by the SpatioTemporal Asset Catalogue (STAC), which helps to keep things consistent across different missions.\nProcessing History Metadata: Keeping a record of how the data has been processed.\nOther Metadata: Information like the status of the sensor and details about the satellite’s orbit.\n\n\n\n\n\n\n\nNote\n\n\n\nEOPF and STAC: Learn more about EOPF and STAC here.\n\n\n\n\nEOPF encoding structure\nAn encoding structure can be seen as the specific method used to package and store data and its associated metadata in a digital format. Building on the consistent data structure and clear metadata, the new storage system must be capable of handling various aspects of current Sentinel data (such as manifest files and tile structures from the .SAFE format) while remaining fully compatible with cloud environments.\nESA chose .zarr as encoding format as it allows for instant access to data, efficient processing of massive amounts of data, and seamless integration with other datasets. The EOPF Sentinel Zarr data encoding allows you to work with data from multiple missions more effectively.\n\n\n\n\n\n\nNote\n\n\n\nLearn more about the EOPF Sentinel Zarr format here. And learn more about cloud-optimised geospatial data formats in general in the Cloud-Optimised Geospatial Data Formats Guide\n\n\n\n\nEOPF processor framework\nThe way Sentinel data is processed is being updated to take advantage of modern cloud computing. This will make the processing faster and more efficient, and at the same time ensure the scientific quality and accuracy of the Sentinel data remains the same.\n\n\n\n\n\n\nNote\n\n\n\nTo learn more about the EOPF processor framework, visit https://eopf.copernicus.eu/eopf/",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to the EOPF</span>"
    ]
  },
  {
    "objectID": "11_about_eopf.html#conclusion",
    "href": "11_about_eopf.html#conclusion",
    "title": "Introduction to the EOPF",
    "section": "Conclusion",
    "text": "Conclusion\nThroughout this section, we explored the EOPF initiative and its adoption of the .zarrformat. This new approach is set to significantly improve and simplify how we access and work with data from the satellite missions Sentinel-1, Sentinel-2, and Sentinel-3.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to the EOPF</span>"
    ]
  },
  {
    "objectID": "11_about_eopf.html#whats-next",
    "href": "11_about_eopf.html#whats-next",
    "title": "Introduction to the EOPF",
    "section": "What’s next?",
    "text": "What’s next?\nIn the following section, we learn why EO data needs to be cloud-optimised when processed in the cloud.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to the EOPF</span>"
    ]
  },
  {
    "objectID": "12_about_cloudoptimized_formats.html",
    "href": "12_about_cloudoptimized_formats.html",
    "title": "About cloud-optimised formats",
    "section": "",
    "text": "Introduction\nIn this section, we will dive into cloud-optimised geospatial formats. We explore why these new formats are important and will introduce you to two common cloud-optimised data formats specifically for raster files.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "12_about_cloudoptimized_formats.html#why-to-cloud-optimise-geospatial-data-formats",
    "href": "12_about_cloudoptimized_formats.html#why-to-cloud-optimise-geospatial-data-formats",
    "title": "About cloud-optimised formats",
    "section": "Why to cloud-optimise geospatial data formats?",
    "text": "Why to cloud-optimise geospatial data formats?\nThe volume of EO data has grown exponentially in recent years. The Copernicus programme alone generates ~16TB daily from the Sentinel missions. Traditional file formats, like .SAFE (where each file can be hundreds of megabytes), are optimised for efficient archiving and distributing data. This means that we often download the data from an entire overpass, even if we only need to access a small part of it. For example, if we want to do an analysis of the area of a single city over a decade.\nWith growing data volumes, this becomes a challenge. To picture the different nature of challenges we come across, let us compare a traditional local workflow with a cloud-based workflow:\n\nTraditional local workflow: When working locally, we download much more data than we need, and we are constrained by the compute and storage capacity of the local system. However, an advantage of working locally is that data and compute are close together, meaning that there is not much delay in accessing the data.\nCloud-based workflow: Cloud environments overcome the limitations local workflows have. A cloud environment offers limitless storage and compute capacity. On the contrary, data storage, compute, and you the destination are far apart. There is an additional time for data to travel between the storage location, processing resources and us. This time is referred to as data latency.\n\n\n\n\n\n\n\nNote\n\n\n\nData latency refers to the time it takes for data to be transmitted or processed from cloud storage to your computer. In local workflows, data latency is minimal, whereas in cloud-based workflows, data latency needs to be optimised.\n\n\n\nAnalogy: Comparing local and cloud-based workflows with ordering a pizza\nTo understand the principal concept, let us compare local and cloud-based workflows with ordering a pizza. Local workflows are similar to placing an order at a pizza store on your street. It is quick since the data (pizza) is easily accessible, but we can only choose from what the local pizza store offers.\nOn the other hand, cloud-based workflows are comparable to ordering a pizza from a pizza store in a different city or even country. This option allows you to order different types of pizzas, which are not available in the pizza store on your street. While we might have more options to choose from, the time between order and delivery can become a challenge. The time until your pizza from a different town or country arrives at your house is called data latency.\nHence, the overall goal with cloud-based workflows is to minimise data latency as much as possible. This is why traditional data formats need to be cloud-optimised.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "12_about_cloudoptimized_formats.html#characteristics-of-cloud-optimised-formats",
    "href": "12_about_cloudoptimized_formats.html#characteristics-of-cloud-optimised-formats",
    "title": "About cloud-optimised formats",
    "section": "Characteristics of cloud-optimised formats",
    "text": "Characteristics of cloud-optimised formats\nCloud-optimised formats are optimised to minimise data latency. By allowing for an efficient retrieval of smaller, specific chunks of information rather than downloading an entire file. Accessing a smaller data subset also reduces the costs associated with data transfer and data processing.\nCloud-optimised geospatial data formats have the following characteristics:\n\nData is accessible over an HTTP protocol.\nRead-Oriented, as it supports partial and parallel reads.\nData is organised in internal groupings (such as chunks, tiles, shards) for efficient subsetting, distributed processing and data access in memory.\nMetadata can be accessed in one read.\n\n\n\n\n\n\n\nNote\n\n\n\nWhen accessing data over the internet (e.g. through object stores in the cloud), latency is high compared to local storage, so it is recommended to fetch lots of data in fewer reads.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "12_about_cloudoptimized_formats.html#cloud-optimised-geospatial-raster-formats",
    "href": "12_about_cloudoptimized_formats.html#cloud-optimised-geospatial-raster-formats",
    "title": "About cloud-optimised formats",
    "section": "Cloud-Optimised Geospatial Raster Formats",
    "text": "Cloud-Optimised Geospatial Raster Formats\nFor satellite data, two main cloud-optimised formats are being used:\n\nCloud-Optimised GeoTIFF (COG): Optimised for 2D image data and originates from the traditional GeoTIFF format, and\nZarr: Used and designed for complex, n-dimensional data structures and originates from the traditional formats netCDF and HDF5.\n\n\nCloud-optimised GeoTIFF (COG)\nCOGs have been widely used as a cloud-native format for satellite imagery and improve the standard GeoTIFF format by:\n\nOrganising data into tiles: Dividing the data into smaller, manageable squares (like 512x512 pixels).\nIncluding lower-resolution previews: Having pre-generated, less detailed versions of the data. This allows for fast and efficient data visualisations.\n\nA key feature of COGs is the Internal File Directory (IFD), which acts like an internal index. This allows for retrieving only the parts of the data needed using simple web requests. For example, it is possible to access just the tiles covering Paris from a large Sentinel-2 image of Europe.\n\n\n\nCOG structure. Retrieved from CNG documentation\n\n\n\n\nMulti-dimensional Array Storage with Zarr\nZarr is the cloud-optimised version for the traditional formats netCDF and HDF5, and is specifically designed for storing and accessing large n-dimensional arrays in the cloud by:\n\nChunking: Breaking large arrays into smaller pieces that can be accessed independently\nCompression: Each chunk can be compressed individually for efficient storage\nHierarchical Organisation: Arrays are organised in groups, similar to folders in a filesystem\nCloud-Native Access: Optimised for reading partial data over HTTP\nParallel I/O: Multiple chunks can be read or written simultaneously\nSelf-Description: Rich metadata is stored alongside the data using JSON\n\nThis makes Zarr particularly well-suited as a storage format for processing Earth observation data in the cloud.\n\n\n\nZarr’s hierarchical organization showing stores, groups, arrays, and chunks\n\n\n\n\nWhen to use COG versus Zarr?\nThe table below compares some features of COG and Zarr:\n\n\n\n\n\n\n\n\nFeature\nZarr\nCOG\n\n\n\n\nStructure\nMulti-file chunks\nSingle file\n\n\nAccess\nParallel\nSequential\n\n\nCompression\nDifferently per-chunk\nWhole-file\n\n\nScales\nMulti-scale in single file\nSeparate, pre-generated lower-resolution files\n\n\n\n Based on the structure and capabilities for each format, COGs are used when:\n\nYou work with two-dimensional raster data (like satellite images or elevation models)\nYou need to easily visualise or access specific geographic areas without loading the entire dataset.\nInteroperability with existing GIS software is important, as COG is a widely adopted standard.\n\nOn the other hand, Zarr is more often used when:\n\nYou deal with large, multi-dimensional datasets that might be updated or modified.\nYou are performing complex analyses that involve accessing different parts of the data in parallel.\nAn efficient handling of different resolutions or variables within a single dataset is required.\n\n\n\n\n\n\n\nNote\n\n\n\nZarr vs COG: Want to learn more about the differences and similarities of COG and Zarr? Then we recommend the following blog post by Julia Signell and Jarrett Keifer from Element84, where they discuss “Is Zarr the new COG?”",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "12_about_cloudoptimized_formats.html#conclusion",
    "href": "12_about_cloudoptimized_formats.html#conclusion",
    "title": "About cloud-optimised formats",
    "section": "Conclusion",
    "text": "Conclusion\nIn this section, we explored the fundamental concepts of cloud-optimised geospatial formats. By understanding the core characteristics of these formats and by looking at specific examples like Zarr, you now have a solid foundation for appreciating how these innovations are making geospatial data more accessible, efficient, and powerful in the cloud.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "12_about_cloudoptimized_formats.html#whats-next",
    "href": "12_about_cloudoptimized_formats.html#whats-next",
    "title": "About cloud-optimised formats",
    "section": "What’s next?",
    "text": "What’s next?\nNow that we have an idea of the available cloud-optimised formats for satellite imagery and the reason why we need to optimise traditional formats for the cloud, in the next section, we will explore the EOPF data products that are being re-processed as part of the EOPF Zarr Sample Service.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "13_overview_eopf_datasets.html",
    "href": "13_overview_eopf_datasets.html",
    "title": "Overview of EOPF Zarr Products",
    "section": "",
    "text": "Introduction\nIn the previous section, we introduced the Earth Observation Processing Framework (EOPF) initiative and explored the advantages of cloud-optimised formats like Zarr. Now, it is time to discover which data products will be available and where you can access them.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Overview of EOPF Zarr Products</span>"
    ]
  },
  {
    "objectID": "13_overview_eopf_datasets.html#available-eopf-zarr-products",
    "href": "13_overview_eopf_datasets.html#available-eopf-zarr-products",
    "title": "Overview of EOPF Zarr Products",
    "section": "Available EOPF Zarr products",
    "text": "Available EOPF Zarr products\nRe-engineered EOPF Zarr products are available for exploration via the EOPF Sentinel Zarr Sample Service STAC Catalog. Data from Sentinel-1, Sentinel-2 and Sentinel-3 missions are being reprocessed and made available.\n\n\n\n\n\n\nImportant\n\n\n\nThe re-processing from the Sentinel missions is an ongoing activity as part of the EOPF Sentinel Zarr Sample Service. This page and our tutorials will continuously be updated as soon as new data products are available.\n\n\nAn overview of the datasets that are being re-engineered for different processing levels is given below.\n\nSentinel-1\nSentinel-1 is a radar imaging mission that is composed of a constellation of two polar-orbiting satellites providing continuous all-weather, day and night imagery.\n\n\n\nProduct\nInstrument\nDescription\nAvailable at\n\n\n\n\nLevel-1 GRD\nGround Range Detected\nThe Sentinel-1 Level-1 GDR products consist of focused SAR data that has been detected, multi-looked and projected to ground range using the Earth ellipsoid model WGS84.\nthis link\n\n\nLevel-1 SLC\nSingle Look Complex (\nThe Sentinel-1 Level-1 SLC products consist of focused SAR data, geo-referenced using orbit and attitude data from the satellite, and provided in slant-range geometry.\nthis link\n\n\nLevel-2 OCN\nOcean\nThe Sentinel-1 Level-2 OCN products for wind, wave and currents applications may contain the following geophysical components derived from the SAR data: Ocean Wind field (OWI), Ocean Swell spectra (OSW), Surface Radial Velocity (RVL).\nthis link\n\n\n\n\n\nSentinel-2\nSentinel-2 acquires optical imagery at high spatial resolution (10m to 60m) over land and coastal waters. The mission supports applications such as agricultural monitoring, emergency management, land cover classifications, and water quality.\n\n\n\nProduct\nInstrument\nDescription\nAvailable at\n\n\n\n\nLevel-1C\nMulti-Spectral Instrument\nThe Sentinel-2 Level-1C product is composed of 110x110 km2 tiles (ortho-images in UTM/WGS84 projection). Earth is subdivided into a predefined set of tiles, defined in UTM/WGS84 projection and using a 100 km step.\nthis link\n\n\nLevel-2A\nMulti-Spectral Instrument\nThe Sentinel-2 Level-2A Collection 1 product provides orthorectified Surface Reflectance (Bottom-Of-Atmosphere: BOA), with sub-pixel multispectral and multitemporal registration accuracy.\nthis link\n\n\n\n\n\nSentinel-3\nSentinel-3 is a mission that regularly measures our Earth’s oceans, land, rivers, lakes, ice on land, sea ice, and the atmosphere. Its goal is to keep track of and help us understand how these large parts of our planet change over long periods.\n\nOcean and Land Colour Instrument\n\n\n\nProduct\nProduct\nDescription\nAvailable at\n\n\n\n\nLevel-1 EFR\nEarth Full Resolution\nProvides TOA radiances at full resolution for each pixel in the instrument grid, each view and each OLCI channel, plus annotation data associated with OLCI pixels.\nthis link\n\n\nLevel-1 ERR\nEarth Reduced Resolution\nThe Sentinel-3 OLCI L1 ERR product provides TOA radiances at reduced resolution for each pixel in the instrument grid, each view and each OLCI channel, plus annotation data associated with OLCI pixels.\nthis link\n\n\nLevel-2 LFR\nLand Full Resolution\nThe Sentinel-3 OLCI L2 LFR product provides land and atmospheric geophysical parameters computed for full resolution.\nthis link\n\n\nLevel-2 LRR\nLand Reduced Resolution\nThe Sentinel-3 OLCI L2 LRR product provides land and atmospheric geophysical parameters computed for reduced resolution.\nthis link\n\n\n\n\n\nSea and Land Surface Temperature Radiometer\n\n\n\nProduct\nData\nDescription\nAvailable at\n\n\n\n\nLevel-1 RBT\nRadiance Brightness Temperature\nThe Sentinel-3 SLSTR Level-1B RBT product provides radiances and brightness temperatures for each pixel in a regular image grid for each view and SLSTR channel.\nthis link\n\n\nLevel-2 LST\nLST: Land Surface Temperature\nThe Sentinel-3 SLSTR Level-2 LST product provides land surface temperature.\nthis link",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Overview of EOPF Zarr Products</span>"
    ]
  },
  {
    "objectID": "13_overview_eopf_datasets.html#conclusion",
    "href": "13_overview_eopf_datasets.html#conclusion",
    "title": "Overview of EOPF Zarr Products",
    "section": "Conclusion",
    "text": "Conclusion\nIn this section, we provide an overview of the available Sentinel Missions that will be re-processed and made available as EOPF Zarr products.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Overview of EOPF Zarr Products</span>"
    ]
  },
  {
    "objectID": "13_overview_eopf_datasets.html#whats-next",
    "href": "13_overview_eopf_datasets.html#whats-next",
    "title": "Overview of EOPF Zarr Products",
    "section": "What’s next?",
    "text": "What’s next?\nIn the following chapter, we will dive deep into EOPF Zarr format and understand why it can provide an optimal and efficient application.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Overview of EOPF Zarr Products</span>"
    ]
  },
  {
    "objectID": "21_what_is_zarr.html",
    "href": "21_what_is_zarr.html",
    "title": "Overview of the EOPF Zarr format",
    "section": "",
    "text": "Introduction\nIn our journey to understand cloud-optimised Earth Observation (EO) data, we have frequently mentioned the Zarr format. Now, we will take a closer look and truly understand what Zarr is and why it is such a game-changer for large datasets like those from ESA’s Sentinel missions. This chapter will break down the essential building blocks of Zarr, explaining how it organises data to make it incredibly efficient for cloud-based analysis.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "21_what_is_zarr.html#what-is-zarr",
    "href": "21_what_is_zarr.html#what-is-zarr",
    "title": "Overview of the EOPF Zarr format",
    "section": "What Is Zarr?",
    "text": "What Is Zarr?\nZarr is an open-source, cloud-native protocol for storing multi-dimensional arrays. It is specifically designed to work well with cloud storage and larger-scale computing systems and can be seen as a cloud-native alternative to older formats like HDF5 or NetCDF.\nKey advantage to traditional formats is that the Zarr specification stores large multi-dimensional arrays in chunks, which are smaller pieces of the larger array. Chunks can be accessed individually, or multiple chunks can be read and written in parallel, making data access highly efficient.\nZarr works across different storage systems, including local file systems, cloud object storage, as well as distributed file systems, offering a greater flexibility compared to traditional file formats.\nIn addition, Zarr embeds metadata directly alongside the data. This makes Zarr self-descriptive, as each data array contains descriptive information about itself, such as data type, dimensions or additional attributes.\n\n\n\n\n\n\nNote\n\n\n\nPro tip: Learn more about Zarr in the official Zarr Documentation and the Zarr V3 storage specification",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "21_what_is_zarr.html#components-of-zarr",
    "href": "21_what_is_zarr.html#components-of-zarr",
    "title": "Overview of the EOPF Zarr format",
    "section": "Components of Zarr",
    "text": "Components of Zarr\nZarr is organised in a human-readable, hierarchical structure using simple JSON metadata files and is composed of groups and stores, chunks and metadata:\n\nGroups and Stores\nGroups and stores are concepts that allow Zarr to differentiate between (i) where the data is stored (stores) and (ii) how it is organised (groups). A group is a container for logically organising the data, similar to folders in a file system. A store defines where the data is stored; it can be, e.g. a bucket in the cloud or a directory on a disk.\n\n\nChunks\nZarr divides arrays into smaller, independent pieces (chunks). Through chunking, it is possible to retrieve and process specific areas without loading the complete dataset. Its organisation into chunks is the main reason for Zarr’s high performance. Chunks are saved as binary files inside a /c directory and are further organised through nested folder paths based on their index, e.g. c/0/0/0 for the chunk position [0,0.0].\n\n\nMetadata\nZarr uses descriptive metadata to describe the individual arrays but also the full hierarchy of the dataset. Metadata is stored in zarr.json files and is available on the array, group and store levels. This structured metadata approach makes Zarr datasets self-descriptive and easy to navigate.\nThe graphic below shows an overview of all relevant Zarr components.\n\n\n\nZarr conceptual structure and overview of Zarr components",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "21_what_is_zarr.html#eopf-zarr-structure",
    "href": "21_what_is_zarr.html#eopf-zarr-structure",
    "title": "Overview of the EOPF Zarr format",
    "section": "EOPF Zarr Structure",
    "text": "EOPF Zarr Structure\nThe ESA EOPF defines Zarr as the encoding format for the EOPF Sentinel Zarr Samples Service. The Zarr encoding is well aligned with ESA’s objective of enhancing the accessibility of Sentinel data by modernising the previous .SAFE encoding into a flexible, cloud-native structure. The cloud-native nature of zarr is expected to broaden the applications of the Sentinel data within the geospatial community while maintaining data quality and established algorithms.\nEOPF Zarr products consist of four main groups:\n\n\n\n\n\n\n\nGroup\nDescription\n\n\n\n\nAttributes\nSTAC format metadata for the Zarr element\n\n\nMeasurements\nMain retrieved variables\n\n\nConditions\nMeasurement context (geometric angles, meteorological/instrumental data)\n\n\nQuality\nFlags and quality information for measurement filtering\n\n\n\n\nEOPF Zarr product example: Sentinel-2 L2A\nLet us imagine a Sentinel-2 L2A tile. The tile has dimensions of approximately 10,980 by 10,980 pixels, and includes 12 spectral bands (B01 to B12, excluding B10) at different resolutions, plus additional data arrays such as a Scene Classification Map (SCL) and Atmospheric Optical Thickness (AOT).\nFor efficient handling, the data is divided into 1,024 by 1,024-pixel chunks. This chunking strategy allows for optimal performance when reading specific spatial regions of interest.\nThe figure below gives a graphical overview of how an EOPF Zarr Sentinel-2 L2A product file is organised. \nThe table below provides a more detailed outline of what content is available in the different groups.\n\n\n\n\n\n\n\n\nGroup\n\nContent\n\n\n\n\nAttributes\n\nProcessing history metadata  Chunking configuration  Global metadata (acquisition time, sensing time, etc.)  Product-specific metadata≈\n\n\nMeasurements\n10m resolution (r10)\nB02 (Blue, 490nm)  B03 (Green, 560nm)  B04 (Red, 665nm) B08 (NIR, 842nm)\n\n\n\n20m resolution (r20)\nB05 (Red Edge 1, 705nm) B06 (Red Edge 2, 740nm) B07 (Red Edge 3, 783nm) B8A (Narrow NIR, 865nm) B11 (SWIR 1, 1610nm) B12 (SWIR 2, 2190nm)\n\n\n\n60m resolution (r60)\nB01 (Coastal aerosol, 443nm) &lt;br?B09 (Water vapour, 945nm)\n\n\nConditions\n\nSun angles (zenith, azimuth)  Viewing angles  Mean solar irradiance  Atmospheric parameters such as (i) Aerosol Optical Thickness (AOT), (ii) Water Vapour (WV) and (iii) Cloud and snow probability\n\n\nQuality\n\nScene Classification Layer (SCL)  Quality flags for each band  Detector footprint  Defective pixels masks\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nZarr Deep Dive: Dive deeper into the benefits of Zarr in a blog post by Lindsey Nield from the Earthmover team: Fundamentals: What is Zarr? A Cloud-Native Format for Tensor Data.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "21_what_is_zarr.html#conclusion",
    "href": "21_what_is_zarr.html#conclusion",
    "title": "Overview of the EOPF Zarr format",
    "section": "Conclusion",
    "text": "Conclusion\nThe EOPF Zarr structure allows for efficient access to individual bands or specific spatial regions without loading the entire dataset, making it ideal for large-scale geospatial analysis. It further ensures all relevant metadata is co-located with the data, enhancing data discoverability and usability.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "21_what_is_zarr.html#whats-next",
    "href": "21_what_is_zarr.html#whats-next",
    "title": "Overview of the EOPF Zarr format",
    "section": "What’s next?",
    "text": "What’s next?\nNow that you have a theoretical grasp of the Zarr format, the next section Discover EOPF Zarr - Sentinel-2 L2A will provide a first hands-on experience opening an EOPF Zarr product. We will transition to our first Jupyter Notebook where you will directly interact with a Zarr store.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "22_zarr_structure_S1GRD.html",
    "href": "22_zarr_structure_S1GRD.html",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "",
    "text": "Introduction\n🚀 Launch this notebook in JupyterLab\nIn this section, we will discover how to search and access Sentienl-1 GRD data through EOPF Zarr samples services and how the SAR data is structured inside the groups and subgroups of a .zarr product.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "22_zarr_structure_S1GRD.html#sentinel-1-grd-structure",
    "href": "22_zarr_structure_S1GRD.html#sentinel-1-grd-structure",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "Sentinel-1 GRD structure",
    "text": "Sentinel-1 GRD structure\n\nOpening the Zarr groups and subgroups\nWe start by unwrapping Sentinel-1 GRD .zarr products. You can use the xarray functions open_datatree()and open_dataset() to do this.\nLet’s keep in mind the following: - set engine = \"zarr\", specifically designed for the enoding chosen for the EOPF by ESA. - chunks = {}, to keep the original chunking size defined in the .zarrfile metadata\n\nproductID = \"S1A_IW_GRDH_1SDV_20170508T164830_20170508T164855_016493_01B54C_8604\"\nurl = f\"https://objectstore.eodc.eu:2222/e05ab01a9d56408d82ac32d69a5aae2a:sample-data/tutorial_data/cpm_b716/{productID}.zarr\"\n\ndt = xr.open_datatree(\n    url, \n    engine='zarr', \n    chunks={}\n)\n\nprint_gen_structure(dt, indent=\"\") # So we can visualize the data structure easily\n\nNone\n  S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH\n    conditions\n      antenna_pattern\n      attitude\n      azimuth_fm_rate\n      coordinate_conversion\n      doppler_centroid\n      gcp\n      orbit\n      reference_replica\n      replica\n      terrain_height\n    measurements\n    quality\n      calibration\n      noise\n      noise_range\n  S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VV\n    conditions\n      antenna_pattern\n      attitude\n      azimuth_fm_rate\n      coordinate_conversion\n      doppler_centroid\n      gcp\n      orbit\n      reference_replica\n      replica\n      terrain_height\n    measurements\n    quality\n      calibration\n      noise\n      noise_range\n\n\nAs we can see, Sentinel-1 GRD data is organised in a slightly different way compared to Sentinel-2 and Sentinel 3.\nThere are two main groups with the same subgroups, which correspond to the polarisation information. To identify each polarization you need to check the last two letters of each group.\nFor example: * S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH corresponds to the VH polarization, and * S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VV corresponds to the VV polarization.\nEach polarization group contains the conditions, measurements and quality subgroups. We can list all the groups for the VH polarisation calling .groups.\n\nvh = dt.S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH.groups\nvh\n\n('/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/measurements',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/antenna_pattern',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/attitude',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/azimuth_fm_rate',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/coordinate_conversion',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/doppler_centroid',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/gcp',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/orbit',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/reference_replica',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/replica',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/terrain_height',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/calibration',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/noise',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/noise_range')\n\n\n\n\nBrowsing information inside Zarr\nNow that we know how to access each polarisation group, we can check where some of the relevant information is stored. These variables will help us visualise results.\nFor example, to access the measurements subgroup, we can used the .open_dataset() function. Important is to specify the group we are interested in with the help of the group keyword argument.\n\nmeasurements = xr.open_dataset(\n    url,\n    engine=\"zarr\",\n    group=\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/measurements\",\n    chunks={}\n)\nmeasurements\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 877MB\nDimensions:       (azimuth_time: 16694, ground_range: 26239)\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 134kB 2017-05-08T16:48:30.467...\n  * ground_range  (ground_range) float64 210kB 0.0 10.0 ... 2.624e+05 2.624e+05\n    line          (azimuth_time) int64 134kB dask.array&lt;chunksize=(16694,), meta=np.ndarray&gt;\n    pixel         (ground_range) int64 210kB dask.array&lt;chunksize=(26239,), meta=np.ndarray&gt;\nData variables:\n    grd           (azimuth_time, ground_range) uint16 876MB dask.array&lt;chunksize=(2557, 26239), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 16694ground_range: 26239Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:30.469413574',\n       '2017-05-08T16:48:30.470911148', ..., '2017-05-08T16:48:55.463923851',\n       '2017-05-08T16:48:55.465421425', '2017-05-08T16:48:55.466919000'],\n      shape=(16694,), dtype='datetime64[ns]')ground_range(ground_range)float640.0 10.0 ... 2.624e+05 2.624e+05array([0.0000e+00, 1.0000e+01, 2.0000e+01, ..., 2.6236e+05, 2.6237e+05,\n       2.6238e+05], shape=(26239,))line(azimuth_time)int64dask.array&lt;chunksize=(16694,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n130.42 kiB\n130.42 kiB\n\n\nShape\n(16694,)\n(16694,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         16694 1\n\n\n\n\npixel(ground_range)int64dask.array&lt;chunksize=(26239,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n204.99 kiB\n204.99 kiB\n\n\nShape\n(26239,)\n(26239,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         26239 1\n\n\n\n\nData variables: (1)grd(azimuth_time, ground_range)uint16dask.array&lt;chunksize=(2557, 26239), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :measurement data set for GRD IW\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n835.48 MiB\n127.97 MiB\n\n\nShape\n(16694, 26239)\n(2557, 26239)\n\n\nDask graph\n7 chunks in 2 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n               26239 16694\n\n\n\n\nIndexes: (2)azimuth_timePandasIndexPandasIndex(DatetimeIndex([   '2017-05-08 16:48:30.467916',\n               '2017-05-08 16:48:30.469413574',\n               '2017-05-08 16:48:30.470911148',\n               '2017-05-08 16:48:30.472408722',\n               '2017-05-08 16:48:30.473906296',\n               '2017-05-08 16:48:30.475403870',\n               '2017-05-08 16:48:30.476901444',\n               '2017-05-08 16:48:30.478399018',\n               '2017-05-08 16:48:30.479896592',\n               '2017-05-08 16:48:30.481394166',\n               ...\n               '2017-05-08 16:48:55.453440833',\n               '2017-05-08 16:48:55.454938407',\n               '2017-05-08 16:48:55.456435981',\n               '2017-05-08 16:48:55.457933555',\n               '2017-05-08 16:48:55.459431129',\n               '2017-05-08 16:48:55.460928703',\n               '2017-05-08 16:48:55.462426277',\n               '2017-05-08 16:48:55.463923851',\n               '2017-05-08 16:48:55.465421425',\n                  '2017-05-08 16:48:55.466919'],\n              dtype='datetime64[ns]', name='azimuth_time', length=16694, freq=None))ground_rangePandasIndexPandasIndex(Index([     0.0,     10.0,     20.0,     30.0,     40.0,     50.0,     60.0,\n           70.0,     80.0,     90.0,\n       ...\n       262290.0, 262300.0, 262310.0, 262320.0, 262330.0, 262340.0, 262350.0,\n       262360.0, 262370.0, 262380.0],\n      dtype='float64', name='ground_range', length=26239))Attributes: (0)\n\n\nAntoher way to open a subgroup is converting the information showed on the data tree to a data set information, using .to_dataset() function.\n\nmeasurements2 = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/measurements\"].to_dataset()\nif measurements == measurements2:\n    print(\"Yes, it's the same!\")\n\nmeasurements2\n\nYes, it's the same!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 877MB\nDimensions:       (azimuth_time: 16694, ground_range: 26239)\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 134kB 2017-05-08T16:48:30.467...\n  * ground_range  (ground_range) float64 210kB 0.0 10.0 ... 2.624e+05 2.624e+05\n    line          (azimuth_time) int64 134kB dask.array&lt;chunksize=(16694,), meta=np.ndarray&gt;\n    pixel         (ground_range) int64 210kB dask.array&lt;chunksize=(26239,), meta=np.ndarray&gt;\nData variables:\n    grd           (azimuth_time, ground_range) uint16 876MB dask.array&lt;chunksize=(2557, 26239), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 16694ground_range: 26239Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:30.469413574',\n       '2017-05-08T16:48:30.470911148', ..., '2017-05-08T16:48:55.463923851',\n       '2017-05-08T16:48:55.465421425', '2017-05-08T16:48:55.466919000'],\n      shape=(16694,), dtype='datetime64[ns]')ground_range(ground_range)float640.0 10.0 ... 2.624e+05 2.624e+05array([0.0000e+00, 1.0000e+01, 2.0000e+01, ..., 2.6236e+05, 2.6237e+05,\n       2.6238e+05], shape=(26239,))line(azimuth_time)int64dask.array&lt;chunksize=(16694,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n130.42 kiB\n130.42 kiB\n\n\nShape\n(16694,)\n(16694,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         16694 1\n\n\n\n\npixel(ground_range)int64dask.array&lt;chunksize=(26239,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n204.99 kiB\n204.99 kiB\n\n\nShape\n(26239,)\n(26239,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         26239 1\n\n\n\n\nData variables: (1)grd(azimuth_time, ground_range)uint16dask.array&lt;chunksize=(2557, 26239), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :measurement data set for GRD IW\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n835.48 MiB\n127.97 MiB\n\n\nShape\n(16694, 26239)\n(2557, 26239)\n\n\nDask graph\n7 chunks in 2 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n               26239 16694\n\n\n\n\nIndexes: (2)azimuth_timePandasIndexPandasIndex(DatetimeIndex([   '2017-05-08 16:48:30.467916',\n               '2017-05-08 16:48:30.469413574',\n               '2017-05-08 16:48:30.470911148',\n               '2017-05-08 16:48:30.472408722',\n               '2017-05-08 16:48:30.473906296',\n               '2017-05-08 16:48:30.475403870',\n               '2017-05-08 16:48:30.476901444',\n               '2017-05-08 16:48:30.478399018',\n               '2017-05-08 16:48:30.479896592',\n               '2017-05-08 16:48:30.481394166',\n               ...\n               '2017-05-08 16:48:55.453440833',\n               '2017-05-08 16:48:55.454938407',\n               '2017-05-08 16:48:55.456435981',\n               '2017-05-08 16:48:55.457933555',\n               '2017-05-08 16:48:55.459431129',\n               '2017-05-08 16:48:55.460928703',\n               '2017-05-08 16:48:55.462426277',\n               '2017-05-08 16:48:55.463923851',\n               '2017-05-08 16:48:55.465421425',\n                  '2017-05-08 16:48:55.466919'],\n              dtype='datetime64[ns]', name='azimuth_time', length=16694, freq=None))ground_rangePandasIndexPandasIndex(Index([     0.0,     10.0,     20.0,     30.0,     40.0,     50.0,     60.0,\n           70.0,     80.0,     90.0,\n       ...\n       262290.0, 262300.0, 262310.0, 262320.0, 262330.0, 262340.0, 262350.0,\n       262360.0, 262370.0, 262380.0],\n      dtype='float64', name='ground_range', length=26239))Attributes: (0)",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "22_zarr_structure_S1GRD.html#understanding-and-visualizing-sar-products",
    "href": "22_zarr_structure_S1GRD.html#understanding-and-visualizing-sar-products",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "Understanding and visualizing SAR products",
    "text": "Understanding and visualizing SAR products\nWe can do the same for other subgroups that contain SAR information.\n\nGround Range Detected\nA Ground Range Detected (GRD) product shows us the amplitude of a SAR image. The amplitude reflects the intensity of the radar backscatter, which is the same thing as saying that the amplitude shows how much energy is reflected or absorbed by the surface.\nBecause the grd variable is very heavy for plotting, we need to decimate it. We will use the dataset created before for measurements to access the grd variable.\n\ngrd = measurements.grd\ngrd_decimated = grd.isel(\n    azimuth_time=slice(None, None, 10), ground_range=slice(None, None, 10)\n)\n\n\ngrd_decimated.plot(vmax=200)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSigma Nought and Digital Number\nWe can find the calibration subgroup inside the quality subgroup. It is valuable to take a look at it, as it provides data concerning:\n\nsigma_noughtor backscatter coefficient: It represents the strength of the radar signal backscattered (or reflected back) from a target on Earth’s surface. See it as how much radar energy is reflected back toward the satellite from a unit area on the ground. This information is rescaled to decibels dB in a common workflow.\ndn: A digital number representing the raw intensity data measured by the SAR sensor.\n\n\ncalibration = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/calibration\"].to_dataset()\ncalibration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 292kB\nDimensions:       (azimuth_time: 27, ground_range: 657)\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 216B 2017-05-08T16:48:30.4679...\n  * ground_range  (ground_range) float64 5kB 0.0 6.677e+06 ... 4.38e+09\n    line          (azimuth_time) uint32 108B dask.array&lt;chunksize=(27,), meta=np.ndarray&gt;\n    pixel         (ground_range) uint32 3kB dask.array&lt;chunksize=(657,), meta=np.ndarray&gt;\nData variables:\n    beta_nought   (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;\n    dn            (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;\n    gamma         (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;\n    sigma_nought  (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 27ground_range: 657Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...dimensions :['azimuth_time']dtype :&lt;M8[us]long_name :zero doppler azimuth time at which calibration vector appliesarray(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:31.467916000',\n       '2017-05-08T16:48:32.467916000', '2017-05-08T16:48:33.467916000',\n       '2017-05-08T16:48:34.467916000', '2017-05-08T16:48:35.467916000',\n       '2017-05-08T16:48:36.467916000', '2017-05-08T16:48:37.467916000',\n       '2017-05-08T16:48:38.467916000', '2017-05-08T16:48:39.467916000',\n       '2017-05-08T16:48:40.467916000', '2017-05-08T16:48:41.467916000',\n       '2017-05-08T16:48:42.467916000', '2017-05-08T16:48:43.467916000',\n       '2017-05-08T16:48:44.467916000', '2017-05-08T16:48:45.467916000',\n       '2017-05-08T16:48:46.467916000', '2017-05-08T16:48:47.467916000',\n       '2017-05-08T16:48:48.467916000', '2017-05-08T16:48:49.467916000',\n       '2017-05-08T16:48:50.467916000', '2017-05-08T16:48:51.467916000',\n       '2017-05-08T16:48:52.467916000', '2017-05-08T16:48:53.467916000',\n       '2017-05-08T16:48:54.467916000', '2017-05-08T16:48:55.467916000',\n       '2017-05-08T16:48:56.467916000'], dtype='datetime64[ns]')ground_range(ground_range)float640.0 6.677e+06 ... 4.38e+09dimensions :['ground_range']dtype :&lt;f8array([0.000000e+00, 6.677200e+06, 1.335440e+07, ..., 4.366889e+09,\n       4.373566e+09, 4.379909e+09], shape=(657,))line(azimuth_time)uint32dask.array&lt;chunksize=(27,), meta=np.ndarray&gt;dimensions :['azimuth_time']dtype :&lt;u4long_name :image line at which the calibration vector applies\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n108 B\n108 B\n\n\nShape\n(27,)\n(27,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         27 1\n\n\n\n\npixel(ground_range)uint32dask.array&lt;chunksize=(657,), meta=np.ndarray&gt;dimensions :['ground_range']dtype :&lt;u4long_name :image pixel at which the calibration vector applies (this array contains the count attribute number of integer values (i.e. one value per point in the noise vector); the maximum length of this array is one value for every pixel in an image line, however in general the vector is subsampled)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.57 kiB\n2.57 kiB\n\n\nShape\n(657,)\n(657,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         657 1\n\n\n\n\nData variables: (4)beta_nought(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'beta nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :beta nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\ndn(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'digital number calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :digital number calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\ngamma(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'gamma calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :gamma calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\nsigma_nought(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'sigma nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :sigma nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\nIndexes: (2)azimuth_timePandasIndexPandasIndex(DatetimeIndex(['2017-05-08 16:48:30.467916', '2017-05-08 16:48:31.467916',\n               '2017-05-08 16:48:32.467916', '2017-05-08 16:48:33.467916',\n               '2017-05-08 16:48:34.467916', '2017-05-08 16:48:35.467916',\n               '2017-05-08 16:48:36.467916', '2017-05-08 16:48:37.467916',\n               '2017-05-08 16:48:38.467916', '2017-05-08 16:48:39.467916',\n               '2017-05-08 16:48:40.467916', '2017-05-08 16:48:41.467916',\n               '2017-05-08 16:48:42.467916', '2017-05-08 16:48:43.467916',\n               '2017-05-08 16:48:44.467916', '2017-05-08 16:48:45.467916',\n               '2017-05-08 16:48:46.467916', '2017-05-08 16:48:47.467916',\n               '2017-05-08 16:48:48.467916', '2017-05-08 16:48:49.467916',\n               '2017-05-08 16:48:50.467916', '2017-05-08 16:48:51.467916',\n               '2017-05-08 16:48:52.467916', '2017-05-08 16:48:53.467916',\n               '2017-05-08 16:48:54.467916', '2017-05-08 16:48:55.467916',\n               '2017-05-08 16:48:56.467916'],\n              dtype='datetime64[ns]', name='azimuth_time', freq=None))ground_rangePandasIndexPandasIndex(Index([         0.0,    6677200.0,   13354400.0,   20031600.0,   26708800.0,\n         33386000.0,   40063200.0,   46740400.0,   53417600.0,   60094800.0,\n       ...\n       4320148400.0, 4326825600.0, 4333502800.0, 4340180000.0, 4346857200.0,\n       4353534400.0, 4360211600.0, 4366888800.0, 4373566000.0, 4379909340.0],\n      dtype='float64', name='ground_range', length=657))Attributes: (0)\n\n\n\ncalibration.sigma_nought.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nGCP\nThe gcp subgroup inside conditions is also important. GCP stands for ground control points which are known and precise geolocated references on the Earth’s surface. They can be used later to georeference the GRD image.\n\ngcp = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/gcp\"].to_dataset()\ngcp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 12kB\nDimensions:               (azimuth_time: 10, ground_range: 21)\nCoordinates:\n  * azimuth_time          (azimuth_time) datetime64[ns] 80B 2017-05-08T16:48:...\n  * ground_range          (ground_range) float64 168B 0.0 ... 2.624e+05\n    line                  (azimuth_time) uint32 40B dask.array&lt;chunksize=(10,), meta=np.ndarray&gt;\n    pixel                 (ground_range) uint32 84B dask.array&lt;chunksize=(21,), meta=np.ndarray&gt;\nData variables:\n    azimuth_time_gcp      (azimuth_time, ground_range) datetime64[ns] 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    elevation_angle       (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    height                (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    incidence_angle       (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    latitude              (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    longitude             (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    slant_range_time_gcp  (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 10ground_range: 21Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:33.469054000',\n       '2017-05-08T16:48:36.470192000', '2017-05-08T16:48:39.471330000',\n       '2017-05-08T16:48:42.472469000', '2017-05-08T16:48:45.473607000',\n       '2017-05-08T16:48:48.474745000', '2017-05-08T16:48:51.475884000',\n       '2017-05-08T16:48:54.477022000', '2017-05-08T16:48:55.466919000'],\n      dtype='datetime64[ns]')ground_range(ground_range)float640.0 1.312e+04 ... 2.624e+05array([     0.,  13120.,  26240.,  39360.,  52480.,  65600.,  78720.,  91840.,\n       104960., 118080., 131200., 144320., 157440., 170560., 183680., 196800.,\n       209920., 223040., 236160., 249280., 262380.])line(azimuth_time)uint32dask.array&lt;chunksize=(10,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n40 B\n40 B\n\n\nShape\n(10,)\n(10,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         10 1\n\n\n\n\npixel(ground_range)uint32dask.array&lt;chunksize=(21,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n84 B\n84 B\n\n\nShape\n(21,)\n(21,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         21 1\n\n\n\n\nData variables: (7)azimuth_time_gcp(azimuth_time, ground_range)datetime64[ns]dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\ndatetime64[ns] numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nelevation_angle(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nheight(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nincidence_angle(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nlatitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nlongitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nslant_range_time_gcp(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nIndexes: (2)azimuth_timePandasIndexPandasIndex(DatetimeIndex(['2017-05-08 16:48:30.467916', '2017-05-08 16:48:33.469054',\n               '2017-05-08 16:48:36.470192', '2017-05-08 16:48:39.471330',\n               '2017-05-08 16:48:42.472469', '2017-05-08 16:48:45.473607',\n               '2017-05-08 16:48:48.474745', '2017-05-08 16:48:51.475884',\n               '2017-05-08 16:48:54.477022', '2017-05-08 16:48:55.466919'],\n              dtype='datetime64[ns]', name='azimuth_time', freq=None))ground_rangePandasIndexPandasIndex(Index([     0.0,  13120.0,  26240.0,  39360.0,  52480.0,  65600.0,  78720.0,\n        91840.0, 104960.0, 118080.0, 131200.0, 144320.0, 157440.0, 170560.0,\n       183680.0, 196800.0, 209920.0, 223040.0, 236160.0, 249280.0, 262380.0],\n      dtype='float64', name='ground_range'))Attributes: (0)\n\n\n\ngcp.plot.scatter(x=\"longitude\", y=\"latitude\", hue=\"height\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nOrbit\norbit subgroup inside conditions is a variable that reflects how the orbital trajectory of the sattelite behaved during the flight.\n\norbit = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/orbit\"].to_dataset()\norbit\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 952B\nDimensions:       (azimuth_time: 17, axis: 3)\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 136B 2017-05-08T16:47:24.0541...\nDimensions without coordinates: axis\nData variables:\n    position      (azimuth_time, axis) float64 408B dask.array&lt;chunksize=(17, 3), meta=np.ndarray&gt;\n    velocity      (azimuth_time, axis) float64 408B dask.array&lt;chunksize=(17, 3), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 17axis: 3Coordinates: (1)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:47:24.054129 ... 2...dimensions :['azimuth_time']dtype :&lt;M8[us]long_name :time stamp at which orbit state vectors applyarray(['2017-05-08T16:47:24.054129000', '2017-05-08T16:47:34.054128000',\n       '2017-05-08T16:47:44.054128000', '2017-05-08T16:47:54.054128000',\n       '2017-05-08T16:48:04.054129000', '2017-05-08T16:48:14.054128000',\n       '2017-05-08T16:48:24.054128000', '2017-05-08T16:48:34.054128000',\n       '2017-05-08T16:48:44.054129000', '2017-05-08T16:48:54.054128000',\n       '2017-05-08T16:49:04.054128000', '2017-05-08T16:49:14.054128000',\n       '2017-05-08T16:49:24.054129000', '2017-05-08T16:49:34.054128000',\n       '2017-05-08T16:49:44.054128000', '2017-05-08T16:49:54.054128000',\n       '2017-05-08T16:50:04.054129000'], dtype='datetime64[ns]')Data variables: (2)position(azimuth_time, axis)float64dask.array&lt;chunksize=(17, 3), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time'], 'dimensions': ['azimuth_time', 'axis'], 'dtype': '&lt;f8', 'long_name': 'position vector', 'units': 'm'}dtype :&lt;f8long_name :position vectorunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n408 B\n408 B\n\n\nShape\n(17, 3)\n(17, 3)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 17\n\n\n\n\nvelocity(azimuth_time, axis)float64dask.array&lt;chunksize=(17, 3), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time'], 'dimensions': ['azimuth_time', 'axis'], 'dtype': '&lt;f8', 'long_name': 'velocity vector', 'units': 'm/s'}dtype :&lt;f8long_name :velocity vectorunits :m/s\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n408 B\n408 B\n\n\nShape\n(17, 3)\n(17, 3)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 17\n\n\n\n\nIndexes: (1)azimuth_timePandasIndexPandasIndex(DatetimeIndex(['2017-05-08 16:47:24.054129', '2017-05-08 16:47:34.054128',\n               '2017-05-08 16:47:44.054128', '2017-05-08 16:47:54.054128',\n               '2017-05-08 16:48:04.054129', '2017-05-08 16:48:14.054128',\n               '2017-05-08 16:48:24.054128', '2017-05-08 16:48:34.054128',\n               '2017-05-08 16:48:44.054129', '2017-05-08 16:48:54.054128',\n               '2017-05-08 16:49:04.054128', '2017-05-08 16:49:14.054128',\n               '2017-05-08 16:49:24.054129', '2017-05-08 16:49:34.054128',\n               '2017-05-08 16:49:44.054128', '2017-05-08 16:49:54.054128',\n               '2017-05-08 16:50:04.054129'],\n              dtype='datetime64[ns]', name='azimuth_time', freq=None))Attributes: (0)\n\n\n\n# Extract position components (X, Y, Z coordinates in space)\npos_x = orbit.position[:, 0]\npos_y = orbit.position[:, 1] \npos_z = orbit.position[:, 2]\n\n# Extract velocity components and calculate magnitude\nvel_x = orbit.velocity[:, 0]\nvel_y = orbit.velocity[:, 1]\nvel_z = orbit.velocity[:, 2]\nvelocity_magnitude = np.sqrt(vel_x**2 + vel_y**2 + vel_z**2)\n\n# Convert time to numeric for potential use in point sizing\ntime_numeric = (orbit.azimuth_time - orbit.azimuth_time[0]) / np.timedelta64(1, 's')\n\nfig = plt.figure(figsize=(12, 10))\nax = fig.add_subplot(111, projection='3d')\n\n# 3D scatter plot: X, Y, Z positions colored by velocity magnitude\nscatter = ax.scatter(pos_x, pos_y, pos_z,\n                    c=velocity_magnitude, cmap='plasma', s=60)\n\nax.set_xlabel('Position X (m)')\nax.set_ylabel('Position Y (m)')\nax.set_zlabel('Position Z (m)')\nplt.colorbar(scatter, label='Velocity Magnitude (m/s)')\nax.set_title('Satellite 3D Orbital Trajectory (colored by velocity magnitude)')\n\n# Set a good viewing angle\nax.view_init(elev=10, azim=70)\nplt.show()",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "22_zarr_structure_S1GRD.html#now-it-is-your-turn",
    "href": "22_zarr_structure_S1GRD.html#now-it-is-your-turn",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "💪 Now it is your turn",
    "text": "💪 Now it is your turn\nWith everything we have learnt so far, you are now able to explore Sentinel-1 GRD items and plot their visuals.\n\nTask 1: Reproduce the workflow with your dataset\nDefine an area of interest, search and filter the Sentinel-1 GRD collection for the area where you live. Explore the data tree, and the structure of one of the items.\n\n\nTask 2: Explore other variables\nWe’ve learnt how to look, explore and plot some specific variables inside the .zarr subgroups, but there are many more. Try to explore and understand what are some other variables, like terrain_height our noise_range.\n\n\nTask 3: Play with the image plotting\nThere are many ways to plot an image. Try to play with the variables you are plotting, changing the axis coordinates, maximum values shown or hue values.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "22_zarr_structure_S1GRD.html#conclusion",
    "href": "22_zarr_structure_S1GRD.html#conclusion",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial provided the basics to explore and understand how the Sentinel-1 GRD is structured inside the .zarr format and what to expect to find inside of it.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "22_zarr_structure_S1GRD.html#whats-next",
    "href": "22_zarr_structure_S1GRD.html#whats-next",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "What’s next?",
    "text": "What’s next?\nThe next section shows how to perform basic operations on .zarr Sentinel-1 GRD data, using some of the variables we have discovered in this section.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "23_S1_basic_operations.html",
    "href": "23_S1_basic_operations.html",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "",
    "text": "Introduction\n🚀 Launch this notebook in JupyterLab\nIn this notebook, we will explore additional functionalities that can be applied to Sentinel-1 GRD data. Continuing to access the data through the EOPF Zarr sample services, we will learn how to visualize and carry out basic SAR operations, such as georeferencing and backscatter calibration, using the .zarr format.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "23_S1_basic_operations.html#georeferencing-grd-product",
    "href": "23_S1_basic_operations.html#georeferencing-grd-product",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "Georeferencing GRD product",
    "text": "Georeferencing GRD product\nAs seen in the previous chapter, plotting a Sentinel-1 GRD item displays an image with azimuth_time and ground_rangecoordinates. While these are indeed valid coordinates for Sentinel-1 products, they are only meaningful within the context of image acquisition. \nTo compare them with other geospatial datasets or to examine their actual location on Earth, the data needs to be georeferenced using geographic coordinates, such as latitude and longitude.\n\nOpening the product\nAs usual, the first step is to open the Sentinel-1 GRD product we are going to work with. Using the well know functions open_datatree() and open_dataset(), we open the .zarrproduct.\n\nurl = \"https://objectstore.eodc.eu:2222/e05ab01a9d56408d82ac32d69a5aae2a:sample-data/tutorial_data/cpm_b716/S1A_IW_GRDH_1SDV_20170508T164830_20170508T164855_016493_01B54C_8604.zarr\"\ndt = xr.open_datatree(url, engine='zarr', chunks={})\n\nWe can access .groups and explore what is inside the polarisation group, as it corresponds to the information we will be working with. This is going to help us later opening specific subgroups, such as measurementssubgroup.\n\ndt.S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH.groups\n\n('/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/measurements',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/antenna_pattern',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/attitude',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/azimuth_fm_rate',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/coordinate_conversion',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/doppler_centroid',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/gcp',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/orbit',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/reference_replica',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/replica',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/terrain_height',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/calibration',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/noise',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/noise_range')\n\n\n\nmeasurements = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/measurements\"].to_dataset()\n\nAs the measurements.grdarray is large to be directly plotted, we need to slice it. Applying the .isel()method is useful in this case. We observe that the grd product coordinates azimuth_time and ground_range and not stored in geographical coordinates.\n\ngrd = measurements.grd.isel(\n    azimuth_time=slice(None, None, 10), ground_range=slice(None, None, 10)\n)\ngrd.plot(vmax=300)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSetting the GCP\nIn order to georeference the image with the correspondent latitude and longitude coordinates, we need to access and use the ground control points stored into the .zarr structure.\nThese are well known points that contain both the latitude and longitude coordinates but also the azimuth time and ground range coordinates, making it possible to georeference the grd image.\n\nground_control_point = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/gcp\"].to_dataset()\nground_control_point\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 12kB\nDimensions:               (azimuth_time: 10, ground_range: 21)\nCoordinates:\n  * azimuth_time          (azimuth_time) datetime64[ns] 80B 2017-05-08T16:48:...\n  * ground_range          (ground_range) float64 168B 0.0 ... 2.624e+05\n    line                  (azimuth_time) uint32 40B dask.array&lt;chunksize=(10,), meta=np.ndarray&gt;\n    pixel                 (ground_range) uint32 84B dask.array&lt;chunksize=(21,), meta=np.ndarray&gt;\nData variables:\n    azimuth_time_gcp      (azimuth_time, ground_range) datetime64[ns] 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    elevation_angle       (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    height                (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    incidence_angle       (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    latitude              (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    longitude             (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    slant_range_time_gcp  (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 10ground_range: 21Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:33.469054000',\n       '2017-05-08T16:48:36.470192000', '2017-05-08T16:48:39.471330000',\n       '2017-05-08T16:48:42.472469000', '2017-05-08T16:48:45.473607000',\n       '2017-05-08T16:48:48.474745000', '2017-05-08T16:48:51.475884000',\n       '2017-05-08T16:48:54.477022000', '2017-05-08T16:48:55.466919000'],\n      dtype='datetime64[ns]')ground_range(ground_range)float640.0 1.312e+04 ... 2.624e+05array([     0.,  13120.,  26240.,  39360.,  52480.,  65600.,  78720.,  91840.,\n       104960., 118080., 131200., 144320., 157440., 170560., 183680., 196800.,\n       209920., 223040., 236160., 249280., 262380.])line(azimuth_time)uint32dask.array&lt;chunksize=(10,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n40 B\n40 B\n\n\nShape\n(10,)\n(10,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         10 1\n\n\n\n\npixel(ground_range)uint32dask.array&lt;chunksize=(21,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n84 B\n84 B\n\n\nShape\n(21,)\n(21,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         21 1\n\n\n\n\nData variables: (7)azimuth_time_gcp(azimuth_time, ground_range)datetime64[ns]dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\ndatetime64[ns] numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nelevation_angle(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nheight(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nincidence_angle(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nlatitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nlongitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nslant_range_time_gcp(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nIndexes: (2)azimuth_timePandasIndexPandasIndex(DatetimeIndex(['2017-05-08 16:48:30.467916', '2017-05-08 16:48:33.469054',\n               '2017-05-08 16:48:36.470192', '2017-05-08 16:48:39.471330',\n               '2017-05-08 16:48:42.472469', '2017-05-08 16:48:45.473607',\n               '2017-05-08 16:48:48.474745', '2017-05-08 16:48:51.475884',\n               '2017-05-08 16:48:54.477022', '2017-05-08 16:48:55.466919'],\n              dtype='datetime64[ns]', name='azimuth_time', freq=None))ground_rangePandasIndexPandasIndex(Index([     0.0,  13120.0,  26240.0,  39360.0,  52480.0,  65600.0,  78720.0,\n        91840.0, 104960.0, 118080.0, 131200.0, 144320.0, 157440.0, 170560.0,\n       183680.0, 196800.0, 209920.0, 223040.0, 236160.0, 249280.0, 262380.0],\n      dtype='float64', name='ground_range'))Attributes: (0)\n\n\nSince we previously downsampled the grd product, the coordinate grid (azimuth time and ground range) was processed accordingly. To ensure that the ground control points (latitude and longitude arrays) align properly with this modified grid, we need to apply the same downsample interpolation to them.\nWe can achieve this using the .interp_like() method from xarray. This function interpolates the ground control point data to match the dimensions and coordinates of the grd product, specifically over the current azimuth_time and ground_range.\n\ngcp = ground_control_point.interp_like(grd)\n\n\n\nGeoreferencing the product\nThe final step is to assign the corresponding decimated latitude and longitude values (interpolated from the ground control points) to the grd product. This can be done using the .assign_coords() method.\nAfter assigning the coordinates, the grd dataset will include latitude and longitude as new entries in its coordinate system. When plotting the grd image, you can then specify longitude as the x axis and latitude as the y axis. This will display a properly georeferenced image, allowing it to be compared directly with other spatial datasets.\n\ngrd = grd.assign_coords({\"latitude\": gcp.latitude, \"longitude\": gcp.longitude})\ngrd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'grd' (azimuth_time: 1670, ground_range: 2624)&gt; Size: 9MB\ndask.array&lt;getitem, shape=(1670, 2624), dtype=uint16, chunksize=(256, 2624), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 13kB 2017-05-08T16:48:30.4679...\n  * ground_range  (ground_range) float64 21kB 0.0 100.0 ... 2.622e+05 2.623e+05\n    line          (azimuth_time) float64 13kB dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n    pixel         (ground_range) float64 21kB dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n    latitude      (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\n    longitude     (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\nAttributes:\n    _eopf_attrs:  {'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_r...\n    dtype:        &lt;u2\n    long_name:    measurement data set for GRD IWxarray.DataArray'grd'azimuth_time: 1670ground_range: 2624dask.array&lt;chunksize=(256, 2624), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n8.36 MiB\n1.28 MiB\n\n\nShape\n(1670, 2624)\n(256, 2624)\n\n\nDask graph\n7 chunks in 3 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n               2624 1670\n\n\n\n\nCoordinates: (6)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:30.482891740',\n       '2017-05-08T16:48:30.497867480', ..., '2017-05-08T16:48:55.432474797',\n       '2017-05-08T16:48:55.447450537', '2017-05-08T16:48:55.462426277'],\n      shape=(1670,), dtype='datetime64[ns]')ground_range(ground_range)float640.0 100.0 ... 2.622e+05 2.623e+05array([0.000e+00, 1.000e+02, 2.000e+02, ..., 2.621e+05, 2.622e+05, 2.623e+05],\n      shape=(2624,))line(azimuth_time)float64dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 kiB\n13.05 kiB\n\n\nShape\n(1670,)\n(1670,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         1670 1\n\n\n\n\npixel(ground_range)float64dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n20.50 kiB\n20.50 kiB\n\n\nShape\n(2624,)\n(2624,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1\n\n\n\n\nlatitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nlongitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nIndexes: (2)azimuth_timePandasIndexPandasIndex(DatetimeIndex([   '2017-05-08 16:48:30.467916',\n               '2017-05-08 16:48:30.482891740',\n               '2017-05-08 16:48:30.497867480',\n               '2017-05-08 16:48:30.512843220',\n               '2017-05-08 16:48:30.527818960',\n               '2017-05-08 16:48:30.542794700',\n               '2017-05-08 16:48:30.557770440',\n               '2017-05-08 16:48:30.572746180',\n               '2017-05-08 16:48:30.587721921',\n               '2017-05-08 16:48:30.602697661',\n               ...\n               '2017-05-08 16:48:55.327644616',\n               '2017-05-08 16:48:55.342620356',\n               '2017-05-08 16:48:55.357596097',\n               '2017-05-08 16:48:55.372571837',\n               '2017-05-08 16:48:55.387547577',\n               '2017-05-08 16:48:55.402523317',\n               '2017-05-08 16:48:55.417499057',\n               '2017-05-08 16:48:55.432474797',\n               '2017-05-08 16:48:55.447450537',\n               '2017-05-08 16:48:55.462426277'],\n              dtype='datetime64[ns]', name='azimuth_time', length=1670, freq=None))ground_rangePandasIndexPandasIndex(Index([     0.0,    100.0,    200.0,    300.0,    400.0,    500.0,    600.0,\n          700.0,    800.0,    900.0,\n       ...\n       261400.0, 261500.0, 261600.0, 261700.0, 261800.0, 261900.0, 262000.0,\n       262100.0, 262200.0, 262300.0],\n      dtype='float64', name='ground_range', length=2624))Attributes: (3)_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :measurement data set for GRD IW\n\n\n\ngrd.plot(x=\"longitude\", y=\"latitude\", vmax=300)\nplt.show()",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "23_S1_basic_operations.html#calibrating-amplitude-and-intensity",
    "href": "23_S1_basic_operations.html#calibrating-amplitude-and-intensity",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "Calibrating amplitude and intensity",
    "text": "Calibrating amplitude and intensity\nIn Sentinel-1 GRD products, only the amplitude of the signal is stored, while the phase information is discarded, unlike Single Look Complex (SLC) products, which preserve both. Therefore, it is essential to calibrate the amplitude using the raw Digital Number (DN) values and the additional metadata provided in the calibration subgroup.\nThe relationship between intensity and amplitude is given by: \\[\n\\text{Intensity} = |\\text{Amplitude}|^2\n\\]\n\ncalibration = dt[\"/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/calibration\"].to_dataset()\n\n\nAmplitude\nSince amplitude represents the strength of the radar signal that is backscattered and received by the sensor, amplitude calibration is essential to convert raw digital numbers (DN) into physically meaningful amplitude values. This calibration involves applying the beta_nought coefficient, which represents the normalized radar backscatter without accounting for the incidence angle.\nThe result is a calibrated amplitude image, where pixel values approximate the physical radar backscatter amplitude. To perform this calibration, we use the .calibrate_amplitude() method from the xarray_sentinel library.\n\ncalibrate_amplitude = xarray_sentinel.calibrate_amplitude(\n    grd, calibration.beta_nought\n)\ncalibrate_amplitude.plot(vmax=0.8)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nIntensity\nSimilar to the amplitude calibration process, intensity calibration can be performed using the .calibrate_intensity() method from the xarray_sentinel library. This method converts the raw Digital Number (DN) values into radar backscatter intensity. The output is a physically meaningful radar brightness image, usually represented in decibels (dB).\n\ncalibrate_intensity = xarray_sentinel.calibrate_intensity(\n    grd, calibration.beta_nought, as_db=True\n)\ncalibrate_intensity.plot(vmin=-20, vmax=5)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nGeoreferenced intensity\nBecause we georeferenced the grd image in the measurements.grd dataset before performing the calibrations, both calibrated_amplitude and calibrated_intensity now include not only azimuth_time and ground_range as coordinates but also latitude and longitude.\nThis allows us to create the same calibrated intensity plot as before, but now georeferenced using geographic coordinates (longitude on the x axis and latitude on the y axis).\n\ncalibrate_intensity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (azimuth_time: 1670, ground_range: 2624)&gt; Size: 18MB\ndask.array&lt;maximum, shape=(1670, 2624), dtype=float32, chunksize=(256, 2624), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 13kB 2017-05-08T16:48:30.4679...\n  * ground_range  (ground_range) float64 21kB 0.0 100.0 ... 2.622e+05 2.623e+05\n    line          (azimuth_time) float64 13kB dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n    pixel         (ground_range) float64 21kB dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n    latitude      (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\n    longitude     (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\nAttributes:\n    _eopf_attrs:  {'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_r...\n    dtype:        &lt;u2\n    long_name:    beta nought calibration vector (this array contains the cou...\n    units:        dBxarray.DataArrayazimuth_time: 1670ground_range: 2624dask.array&lt;chunksize=(256, 2624), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.72 MiB\n2.56 MiB\n\n\nShape\n(1670, 2624)\n(256, 2624)\n\n\nDask graph\n7 chunks in 14 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n               2624 1670\n\n\n\n\nCoordinates: (6)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:30.482891740',\n       '2017-05-08T16:48:30.497867480', ..., '2017-05-08T16:48:55.432474797',\n       '2017-05-08T16:48:55.447450537', '2017-05-08T16:48:55.462426277'],\n      shape=(1670,), dtype='datetime64[ns]')ground_range(ground_range)float640.0 100.0 ... 2.622e+05 2.623e+05array([0.000e+00, 1.000e+02, 2.000e+02, ..., 2.621e+05, 2.622e+05, 2.623e+05],\n      shape=(2624,))line(azimuth_time)float64dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 kiB\n13.05 kiB\n\n\nShape\n(1670,)\n(1670,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         1670 1\n\n\n\n\npixel(ground_range)float64dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n20.50 kiB\n20.50 kiB\n\n\nShape\n(2624,)\n(2624,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1\n\n\n\n\nlatitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nlongitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nIndexes: (2)azimuth_timePandasIndexPandasIndex(DatetimeIndex([   '2017-05-08 16:48:30.467916',\n               '2017-05-08 16:48:30.482891740',\n               '2017-05-08 16:48:30.497867480',\n               '2017-05-08 16:48:30.512843220',\n               '2017-05-08 16:48:30.527818960',\n               '2017-05-08 16:48:30.542794700',\n               '2017-05-08 16:48:30.557770440',\n               '2017-05-08 16:48:30.572746180',\n               '2017-05-08 16:48:30.587721921',\n               '2017-05-08 16:48:30.602697661',\n               ...\n               '2017-05-08 16:48:55.327644616',\n               '2017-05-08 16:48:55.342620356',\n               '2017-05-08 16:48:55.357596097',\n               '2017-05-08 16:48:55.372571837',\n               '2017-05-08 16:48:55.387547577',\n               '2017-05-08 16:48:55.402523317',\n               '2017-05-08 16:48:55.417499057',\n               '2017-05-08 16:48:55.432474797',\n               '2017-05-08 16:48:55.447450537',\n               '2017-05-08 16:48:55.462426277'],\n              dtype='datetime64[ns]', name='azimuth_time', length=1670, freq=None))ground_rangePandasIndexPandasIndex(Index([     0.0,    100.0,    200.0,    300.0,    400.0,    500.0,    600.0,\n          700.0,    800.0,    900.0,\n       ...\n       261400.0, 261500.0, 261600.0, 261700.0, 261800.0, 261900.0, 262000.0,\n       262100.0, 262200.0, 262300.0],\n      dtype='float64', name='ground_range', length=2624))Attributes: (4)_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :beta nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)units :dB\n\n\n\ncalibrate_intensity.plot(x=\"longitude\", y=\"latitude\", vmin=-20, vmax=5)\nplt.show()",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "23_S1_basic_operations.html#now-it-is-your-turn",
    "href": "23_S1_basic_operations.html#now-it-is-your-turn",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "💪 Now it is your turn",
    "text": "💪 Now it is your turn\nThe following exercises will help you to better understand the calibration processes studied before.\n\nTask 1: Reproduce this workflow on a different area\nUsing what you’ve already learned about the STAC catalog and Sentinel-1 GRD products, repeat this workflow with a different Sentinel-1 GRD scene. Try to use a scene from the area where you live, just like you did on the previous chapter. Then, observe how the geographical coordinates of the georeferenced image differ between products.\n\n\nTask 2: Explore intensity and amplitude values\nDiscover what happens when the maximum and minimum value on x and y axis change. These will create new results, especially when considering the plots on amplitude and intensity calibration.\n\n\nTask 3: Compare the intensity values with other datsets\nTry to calibrate and plot some grd products from other datasets and see how the intensity values change over different areas, textures and surfaces.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "23_S1_basic_operations.html#conclusion",
    "href": "23_S1_basic_operations.html#conclusion",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "Conclusion",
    "text": "Conclusion\nDuring this tutorial we’ve learnt how to compute amplitude and intensity calibration on Sentinel-1 GRD data and how to georeference measurements.grd variable into geographical coordinates. For most of the operations we used xarray_sentinel methods.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "23_S1_basic_operations.html#whats-next",
    "href": "23_S1_basic_operations.html#whats-next",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "What’s next?",
    "text": "What’s next?\nNow that you have been introduced to the .zarr encoding format, learned its core concepts, and understood the basics of how to explore it, you are prepared for the next step. In the following chapter we will introduce you to the Sentinel-2 L-2A .zarr structure. As we go along, we are more and more transition from theory to practice, providing you with hands-on tutorials working with EOPF .zarr products.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "24_zarr_struct_S2L2A.html",
    "href": "24_zarr_struct_S2L2A.html",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "",
    "text": "Introduction\n🚀 Launch this notebook in JupyterLab\nThis tutorial introduces you to the structure of an EOPF Zarr product sample for Sentinel-2 L2A data. We will demonstrate how to access and open a .zarr product sample with xarray, how to visualise the zarr encoding structure, explore embedded information, and retrieve relevant metadata for further processing.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "24_zarr_struct_S2L2A.html#open-a-zarr-store",
    "href": "24_zarr_struct_S2L2A.html#open-a-zarr-store",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "Open a Zarr Store",
    "text": "Open a Zarr Store\nIn a first step, we use the open_datatree() function from the xarray library to open a .zarr store as a DataTree. Inside, we need to define the following key word arguments:\n\nfilename_or_obj: path leading to a .zarr store\nengine: zarr, as it is the encoding structure of the file.\nchunks: loads the data with Dask using the engine’s preferred chunk size. If {} the loaded chunks are identical to the format’s original chunk size.\n\nThe final print of the DataTree object is commented out, as the display can be quite extensive, showing the entire content within the .zarr. An alternative is to apply a helper function that only displays the higher-level structure as shown in the next code cell.\n\nurl = 'https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:202506-s02msil2a/10/products/cpm_v256/S2C_MSIL2A_20250610T103641_N0511_R008_T32UMD_20250610T132001.zarr'\n\ns2l2a_zarr_sample= xr.open_datatree(\n    url, \n    engine=\"zarr\")  # storage format\n\nIf we apply the helper function print_gen_structure on the root of the DataTree object, we will get a listing of the tree-like structure of the object. We can see all Zarr groups, such as measurements, quality and conditions, their sub-groups and content.\n\nprint(\"Zarr Sentinel 2 L2A Structure\")\nprint_gen_structure(s2l2a_zarr_sample.root) \nprint(\"-\" * 30)\n\nZarr Sentinel 2 L2A Structure\nNone\n  conditions\n    geometry\n    mask\n      detector_footprint\n        r10m\n        r20m\n        r60m\n      l1c_classification\n        r60m\n      l2a_classification\n        r20m\n        r60m\n    meteorology\n      cams\n      ecmwf\n  measurements\n    reflectance\n      r10m\n      r20m\n      r60m\n  quality\n    atmosphere\n      r10m\n      r20m\n      r60m\n    l2a_quicklook\n      r10m\n      r20m\n      r60m\n    mask\n      r10m\n      r20m\n      r60m\n    probability\n      r20m\n------------------------------",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "24_zarr_struct_S2L2A.html#extract-information-from-zarr-groups",
    "href": "24_zarr_struct_S2L2A.html#extract-information-from-zarr-groups",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "Extract information from Zarr groups",
    "text": "Extract information from Zarr groups\nIn the next step, we can explore the content of individually contained .zarr groups. By specifying the name of the group and subgroup and adding it into square brackets, we can extract the content of the relevant group. Let us for example, extract the content of the subgroup reflectance under measurements.\nAs a result, it is visible that there are three subgroups of the parent node measurements/reflectance: r10, r20 and r60, which are the DataArrays with the three different resolutions of the Sentinel-2 L2A data.\nThe xarray.DataTree structure allows the exploration of additional group-related metadata and information. For example, we can find the chunksize of each array and the coordinates.\n\n# # Retrieving the reflectance groups:\n# s2l2a_zarr_sample[\"measurements/reflectance\"] # Run it yourself for an inteactive overview",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "24_zarr_struct_S2L2A.html#extract-zarr-metadata-on-different-levels",
    "href": "24_zarr_struct_S2L2A.html#extract-zarr-metadata-on-different-levels",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "Extract Zarr metadata on different levels",
    "text": "Extract Zarr metadata on different levels\nThrough s2l2a_zarr_sample.attrs[] we are able to visualise both the stac_discovery and other_metadata included in the zarr store.   For the properties inside stac_discovery for example we can get the parameters included:\n\n# STAC metadata style:\nprint(list(s2l2a_zarr_sample.attrs[\"stac_discovery\"].keys()))\n\n['assets', 'bbox', 'geometry', 'id', 'links', 'properties', 'stac_extensions', 'stac_version', 'type']\n\n\nWe are also, able to retrieve specific information by diving deep into the stac_discovery metadata, such as:\n\nprint('Date of Item Creation: ', s2l2a_zarr_sample.attrs['stac_discovery']['properties']['created'])\nprint('Item Bounding Box    : ', s2l2a_zarr_sample.attrs['stac_discovery']['bbox'])\nprint('Item ESPG            : ', s2l2a_zarr_sample.attrs['stac_discovery']['properties']['proj:epsg'])\nprint('Sentinel Platform    : ', s2l2a_zarr_sample.attrs['stac_discovery']['properties']['platform'])\nprint('Item Processing Level: ', s2l2a_zarr_sample.attrs['stac_discovery']['properties']['processing:level'])\n\nDate of Item Creation:  2025-06-10T13:20:01+00:00\nItem Bounding Box    :  [9.146276872400831, 52.25344953517325, 7.500940412097549, 53.24953673463324]\nItem ESPG            :  32632\nSentinel Platform    :  sentinel-2c\nItem Processing Level:  L2A\n\n\nAnd from other_metadata, we are able to retrieve the information specific to the instrument variables.\n\n# Complementing metadata:\nprint(list(s2l2a_zarr_sample.attrs[\"other_metadata\"].keys()))\n\n['AOT_retrieval_model', 'L0_ancillary_data_quality', 'L0_ephemeris_data_quality', 'NUC_table_ID', 'SWIR_rearrangement_flag', 'UTM_zone_identification', 'absolute_location_assessment_from_AOCS', 'band_description', 'declared_accuracy_of_AOT_model', 'declared_accuracy_of_radiative_transfer_model', 'declared_accuracy_of_water_vapour_model', 'electronic_crosstalk_correction_flag', 'eopf_category', 'geometric_refinement', 'history', 'horizontal_CRS_code', 'horizontal_CRS_name', 'mean_sensing_time', 'mean_sun_azimuth_angle_in_deg_for_all_bands_all_detectors', 'mean_sun_zenith_angle_in_deg_for_all_bands_all_detectors', 'mean_value_of_aerosol_optical_thickness', 'mean_value_of_total_water_vapour_content', 'meteo', 'multispectral_registration_assessment', 'onboard_compression_flag', 'onboard_equalization_flag', 'optical_crosstalk_correction_flag', 'ozone_source', 'ozone_value', 'percentage_of_degraded_MSI_data', 'planimetric_stability_assessment_from_AOCS', 'product_quality_status', 'reflectance_correction_factor_from_the_Sun-Earth_distance_variation_computed_using_the_acquisition_date', 'spectral_band_of_reference']",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "24_zarr_struct_S2L2A.html#now-it-is-your-turn",
    "href": "24_zarr_struct_S2L2A.html#now-it-is-your-turn",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "💪 Now it is your turn",
    "text": "💪 Now it is your turn\nAs we are able to retrieve several items from the EOPF Sentinel Zarr Samples Service STAC API, let us try the following:\n\nTask\nGo to the Sentinel-2 Level-2A collection and:\n\nChoose an item of interest.\nReplicate the workflow and explore the item’s metadata. When was it retrieved?\nWhat are the dimensions?\nWhat is the detailed location of the item?",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "24_zarr_struct_S2L2A.html#conclusion",
    "href": "24_zarr_struct_S2L2A.html#conclusion",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial provides an initial understanding of the .zarr structure for a Sentinel-2 L2A product sample. By using the xarray library, we can effectively navigate and inspect the different components within the .zarr format, including its metadata and array organisation.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "24_zarr_struct_S2L2A.html#whats-next",
    "href": "24_zarr_struct_S2L2A.html#whats-next",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "What’s next?",
    "text": "What’s next?\nNow that you have been introduced to the .zarr encoding format, learned its core concepts, and understood the basics of how to explore it, you are prepared for the next step. In the following chapter we will introduce you to the Sentinel-3 SLSTR Level-2 LST .zarr structure. As we go along, we are more and more transition from theory to practice, providing you with hands-on tutorials working with EOPF .zarr products.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "25_zarr_struct_S3.html",
    "href": "25_zarr_struct_S3.html",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "",
    "text": "Introduction\n🚀 Launch this notebook in JupyterLab\nThis tutorial introduces you to the structure of an EOPF Zarr product sample for Sentinel-3 SLSTR Level-2 Land Surface Temperature data. We will demonstrate how to access and open a .zarr product sample with xarray, how to visualise the zarr encoding structure, explore embedded information, and retrieve relevant metadata for further processing.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "25_zarr_struct_S3.html#open-the-zarr-store",
    "href": "25_zarr_struct_S3.html#open-the-zarr-store",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "Open the zarr Store",
    "text": "Open the zarr Store\nIn a first step, we use the open_datatree() function from the xarray library to open a .zarr store as a DataTree. Inside, we need to define the following key word arguments:\n\nfilename_or_obj: path leading to a .zarr store\nengine: zarr, as it is the encoding structure of the file.\nchunks: loads the data with Dask using the engine’s preferred chunk size. If {} the loaded chunks are identical to the format’s original chunk size.\n\nThe final print of the DataTree object is commented out, as the display can be quite extensive, showing the entire content within the .zarr. An alternative is to apply a helper function that only displays the higher-level structure as shown in the next code cell.\n\n# Defining the storage path:\nurl = 'https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:202505-s03slslst/29/products/cpm_v256/S3B_SL_2_LST____20250529T093001_20250529T093301_20250623T143718_0179_107_093_2340_ESA_O_NT_004.zarr'\n\n# Opening the .zarr's data tree:\ns3_lst_zarr_sample= xr.open_datatree(\n    url, engine=\"zarr\")\n\nIf we apply the helper function print_gen_structure on the root of the DataTree object, we will get a listing of the tree-like structure of the object. We can see all Zarr groups, such as measurements, quality and conditions, their sub-groups and content.\n\nprint(\"Zarr Sentinel-3 SLSTR Level-2 LST\")\nprint_gen_structure(s3_lst_zarr_sample.root) \nprint(' ', 'attributes', list(s3_lst_zarr_sample.attrs.keys()))\n\nZarr Sentinel-3 SLSTR Level-2 LST\nNone\n  conditions\n    auxiliary\n      orphan\n    geometry\n    meteorology\n    processing\n      orphan\n    time\n  measurements\n    orphan\n  quality\n    orphan\n  attributes ['other_metadata', 'stac_discovery']",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "25_zarr_struct_S3.html#extract-information-from-zarr-groups",
    "href": "25_zarr_struct_S3.html#extract-information-from-zarr-groups",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "Extract information from Zarr groups",
    "text": "Extract information from Zarr groups\nIn the next step, we can explore the content of individual .zarr groups. By specifying the name of the group and subgroup and adding it into square brackets, we can extract the content of the relevant group. Let us extract the content of the subgroup orphan under measurements.\nAs a result, it is visible that Land Surface Temperature is stored as lst, with its respective coordinates in both x and y (EPSG: Respective to UTM zone) and latitude and longitude (EPSG:4326).\nThe xarray.DataTree structure allows the exploration of additional group-related metadata and information. For example, we can find the chunksize of each array and the coordinates.\n\n# Retrieving the group where LST is stored:\ns3_lst_zarr_sample[\"measurements/orphan\"] # Run it yourself for an inteactive overview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DatasetView&gt; Size: 8MB\nDimensions:    (rows: 1200, columns: 1500, orphan_pixels: 187)\nCoordinates:\n    latitude   (rows, orphan_pixels) float64 2MB ...\n    longitude  (rows, orphan_pixels) float64 2MB ...\n    x          (rows, orphan_pixels) float64 2MB ...\n    y          (rows, orphan_pixels) float64 2MB ...\nDimensions without coordinates: rows, columns, orphan_pixels\nData variables:\n    lst        (rows, orphan_pixels) float32 898kB ...xarray.DataTreeGroups: (0)Dimensions:rows: 1200columns: 1500orphan_pixels: 187Coordinates: (4)latitude(rows, orphan_pixels)float64...long_name :Latitude of detector FOV centre on the earth's surfaceshort_name :latitude_orphanstandard_name :latitudeunits :degrees_northvalid_max :90000000valid_min :-90000000[224400 values with dtype=float64]longitude(rows, orphan_pixels)float64...long_name :Longitude of detector FOV centre on the earth's surfaceshort_name :longitude_orphanstandard_name :longitudeunits :degrees_eastvalid_max :180000000valid_min :-180000000[224400 values with dtype=float64]x(rows, orphan_pixels)float64...long_name :Geolocated x (across track) coordinate of detector FOV centreshort_name :x_orphanunits :mvalid_max :1000000valid_min :-500000[224400 values with dtype=float64]y(rows, orphan_pixels)float64...long_name :Geolocated y (along track) coordinate of detector FOV centreshort_name :y_orphanunits :mvalid_max :100000000valid_min :-1000000[224400 values with dtype=float64]Inherited coordinates: (0)Data variables: (1)lst(rows, orphan_pixels)float32..._eopf_attrs :{'coordinates': ['x', 'y', 'latitude', 'longitude'], 'dimensions': ['rows', 'orphan_pixels'], 'long_name': 'ungridded land surface temperature', 'standard_name': 'surface_temperature', 'units': 'K'}long_name :ungridded land surface temperatureshort_name :lst_orphanstandard_name :surface_temperatureunits :Kvalid_max :32767valid_min :-32767[224400 values with dtype=float32]Attributes: (0)",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "25_zarr_struct_S3.html#extract-zarr-metadata-on-different-levels",
    "href": "25_zarr_struct_S3.html#extract-zarr-metadata-on-different-levels",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "Extract Zarr metadata on different levels",
    "text": "Extract Zarr metadata on different levels\nThrough s3a_lst_zarr_sample.attrs[] we are able to visualise both the stac_discovery and other_metadata included in the zarr store.   For the properties inside stac_discovery for example we can get the parameters included:\n\n# STAC metadata style:\nprint(list(s3_lst_zarr_sample.attrs[\"stac_discovery\"].keys()))\n\n['assets', 'bbox', 'collection', 'geometry', 'id', 'links', 'properties', 'stac_extensions', 'stac_version', 'type']\n\n\nWe are also, able to retrieve specific information by diving deep into the stac_discovery metadata, such as:\n\nprint('Date of Item Creation: ', s3_lst_zarr_sample.attrs['stac_discovery']['properties']['created'])\nprint('Item Bounding Box    : ', s3_lst_zarr_sample.attrs['stac_discovery']['bbox'])\nprint('Sentinel Platform    : ', s3_lst_zarr_sample.attrs['stac_discovery']['properties']['platform'])\nprint('Item Processing Level: ', s3_lst_zarr_sample.attrs['stac_discovery']['properties']['processing:level'])\nprint('Class ID.            : ', s3_lst_zarr_sample.attrs['stac_discovery']['properties']['product:timeliness_category'])\n\nDate of Item Creation:  2025-06-23T14:37:18+00:00\nItem Bounding Box    :  [20.6857, 28.6806, 1.68414, 41.9899]\nSentinel Platform    :  sentinel-3b\nItem Processing Level:  L2\nClass ID.            :  NT\n\n\nAnd from other_metadata, we are able to retrieve the information specific to the instrument variables.\n\n# Complementing metadata:\nprint(list(s3_lst_zarr_sample.attrs[\"other_metadata\"].keys()))\n\n['L0_offset_between_scan_index_and_ISP_scan_count_in', 'absolute_pass_number', 'band_description', 'cycle_number', 'data_information', 'eopf_category', 'ephemeris', 'history', 'i_nadir_first_acquired_pixel', 'i_oblique_first_acquired_pixel', 'in_scan_period_in_microseconds', 'meteo', 'phase_identifier', 'pixel_time_sampling_interval_along_scan_i_in_microseconds', 'product_unit', 'relative_pass_number', 'single_meteofield_synoptic_time_UTC_hours']\n\n\nSome relevant information included:\n\nprint('i Nadir First Pixel   :', s3_lst_zarr_sample.attrs['other_metadata']['i_nadir_first_acquired_pixel'])\nprint('i Oblique First Pixel :',s3_lst_zarr_sample.attrs['other_metadata']['i_oblique_first_acquired_pixel'])\nprint('Phase Identifier      :',s3_lst_zarr_sample.attrs['other_metadata']['phase_identifier'])\n\ni Nadir First Pixel   : 2469\ni Oblique First Pixel : 1124\nPhase Identifier      : 4",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "25_zarr_struct_S3.html#now-it-is-your-turn",
    "href": "25_zarr_struct_S3.html#now-it-is-your-turn",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "💪 Now it is your turn",
    "text": "💪 Now it is your turn\nAs we are able to retrieve several items from the EOPF Sentinel Zarr Samples Service STAC API, let us try the following:\n\nTask\nGo to the Sentinel-3 SLSTR Level-2 LST collection and:\n\nChoose an item of interest.\nReplicate the workflow and explore the item’s metadata. When was it retrieved?\nWhat are the dimensions of the LST group?\nWhat are the values of the bbox (location) of the item?",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "25_zarr_struct_S3.html#conclusion",
    "href": "25_zarr_struct_S3.html#conclusion",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial provides an initial understanding of the .zarr structure for a Sentinel-3 SLSTR Level-2 LST product sample. By using the xarray library, we can effectively navigate and inspect the different components within the .zarr format, including its metadata and array organisation.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "25_zarr_struct_S3.html#whats-next",
    "href": "25_zarr_struct_S3.html#whats-next",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "What’s next?",
    "text": "What’s next?\nNow that you have been introduced to the .zarr encoding format, learned its core concepts, and understood the basics of how to explore it, you are prepared for the next step. In the following chapter we will dive into the chunks concept for zarr and why is it relevant for EO.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "31_zarr_chunking_intro.html",
    "href": "31_zarr_chunking_intro.html",
    "title": "An introduction to Chunking",
    "section": "",
    "text": "Introduction\nChunking is the secret sauce that makes .zarr format incredibly efficient for Earth Observation data processing. Understanding chunking allows us to transform the way we work with massive satellite datasets. This means somehow, turning memory-crushing, slow operations into fast, scalable analysis workflows.\nThis introduction takes you from chunking basics to advanced optimisation strategies specifically tailored for EOPF (Earth Observation Processing Framework) datasets.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "31_zarr_chunking_intro.html#what-are-chunks",
    "href": "31_zarr_chunking_intro.html#what-are-chunks",
    "title": "An introduction to Chunking",
    "section": "What are chunks?",
    "text": "What are chunks?\nZarr revolutionises how we store and access large multidimensional arrays by breaking them into smaller, manageable pieces called chunks. Think of chunks as rectangular tiles that together compose a complete dataset, but with a significant difference: they allow us to access and process each of the components independently.\n\nA chunk is .zarr’s fundamental storage unit: an equally-sized block of array data that gets compressed and stored as a separate object.\n\nFor example, when we have a massive 10,000 × 10,000 pixel satellite image, zarr might divide it into 100 chunks of 1,000 × 1,000 pixels each. Then, each chunk becomes a separate compressed file or object in our storage system.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "31_zarr_chunking_intro.html#why-chunks-transform-performance",
    "href": "31_zarr_chunking_intro.html#why-chunks-transform-performance",
    "title": "An introduction to Chunking",
    "section": "Why chunks transform performance",
    "text": "Why chunks transform performance\nChunking addresses three critical performance bottlenecks in large-scale data processing:\n\nMemory efficiency: Instead of loading entire datasets into RAM, chunks allow us to only load the specific data we need. This allows us to work with datasets larger than our available memory, like a 100 GB satellite time series. It can be processed on a machine with just 8 GB of RAM.\nI/O optimisation: Chunking minimises data transfer, as it only reads relevant sections. When we need data from one geographic region, zarr loads only those chunks covering that area. For cloud storage, this translates to fewer, more efficient HTTP requests instead of downloading massive files. It also reduces data latency.\nParallel processing: Different chunks can be processed simultaneously by multiple CPU cores or distributed workers. This transforms compute-intensive operations from sequential bottlenecks into scalable parallel workflows.\n\n\nChunk sizes for performance\nChunk size selection fundamentally determines the performance characteristics over our dataset. The choice of chunking size affects memory usage, I/O efficiency, parallel scaling, and network transfer costs. That is the reason, it is one of the most critical optimisation decisions in Earth Observation data processing.\nThere are three levels of chunk sizes:\n\n\n\n\n\n\n\n\nChunk size\nAdvantages\nDisadvantages\n\n\n\n\nSmall chunks (1-10 MB)\nFine-grained access patterns, minimise memory usage per operation, and enable high granularity for parallel processing.\nHigh metadata overhead, requires numerous network requests for cloud storage, and creates complex task graphs.\n\n\nMedium chunks (10-100 MB)\nOptimal balance for most Earth Observation applications, works well with cloud storage byte-range requests, enables efficient compression ratios, and supports good parallelisation without excessive overhead.\nDepend exclusively on the dataset size, making it difficult to replicate\n\n\nLarge chunks (&gt;100 MB)\nMaximises compression efficiency, minimises network request count, and dramatically reduces metadata overhead for massive datasets.\nIncreases memory requirements, may transfer unnecessary data for sparse access patterns, and can limit parallel efficiency.\n\n\n\n\n\nA simple chunking example\nWe can explore chunking with a simple 2D raster dataset example. Imagine we have a 6×6 grid representing temperature data. This simple dataset can be chunked in different ways, each with its own advantages and tradeoffs:\n\n\n\nChunking sizes over the same dataset\n\n\n\n\n\n\n\n\n\n\n1×1 Chunks\n2×2 Chunks\n3×3 Chunks\n\n\n\n\n- Each pixel is a chunk- Maximum flexibility but high overhead- 36 total chunks- Good for random access to individual cells- Poor for operations that need adjacent cells\n- Each chunk contains 4 cells- Balanced approach- 9 total chunks- Good for small region operations- Reasonable compression potential\n- Each chunk contains 9 cells- More efficient storage- 4 total chunks- Better compression- Less granular access\n\n\n\n\n\nCompression of chunks\nCompression interactions significantly affect optimal chunk sizes. Larger chunks generally achieve better compression ratios, which are important for spectral data with high spatial correlation. However, compressed chunks must be fully decompressed when accessed, potentially increasing memory usage beyond the nominal chunk size. Balance compression benefits with memory requirements for your specific workflows.\nThe available compression algorithms for zarr are the following.\n\n\n\n\n\n\n\nCompression Algorithm\nDescription\n\n\n\n\nBlosc with LZ4\nProvides excellent speed with moderate compression ratios, making it ideal for interactive applications where decompression speed matters more than maximum storage efficiency. LZ4 typically achieves 2-5× compression on satellite data with very fast decompression.\n\n\nZstandard (Zstd)\nOffers an exceptional balance between compression ratio and speed, making it the preferred choice for many Earth Observation applications. Zstd often achieves 3-8× compression on spectral data while maintaining reasonable decompression performance.\n\n\nSpecialised algorithms\nSuch as JPEG 2000, provide excellent compression for certain data types but may not integrate well with general-purpose array processing workflows. Consider format compatibility when selecting compression approaches.\n\n\n\nCompression effectiveness depends heavily on network characteristics:\n\nBandwidth-limited environments benefit tremendously from aggressive compression since decompression is typically faster than network transfer. In these cases, higher compression ratios directly translate to reduced analysis time.\nHigh-bandwidth, low-latency networks may make compression counterproductive if decompression becomes the bottleneck. Profile your specific network environment to determine optimal compression levels.\nCloud storage considerations include both transfer costs and access speed. Compressed data reduces both storage costs and transfer times, but increases CPU usage. For most Earth Observation applications, compression provides net benefits.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "31_zarr_chunking_intro.html#why-is-it-relevant-to-chunk-eo-data",
    "href": "31_zarr_chunking_intro.html#why-is-it-relevant-to-chunk-eo-data",
    "title": "An introduction to Chunking",
    "section": "Why is it relevant to chunk EO data",
    "text": "Why is it relevant to chunk EO data\nEarth Observation datasets exhibit characteristics that significantly influence optimal chunking strategies. We can consider their structure, sizes, processing workflows and spatial and temporal resolutions.\n\nMulti-dimensional complexity: Satellite data combines spatial dimensions (often tens of thousands of pixels per side), spectral dimensions (multiple wavelength bands), and temporal dimensions (time series spanning years or decades). Each dimension has different access patterns and computational requirements.\nScale characteristics: Modern satellites generate massive data volumes. The Sentinel-2 mission alone, for example, produces approximately 1.6 TB per orbit, with the full archive exceeding 25 petabytes and growing rapidly. Processing workflows must handle this scale efficiently.\nAccess patterns: Unlike general-purpose arrays, EO data has predictable access patterns. Spatial analysis typically accesses rectangular geographic regions. Spectral analysis needs multiple bands for the same locations. Time series analysis follows individual pixels or regions through time.\nHeterogeneous resolutions: Many instruments capture data at multiple spatial resolutions simultaneously. Some missions require coordinated chunking strategies that balance storage efficiency with processing convenience.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "31_zarr_chunking_intro.html#now-it-is-your-turn",
    "href": "31_zarr_chunking_intro.html#now-it-is-your-turn",
    "title": "An introduction to Chunking",
    "section": "💪 Now it is your turn",
    "text": "💪 Now it is your turn\nFor a deep dive into the chunking theory and further technical resources, we recommend going through the following resources:\n\nChunks and Chunkability: Tyranny of the Chunk\nChoosing Good Chunk Sizes in Dask - Dask team’s chunking recommendations\nOptimization Practices - Chunking - ESIP Fed’s chunking best practices\nOptimal Chunking Strategies for Cloud-based Storage - Research on geospatial chunking",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "31_zarr_chunking_intro.html#conclusion",
    "href": "31_zarr_chunking_intro.html#conclusion",
    "title": "An introduction to Chunking",
    "section": "Conclusion",
    "text": "Conclusion\nThis chapter introduced the logic behind data chunking and its relevance for scalable analysis workflows. We explored how optimising the size, compression and considering the transfer of these chunks significantly enhances the efficiency of data retrieval.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "31_zarr_chunking_intro.html#whats-next",
    "href": "31_zarr_chunking_intro.html#whats-next",
    "title": "An introduction to Chunking",
    "section": "What’s next?",
    "text": "What’s next?\nIn the following section , we will go over optimal chunking strategies and relevant considerations when aiming for making Earth Observation workflows more efficient.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "32_zarr_chunking_strat.html",
    "href": "32_zarr_chunking_strat.html",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "",
    "text": "Introduction\nIn the previous section, we explored the fundamentals of Zarr chunking and its significance for Earth Observation data. Now we will delve into the specifications and challenges that address geospatial multi-resolution datasets.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "32_zarr_chunking_strat.html#what-we-will-learn",
    "href": "32_zarr_chunking_strat.html#what-we-will-learn",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "What we will learn",
    "text": "What we will learn\n\n🚀 The workflow for choosing an optimal chunking strategy for EO\n🔎 The EOPF Sentinel’s missions chunking structure\n💪 How to choose the optimal chunk size depending on a data application",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "32_zarr_chunking_strat.html#fundamental-optimisation-principles",
    "href": "32_zarr_chunking_strat.html#fundamental-optimisation-principles",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Fundamental optimisation principles",
    "text": "Fundamental optimisation principles\nSuccessful Zarr chunking for Earth Observation applications requires balancing multiple competing factors while understanding the specific characteristics of the data, access patterns, and computational environment.\n\nPrinciple 1: Start with proven defaults and optimize based on measured performance. Most defaults consider 100MB target chunk sizes for initial implementations, employ consolidated metadata, and enable compression with balanced algorithms. These defaults work well for most Earth Observation applications and provide a solid foundation for further optimisation.\nPrinciple 2: Measure actual performance rather than relying on theoretical expectations. Use monitoring tools to track memory usage, I/O throughput, task duration, and parallel efficiency. The Dask dashboard provides excellent visualisation of performance characteristics, including task streams, memory usage patterns, and worker utilisation.\nPrinciple 3: Align with access patterns by designing chunks around how your applications actually use the data. Spatial analysis applications should use large spatial chunks. Time series analysis should favour temporal chunking. Visualisation applications should align with tile boundaries and zoom levels.\nPrinciple 4: Consider computational overhead relative to chunk processing time. Each chunk access involves ~1ms of scheduling overhead, so chunks should require significantly more computation time to maintain efficiency. For most Earth Observation algorithms, this translates to a minimum 10-100ms processing per chunk, supporting the 10-100 MB chunk size recommendation.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "32_zarr_chunking_strat.html#implementation-workflow",
    "href": "32_zarr_chunking_strat.html#implementation-workflow",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Implementation workflow",
    "text": "Implementation workflow\nFollow a systematic approach to chunking optimisation:\n\nAssess your data and analysis objectives: total size, dimensionality optimisation, access patterns, and storage environment\nIdentify computational requirements: available memory, processing power, and network bandwidth\nStart with conservative defaults: 100MB chunks, consolidated metadata, moderate compression\nImplement monitoring: track key performance metrics throughout your workflow\nOptimise iteratively: adjust chunk sizes and strategies based on measured performance\nValidate improvements: ensure optimizations actually improve real-world performance",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "32_zarr_chunking_strat.html#default-eopf-chunking-structure",
    "href": "32_zarr_chunking_strat.html#default-eopf-chunking-structure",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Default EOPF Chunking Structure",
    "text": "Default EOPF Chunking Structure\n\nSentinel-1 Level-1 GRD\nThe grd variable in the EOPF Sentinel-1 GRD dataset structure is particularly relevant for chunking. It is contained inside each of the VH and VV groups measurements respectiveley storing the variable as multidimensional arrays.\n\nChunking organisation\nEach contained grd array is chunked along both:\n\nazimuth_time : 7 - 9 chunks (depends on the item).\nground_range : No chunking along the dimension.\n\n\n\n\nSentinel-2\nThe measurements group in the EOPF Sentinel-2 dataset structure is particularly relevant for chunking. It contains the reflectance group, which is further divided into three different spatial resolutions: 10m, 20m, and 60m, respectively, containing spectral bands (e.g., B02, B03, B04) stored as multidimensional arrays.\n\nChunking organisation of Level-2A:\n\nr10m: Variables like B02, B03, and B04 are chunked into 1830×1830 pixel blocks, optimizing for high-resolution spatial analysis.\nr20m: Variables such as B05, B06, and B07 use 915×915 pixel chunks, balancing storage efficiency and processing convenience for medium-resolution data.\nr60m: Variables like B01 and B09 are chunked into 305×305 pixel blocks, aligning with the coarser resolution requirements of atmospheric correction bands.\n\nThis chunking ensures the three resolutions are chunked into 36 pieces (6×6) chunks each. This strategy provides efficient access and processing across different resolutions, tailored to the specific structure of Sentinel-2 data.\n\n\n\nSentinel-3 (LST)\nThis section is under development 🛰️\n\nChunking organisation of SLSTR\nThis section is under development 🛰️",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "32_zarr_chunking_strat.html#use-case-specific-optimisation",
    "href": "32_zarr_chunking_strat.html#use-case-specific-optimisation",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Use case-specific optimisation",
    "text": "Use case-specific optimisation\nDifferent Earth Observation applications have dramatically different optimal chunking strategies:\n\nScientific analysis workflows should align chunks with computational patterns.\nFor time series analysis, the recommendation relies on large spatial chunks but small temporal chunks to optimize pixel-by-pixel processing.\nFor spatial analysis algorithms, reverse this pattern with large temporal chunks and smaller spatial chunks. Consider algorithm-specific requirements.\nVisualisation and display applications benefit from tile-aligned chunking that matches web mapping standards. The usual sizes are 256×256 or 512×512 pixel chunks aligned with standard tile pyramid levels. This enables efficient zoom and pan operations by loading only visible tiles. Progressive loading with smaller chunks (1-10 MB) creates responsive user interfaces.\nTiling and map service workflows require careful alignment with tile boundaries and zoom levels. Web Mercator tiling works best with chunks that are multiples of 256×256 pixels. Consider different chunk sizes for different zoom levels to optimise both overview generation and detail rendering.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "32_zarr_chunking_strat.html#do-not-forget-to-consider",
    "href": "32_zarr_chunking_strat.html#do-not-forget-to-consider",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Do not forget to consider…",
    "text": "Do not forget to consider…\n\nOver-chunking: too many small chunks create scheduler overhead and poor parallel efficiency. Symptoms include excessive white space in task streams and slow computation startup. Solution: increase chunk sizes to reduce task graph complexity.\nUnder-chunking: too few large chunks causes memory exhaustion and poor parallelisation. Watch for memory spilling indicators and idle workers. Solution: decrease chunk sizes to better utilise available parallelism.\nIgnoring storage alignment: creates poor I/O performance when Zarr chunks don’t align with underlying storage chunk boundaries. Always ensure your chunk dimensions are multiples of storage format chunks.\nFrequent rechunking: Some operations are expensive and should be avoided through careful initial chunk selection. Plan your chunking strategy around your complete workflow rather than optimising individual operations in isolation.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "32_zarr_chunking_strat.html#conclusion",
    "href": "32_zarr_chunking_strat.html#conclusion",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Conclusion",
    "text": "Conclusion\nThis chapter presented the specific workflow for setting up an optimal data chunking strategy for EO applications. We reviewed the default chunking strategies available in the EOPF STAC Catalog for Sentinel missions as well as discussing key considerations required based on the type of application and use case. We also presented some considerations that, if overlooked, could lead to a loss of optimisation.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "32_zarr_chunking_strat.html#whats-next",
    "href": "32_zarr_chunking_strat.html#whats-next",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "What’s next?",
    "text": "What’s next?\nNow that you have been introduced to the .zarr chunking reasoning and strategies, you are prepared for the next step. In the following chapter we will introduce you to STAC and the EOPF Zarr STAC Catalog. As we go along, we are more and more transitioning from theory to practice, providing you with hands-on tutorials working with EOPF .zarr products.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "41_stac_intro.html",
    "href": "41_stac_intro.html",
    "title": "Introduction to STAC",
    "section": "",
    "text": "Introduction\nWelcome to the chapter on EOPF and STAC. In the following section, we will introduce you to the Spatio-Temporal Asset Catalog (STAC). We will explain its fundamental principles and, most importantly, we will explore its structure and core components. Understanding the fundamentals of STAC is key in order to be able to effectively discover and access data from STAC catalogs.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "41_stac_intro.html#about-stac",
    "href": "41_stac_intro.html#about-stac",
    "title": "Introduction to STAC",
    "section": "About STAC",
    "text": "About STAC\nThe Spatio-Temporal Asset Catalog (STAC) is a standardised way to catalog and describe geospatial (raster) data. STAC makes it easier to discover, access, and work with geospatial data, in particular satellite data, as it provides a common language for describing spatial and temporal characteristics of the data. This common language improves interoperability between different data providers and software tools.\nThe main goal of STAC is to allow data providers to share their data easily, making it universal for users to understand the where, when, how, and what of the collected data.\nSTAC uses JSON (JavaScript Object Notation) to structure the metadata of geo-referenced datasets. JSON makes it machine-readable. Through its design, STAC is simple and extensible in its design as it is based on a network of JSON files.\nSTAC has evolved into a well-recognised community standard. The key benefit supporting its wide adoption is that one can use the same code and API to access data from different data repositories.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "41_stac_intro.html#the-stac-ecosystem",
    "href": "41_stac_intro.html#the-stac-ecosystem",
    "title": "Introduction to STAC",
    "section": "The STAC ecosystem",
    "text": "The STAC ecosystem\nSTAC has evolved into a vast ecosystem offering various resources and tools for accessing, managing, and building STAC catalogs. Below is a non-exclusive list of tools and plug-ins that will help to explore the STAC ecosystem:\n\n\n\nCategory\nTool/Plugin\nDescription\nLanguage\n\n\n\n\nSTAC Tools\nSTAC Browser\nA user-friendly web interface for visually exploring and interacting with various STAC catalogs.\nWeb interface\n\n\n\nSTAC Server\nA reference implementation for serving STAC catalogs and collections.\nPython\n\n\nSTAC libraries and plug-ins\nSTAC Validator\nA tool for programmatically validating STAC Catalogs, Collections, and Items to ensure compliance with the STAC specification.\nPython\n\n\n\nPySTAC\nA Python library for reading, writing, and validating STAC objects, facilitating the creation and manipulation of STAC data.\nPython\n\n\n\npystac-client\nA Python library that provides a convenient and powerful interface for searching and accessing STAC data from STAC API servers.\nPython\n\n\n\nrstac\nAn R package that provides functionalities for interacting with STAC APIs and working with STAC objects within the R environment.\nR\n\n\n\nSTAC.jl\nA Julia package designed for working with STAC, enabling users to interact with STAC catalogs and process geospatial data.\nJulia\n\n\n\nSTACCube.jl\nA Julia package that facilitates the creation and management of STAC-compliant data cubes from various geospatial datasets.\nJulia",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "41_stac_intro.html#stac-components",
    "href": "41_stac_intro.html#stac-components",
    "title": "Introduction to STAC",
    "section": "STAC components",
    "text": "STAC components\nNow, let us start exploring the structure of STAC. STAC consists of four main components: (i) Catalog, (ii) Collection, (iii) Item and (iv) Asset. See the figure below for the principal organisation of the STAC components.\n\n\n\nSTAC structure\n\n\n\nLet us now explore in more detail the individual components:\n\nCatalog\nA Catalog serves as the initial entry point of a STAC. A catalog is a very simple construct; it simply provides links to Collections or Items. The closest analogue is a folder on your computer. A Catalog can be a folder for Items, but it can also be a folder for Collections or other Catalogs. When searching for specific data, you first establish a connection to a valid STAC catalog.\n\n\nCollection\nCollections are containers that support the grouping of Items. The Collection entity shares most fields with the Catalog entity but has several additional fields, such as license, extent (spatial and temporal), providers, keywords and summaries. Every Item in a Collection links back to its Collection. Collection is often used to provide additional structure in a STAC catalog.\n\n\n\n\n\n\nNote\n\n\n\nBut when to use a Collection versus a Catalog? A Collection generally consists of a set of assets that share the same properties and share higher-level metadata. For example, data from the same satellite sensor or constellation would typically be in one Collection.\nCatalogs, in turn, are used to split overly large Collections into groups and to group collections into a catalog of Collections (e.g. as an entry point for navigation to several Collections).\nIt is recommended to use Collections for what you want users to find and Catalogs for structuring and grouping Collections.\n\n\n\n\nItem\nAn Item is the fundamental element of STAC and typically represents a single scene at one place and time. It is a GeoJSON supplemented with additional metadata, which serves as an index to Assets.\n\n\n\nItem entity\n\n\n\n\nAsset\nAn Asset is the smallest element inside a STAC and represents the individual data file that is linked in a STAC Item.\n\n\nAnalogy: Organising a drinks menu as a STAC\nTo better understand the relation of STAC components, let us imagine a Drinks menu as a STAC. How would you structure Drinks as a STAC?\nLet us start with the Drinks category itself. The menu is analogous to a STAC Catalog, as it serves as the top-level entry point, providing an overview of all beverages available.\nWithin this Drinks catalog, we can create different categories, such as hot and cold beverages, and caffeinated and non-caffeinated drinks. These categories represent Collections in STAC. For our analogy, let us say the menu is divided into two main collections:\n\nCaffeinated Drinks Collection: This section groups all beverages that contain caffeine.\nNon-Caffeinated Drinks Collection: This section groups all beverages that do not contain caffeine.\n\nEach of these collections contains specific drinks, which are analogous to STAC Items. Drink Items could be, e.g. Juices or Milks. Both represent again a group of specific juices and milks, which are analogous to Assets in STAC. For the Drink Items defined, theirAssets` might include:\n\n\n\nItem\nAssets\n\n\n\n\nMilks\nOat Milk  Regular Milk\n\n\nJuices\nApple Juice  Organge Juice  …\n\n\n\nThe STAC structure allows us to easily navigate a vast amount of data, just as a well-organised menu helps a customer quickly find their desired drink.\n\n\n\nDrinks Menu as a STAC analogy",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "41_stac_intro.html#conclusion",
    "href": "41_stac_intro.html#conclusion",
    "title": "Introduction to STAC",
    "section": "Conclusion",
    "text": "Conclusion\nIn this section, you got an introduction to the Spatio-Temporal Asset Catalog (STAC) and learned what STAC is and explored the main components of a STAC. Understanding the distinction between Catalog, Collection, Items and Assets is important to effectively navigating through STAC APIs.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "41_stac_intro.html#whats-next",
    "href": "41_stac_intro.html#whats-next",
    "title": "Introduction to STAC",
    "section": "What’s next?",
    "text": "What’s next?\nIn the following section, we will explore the web interface of the EOPF Sentinel Zarr Samples Service STAC Catalog.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "42_eopf_stac_zarr_tutorial.html",
    "href": "42_eopf_stac_zarr_tutorial.html",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "",
    "text": "Introduction\nThis section introduces you to the EOPF Sentinel Zarr Samples Service STAC Catalog, which offers access to the re-engineered Sentinel-1, Sentinel-2 and Sentinel-3 data products. We will guide you through its web interface, inspect the various levels of STAC components, and demonstrate how to access the underlying Sentinel Zarr data.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "42_eopf_stac_zarr_tutorial.html#our-starting-point",
    "href": "42_eopf_stac_zarr_tutorial.html#our-starting-point",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "Our Starting Point",
    "text": "Our Starting Point\nThe first step is to access the main homepage of the EOPF Sentinel Zarr Samples Service STAC Catalog. The landing page offers you a comprehensive overview of the available data collections. This serves as our initial entry point into the catalog.\n\n\n\nHome page\n\n\nThree main areas can be identified: (i) the API and URL section, (ii) Search bar and (iii) Collections Display. \nAs outlined in detail in the book section The EOPF Available Datasets, the catalog displays the 11 distinct collections available from the Sentinel-1, Sentinel-2, and Sentinel-3 missions.  The user interface provides an intuitive way to browse through all of these collections. It is possible to filter them by specific criteria or select them manually, allowing precise control over the displayed data.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "42_eopf_stac_zarr_tutorial.html#exploring-sentinel-collections",
    "href": "42_eopf_stac_zarr_tutorial.html#exploring-sentinel-collections",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "Exploring Sentinel Collections",
    "text": "Exploring Sentinel Collections\nLet us now select one of the 11 Collection available, e.g. let us select the Sentinel 2-Level-2A collection. Once you have selected the Collection, you will be directed to the interface of a specific Collection.\n\n\n\nWeb interface of the Sentinel-2 Level-2A Collection of the EOPF Sentinel Zarr Samples Service STAC Catalog\n\n\nThe interface can be divided into five principal sections:\n\nDescription: The name and a brief introduction to the available collection. This includes crucial details such as the temporal extent (the period over which the data was acquired)\nAPI and URL: for further application.\nSpatial Extent: The geographical area of the displayed items is shown on the map.\nAvailable Items: On the right-hand side of the page, a list of links for the items contained within the collection corresponds to the selected collection.\nCollection Metadata: A general overview of the Collection’s metadata, its providers, instruments, and the corresponding DOIs for research.\nMetadata: Specific information about the bands and instruments, such as backscatter or reflectance information.\nAssets in Items: The Assets structure is available for the Items available in the Collection.\n\n\nFiltering Collections\nAny selected Collection (in this case Sentinel-2 Level-2A) allows us to filter the items of our interest by temporal and spatial extent. We can access this tab by clicking on Show Filters on the right side under the Items section.\n\n\n\nOverview of interface that opens when clicking in Show Filters\n\n\nThe interface that opens allows us to select on the calendar a specific period we are interested in. This is particularly useful when we are interested in a temporal analysis. Let us search over the available items captured between May 1st and May 5th 2024.\n\n\n\nFiltering over time\n\n\nAdditionally, we can select a location we are interested in by checking the Filter by spatial extent box. This allows us to refine our search over an area of interest. Once you tick the box, a map activates and allows us to draw a bounding box that we can drag and drop. Let us select Europe as our area of interest.\n\n\n\nFiltering over spatial extent\n\n\nOnce we select the desired period and area via the filters, we can sort the items that match our search by ID, Date and Time, or select the number of resulting items we are interested in per page. In this case, we select 2, so the overview is digestible. Then, we click Submit.\n\n\n\nResulting Items\n\n\nUnder the window, we can now see that two items appear. For example: S2B_MSIL2A_20250504T131719_N0511_R124_T27VVL_20250504T165710\nWe can select any of the resulting items, and this will enable us to access an Item inside the Collection.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "42_eopf_stac_zarr_tutorial.html#exploring-items",
    "href": "42_eopf_stac_zarr_tutorial.html#exploring-items",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "Exploring Items",
    "text": "Exploring Items\nWhen a specific Item sparks our interest, clicking on it will bring us to a detailed overview page for that selected Item. \nThis Item interface is composed of:\n\nDescription: The name of the Item. Depending on the mission and collection it belongs to, the composition of the name changes.\nSpatial Extent: The geographical footprint of the selected Item is shown on the map.\nCollection Metadata: A general overview of the Collection’s metadata, its providers, instruments, resolution, grid and the corresponding DOIs for research.\nAPI and URL: Allows the entry point for further retrieval of the individual assets.\nAssets menu: lists all the Assets that are part of the selected Item.\n\n\n\n\nThe item selected inside the Sentinel-2 Level-2A Collection\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAt this level of the STAC structure, we are already diving deep into the STAC levels, and have explored the Catalog, Collection and Item components described in the Introduction to STAC section.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "42_eopf_stac_zarr_tutorial.html#assets",
    "href": "42_eopf_stac_zarr_tutorial.html#assets",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "Assets",
    "text": "Assets\nInside the selected Item, we will get an overview of the available Assets that belong to the Item. By expanding the dropdown menu for any Asset of interest, you can access its specific metadata and, most importantly, the actual data. \n\n\n\nOverview of the web interface on Asset level\n\n\nIn the case of the Sentinel-2 Level-2A collection, each asset corresponds to one of the 13 spectral bands available. The array information provides details about the structure and content of the data, hinting at the actual values contained within the asset. It also contains the chunking grid specification and all the crucial metadata necessary to structure and process the data through a wide range of geospatial methodologies.\n\nAccessing Assets\nFor direct data access of Assetz and therefore the actual data, there are two options provided via the web interface: * Download: It is possible to download only one asset separately in .zarr format by clicking the Download option associated with an Asset, and * Copy URL: We can also retrieve the unique URL of the specified Asset, which allows us to directly integrate the link into programmatic workflows, without the need to download the Asset. We can get it by simply clicking on the Copy URL option under the Asset of our interest.\n\n\n\nData access options via the web interface",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "42_eopf_stac_zarr_tutorial.html#now-it-is-your-turn",
    "href": "42_eopf_stac_zarr_tutorial.html#now-it-is-your-turn",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "💪 Now it is your turn",
    "text": "💪 Now it is your turn\nYour task now is to explore the web interface of the EOPF Sentinel Zarr Samples Service STAC Catalog on your own and explore other Collections than the one we showcased.\n\nTask 1: Discover Sentinel-1 GRD Data\nNavigate to the Sentinel-1 Level-1 GRD Collection.\n\nHow many items can you find for the most recent two years available in the catalogue?\nTry filtering by different periods and observe how the results change. How many items are available for September 2023?\n\n\n\nTask 2: Mapping Your Interests\nExplore the interactive map within the Sentinel-1 Level-1 GRD and the Sentinel-2 Level-2A collections.\n\nCan you identify and list the names of at least three distinct geographical areas where a significant number of items are available? (Hint: Look for clusters of the displayed items!)\n\n\n\nTask 3: Unpacking an Asset\nSelect an item from any collection that looks interesting to you. Click on it to view its details. Then, expand one of the assets.\n\nWhat kind of array information is provided?\nWho is the data provider?\nHow would this information be useful if you were to process this data?",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "42_eopf_stac_zarr_tutorial.html#conclusion",
    "href": "42_eopf_stac_zarr_tutorial.html#conclusion",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "Conclusion",
    "text": "Conclusion\nThis section walked you through the web interface of the EOPF Sentinel Zarr Samples Service STAC Catalog. We have demonstrated how to navigate its interface, from the initial overview of the available Collections to the detailed inspection of specific Items and Assets. By understanding the structure and components of a STAC catalog, we are able to efficiently access re-engineered EOPF Zarr assets.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "42_eopf_stac_zarr_tutorial.html#whats-next",
    "href": "42_eopf_stac_zarr_tutorial.html#whats-next",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "What’s next?",
    "text": "What’s next?\nIn the next section, we will explore how to programmatically connect to and search through the EOPF Sentinel Zarr Samples Service STAC API with the help of the pystac and the pystac-client Python libraries.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "43_eopf_stac_connection.html",
    "href": "43_eopf_stac_connection.html",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "",
    "text": "Introduction\n🚀 Launch this notebook in JupyterLab\nIn this section, we will dive into the programmatic access of EOPF Zarr Collections available in the EOPF Sentinel Zarr Sample Service STAC Catalog. We will introduce Python libraries that enable us to effectively access and search through STAC catalogs.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "43_eopf_stac_connection.html#establish-a-connection-to-the-eopf-zarr-stac-catalog",
    "href": "43_eopf_stac_connection.html#establish-a-connection-to-the-eopf-zarr-stac-catalog",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "Establish a connection to the EOPF Zarr STAC Catalog",
    "text": "Establish a connection to the EOPF Zarr STAC Catalog\nOur first step is to establish a connection to the EOPF Sentinel Zarr Sample Service STAC Catalog. For this, you need the Catalog’s base URL, which you can find on the web interface under the API & URL tab. By clicking on 🔗Source, you will get the address of the STAC metadata file - which is available here.\n\n\n\nEOPF API url for connection\n\n\nCopy paste the URL: https://stac.core.eopf.eodc.eu/.\nWith the Client.open() function, we can create the access to the starting point of the Catalog by providing the specific url. If the connection was successful, you will see the description of the STAC catalog and additional information.\n\neopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\" #root starting point\neopf_catalog = Client.open(url=eopf_stac_api_root_endpoint) # calls the selected url\neopf_catalog\n\n\n\n\n\n\n    &lt;Client id=eopf-sample-service-stac-api&gt;\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Catalog\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"eopf-sample-service-stac-api\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"STAC catalog of the EOPF Sentinel Zarr Samples Service\"\n        \n    \n                \n            \n                \n                    \n        links[] 20 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"conformance\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/conformance\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC/OGC conformance classes implemented by this server\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"POST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-2A\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lfr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l2-ocn\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-2 OCN\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l2-lst\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-2 LST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-grd\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 GRD\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l1c\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-1C\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-slc\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 SLC\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l1-rbt\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-1 RBT\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-efr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 EFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-err\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 ERR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lrr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LRR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \n        \n            \n                \n        \n            rel\n            \"service-desc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/vnd.oai.openapi+json;version=3.0\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service description\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \n        \n            \n                \n        \n            rel\n            \"service-doc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api.html\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service documentation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        conformsTo[] 21 items\n        \n            \n        \n            \n                \n        \n            0\n            \"http://www.opengis.net/spec/cql2/1.0/conf/basic-cql2\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-text\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/geojson\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/oas30\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/features-filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \"https://api.stacspec.org/v1.0.0-rc.2/item-search#filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \"https://api.stacspec.org/v1.0.0/collections\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \"https://api.stacspec.org/v1.0.0/collections/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \"https://api.stacspec.org/v1.0.0/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \"https://api.stacspec.org/v1.0.0/item-search\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \"https://api.stacspec.org/v1.0.0/item-search#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \"https://api.stacspec.org/v1.0.0/item-search#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \"https://api.stacspec.org/v1.0.0/item-search#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"\n        \n    \n                \n            \n        \n    \n\n\n\n\nCongratulations. We successfully connected to the EOPF Zarr STAC Catalog, and we can now start exploring its content.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "43_eopf_stac_connection.html#explore-available-collections",
    "href": "43_eopf_stac_connection.html#explore-available-collections",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "Explore available collections",
    "text": "Explore available collections\nOnce a connection established, the next logical step is to get an overview of all the collections the STAC catalog offers. We can do this with the function get_all_collections(). The result is a list, which we can loop through to print the relevant collection IDs.\nPlease note: Since the EOPF Zarr STAC Catalog is still in active development, we need to test whether a collection is valid, otherwise you might get an error message. The code below is testing for validity and for one collection, it throws an error.\nYou see, that so far, we can browse through 10 available collections\n\ntry:\n    for collection in eopf_catalog.get_all_collections():\n        print(collection.id)\n\nexcept Exception:\n    print(\n        \"* [https://github.com/EOPF-Sample-Service/eopf-stac/issues/18 appears to not be resolved]\"\n    )\n\nsentinel-2-l2a\nsentinel-3-olci-l2-lfr\nsentinel-1-l2-ocn\nsentinel-3-slstr-l2-lst\nsentinel-1-l1-grd\nsentinel-2-l1c\nsentinel-1-l1-slc\nsentinel-3-slstr-l1-rbt\nsentinel-3-olci-l1-efr\nsentinel-3-olci-l1-err\nsentinel-3-olci-l2-lrr\n\n\nIn a next step, we can select one collection and retrieve certain metadata that allow us to get more information about the selected collection, such as keywords, the ID and useful links for resources.\n\nS2l2a_coll = eopf_catalog.get_collection('sentinel-2-l2a')\nprint('Keywords:        ',S2l2a_coll.keywords)\nprint('Catalog ID:      ',S2l2a_coll.id)\nprint('Available Links: ',S2l2a_coll.links)\n\nKeywords:         ['Copernicus', 'Sentinel', 'EU', 'ESA', 'Satellite', 'Global', 'Imagery', 'Reflectance']\nCatalog ID:       sentinel-2-l2a\nAvailable Links:  [&lt;Link rel=items target=https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a/items&gt;, &lt;Link rel=parent target=https://stac.core.eopf.eodc.eu/&gt;, &lt;Link rel=root target=&lt;Client id=eopf-sample-service-stac-api&gt;&gt;, &lt;Link rel=self target=https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a&gt;, &lt;Link rel=license target=https://sentinel.esa.int/documents/247904/690755/Sentinel_Data_Legal_Notice&gt;, &lt;Link rel=cite-as target=https://doi.org/10.5270/S2_-znk9xsj&gt;, &lt;Link rel=http://www.opengis.net/def/rel/ogc/1.0/queryables target=https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a/queryables&gt;]",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "43_eopf_stac_connection.html#searching-inside-the-eopf-stac-api",
    "href": "43_eopf_stac_connection.html#searching-inside-the-eopf-stac-api",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "Searching inside the EOPF STAC API",
    "text": "Searching inside the EOPF STAC API\nWith the .search() function of the pystac-client library, we can search inside a STAC catalog we established a connection with. We can filter based on a series of parameters to tailor the search for available data for a specific time period and geographic bounding box.\n\nFilter for temporal extent\nLet us search on the datetime parameter. For this, we specify the datetime argument for a time period we are interested in, e.g. from 1 May 2020 to 31 May 2023. In addition, we also specify the collection parameter indicating that we only want to search for the Sentinel-2 L2A collection.\nWe apply the helper function list_found_elements which constructs a list from the search result. If we check the length of the final list, we can see that for the specified time period, 196 items were found.\n\ntime_frame = eopf_catalog.search(  #searching the catalog\n    collections='sentinel-2-l2a',\n    datetime=\"2020-05-01T00:00:00Z/2023-05-31T23:59:59.999999Z\")  # the interval we are interested in, separated by '/'\n\n# we apply the helper function `list_found_elements`\ntime_items=list_found_elements(time_frame)\nprint(time_frame)\n\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-2 L-2A between May 1, 2020, and May 31, 2023:  ',len(time_items[0]))\n\n&lt;pystac_client.item_search.ItemSearch object at 0x7f16127e0da0&gt;\nSearch Results:\nTotal Items Found for Sentinel-2 L-2A between May 1, 2020, and May 31, 2023:   1348\n\n\n\n\nFilter for spatial extent\nNow, let us filter based on a specific area of interest. We can use the bbox argument, which is composed by providing the top-left and bottom-right corner coordinates. It is similar to drawing the extent in the interactive map of the EOPF browser interface.\nFor example, we defined a bounding box of the outskirts of Innsbruck, Austria. We then again apply the helper function list_found_elements and see that for the defined area, only 39 items are available.\n\nbbox_search =  eopf_catalog.search(  #searching the catalog\n    collections='sentinel-2-l2a',\n    bbox=(\n        11.124756, 47.311058, #top left\n        11.459839, 47.463624  #bottom-right\n        )\n)\n\ninnsbruck_sets=list_found_elements(bbox_search) #we apply our constructed function that stores internal information\n\n#Results\nprint(\"Search Result:\")\nprint('Total Items Found:  ',len(innsbruck_sets[0]))\n\nSearch Result:\nTotal Items Found:   94\n\n\n\n\nCombined filtering: Collection + temporal extent + spatial extent\nAs a usual workflow, we often look for datasets within an AOI and a specific period of time. The search() function allows us also to combine the collection, bbox and datetime arguments in one search request.\nLet us now search for Items available for the AOI around Innsbruck within the previously defined timeframe for the Sentinel-2 Level-2A collection. As a result, we get 27 Items that are available for our selection.\n\ninnsbruck_s2 = eopf_catalog.search( \n    collections= 'sentinel-2-l2a', # interest Collection,\n    bbox=(11.124756, 47.311058, # AOI extent\n          11.459839,47.463624),\n    datetime='2020-05-01T00:00:00Z/2025-05-31T23:59:59.999999Z' # interest period\n)\n\ncombined_ins =list_found_elements(innsbruck_s2)\n\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-2 L-2A over Innsbruck:  ',len(combined_ins[0]))\n\nSearch Results:\nTotal Items Found for Sentinel-2 L-2A over Innsbruck:   27\n\n\nLet’s repeat a combined search for a different collection. We define a new AOI for the coastal area of Rostock, Germany and we search over the Sentinel-3 SLSTR-L2 collection for the same time period as above.\nAs a result, 14 Items are available for the specified search.\n\nrostock_s3 = eopf_catalog.search(\n    bbox=(11.766357,53.994566, # AOI extent\n          12.332153,54.265086),\n    collections= ['sentinel-3-slstr-l2-lst'], # interest Collection\n    datetime='2020-05-01T00:00:00Z/2025-05-31T23:59:59.999999Z' # interest period\n)\n\ncombined_ros=list_found_elements(rostock_s3)\n\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-3 SLSTR-L2 over Rostock Coast:  ',len(combined_ros[0]))\n\nSearch Results:\nTotal Items Found for Sentinel-3 SLSTR-L2 over Rostock Coast:   18\n\n\n\n\nRetrieve Asset URLs for accessing the data\nSo far, we have made a search among the STAC catalog and browsed over the general metadata of the collections. To access the actual EOPF Zarr Items, we need to get their storage location in the cloud.\nThe relevant information we can find inside the .items argument by the .get_assets() function. Inside, it allows us to specify the .MediaType we are interested in. In our example, we want to obtain the location of the .zarr file.\nLet us retrieve the url of the 27 available items over Innsbruck. The resulting URL we can then use to directly access an asset in our workflow.\n\nassets_loc=[] # a list with the ids of the items we are interested in\nfor x in range(len(combined_ins[0])): # We retrieve only the first asset in the Innsbruck list combined_ins\n    assets_loc.append(S2l2a_coll # we set into the Sentinel-2 L-2A collection\n                      .get_item(combined_ins[0][x])  # We only get the Innsbruck filtered items\n                      .get_assets(media_type=MediaType.ZARR)) # we obtain the .zarr location\n    \nfirst_item = assets_loc[0]   # we select the first item from our list\n\nprint(\"Search Results:\")\nprint('URL for accessing',combined_ins[0][0],'item:  ',first_item['product']) # assets_loc[0] corresponds only to the first element:\n\nSearch Results:\nURL for accessing S2B_MSIL2A_20250530T101559_N0511_R065_T32TPT_20250530T130924 item:   &lt;Asset href=https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202505-s02msil2a/30/products/cpm_v256/S2B_MSIL2A_20250530T101559_N0511_R065_T32TPT_20250530T130924.zarr&gt;\n\n\n\n\nRetrieve Item metadata\nFinally, once you selected an Item, you can also explore the relevant metadata on Item level. For example with the keys() function, you can retrieve the available assets of the selected Item.\n\nprint('Available Assets: ', list(first_item.keys()))\n\nAvailable Assets:  ['SR_10m', 'SR_20m', 'SR_60m', 'AOT_10m', 'B01_20m', 'B02_10m', 'B03_10m', 'B04_10m', 'B05_20m', 'B06_20m', 'B07_20m', 'B08_10m', 'B09_60m', 'B11_20m', 'B12_20m', 'B8A_20m', 'SCL_20m', 'TCI_10m', 'WVP_10m', 'product']",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "43_eopf_stac_connection.html#now-it-is-your-turn",
    "href": "43_eopf_stac_connection.html#now-it-is-your-turn",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "💪 Now it is your turn",
    "text": "💪 Now it is your turn\nThe following expercises will help you master the STAC API and understand how to find the data you need.\n\nTask 1: Explore Your Area of Interest\n\nGo to http://bboxfinder.com/ and select an area of interest (AOI) (e.g. your hometown, a research site, etc.)\nCopy the bounding box coordinates of your area of interest\nChange the provided code above to search for data over your AOI\n\n\n\nTask 2: Temporal Analysis\n\nCompare data availability across different years for the Sentinel-2 L-2A Collection.\nSearch for items in the year 2022\nRepeat the search for the year 2024\n\n\n\nTask 3: Explore the SAR Mission and combine multiple criteria\n\nDo the same for a different Collection, the Sentinel-1 Level-1 GRD, e.g. you can use the ID sentinel-1-l1-grd\nHow many assets are available for the year 2024?",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "43_eopf_stac_connection.html#conclusion",
    "href": "43_eopf_stac_connection.html#conclusion",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial has provided a clear and practical introduction on how you can programmatically access and search through EOPF Sentinel Zarr Sample Service STAC API.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "43_eopf_stac_connection.html#whats-next",
    "href": "43_eopf_stac_connection.html#whats-next",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "What’s next?",
    "text": "What’s next?\nIn the following section, we will explore how to retrieve an Item of our interest, based on several parameters and load the actual data array as xarray.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "44_eopf_stac_xarray_tutorial.html",
    "href": "44_eopf_stac_xarray_tutorial.html",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "",
    "text": "Introduction\n🚀 Launch this notebook in JupyterLab\nIn this tutorial we will demonstrate how to access EOPF Zarr products directly from the EOPF Sentinel Zarr Sample Service STAC Catalog.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "44_eopf_stac_xarray_tutorial.html#establish-a-connection-to-the-eopf-zarr-stac-catalog",
    "href": "44_eopf_stac_xarray_tutorial.html#establish-a-connection-to-the-eopf-zarr-stac-catalog",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Establish a connection to the EOPF Zarr STAC Catalog",
    "text": "Establish a connection to the EOPF Zarr STAC Catalog\nOur first step is to a connection to the EOPF Zarr STAC Catalog. This involves defining the url of the STAC endpoint. See the previous section for a more detailed explanation how to retrieve the end point url.\nThrough the Client.open() function, we can establish the connection to the EOPF Zarr STAC catalog by providing the specific url.\n\nmax_description_length = 100\n\neopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\" #root starting point\neopf_catalog = Client.open(url=eopf_stac_api_root_endpoint)\n\n# eopf_catalog  #print to have an interative visualisation",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "44_eopf_stac_xarray_tutorial.html#filtering-for-items-of-interest",
    "href": "44_eopf_stac_xarray_tutorial.html#filtering-for-items-of-interest",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Filtering for items of interest",
    "text": "Filtering for items of interest\nFor this tutorial, we will focus on the Sentinel-2 L2A Collection. The EOPF STAC Catalog corresponding id is: sentinel-2-l2a.\nAs we are interested in retrieving and exploring an Item from the collection, we will focus again over the Innsbruck area we have defined in the previous tutorial.\n\ninnsbruck_s2 = eopf_catalog.search( # searching in the Catalog\n    collections= 'sentinel-2-l2a', # interest Collection,\n    bbox=(11.124756, 47.311058, # AOI extent\n          11.459839,47.463624),\n    datetime='2020-05-01T00:00:00Z/2025-05-31T23:59:59.999999Z' # interest period\n)\n\ncombined_ins =list_found_elements(innsbruck_s2)\n\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-2 L-2A over Innsbruck:  ',len(combined_ins[0]))\n\nSearch Results:\nTotal Items Found for Sentinel-2 L-2A over Innsbruck:   27\n\n\nLet us now select the first Item in the list of 27 Items.\n\nfirst_item_id=combined_ins[0][0]\nprint(first_item_id)\n\nS2B_MSIL2A_20250530T101559_N0511_R065_T32TPT_20250530T130924\n\n\nIn a next step, we retrieve the url of the cloud location for the specific item and load the selected Item with the help of xarray.\n\nc_sentinel2 = eopf_catalog.get_collection('sentinel-2-l2a')\n#Choosing the first item available to be opened:\nitem= c_sentinel2.get_item(id=first_item_id)\nitem_assets = item.get_assets(media_type=MediaType.ZARR)\n\ncloud_storage = item_assets['product'].href\n\nprint('Item cloud storage URL for retrieval:',cloud_storage)\n\nItem cloud storage URL for retrieval: https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202505-s02msil2a/30/products/cpm_v256/S2B_MSIL2A_20250530T101559_N0511_R065_T32TPT_20250530T130924.zarr",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "44_eopf_stac_xarray_tutorial.html#examining-dataset-structure",
    "href": "44_eopf_stac_xarray_tutorial.html#examining-dataset-structure",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Examining Dataset Structure",
    "text": "Examining Dataset Structure\nIn the following step, we open the cloud-optimised Zarr dataset using xarray.open_datatree supported by the zarr engine.\nThe subsequent loop then prints out all the available groups within the opened DataTree, providing a comprehensive overview of the hierarchical structure of the EOPF Zarr products.\n\nclient = DaskClient()  # Set up local dask cluster\nclient\n\ndt = xr.open_datatree(\n    cloud_storage,     # the cloud storage url from the Item we are interested in\n    engine=\"zarr\",\n    chunks=\"auto\"      # automatically determine chunk sizes using dask\n)\n\nfor dt_group in sorted(dt.groups):\n    print(\"DataTree group {group_name}\".format(group_name=dt_group)) # getting the available groups\n\nDataTree group /\nDataTree group /conditions\nDataTree group /conditions/geometry\nDataTree group /conditions/mask\nDataTree group /conditions/mask/detector_footprint\nDataTree group /conditions/mask/detector_footprint/r10m\nDataTree group /conditions/mask/detector_footprint/r20m\nDataTree group /conditions/mask/detector_footprint/r60m\nDataTree group /conditions/mask/l1c_classification\nDataTree group /conditions/mask/l1c_classification/r60m\nDataTree group /conditions/mask/l2a_classification\nDataTree group /conditions/mask/l2a_classification/r20m\nDataTree group /conditions/mask/l2a_classification/r60m\nDataTree group /conditions/meteorology\nDataTree group /conditions/meteorology/cams\nDataTree group /conditions/meteorology/ecmwf\nDataTree group /measurements\nDataTree group /measurements/reflectance\nDataTree group /measurements/reflectance/r10m\nDataTree group /measurements/reflectance/r20m\nDataTree group /measurements/reflectance/r60m\nDataTree group /quality\nDataTree group /quality/atmosphere\nDataTree group /quality/atmosphere/r10m\nDataTree group /quality/atmosphere/r20m\nDataTree group /quality/atmosphere/r60m\nDataTree group /quality/l2a_quicklook\nDataTree group /quality/l2a_quicklook/r10m\nDataTree group /quality/l2a_quicklook/r20m\nDataTree group /quality/l2a_quicklook/r60m\nDataTree group /quality/mask\nDataTree group /quality/mask/r10m\nDataTree group /quality/mask/r20m\nDataTree group /quality/mask/r60m\nDataTree group /quality/probability\nDataTree group /quality/probability/r20m",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "44_eopf_stac_xarray_tutorial.html#root-dataset-metadata",
    "href": "44_eopf_stac_xarray_tutorial.html#root-dataset-metadata",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Root Dataset Metadata",
    "text": "Root Dataset Metadata\nWe specifically look for groups containing data variables under /measurements/reflectance/r20m (which corresponds to Sentinel-2 bands at 20m resolution). The output provides key information about the selected group, including its dimensions, available data variables (the different spectral bands), and coordinates.\n\n# Get /measurements/reflectance/r20m group\ngroups = list(dt.groups)\ninteresting_groups = [\n    group for group in groups if group.startswith('/measurements/reflectance/r20m')\n    and dt[group].ds.data_vars\n]\nprint(f\"\\n🔍 Searching for groups with data variables in '/measurements/reflectance/r20m'...\")\n\n\n🔍 Searching for groups with data variables in '/measurements/reflectance/r20m'...\n\n\n\nif interesting_groups:\n    sample_group = interesting_groups[0]\n    group_ds = dt[sample_group].ds\n    \n    print(f\"Group '{sample_group}' Information\")\n    print(\"=\" * 50)\n    print(f\"Dimensions: {dict(group_ds.dims)}\")\n    print(f\"Data Variables: {list(group_ds.data_vars.keys())}\")\n    print(f\"Coordinates: {list(group_ds.coords.keys())}\")\n\nelse:\n    print(\"No groups with data variables found in the first 5 groups.\")\n\nGroup '/measurements/reflectance/r20m' Information\n==================================================\nDimensions: {'y': 5490, 'x': 5490}\nData Variables: ['b01', 'b02', 'b03', 'b04', 'b05', 'b06', 'b07', 'b11', 'b12', 'b8a']\nCoordinates: ['x', 'y']\n\n\nIn a next step, we inspect the attributes of the root dataset within the DataTree. Attributes often contain important high-level metadata about the entire product, such as processing details, STAC discovery information, and more. We print the first few attributes to get an idea of the available metadata.\n\n# Examine the root dataset\nroot_dataset = dt.ds\n\nprint(\"Root Dataset Metadata\")\n\nif root_dataset.attrs:\n    print(f\"\\nAttributes (first 3):\")\n    for key, value in list(root_dataset.attrs.items())[:3]:\n        print(f\"   {key}: {str(value)[:80]}{'...' if len(str(value)) &gt; 80 else ''}\")\n\nRoot Dataset Metadata\n\nAttributes (first 3):\n   other_metadata: {'AOT_retrieval_model': 'SEN2COR_DDV', 'L0_ancillary_data_quality': '4', 'L0_eph...\n   stac_discovery: {'assets': {'analytic': {'eo:bands': [{'center_wavelength': 0.4423, 'common_name...",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "44_eopf_stac_xarray_tutorial.html#visualising-the-rgb-quicklook-composite",
    "href": "44_eopf_stac_xarray_tutorial.html#visualising-the-rgb-quicklook-composite",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Visualising the RGB quicklook composite",
    "text": "Visualising the RGB quicklook composite\nEOPF Zarr Assets include a quick-look RGB composite, which we now want to open and visuliase. We open the Zarr dataset again, but this time, we specifically target the quality/l2a_quicklook/r20m group and its variables.\nThis group typically contains a true colour (RGB) quick-look composite, which is a readily viewable representation of the satellite image.\nWe use xr.open_dataset() and specify the following set of arguments in order to load the quick-look.\n\n## Visualising the RGB quicklook composite:\nds = dt['quality/l2a_quicklook/r20m'].to_dataset()\nds_20_ql= ds['tci']\n\nAs soon as we load the selected group, we can create a simple plot with imshow() to see the quick-look.\n\nds_20_ql.plot.imshow(rgb=\"band\")\nplt.title('RGB Quicklook')\nplt.xlabel('X-coordinate')\nplt.ylabel('Y-coordinate')\nplt.grid(False) # Turn off grid for image plots\nplt.axis('tight') # Ensure axes fit the data tightly\n\n(np.float64(600000.0),\n np.float64(709800.0),\n np.float64(5190240.0),\n np.float64(5300040.0))",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "44_eopf_stac_xarray_tutorial.html#simple-data-analysis-calculating-ndvi",
    "href": "44_eopf_stac_xarray_tutorial.html#simple-data-analysis-calculating-ndvi",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Simple Data Analysis: Calculating NDVI",
    "text": "Simple Data Analysis: Calculating NDVI\nLet us now do a simple analysis with the data from the EOPF Zarr STAC Catalog. Let us calculate the Normalized Difference Vegetation Index (NDVI).\nFirst, we access the /measurements/reflectance/r20m group, as the bands we are interested in are at 20m resolution: the Red (B04) and Near-InfraRed (B08A) bands, which are ones needed for the calculation of the NDVI.\n\n# Visualising the NIR reflectance band and select a subsample region with a specific bounding box and a specific resolution.\nresolution = 2000  # in meters\nred_nir = dt ['/measurements/reflectance/r20m'].to_dataset()\nred_nir.isel(\n    x=slice(\n        red_nir['x'].min().values.flat[0],\n        int(red_nir['x'].min().values.flat[0] + 100000),\n        int(resolution/20),\n    ),\n    y=slice(\n        red_nir['y'].min().values.flat[0],\n        int(red_nir['y'].min().values.flat[0] + 100000),\n        int(resolution/20),\n    )\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 0B\nDimensions:  (y: 0, x: 0)\nCoordinates:\n  * x        (x) int64 0B \n  * y        (y) int64 0B \nData variables:\n    b01      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b02      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b03      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b04      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b05      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b06      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b07      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b11      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b12      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b8a      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;xarray.DatasetDimensions:y: 0x: 0Coordinates: (2)x(x)int64array([], dtype=int64)y(y)int64array([], dtype=int64)Data variables: (10)b01(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b01 442.3 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b01 442.3 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb02(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b02 492.3 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b02 492.3 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb03(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b03 559.0 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b03 559.0 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb04(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b04 665.0 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b04 665.0 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb05(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b05 703.8 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b05 703.8 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb06(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b06 739.1 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b06 739.1 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb07(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b07 779.7 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b07 779.7 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb11(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b11 1610.4 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b11 1610.4 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb12(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b12 2185.7 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b12 2185.7 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb8a(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b8a 864.0 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b8a 864.0 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nIndexes: (2)xPandasIndexPandasIndex(Index([], dtype='int64', name='x'))yPandasIndexPandasIndex(Index([], dtype='int64', name='y'))Attributes: (0)\n\n\nIn a next step, we cast the red (B04) and Near-Infrared (B08a) arrays. This is important for accurate mathematical operations, which we will conduct in the next cell.\n\nred_f = red_nir['b04']\nnir_f = red_nir['b8a']\n\nNow, we perform the initial steps for NDVI calculation: - sum_bands: Calculates the sum of the Near-Infrared and Red bands. - diff_bands: Calculates the difference between the Near-Infrared and Red bands.\nTo prevent division by zero errors in areas where both red and NIR bands might be zero (e.g., water bodies or clouds), this line replaces any NaN values resulting from division by zero with the 0 value. This ensures a clean and robust NDVI product.\n\nsum_bands = nir_f + red_f\n\nzero_mask = (sum_bands == 0) # to avoid 0 division\nsum_bands_z= sum_bands.copy()\nsum_bands_z = da.where(sum_bands_z == 0, 1, sum_bands_z)\n\ndiff_bands = nir_f - red_f\n\nndvi = da.where(sum_bands == 0, 0, diff_bands / sum_bands_z)\n\nIn a final step, we can visualise the calculated NDVI.\n\nplt.imshow(ndvi,cmap='RdYlGn', vmin=-1, vmax=1)\nplt.title('Normalized Difference Vegetation Index (NDVI)')\nplt.xlabel('X-coordinate')\nplt.ylabel('Y-coordinate')\nplt.grid(False) # Turn off grid for image plots\nplt.axis('tight') # Ensure axes fit the data tightly\n\n# Display the plot\nplt.show()",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "44_eopf_stac_xarray_tutorial.html#now-it-is-your-turn",
    "href": "44_eopf_stac_xarray_tutorial.html#now-it-is-your-turn",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "💪 Now it is your turn",
    "text": "💪 Now it is your turn\nWith the foundations learned so far, you are now equipped to access products from the EOPF Zarr STAC catalog. These are your tasks:\n\nTask 1: Explore five additional Sentinel-2 Items for Innsbruck\nReplicate the RGB quick-look and have an overview of the spatial changes.\n\n\nTask 2: Calculate NDVI\nReplicate the NDVI calculation for the additional Innsbruck items.\n\n\nTask 3: Applying more advanced analysis techniques\nThe EOPF STAC Catalog offers a wealth of data beyond Sentinel-2. Replicate the search and data access for data from other collections.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "44_eopf_stac_xarray_tutorial.html#conclusion",
    "href": "44_eopf_stac_xarray_tutorial.html#conclusion",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Conclusion",
    "text": "Conclusion\nIn this section we established a connection to the EOPF Sentinel Zarr Sample Service STAC Catalog and directly accessed an EOPF Zarr item with xarray. In the tutorial you are guided through the process of opening hierarchical EOPF Zarr products using xarray’s DataTree, a library designed for accessing complex hierarchical data structures.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "44_eopf_stac_xarray_tutorial.html#whats-next",
    "href": "44_eopf_stac_xarray_tutorial.html#whats-next",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "What’s next?",
    "text": "What’s next?\nIn the following section we will present several end-to-end workflows, where we will showcase the application of the available Sentinel Products in the EOPF Sentinel Zarr Sample Service STAC Catalog.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "51_eopf_stac_r.html",
    "href": "51_eopf_stac_r.html",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "",
    "text": "Introduction\nIn this section, we will explore programmatic access of the EOPF Zarr Collections available in the EOPF Sentinel Zarr Sample Service STAC Catalog using R. We will introduce R packages that enable us to effectively access and search through STAC catalogs.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "51_eopf_stac_r.html#connect-to-the-eopf-sample-service-stac-api",
    "href": "51_eopf_stac_r.html#connect-to-the-eopf-sample-service-stac-api",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "Connect to the EOPF Sample Service STAC API",
    "text": "Connect to the EOPF Sample Service STAC API\nTo access the EOPF Sample Service STAC catalog in R, we need to give the URL of the STAC API source (https://stac.core.eopf.eodc.eu/) using the function stac().\nThe object stac_source is a query containing information used to connect to the API, but it does not actually make any requests. To make requests to the API, we will always need to use get_request() or put_request(), as appropriate. Running get_request() on stac_source actually retrieves the catalogue:\nstac_source &lt;- stac(\"https://stac.core.eopf.eodc.eu/\")\n\nstac_source |&gt;\n  get_request()\n## ###Catalog\n## - id: eopf-sample-service-stac-api\n## - description: STAC catalog of the EOPF Sentinel Zarr Samples Service\n## - field(s): type, id, title, description, stac_version, conformsTo, links, stac_extensions",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "51_eopf_stac_r.html#browse-collections",
    "href": "51_eopf_stac_r.html#browse-collections",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "Browse collections",
    "text": "Browse collections\nA STAC Collection exists to relate similar data sets together through space, time, and shared metadata. Each Sentinel mission and the downstream analysis-ready data are examples of STAC Collections. To browse STAC Collections, the collections() function is used. We can see that there are 11 collections available in the API:\nstac_collections &lt;- stac_source |&gt;\n  collections() |&gt;\n  get_request()\n\nstac_collections\n## ###Collections\n## - collections (11 item(s)):\n##   - sentinel-2-l2a\n##   - sentinel-3-olci-l2-lfr\n##   - sentinel-1-l2-ocn\n##   - sentinel-3-slstr-l2-lst\n##   - sentinel-1-l1-grd\n##   - sentinel-2-l1c\n##   - sentinel-1-l1-slc\n##   - sentinel-3-slstr-l1-rbt\n##   - sentinel-3-olci-l1-efr\n##   - sentinel-3-olci-l1-err\n##   - sentinel-3-olci-l2-lrr\n## - field(s): collections, links, numberMatched, numberReturned\nThe default printing of the stac_collections() object summarises what’s been returned, but does not give all of the information. To see more about what’s been returned, we use str().\nstac_collections |&gt;\n  str(max.level = 1)\n## List of 4\n##  $ collections   :List of 11\n##  $ links         :List of 3\n##   ..- attr(*, \"class\")= chr [1:2] \"doc_links\" \"list\"\n##  $ numberMatched : int 11\n##  $ numberReturned: int 11\n##  - attr(*, \"class\")= chr [1:3] \"doc_collections\" \"rstac_doc\" \"list\"\nHere, we can see that there is an entry \"collections\" within stac_collections, which we access to return the collections themselves (using head() to only return a few). This shows additional details about each collection, such as the collection id, title, description, and additional fields in the collections.\nstac_collections[[\"collections\"]] |&gt;\n  head(3)\n## [[1]]\n## ###Collection\n## - id: sentinel-2-l2a\n## - title: Sentinel-2 Level-2A\n## - description: \n## The Sentinel-2 Level-2A Collection 1 product provides orthorectified Surface Reflectance (Bottom-Of-Atmosphere: BOA), with sub-pixel multispectral and multitemporal registration accuracy. Scene Classification (including Clouds and Cloud Shadows), AOT (Aerosol Optical Thickness) and WV (Water Vapour) maps are included in the product.\n## - field(s): \n## id, type, links, title, assets, extent, license, keywords, providers, summaries, description, item_assets, stac_version, stac_extensions\n## \n## [[2]]\n## ###Collection\n## - id: sentinel-3-olci-l2-lfr\n## - title: Sentinel-3 OLCI Level-2 LFR\n## - description: \n## The Sentinel-3 OLCI L2 LFR product provides land and atmospheric geophysical parameters computed for full resolution.\n## - field(s): \n## id, type, links, title, assets, extent, license, keywords, providers, summaries, description, item_assets, stac_version, stac_extensions\n## \n## [[3]]\n## ###Collection\n## - id: sentinel-1-l2-ocn\n## - title: Sentinel-1 Level-2 OCN\n## - description: \n## The Sentinel-1 Level-2 Ocean (OCN) products for wind, wave and currents applications may contain the following geophysical components derived from the SAR data: Ocean Wind field (OWI), Ocean Swell spectra (OSW), Surface Radial Velocity (RVL). The availability of components depends on the acquisition mode. The metadata referring to OWI are derived from an internally processed GRD product, the metadata referring to RVL (and OSW, for SM and WV mode) are derived from an internally processed SLC product.\n## - field(s): \n## id, type, links, title, assets, extent, license, keywords, providers, summaries, description, item_assets, stac_version, stac_extensions\nThe Sentinel-2 Level-2A collection can be accessed by getting the first entry in stac_collections()[[\"collections\"]]\nstac_collections[[\"collections\"]][[1]]\n## ###Collection\n## - id: sentinel-2-l2a\n## - title: Sentinel-2 Level-2A\n## - description: \n## The Sentinel-2 Level-2A Collection 1 product provides orthorectified Surface Reflectance (Bottom-Of-Atmosphere: BOA), with sub-pixel multispectral and multitemporal registration accuracy. Scene Classification (including Clouds and Cloud Shadows), AOT (Aerosol Optical Thickness) and WV (Water Vapour) maps are included in the product.\n## - field(s): \n## id, type, links, title, assets, extent, license, keywords, providers, summaries, description, item_assets, stac_version, stac_extensions\nHowever, the best way to access a specific collection is to search for it directly using the collection ID. The ID, “sentinel-2-l2a”, is visible in the Collection output above. It is also accessible in the browsable STAC catalog of the EOPF Sentinel Zarr Samples Service, on the page for that collection, under “Source.”\n\nThe collection ID can be supplied directly in the collections() function. If we look at the query without getting the result, we can see that it has been formed using the collection_id, “sentinel-2-l2a”, as a filter parameter.\nsentinel_2_l2a_query &lt;- stac_source |&gt;\n  collections(collection_id = \"sentinel-2-l2a\")\n\nsentinel_2_l2a_query\n## ###rstac_query\n## - url: https://stac.core.eopf.eodc.eu/\n## - params:\n##   - collection_id: sentinel-2-l2a\n## - field(s): version, base_url, endpoint, params, verb, encode\nAnd that running get_request() will return the collection itself:\nsentinel_2_l2a_query |&gt;\n  get_request()\n## ###Collection\n## - id: sentinel-2-l2a\n## - title: Sentinel-2 Level-2A\n## - description: \n## The Sentinel-2 Level-2A Collection 1 product provides orthorectified Surface Reflectance (Bottom-Of-Atmosphere: BOA), with sub-pixel multispectral and multitemporal registration accuracy. Scene Classification (including Clouds and Cloud Shadows), AOT (Aerosol Optical Thickness) and WV (Water Vapour) maps are included in the product.\n## - field(s): \n## id, type, links, title, assets, extent, license, keywords, providers, summaries, description, item_assets, stac_version, stac_extensions",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "51_eopf_stac_r.html#browse-items",
    "href": "51_eopf_stac_r.html#browse-items",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "Browse items",
    "text": "Browse items\nWithin collections, there are items. Items are the building blocks for STAC. At their core, they are GeoJSON data, along with additional metadata which ensures data provenance is maintained and specific data attributes are captured. A single capture from a Sentinel mission is an example of a STAC item. To get an overview of items within a collection, the items() function is used.\nAn important thing to note with rstac is that you cannot continue to build queries on top of ones that have already had their results returned (via get_request()). It may make sense for a typical workflow in R to “get” the collection, then to try to get the items from it, but this will produce an error:\nsentinel_2_l2a_collection &lt;- stac_source |&gt;\n  collections(collection_id = \"sentinel-2-l2a\") |&gt;\n  get_request()\n\nsentinel_2_l2a_collection |&gt;\n  items()\nError: Invalid rstac_query value.\nIf you see this error — \"Invalid rstac_query value\" — ensure that you are running get_request() at the very end of your query building functions. Using items() this way, we can see that it returns a summary of the collection’s items:\nsentinel_2_l2a_collection_items &lt;- stac_source |&gt;\n  collections(collection_id = \"sentinel-2-l2a\") |&gt;\n  items() |&gt;\n  get_request()\n\nsentinel_2_l2a_collection_items\n## ###Items\n## - features (10 item(s)):\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WEU_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WET_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WDU_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WDT_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WDS_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WCV_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXD_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXC_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXB_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXA_20251015T113514\n## - assets: \n## AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\nThe first 10 items are returned. This number can be changed via the limit argument in items()\nstac_source |&gt;\n  collections(collection_id = \"sentinel-2-l2a\") |&gt;\n  items(limit = 20) |&gt;\n  get_request()\n## ###Items\n## - features (20 item(s)):\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WEU_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WET_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WDU_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WDT_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WDS_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WCV_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXD_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXC_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXB_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXA_20251015T113514\n##   - ... with 10 more feature(s).\n## - assets: \n## AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\nItem properties\nWe can look closer at individual items to see the metadata attached to them. Items are stored under \"features\":\nsentinel_2_l2a_collection_items[[\"features\"]] |&gt;\n  head(2)\n## [[1]]\n## ###Item\n## - id: S2A_MSIL2A_20251015T095041_N0511_R079_T37WEU_20251015T113514\n## - collection: sentinel-2-l2a\n## - bbox: xmin: 38.99946, ymin: 70.25024, xmax: 39.25286, ymax: 70.44757\n## - datetime: 2025-10-15T09:50:41.024000Z\n## - assets: \n## SR_10m, SR_20m, SR_60m, AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, SCL_20m, TCI_10m, WVP_10m, product, product_metadata\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n## \n## [[2]]\n## ###Item\n## - id: S2A_MSIL2A_20251015T095041_N0511_R079_T37WET_20251015T113514\n## - collection: sentinel-2-l2a\n## - bbox: xmin: 38.99947, ymin: 70.25024, xmax: 39.09932, ymax: 70.30602\n## - datetime: 2025-10-15T09:50:41.024000Z\n## - assets: \n## SR_10m, SR_20m, SR_60m, AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, SCL_20m, TCI_10m, WVP_10m, product, product_metadata\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\nAnd an individual item contains a lot of information, such as its bounding box:\nsentinel_2_l2a_first_item &lt;- sentinel_2_l2a_collection_items[[\"features\"]][[1]]\n\nsentinel_2_l2a_first_item[[\"bbox\"]]\n## [1] 38.99946 70.25024 39.25286 70.44757\nAnd many more additional properties, with their properties under \"properties\" in an individual item.\nsentinel_2_l2a_first_item[[\"properties\"]] |&gt;\n  names()\n##  [1] \"gsd\"                                   \"created\"                              \n##  [3] \"mission\"                               \"sci:doi\"                              \n##  [5] \"updated\"                               \"datetime\"                             \n##  [7] \"platform\"                              \"grid:code\"                            \n##  [9] \"proj:bbox\"                             \"proj:code\"                            \n## [11] \"providers\"                             \"published\"                            \n## [13] \"instruments\"                           \"end_datetime\"                         \n## [15] \"product:type\"                          \"constellation\"                        \n## [17] \"eo:snow_cover\"                         \"mgrs:utm_zone\"                        \n## [19] \"proj:centroid\"                         \"eo:cloud_cover\"                       \n## [21] \"start_datetime\"                        \"sat:orbit_state\"                      \n## [23] \"eopf:datatake_id\"                      \"mgrs:grid_square\"                     \n## [25] \"processing:level\"                      \"view:sun_azimuth\"                     \n## [27] \"mgrs:latitude_band\"                    \"processing:lineage\"                   \n## [29] \"product:timeliness\"                    \"sat:absolute_orbit\"                   \n## [31] \"sat:relative_orbit\"                    \"view:sun_elevation\"                   \n## [33] \"processing:facility\"                   \"processing:software\"                  \n## [35] \"eopf:instrument_mode\"                  \"product:timeliness_category\"          \n## [37] \"sat:platform_international_designator\"\nThe introductory tutorial further explains the metadata properties and their extensions.\nFor example, the EOPF instrument mode:\nsentinel_2_l2a_first_item[[\"properties\"]][[\"eopf:instrument_mode\"]]\n## [1] \"INS-NOBS\"\nFor the rest of the tutorial, we will use a small helper function that accesses a given property for the first item returned in a search.\nget_first_item_property &lt;- function(search_results, property) {\n  search_results[[\"features\"]][[1]][[\"properties\"]][[property]]\n}\n\nsentinel_2_l2a_collection_items |&gt;\n  get_first_item_property(\"eopf:instrument_mode\")\n## [1] \"INS-NOBS\"\n\n\nSearch for items\nIf the goal is to access data from a specific mission, it is best to search within a collection’s items, using some of the properties explored above. It’s possible to search based on a number of criteria, including a bounding box, time frame, and other mission properties.\n\nSearch by a bounding box\nTo narrow down items based on a bounding box or time frame, the stac_search() function is used. The collection ID is provided in the collections() argument, and bounding box and time frame are bbox and datetime, respectively.\nThe bounding box values take the sequence of: minimum longitude, minimum latitude, maximum longitude, and maximum latitude, and their coordinate reference system is WGS84. For items whose bounding boxes intersect with Vienna:\nstac_source |&gt;\n  stac_search(\n    collections = \"sentinel-2-l2a\",\n    bbox = c(16.1736, 48.1157, 16.5897, 48.3254)\n  ) |&gt;\n  get_request()\n## ###Items\n## - features (10 item(s)):\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T33UWP_20251015T113604\n##   - S2C_MSIL2A_20251013T095041_N0511_R079_T33UXP_20251013T132105\n##   - S2C_MSIL2A_20251013T095041_N0511_R079_T33UWP_20251013T132105\n##   - S2B_MSIL2A_20251011T100029_N0511_R122_T33UXP_20251011T135204\n##   - S2B_MSIL2A_20251011T100029_N0511_R122_T33UWP_20251011T135204\n##   - S2A_MSIL2A_20251008T100041_N0511_R122_T33UXP_20251008T122613\n##   - S2A_MSIL2A_20251008T100041_N0511_R122_T33UWP_20251008T122613\n##   - S2B_MSIL2A_20251008T095029_N0511_R079_T33UXP_20251008T123009\n##   - S2B_MSIL2A_20251008T095029_N0511_R079_T33UWP_20251008T123009\n##   - S2C_MSIL2A_20251006T100041_N0511_R122_T33UXP_20251006T152515\n## - assets: \n## AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\nThis does – again by default – return the first 10 items, but the number returned can be increased via the limit argument in stac_search().\n\n\nSearch by a time frame\nWhen searching for a specific time frame, items that have a datetime property that intersects with the given time frame will be returned. It’s therefore best to search for a closed or open interval, rather than a specific date and time (which might be difficult to match exactly to an item’s time!). The date-time must be given in RFC 3339 format.\nTo search for a closed interval, separate two date-times by a “/”, e.g. \"2024-12-01T01:00:00Z/2024-12-01T05:00:00Z\":\nmatching_timeframe_items &lt;- stac_source |&gt;\n  stac_search(\n    collections = \"sentinel-2-l2a\",\n    datetime = \"2024-12-01T01:00:00Z/2024-12-01T05:00:00Z\"\n  ) |&gt;\n  get_request()\n\nmatching_timeframe_items\n## ###Items\n## - features (10 item(s)):\n##   - S2A_MSIL2A_20241201T045911_N0511_R133_T44HKD_20241201T065447\n##   - S2A_MSIL2A_20241201T045911_N0511_R133_T44HKC_20241201T065447\n##   - S2A_MSIL2A_20241201T045911_N0511_R133_T43HGU_20241201T065447\n##   - S2A_MSIL2A_20241201T045911_N0511_R133_T43HGT_20241201T065447\n##   - S2A_MSIL2A_20241201T045911_N0511_R133_T43HGS_20241201T065447\n##   - S2A_MSIL2A_20241201T045911_N0511_R133_T43HFU_20241201T065447\n##   - S2A_MSIL2A_20241201T045911_N0511_R133_T43HFT_20241201T065447\n##   - S2A_MSIL2A_20241201T045911_N0511_R133_T43HFS_20241201T065447\n##   - S2A_MSIL2A_20241201T045911_N0511_R133_T43HEV_20241201T065447\n##   - S2A_MSIL2A_20241201T045911_N0511_R133_T43HEU_20241201T065447\n## - assets: \n## AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\nWe can access the matching item’s datetime property to see that it falls within the specified interval:\nmatching_timeframe_items |&gt;\n  get_first_item_property(\"datetime\")\n## [1] \"2024-12-01T04:59:11.024000Z\"\nTo search by an open interval, “..” is used to indicate the open end, e.g. \"../2024-01-01T23:00:00Z\" representing prior to that date-time, and \"2024-01-01T23:00:00Z/..\" representing after it:\nstac_source |&gt;\n  stac_search(\n    collections = \"sentinel-2-l2a\",\n    datetime = \"2025-01-01T23:00:00Z/..\"\n  ) |&gt;\n  get_request()\n## ###Items\n## - features (10 item(s)):\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WEU_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WET_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WDU_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WDT_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WDS_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T37WCV_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXD_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXC_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXB_20251015T113514\n##   - S2A_MSIL2A_20251015T095041_N0511_R079_T36WXA_20251015T113514\n## - assets: \n## AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nSearch by other item properties\nAs shown above, there are a number of other properties attached to STAC items. We can also search using these properties. The stac_search() function is limited to properties like bounding box and time frame, so instead we use ext_filter(). This is a function that makes use of the Common Query Language (CQL2) filter extension, and allows us to do more complicated searching and querying using SQL-like language. It is also important to note that when using ext_filter(), we switch to using post_request() instead of get_request().\nFor this searching, it is helpful to know the data type for an item property in advance, as this will impact what operation to use within ext_filter(). We create an additional helper function for this:\nget_item_property_type &lt;- function(property = NULL) {\n  api_res &lt;- rstac:::make_get_request(\"https://stac.core.eopf.eodc.eu/api\") |&gt;\n    rstac:::content_response_json()\n  item_properties_schema &lt;- api_res[[\"components\"]][[\"schemas\"]][[\"ItemProperties\"]][[\"properties\"]]\n\n  property_types &lt;- lapply(item_properties_schema, function(x) {\n    x[[\"anyOf\"]][[1]][[\"type\"]]\n  })\n\n  if (is.null(property)) {\n    property_types\n  } else {\n    property_types[[property]]\n  }\n}\nWhen no argument is passed to this function, it will return all of the properties and their types:\nget_item_property_type()\n## $title\n## [1] \"string\"\n## \n## $description\n## [1] \"string\"\n## \n## $datetime\n## [1] \"string\"\n## \n## $created\n## [1] \"string\"\n## \n## $updated\n## [1] \"string\"\n## \n## $start_datetime\n## [1] \"string\"\n## \n## $end_datetime\n## [1] \"string\"\n## \n## $license\n## [1] \"string\"\n## \n## $providers\n## [1] \"array\"\n## \n## $platform\n## [1] \"string\"\n## \n## $instruments\n## [1] \"array\"\n## \n## $constellation\n## [1] \"string\"\n## \n## $mission\n## [1] \"string\"\n## \n## $gsd\n## [1] \"number\"\nWhen the name of a property is passed, it will return the type of that property. We can see, for example, that platform is a string, while instruments is an array.\nget_item_property_type(\"platform\")\n## [1] \"string\"\nget_item_property_type(\"instruments\")\n## [1] \"array\"\nSince platform is a string, we use == to indicate equality. For example, to search for items whose platform is “sentinel-2b”:\nsentinel_2b_platform_results &lt;- stac_source |&gt;\n  stac_search(collections = \"sentinel-2-l2a\") |&gt;\n  ext_filter(platform == \"sentinel-2b\") |&gt;\n  post_request()\n\nsentinel_2b_platform_results\n## ###Items\n## - features (10 item(s)):\n##   - S2B_MSIL2A_20251015T094029_N0511_R036_T37WEU_20251015T120020\n##   - S2B_MSIL2A_20251015T094029_N0511_R036_T37WET_20251015T120020\n##   - S2B_MSIL2A_20251015T094029_N0511_R036_T37WES_20251015T120020\n##   - S2B_MSIL2A_20251015T094029_N0511_R036_T37WDU_20251015T120020\n##   - S2B_MSIL2A_20251015T094029_N0511_R036_T37WDQ_20251015T120020\n##   - S2B_MSIL2A_20251015T094029_N0511_R036_T37WCV_20251015T120020\n##   - S2B_MSIL2A_20251015T094029_N0511_R036_T36WXU_20251015T120020\n##   - S2B_MSIL2A_20251015T094029_N0511_R036_T36WXD_20251015T120020\n##   - S2B_MSIL2A_20251015T094029_N0511_R036_T36WWS_20251015T120020\n##   - S2B_MSIL2A_20251015T094029_N0511_R036_T36WWE_20251015T120020\n## - assets: \n## AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\nsentinel_2b_platform_results |&gt;\n  get_first_item_property(\"platform\")\n## [1] \"sentinel-2b\"\nIf the search value is contained in another variable, the variable must be escaped in the search by using double curly braces:\nsearch_platform &lt;- \"sentinel-2b\"\n\nsentinel_2b_platform_results &lt;- stac_source |&gt;\n  stac_search(collections = \"sentinel-2-l2a\") |&gt;\n  ext_filter(platform == {{ search_platform }}) |&gt;\n  post_request()\n\nsentinel_2b_platform_results |&gt;\n  get_first_item_property(\"platform\")\n## [1] \"sentinel-2b\"\nNote also that there is no limit argument in ext_filter(). To limit the number of items returned, the limit is supplied in stac_search() beforehand, since these search functions build upon one another:\nstac_source |&gt;\n  stac_search(collections = \"sentinel-2-l2a\", limit = 1) |&gt;\n  ext_filter(platform == {{ search_platform }}) |&gt;\n  post_request()\n## ###Items\n## - features (1 item(s)):\n##   - S2B_MSIL2A_20251015T094029_N0511_R036_T37WEU_20251015T120020\n## - assets: \n## AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\nTo search for items with cloud cover of less than 40, we use &lt;=:\nstac_source |&gt;\n  stac_search(collections = \"sentinel-2-l2a\") |&gt;\n  ext_filter(`eo:cloud_cover` &lt;= 40) |&gt;\n  post_request() |&gt;\n  get_first_item_property(\"eo:cloud_cover\")\n## [1] 20.38686\nIf we want to search for items where instruments is “msi”, we use the a_contains() function. We need to use this instead of == because instruments is an array, as seen above. This means it operates like a list within R, and can contain multiple values – a_contains() searches for the value \"msi\" within the list of values that is instruments.\nstac_source |&gt;\n  stac_search(collections = \"sentinel-2-l2a\") |&gt;\n  ext_filter(a_contains(instruments, \"msi\")) |&gt;\n  post_request() |&gt;\n  get_first_item_property(\"instruments\")\n## [1] \"msi\"\nNote that there is currently a bug with how the rstac package converts the API’s data to an R object. This bug makes it unclear that instruments is a list that needs to be searched within (instead of a single value). There is an issue to fix this bug in the rstac github repository. We hope that the helper function get_item_property_type() will be helpful in the meantime to determine which filtering operation to use.\nThe documentation for ext_filter() contains information on how to construct many more searches than we’ve shown here.\n\n\nCombine search criteria\nYou can combine multiple filter criteria by specifying them together. We have already seen how to combine multiple criteria (collection ID and bounding box, for example) in stac_search() by using the named arguments. We can also filter by bounding box and datetime in the same way. Multiple criteria in ext_filter() are separated by &&:\nmultiple_criteria_items &lt;- stac_source |&gt;\n  stac_search(\n    collections = \"sentinel-2-l2a\",\n    bbox = c(16.1736, 48.1157, 16.5897, 48.3254),\n    datetime = \"../2025-06-01T23:00:00Z\"\n  ) |&gt;\n  ext_filter(\n    platform == \"sentinel-2a\" &&\n      `eo:cloud_cover` &lt;= 40\n  ) |&gt;\n  post_request()\n\nmultiple_criteria_items |&gt;\n  get_first_item_property(\"datetime\")\n## [1] \"2025-05-31T10:00:51.024000Z\"\nmultiple_criteria_items |&gt;\n  get_first_item_property(\"platform\")\n## [1] \"sentinel-2a\"\nmultiple_criteria_items |&gt;\n  get_first_item_property(\"eo:cloud_cover\")\n## [1] 8.41613",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "51_eopf_stac_r.html#browse-assets",
    "href": "51_eopf_stac_r.html#browse-assets",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "Browse assets",
    "text": "Browse assets\nFinally, assets fall under STAC items and direct users to the actual data itself. Each asset refers to data associated with the Item that can be downloaded or streamed.\nWe will look at the assets for a specific item from the Sentinel-2 Level-2A collection. Like collections, items can be filtered by their IDs. Their IDs are also available through the API:\nsentinel_2_l2a_collection_items[[\"features\"]][[1]]\n## ###Item\n## - id: S2A_MSIL2A_20251015T095041_N0511_R079_T37WEU_20251015T113514\n## - collection: sentinel-2-l2a\n## - bbox: xmin: 38.99946, ymin: 70.25024, xmax: 39.25286, ymax: 70.44757\n## - datetime: 2025-10-15T09:50:41.024000Z\n## - assets: \n## SR_10m, SR_20m, SR_60m, AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, SCL_20m, TCI_10m, WVP_10m, product, product_metadata\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\nOr through the STAC catalog of the EOPF Sentinel Zarr Samples Service, on the page for that item, under “Source”:\n\nTo select a single item, supply its ID in the items() function:\nexample_item &lt;- stac_source |&gt;\n  collections(\"sentinel-2-l2a\") |&gt;\n  items(\"S2A_MSIL2A_20250517T085541_N0511_R064_T35QKA_20250517T112203\") |&gt;\n  get_request()\n\nexample_item\n## ###Item\n## - id: S2A_MSIL2A_20250517T085541_N0511_R064_T35QKA_20250517T112203\n## - collection: sentinel-2-l2a\n## - bbox: xmin: 25.04240, ymin: 17.98988, xmax: 25.20347, ymax: 18.11305\n## - datetime: 2025-05-17T08:55:41.024000Z\n## - assets: \n## SR_10m, SR_20m, SR_60m, AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, SCL_20m, TCI_10m, WVP_10m, product, product_metadata\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\nThere are a number of helpful functions for working with an item’s assets, such as items_assets() which lists them:\n# List the assets in an item\nexample_item |&gt;\n  items_assets()\n##  [1] \"SR_10m\"           \"SR_20m\"           \"SR_60m\"           \"AOT_10m\"          \"B01_20m\"         \n##  [6] \"B02_10m\"          \"B03_10m\"          \"B04_10m\"          \"B05_20m\"          \"B06_20m\"         \n## [11] \"B07_20m\"          \"B08_10m\"          \"B09_60m\"          \"B11_20m\"          \"B12_20m\"         \n## [16] \"B8A_20m\"          \"SCL_20m\"          \"TCI_10m\"          \"WVP_10m\"          \"product\"         \n## [21] \"product_metadata\"\nAnd assets_select() which allows us to select specific assets (in this case, the “Surface Reflectance - 10m” asset):\nsr_10m &lt;- example_item |&gt;\n  assets_select(asset_names = \"SR_10m\")\n\nsr_10m\n## ###Item\n## - id: S2A_MSIL2A_20250517T085541_N0511_R064_T35QKA_20250517T112203\n## - collection: sentinel-2-l2a\n## - bbox: xmin: 25.04240, ymin: 17.98988, xmax: 25.20347, ymax: 18.11305\n## - datetime: 2025-05-17T08:55:41.024000Z\n## - assets: SR_10m\n## - item's fields: \n## assets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\nFor example, the “product” asset will be useful to working with EOPF Sample Service Zarr data, as this is the top-level Zarr hierarchy. We can select this asset, and then use assets_url() to get its URL:\nexample_item |&gt;\n  assets_select(asset_names = \"product\") |&gt;\n  assets_url()\n## [1] \"https://objectstore.eodc.eu:2222/e05ab01a9d56408d82ac32d69a5aae2a:202505-s02msil2a/17/products/cpm_v256/S2A_MSIL2A_20250517T085541_N0511_R064_T35QKA_20250517T112203.zarr\"\nIt is also helpful to know which assets actually contain Zarr data. Assets can be Zarr groups, which share common dimensions and coordinates, and contain Zarr arrays within them. An asset can also be an individual Zarr array.\nTo look more at this, we will extract metadata attached to the Zarr assets. The \"assets\" entry of example_item contains a lot of useful information, but it is a bit difficult to read and manipulate:\nnames(example_item[[\"assets\"]])\n##  [1] \"SR_10m\"           \"SR_20m\"           \"SR_60m\"           \"AOT_10m\"          \"B01_20m\"         \n##  [6] \"B02_10m\"          \"B03_10m\"          \"B04_10m\"          \"B05_20m\"          \"B06_20m\"         \n## [11] \"B07_20m\"          \"B08_10m\"          \"B09_60m\"          \"B11_20m\"          \"B12_20m\"         \n## [16] \"B8A_20m\"          \"SCL_20m\"          \"TCI_10m\"          \"WVP_10m\"          \"product\"         \n## [21] \"product_metadata\"\nexample_item[[\"assets\"]][[\"SR_10m\"]]\n## $gsd\n## [1] 10\n## \n## $href\n## [1] \"https://objectstore.eodc.eu:2222/e05ab01a9d56408d82ac32d69a5aae2a:202505-s02msil2a/17/products/cpm_v256/S2A_MSIL2A_20250517T085541_N0511_R064_T35QKA_20250517T112203.zarr/measurements/reflectance/r10m\"\n## \n## $type\n## [1] \"application/vnd+zarr\"\n## \n## $bands\n## $bands[[1]]\n## $bands[[1]]$name\n## [1] \"B02\"\n## \n## $bands[[1]]$common_name\n## [1] \"blue\"\n## \n## $bands[[1]]$description\n## [1] \"Blue (band 2)\"\n## \n## $bands[[1]]$center_wavelength\n## [1] 0.49\n## \n## $bands[[1]]$full_width_half_max\n## [1] 0.098\n## \n## \n## $bands[[2]]\n## $bands[[2]]$name\n## [1] \"B03\"\n## \n## $bands[[2]]$common_name\n## [1] \"green\"\n## \n## $bands[[2]]$description\n## [1] \"Green (band 3)\"\n## \n## $bands[[2]]$center_wavelength\n## [1] 0.56\n## \n## $bands[[2]]$full_width_half_max\n## [1] 0.045\n## \n## \n## $bands[[3]]\n## $bands[[3]]$name\n## [1] \"B04\"\n## \n## $bands[[3]]$common_name\n## [1] \"red\"\n## \n## $bands[[3]]$description\n## [1] \"Red (band 4)\"\n## \n## $bands[[3]]$center_wavelength\n## [1] 0.665\n## \n## $bands[[3]]$full_width_half_max\n## [1] 0.038\n## \n## \n## $bands[[4]]\n## $bands[[4]]$name\n## [1] \"B08\"\n## \n## $bands[[4]]$common_name\n## [1] \"nir\"\n## \n## $bands[[4]]$description\n## [1] \"NIR 1 (band 8)\"\n## \n## $bands[[4]]$center_wavelength\n## [1] 0.842\n## \n## $bands[[4]]$full_width_half_max\n## [1] 0.145\n## \n## \n## \n## $roles\n## [1] \"data\"        \"reflectance\" \"dataset\"    \n## \n## $title\n## [1] \"Surface Reflectance - 10m\"\n## \n## $`xarray:open_dataset_kwargs`\n## $`xarray:open_dataset_kwargs`$chunks\n## named list()\n## \n## $`xarray:open_dataset_kwargs`$engine\n## [1] \"eopf-zarr\"\n## \n## $`xarray:open_dataset_kwargs`$op_mode\n## [1] \"native\"\nSo, we will reformat it to be easier to work with. To do so, we first load the tidyverse package for data manipulation (installing it first, if necessary):\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)\nWe will retain only the title and roles of each asset.\nasset_metadata &lt;- example_item[[\"assets\"]] |&gt;\n  map(\\(asset) {\n    asset[c(\"title\", \"roles\")]\n  })\n\nhead(asset_metadata, 5)\n## $SR_10m\n## $SR_10m$title\n## [1] \"Surface Reflectance - 10m\"\n## \n## $SR_10m$roles\n## [1] \"data\"        \"reflectance\" \"dataset\"    \n## \n## \n## $SR_20m\n## $SR_20m$title\n## [1] \"Surface Reflectance - 20m\"\n## \n## $SR_20m$roles\n## [1] \"data\"        \"reflectance\" \"dataset\"    \n## \n## \n## $SR_60m\n## $SR_60m$title\n## [1] \"Surface Reflectance - 60m\"\n## \n## $SR_60m$roles\n## [1] \"data\"        \"reflectance\" \"dataset\"    \n## \n## \n## $AOT_10m\n## $AOT_10m$title\n## [1] \"Aerosol optical thickness (AOT)\"\n## \n## $AOT_10m$roles\n## [1] \"data\"\n## \n## \n## $B01_20m\n## $B01_20m$title\n## [1] \"Coastal aerosol (band 1) - 20m\"\n## \n## $B01_20m$roles\n## [1] \"data\"        \"reflectance\"\nThen, we can filter to only keep assets who have the roles “dataset” (these are Zarr groups):\nasset_metadata |&gt;\n  keep(\\(asset) {\n    \"dataset\" %in% asset[[\"roles\"]]\n  })\n## $SR_10m\n## $SR_10m$title\n## [1] \"Surface Reflectance - 10m\"\n## \n## $SR_10m$roles\n## [1] \"data\"        \"reflectance\" \"dataset\"    \n## \n## \n## $SR_20m\n## $SR_20m$title\n## [1] \"Surface Reflectance - 20m\"\n## \n## $SR_20m$roles\n## [1] \"data\"        \"reflectance\" \"dataset\"    \n## \n## \n## $SR_60m\n## $SR_60m$title\n## [1] \"Surface Reflectance - 60m\"\n## \n## $SR_60m$roles\n## [1] \"data\"        \"reflectance\" \"dataset\"\nOr to those who have roles “data”, but not “dataset” or “metadata” (these are individual Zarr arrays):\nzarr_arrays &lt;- asset_metadata |&gt;\n  keep(\\(asset) {\n    \"data\" %in% asset[[\"roles\"]] & \n      !(\"dataset\" %in% asset[[\"roles\"]] | \"metadata\" %in% asset[[\"roles\"]])\n  })\n\nnames(zarr_arrays)\n##  [1] \"AOT_10m\" \"B01_20m\" \"B02_10m\" \"B03_10m\" \"B04_10m\" \"B05_20m\" \"B06_20m\" \"B07_20m\" \"B08_10m\"\n## [10] \"B09_60m\" \"B11_20m\" \"B12_20m\" \"B8A_20m\" \"SCL_20m\" \"TCI_10m\" \"WVP_10m\"\nhead(zarr_arrays, 3)\n## $AOT_10m\n## $AOT_10m$title\n## [1] \"Aerosol optical thickness (AOT)\"\n## \n## $AOT_10m$roles\n## [1] \"data\"\n## \n## \n## $B01_20m\n## $B01_20m$title\n## [1] \"Coastal aerosol (band 1) - 20m\"\n## \n## $B01_20m$roles\n## [1] \"data\"        \"reflectance\"\n## \n## \n## $B02_10m\n## $B02_10m$title\n## [1] \"Blue (band 2) - 10m\"\n## \n## $B02_10m$roles\n## [1] \"data\"        \"reflectance\"",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "51_eopf_stac_r.html#now-it-is-your-turn",
    "href": "51_eopf_stac_r.html#now-it-is-your-turn",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "💪 Now it is your turn",
    "text": "💪 Now it is your turn\nThe following expercises will help you master the STAC API and understand how to find the data you need.\n\nTask 1: Explore Your Area of Interest\n\nGo to http://bboxfinder.com/ and select an area of interest (AOI) (e.g. your hometown, a research site, etc.)\nCopy the bounding box coordinates of your area of interest\nChange the provided code above to search for data over your AOI\n\n\n\nTask 2: Temporal Analysis\n\nCompare data availability across different years for the Sentinel-2 L-2A Collection.\nSearch for items in the year 2022\nRepeat the search for the year 2024\n\n\n\nTask 3: Explore the SAR Mission and combine multiple criteria\n\nDo the same for a different Collection, the Sentinel-1 Level-1 GRD, e.g. you can use the ID sentinel-1-l1-grd\nHow many assets are available for the year 2024?",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "51_eopf_stac_r.html#conclusion",
    "href": "51_eopf_stac_r.html#conclusion",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial has provided a clear and practical introduction on how you can programmatically access and search through EOPF Sentinel Zarr Sample Service STAC API using R.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "51_eopf_stac_r.html#whats-next",
    "href": "51_eopf_stac_r.html#whats-next",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "What’s next?",
    "text": "What’s next?\nA tutorial on how to load an item of interest and load the Zarr data into R is coming to EOPF-101 soon! For now, please view this next tutorial in the EOPF tooling guide.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "61_sardinia_s2_tfci.html",
    "href": "61_sardinia_s2_tfci.html",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "",
    "text": "Introduction\n🚀 Launch this notebook in JupyterLab\nCommunities and ecosystems worldwide are under increasing threat from wildfires, a problem that is being made worse by climate change.\nMonitoring these events is crucial, and satellite imagery is an invaluable tool in this effort. The Sentinel satellite missions offer valuable insights into the different stages of a fire. A True Colour Composite of Sentinel-2 data can be used to track smoke, False Colour Composites can clearly distinguish healthy vegetation from damaged or burnt areas. Furthermore, True- or False color composites can be combined with other data sources, such as Land Surface Temperature (LST) from Sentinel-3. Temperature anomalies retrieved from Sentinel-3 data are useful information to get a more comprehensive picture of a fire event.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "61_sardinia_s2_tfci.html#setting-up-the-environment",
    "href": "61_sardinia_s2_tfci.html#setting-up-the-environment",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Setting up the environment",
    "text": "Setting up the environment\n\nDefining parameters for querying the EOPF STAC catalog\nAs a first step, we need to define specific parameters for our query, including:\n\ntwo key dates for our comparison: one date for a pre-fire view, 3rd of June 2025 (one week before the event) and a second for the post-fire view on 21st June 2025 (10 days after)\nthe data collection we are interested in, and\nbounding box information for the area of interest.\n\nIn addition, we set the appropriate re-projection parameters to ensure a smooth and efficient workflow.\n\n# The timeframe and area of interest for our filtering\ndef_collection = 'sentinel-2-l2a' # collection\n# Before the fire:\npre_f  = '2025-06-03'\n# After the fire:\npost_f = '2025-06-21'\n\nsearch_bbox = (8.847198,40.193395,8.938865,40.241895)\n\n# Definition of the transformer parameters from lat/lon to UTM that ensure\n# correct overlay of layers\ntransformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32632\", always_xy=True)\n\nt_utm_to_deg = Transformer.from_crs(\"EPSG:32632\",\"EPSG:4326\", always_xy=True)\n\n\n\nInitiate a Dask cluster\nIn a next step we initiate a virtual Dask cluster. This cluster consists of a scheduler (the “brain”) and several workers (the “hands”), which enables faster processing of large datasets by breaking down tasks and running them in parallel.  A client is then created to manage communication between the code and this cluster.\nFor more information, feel free to visit the dask documentation and the tutorial How to use dask.\n\n# To track the the performance the code will have\nst = time.time()\n\ncluster = LocalCluster()\nclient = cluster.get_client()\nclient\n\n\n     \n    \n        Client\n        Client-b7d14e30-aa0d-11f0-92a3-56b7a1fe0ab7\n        \n\n\n\nConnection method: Cluster object\nCluster type: distributed.LocalCluster\n\n\nDashboard: http://127.0.0.1:8787/status\n\n\n\n\n\n\n        \n\n        \n            \n            Cluster Info\n            \n    \n    \n    \n        LocalCluster\n        1ac5ba06\n        \n\n\n\nDashboard: http://127.0.0.1:8787/status\nWorkers: 4\n\n\nTotal threads: 4\nTotal memory: 15.62 GiB\n\n\nStatus: running\nUsing processes: True\n\n\n\n\n\n        \n            \n                Scheduler Info\n            \n\n            \n    \n         \n        \n            Scheduler\n            Scheduler-14b77294-eba8-4c88-8448-870518668c5f\n            \n\n\n\nComm: tcp://127.0.0.1:41695\nWorkers: 0\n\n\nDashboard: http://127.0.0.1:8787/status\nTotal threads: 0\n\n\nStarted: Just now\nTotal memory: 0 B\n\n\n\n\n        \n    \n\n    \n        \n            Workers\n        \n\n        \n        \n             \n            \n            \n                \n                    Worker: 0\n                \n                \n\n\n\nComm: tcp://127.0.0.1:46331\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:40617/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:34955\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-nooo2_cr\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 1\n                \n                \n\n\n\nComm: tcp://127.0.0.1:35299\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:45937/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:34985\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-n3lderya\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 2\n                \n                \n\n\n\nComm: tcp://127.0.0.1:33171\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:44999/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:41633\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-lvxdrqro\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 3\n                \n                \n\n\n\nComm: tcp://127.0.0.1:40511\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:42647/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:32989\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-kk3oqzw_\n\n\n\n\n            \n            \n        \n        \n\n    \n\n\n        \n    \n\n            \n        \n\n    \n\n\n\n\n\nEstablish a connection to the EOPF STAC Catalog\nData is retrieved from the endpoint of the EOPF STAC Catalog. We can do this with the function Client.open() from the pystac_client library.\n\neopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\" #root starting point\neopf_catalog = Client.open(url=eopf_stac_api_root_endpoint) # calls the selected url",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "61_sardinia_s2_tfci.html#pre-fire-visualisation",
    "href": "61_sardinia_s2_tfci.html#pre-fire-visualisation",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Pre-Fire Visualisation",
    "text": "Pre-Fire Visualisation\nThe first step is to create a visual representation of our area of interest for a day before the fire occured: 3 June 2025. We will use the parameters we defined at the beginning to query the STAC collection and retrieve the specific pre-fire images needed for our analysis.\nWith the search() function, you can query a STAC catalog based on given keyword arguments. As a result of the search, you see that one Item is returned from the STAC Catalog.\n\n# Interest timeframe parameters for the filtering\ndate_pre = pre_f + 'T00:00:00Z/' + pre_f + 'T23:59:59.999999Z' # interest period\ns2_col = list(eopf_catalog.search(\n                bbox= search_bbox, # area\n                datetime= date_pre, #time frame\n                collections=def_collection # collection\n                ).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_col]  # stores the available Items URLs\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-2 L2A over Sardinia:  ',len(av_urls))\n\nSearch Results:\nTotal Items Found for Sentinel-2 L2A over Sardinia:   1\n\n\nNow, we can retrieve the item and directly and open it as a xarray.DataTree. In addition, key information from the item’s properties is also extracted to verify key properties of the item.\n\n# We are interested in the datasets contained in the measurements bands for True Colour and False Colour Composites.\ns2_zarr = xr.open_datatree(\n    av_urls[0], engine=\"zarr\", #we always get the earliest one (the first available item goes last)\n    chunks={},\n    decode_timedelta=False\n    )\n\n# Store interest parameters for further plotting:\ndate = s2_zarr.attrs['stac_discovery']['properties']['start_datetime'][:10]\ntime_zarr = s2_zarr.attrs['stac_discovery']['properties']['start_datetime'][11:19]\ntarget_crs = s2_zarr.attrs[\"stac_discovery\"][\"properties\"][\"proj:epsg\"]\n\nprint(f'Item for the {date} at {time_zarr}')\n\nItem for the 2025-06-03 at 10:10:41\n\n\nThe spectral bands we will need for our analysis are found within the /reflectance group, specifically under the r20m subgroup.\nBefore directly processing our assets of interest, we will filter out invalid pixels, such as pixels containing clouds, cloud shadows, or areas with no data. We will use the Scene Classification Layer (SCL) available inside the .zarr item, which is a separate asset located under the /classification/r20m group.\nBy using the pre-defined validate_scl() function, we can create a boolean mask that masks out invalid pixels.\n\n# Extract the resolution group we are interested to analyse over:\nzarr_meas = s2_zarr.measurements.reflectance.r20m\n\n# Extract the Scene Classification Layer at 20m resolution:\nl2a_class_20m = s2_zarr.conditions.mask.l2a_classification.r20m.scl\n\n# Apply the function `validatae_scl` to mask out invalid pixels\nvalid_mask = validate_scl(l2a_class_20m)\n\nThe visualisation we are intending to create covers a larger extent than the specific fire area. This helps us to better understand the event’s overall spatial extent. For this, we generate a bounding box to visually pinpoint the fire’s precise location within a wider composite image.\n\n# Defining a larger bounding box for better visualisation:\nbbox_vis = (8.649555,40.073583,9.127893,40.343840)\n\n# A fixed geographic bounding box to highlight the AOI in the map format\nmap_box = search_bbox\n\nIn next step, we need to reproject the area of interest from EPSG: 4326 to UTM coordinates. Once the area is defined, our loaded data (zarr_meas) is masked using the defined bbox_utm. After extracting the area, only the valid pixels are selected.\n\n# A new list with the converted UTM coordinates\nbbox_utm = lat_lon_to_utm_box((bbox_vis[0], bbox_vis[1]),(bbox_vis[2], bbox_vis[3]),transformer)\n\n# Use the box() function to create a polygon from the coordinates\nmap_box = box(map_box[0],map_box[1],map_box[2],map_box[3])\n\n# Boolean mask for the 'x' dimension (longitude/easting)\nx_mask = (zarr_meas['x'] &gt;= bbox_utm[0]) & (zarr_meas['x'] &lt;= bbox_utm[2])\n# Boolean mask for the 'y' dimension (latitude/northing)\ny_mask = (zarr_meas['y'] &gt;= bbox_utm[1]) & (zarr_meas['y'] &lt;= bbox_utm[3])\n\n# Combined mask for the bounding box\nbbox_mask = x_mask & y_mask\n\n# Extract row and column indices where the mask is True\ncols,rows = np.where(bbox_mask)\n\n\nPre-Fire True Colour Image\nOnce we have created the necessary masks, we can proceed to create True Color Image composites. For the composite creation, zarr_meas contains the assets we are interested in. The TCI composite makes use of the red (B04), green (B03), and blue (B02) bands to create a view that looks natural to the human eye.\nxarray’s where() function allows us to apply the SLC filtering we had previously defined.\n\n# True colour channels we are interested to retrieve composite:\ntc_red  = 'b04'\ntc_green= 'b03'\ntc_blue = 'b02'\n\n# The tc_red, tc_green, and tc_blue variables are inputs specifying the band names\nred = zarr_meas[tc_red].where(valid_mask)\ngre = zarr_meas[tc_green].where(valid_mask)\nblu = zarr_meas[tc_blue].where(valid_mask)\n\n# Visualising the green band:\nplt.imshow(gre)\nplt.title('Green Reflectance (b03)')\n\nText(0.5, 1.0, 'Green Reflectance (b03)')\n\n\n\n\n\n\n\n\n\nThe next step is to clip the retrieved asset to our area of interest which we defined earlier with specific bounding box information. We can apply the mask_sub_utm() function, which will masks the three bands to the defined bounding box.\nIt is important to point out that until now, we have not accessed on disk the data. Once we add the .values argument to the resulting _ from mask_sub_utm(), the data is accessed.\n.zarr contains x and y information for each of the pixels, and storing these values for a further geolocalisation of our item of interest is essential.\nYou can visualise the blue (B02) band to verify the clipped area.\n\n# The mask_sub_utm() function takes the bands and masks them to the valid rows and columns from the bbox_mask\nred = mask_sub_utm(red,rows, cols).values\ngre = mask_sub_utm(gre,rows, cols).values\nblu = mask_sub_utm(blu,rows, cols).values\n\n# The zarr_meas group is the input dataset containing the dimensions\n# by slicing the 'y' dimension array based on the minimum and maximum row indices\ny_zarr = zarr_meas['y'].isel(y=slice(rows.min(), rows.max() + 1)).values\n# also, the same for the 'x' dimension array based on the minimum and maximum column indices\nx_zarr = zarr_meas['x'].isel(x=slice(cols.min(), cols.max() + 1)).values\n\n# We transform the original x,y bbox from our clip to decimal degree coordinates\nmap_ext_deg_pre = list(t_utm_to_deg.transform(np.nanmin(x_zarr),np.nanmin(y_zarr)) + \n                   t_utm_to_deg.transform(np.nanmax(x_zarr),np.nanmax(y_zarr)))\n\n# Visualising the clipped red band:\nplt.imshow(blu)\nplt.title('Clipped Blue Reflectance (b02)')\n\nText(0.5, 1.0, 'Clipped Blue Reflectance (b02)')\n\n\n\n\n\n\n\n\n\nTo create the composite image, we need to normalise each of the input assets. Normalisation ensures that the bands have a consistent and predictable range of values. This supports optimal data processing and removes the influence of external factors (like changing light conditions) allowing for a meaningful comparison among generated composites.\nThe normalisation_str_gm() function achieves this by scaling the reflectance values to a standard range (0-255) using the percentile-based method.\nOnce the values for our three bands have been normalised, they can be stacked in an RGB format to generate the initial True Colour Image (TCI).\n\n# Input: percentile range for contrast stretching\ncontrast_stretch_percentile=(2, 98)\n# Input: gamma correction value\ngamma=1.8\n\n# Apply normalisation to the red, green and blue bands using the specified percentile and gamma values\nred_processed = normalisation_str_gm(red, *contrast_stretch_percentile, gamma)\ngreen_processed = normalisation_str_gm(gre, *contrast_stretch_percentile, gamma)\nblue_processed = normalisation_str_gm(blu, *contrast_stretch_percentile, gamma)\n\n# We stack the processed red, green, and blue arrays\nrgb_composite_sm = np.dstack((red_processed, green_processed, blue_processed)).astype(np.float32)\n\nplt.imshow(rgb_composite_sm)\nplt.title('RGB Composite')\n\nText(0.5, 1.0, 'RGB Composite')\n\n\n\n\n\n\n\n\n\nThe image is currently displayed with a neutral colour ramp and with the non-valid masked pixels. Some of the details can be enhanced based on the information the overall composite contains.\nFor this, we can apply a histogram equalisation. This technique will adjust the brightness and improve the visibility of details within our image.  Through the skimage library, we can apply the exposure.equalize_adapthist() function. This method creates a more natural-looking and visually balanced composite.\n\n#Adding equalisation from skimage:\nfire_tc = exposure.equalize_adapthist(rgb_composite_sm)\n\nplt.imshow(fire_tc)\nplt.title('Equalised Composite') # Add a title for clarity\n\nText(0.5, 1.0, 'Equalised Composite')\n\n\n\n\n\n\n\n\n\n\n\nPre-Fire False Colour Image\nNext, a False Colour Image (FCI) is created to provide a clearer overview of vegetation health.\nThis image uses the Shortwave Infrared (B12), Near-Infrared (B8a), and Blue (B02) bands. This specific combination enhances the distinction between healthy vegetation, which appears green, and damaged or burnt areas, which are shown in vivid, contrasting colours.\nThis False Colour composite will help us to better highlight the full extent of the fire.\n\n# The false colour channels we are interested to retrieve coposite:\nfc_swir = 'b12'\nfc_nir =  'b8a'\nfc_blue = 'b02'\n\nFollowing the same principle as of the creation of the True Colour composite, we can choose the relevant bands and apply the masking and clipping steps.\n\n# The zarr_meas object is the input dataset containing the bands, fc_red, fc_green, fc_blue specify the bands\n# The where() method is used to apply the boolean valid_mask to the bands\nswir = zarr_meas[fc_swir].where(valid_mask)\nnir =  zarr_meas[fc_nir].where(valid_mask)\nblu =  zarr_meas[fc_blue].where(valid_mask)\n\n# The mask_sub_utm() function takes the bands and masks them to the specified rows and columns\nswir = mask_sub_utm(swir,rows, cols).values\nnir = mask_sub_utm(nir,rows, cols).values\nblu = mask_sub_utm(blu,rows, cols).values\n\nThen, we can apply the normalisation function, followed by the stacking of the three bands. The False Colour composite $$$ explain the colouring\n\n# Apply the normalisation function to each band\nswir_processed = normalisation_str_gm(swir, *contrast_stretch_percentile, gamma)\nnir_processed = normalisation_str_gm(nir, *contrast_stretch_percentile, gamma)\nblue_processed = normalisation_str_gm(blu, *contrast_stretch_percentile, gamma)\n\n# Use np.dstack to create a false-colour composite from the processed bands\nfalse_composite= np.dstack((swir_processed, nir_processed, blue_processed)).astype(np.float32)\n\n# Output:\nplt.imshow(false_composite)\nplt.title('False Composite')\n\nText(0.5, 1.0, 'False Composite')\n\n\n\n\n\n\n\n\n\nWe then continue and also apply the equalisation function.\n\n# Apply adaptive histogram equalisation to enhance contrast for fire detection\nfire_fc = exposure.equalize_adapthist(false_composite)\n\n# Create a figure to plot\n\nplt.imshow(fire_fc)\nplt.title('Equalised False Composite')\n\nText(0.5, 1.0, 'Equalised False Composite')",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "61_sardinia_s2_tfci.html#post-fire-visualisation",
    "href": "61_sardinia_s2_tfci.html#post-fire-visualisation",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Post-Fire Visualisation",
    "text": "Post-Fire Visualisation\nNow, we will replicate the same visualisation for a specific time after the fire: 10 June 2025. Considering this new date, we will retrieve images from the same collection that correspond to our new timeframe of interest.\n\ndate_post = post_f + 'T00:00:00Z/' + post_f + 'T23:59:59.999999Z' # interest period\n\ns2_post = list(eopf_catalog.search(\n                bbox= search_bbox, \n                datetime= date_post,\n                collections=def_collection).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_post]\nav_urls\n\n['https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202506-s02msil2a/21/products/cpm_v256/S2C_MSIL2A_20250621T100611_N0511_R022_T32TMK_20250623T084315.zarr']\n\n\nWe open again the the retrieved item from our filtered results, followed by the masking and validation steps to ensure a clean, cloud-free composite.\n\npost_zarr = xr.open_datatree(\n    av_urls[0], engine=\"zarr\", #we always get the earliest one (last)\n    chunks={},\n    decode_timedelta=False\n    )\n\nzarr_meas = post_zarr.measurements.reflectance.r20m\n\n# Extractthe cloud free mask at 20m resolution:\nl2a_class_20m = post_zarr.conditions.mask.l2a_classification.r20m.scl\n\nvalid_mask = validate_scl(l2a_class_20m)  # Boolean mask (10980x10980)\n\n\nPost-Fire True Colour Image\nOnce invalid pixels are filtered out, we can generate the corresponding True-Color composite to get a view of our area of interest after the fire event. We again clip the retrieved assets to our specific bounding box.\n\n# Create UTM masks for rows and columns based on the bounding box.\ncols_post, rows_post = zarr_mask_utm(bbox_utm, zarr_meas)\n\n# Select the red, green, and blue bands and apply the valid mask.\nred = zarr_meas[tc_red].where(valid_mask)\ngre =  zarr_meas[tc_green].where(valid_mask)\nblu =  zarr_meas[tc_blue].where(valid_mask)\n\n# Mask and clip the selected bands using the row and column indices.\nred = mask_sub_utm(red,rows_post, cols_post).values\ngre = mask_sub_utm(gre,rows_post, cols_post).values\nblu = mask_sub_utm(blu,rows_post, cols_post).values\n\n# Slice the y-dimension values using the new row indices.\ny_zarr = zarr_meas['y'].isel(y=slice(rows_post.min(), rows_post.max() + 1)).values\n# Slice the x-dimension values using the new column indices.\nx_zarr = zarr_meas['x'].isel(x=slice(cols_post.min(), cols_post.max() + 1)).values\n\n# We transform the original x,y bbox from our clip to decimal degree coordinates\nmap_ext_deg_post = list(t_utm_to_deg.transform(np.nanmin(x_zarr),np.nanmin(y_zarr)) + \n                   t_utm_to_deg.transform(np.nanmax(x_zarr),np.nanmax(y_zarr)))\n\nAnd, once the new area is defined, we normalise, stack and equalize the composite.\n\n# Apply normalisation and gamma correction to the red, green, and blue bands.\nred_processed = normalisation_str_gm(red, *contrast_stretch_percentile, gamma)\ngreen_processed = normalisation_str_gm(gre, *contrast_stretch_percentile, gamma)\nblue_processed = normalisation_str_gm(blu, *contrast_stretch_percentile, gamma)\n\n# Stack the processed bands to create a single true-colour composite image.\nrgb_composite_sm = np.dstack((red_processed, green_processed, blue_processed)).astype(np.float32)\n\n# Apply adaptive histogram equalisation to enhance the composite image.\ntc_post = exposure.equalize_adapthist(rgb_composite_sm)\n\nplt.imshow(tc_post)\nplt.title('Equalised Composite') # Add a title for clarity\n\nText(0.5, 1.0, 'Equalised Composite')\n\n\n\n\n\n\n\n\n\n\n\nPost-Fire False Colour Image\nAnd as the last processing step, we create the False Colour composite for the same day, to clearly visualise the extent of the burn scars and vegetation recovery.\n\n# Select the red, green, and blue bands and apply the valid mask.\n\nswir = zarr_meas[fc_swir].where(valid_mask)\nnir =  zarr_meas[fc_nir].where(valid_mask)\nblu =  zarr_meas[fc_blue].where(valid_mask)\n\n# Mask and clip the selected bands using the row and column indices.\n\nswir = mask_sub_utm(swir,rows_post, cols_post).values\nnir = mask_sub_utm(nir,rows_post, cols_post).values\nblu = mask_sub_utm(blu,rows_post, cols_post).values\n\n# Apply normalisation and gamma correction to the red, green, and blue bands.\n\nswir_processed = normalisation_str_gm(swir, *contrast_stretch_percentile, gamma)\nnir_processed = normalisation_str_gm(nir, *contrast_stretch_percentile, gamma)\nblue_processed = normalisation_str_gm(blu, *contrast_stretch_percentile, gamma)\n\n\n# Stack the processed bands to create a single false-colour composite image.\nfalse_composite= np.dstack((swir_processed, nir_processed, blue_processed)).astype(np.float32)\n\n# Apply adaptive histogram equalisation to enhance the composite image.\nfc_post = exposure.equalize_adapthist(false_composite)\n\nplt.imshow(fc_post)\nplt.title('Equalised Composite') # Add a title for clarity\n\nText(0.5, 1.0, 'Equalised Composite')",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "61_sardinia_s2_tfci.html#compare-pre--and-post-fire-composites",
    "href": "61_sardinia_s2_tfci.html#compare-pre--and-post-fire-composites",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Compare pre- and post-fire composites",
    "text": "Compare pre- and post-fire composites\nAs a last step, we will georeference and visualise the created composites together, presenting it in a way that makes it easier to recognise and understand the monitored areas.\nWe will use the cartopy library to pinpoint the location of our georeferenced datasets based on their CRS and geospatial bounding box. The visualisation will be a 2x2 matrix, offering a comprehensive, multi-channel overview.\nFinally, the plot will be enhanced by adding key elements such as grid lines for improved geolocation, a clear title, and a bounding box to highlight the specific area of the fire. This approach allows for a direct visual comparison of the landscape’s state before and after the event.\n\ndata_ll = ccrs.PlateCarree()\n\nfig, axs = plt.subplots(2, 2, figsize=(15, 9), subplot_kw={'projection': data_ll})\n\n# Pre fire TCI\nax1 = axs[0,0]\nax1.imshow(fire_tc, origin='upper',\n                extent=[map_ext_deg_pre[0],map_ext_deg_pre[2],\n                        map_ext_deg_pre[1],map_ext_deg_pre[3]],  # item\n                transform=data_ll)\nax1.add_geometries(map_box, crs=data_ll, facecolor='none', \n                   edgecolor='yellow', linewidth=2, linestyle='-')\nax1.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # gridlines and labels\nax1.set_title(f'TCI for {pre_f}')\n\n# Pre fire FCI\nax2 = axs[0,1]\nax2.imshow(fire_fc, origin='upper',\n                extent=[map_ext_deg_pre[0],map_ext_deg_pre[2],\n                        map_ext_deg_pre[1],map_ext_deg_pre[3]],  # item\n                transform=data_ll)\nax2.add_geometries(map_box, crs=data_ll, facecolor='none', \n                   edgecolor='yellow', linewidth=2, linestyle='-')\nax2.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # gridlines and labels\nax2.set_title(f'FCI for {pre_f}')\n\n#Post fire TCO\nax3 = axs[1,0]\nax3.imshow(tc_post, origin='upper',\n                extent=[map_ext_deg_post[0],map_ext_deg_post[2],\n                        map_ext_deg_post[1],map_ext_deg_post[3]],  # item\n                transform=data_ll)\nax3.add_geometries(map_box, crs=data_ll, facecolor='none', \n                   edgecolor='yellow', linewidth=2, linestyle='-')\nax3.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # gridlines and labels\nax3.set_title(f'TCI for {post_f}')\n\n# Post fire FCI\nax4 = axs[1,1]\nax4.imshow(fc_post, origin='upper',\n                extent=[map_ext_deg_post[0],map_ext_deg_post[2],\n                        map_ext_deg_post[1],map_ext_deg_post[3]],  # item\n                transform=data_ll)\nax4.add_geometries(map_box, crs=data_ll, facecolor='none', \n                   edgecolor='yellow', linewidth=2, linestyle='-')\nax4.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # gridlines and labels\nax4.set_title(f'FCI for {post_f}')\n\n# Adjust the layout to prevent titles from overlapping\nfig.suptitle(f'Sentinel-2 L2A TCI and FCI', fontsize=16)\n# Display the combined plot\nplt.show()",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "61_sardinia_s2_tfci.html#calculating-processing-time",
    "href": "61_sardinia_s2_tfci.html#calculating-processing-time",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Calculating processing time",
    "text": "Calculating processing time\n\net = time.time()\n\ntotal_t = et - st\n\nprint('Total Running Time: ', total_t,' seconds')\n\nTotal Running Time:  60.672173738479614  seconds\n\n\nAs our plots show, the True Colour Image reveals a clear change in the state of the vegetation, with an evident burn scar visible on the ground. The False Colour Image also highlights a significant change in the spectral response, which precisely encloses the spot where the fire occurred.\nIt is important to note the efficiency of this monitoring workflow. The entire process from defining the area of interest to searching, accessing, processing, and visualising the data takes less than a minute, without the need to download data.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "61_sardinia_s2_tfci.html#conclusion",
    "href": "61_sardinia_s2_tfci.html#conclusion",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Conclusion",
    "text": "Conclusion\nHaving processed the key spectral bands, we have successfully established a visual baseline for our monitoring workflow.\nThe generation of these composites allows us to quickly gain an overview of the spatial changes resulting from a fire event, as observed by Sentinel-2 L-2A.\nThis workflow is highly replicable, enabling us to replicate these defined steps at various points in time. This ability to generate consistent visualisations will allow us to understand the full dynamics of a fire’s event lifecycle over time, from its beginning to the subsequent recovery of the landscape.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "61_sardinia_s2_tfci.html#whats-next",
    "href": "61_sardinia_s2_tfci.html#whats-next",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "What’s next?",
    "text": "What’s next?\nIn the next tutorial, we will apply the workflow we have generated to create a True Colour Image from Sentinel-2 L2A data for the day of the fire.\nTo obtain a more detailed overview of the fire’s state, we will integrate a new dataset into our workflow: Sentinel-3 data. This will enable us to analyse thermal information and pinpoint the active fire’s location.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "62_sardinia_s3_lst.html",
    "href": "62_sardinia_s3_lst.html",
    "title": "Fire in Sardinia 2025 - Part 2",
    "section": "",
    "text": "Introduction\n🚀 Launch this notebook in JupyterLab\nOn June 10th, 2025, a significant wildfire in Italy’s Nuoro Province in Sardinia burned approximately 1000 hectares, a scale that is clearly visible in satellite imagery with a 20-meter resolution. The European Forest Fire Information System (EFFIS) keeps record of these events.\nThis notebook demonstrates how two different .zarr encoded Sentinel Mission products can be combined to provide a compelling and informative overview of an active fire event.\nFirst, we will use reflectance data from Sentinel-2 L2A to locate the area of the fire on the ground. At the same time, we will use data from Sentinel-3 SLSTR Land Surface Temperature (LST) to demonstrate the intense heat emanating from the fire.\nBy combining these two datasets, we will not only be able to see the fire location and its state on the day of the event, but also understand its thermal intensity, providing a more complete perspective on its dynamics.\nThis notebook is the second a series of three notebook:",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 2</span>"
    ]
  },
  {
    "objectID": "62_sardinia_s3_lst.html#setting-up-the-environment",
    "href": "62_sardinia_s3_lst.html#setting-up-the-environment",
    "title": "Fire in Sardinia 2025 - Part 2",
    "section": "Setting up the environment",
    "text": "Setting up the environment\n\nInitiate a Dask cluster\nThe first step is to initiate a virtual Dask cluster. This cluster consists of a scheduler (the “brain”) and several workers (the “hands”), which enables faster processing of large datasets by breaking down tasks and running them in parallel.\nA client is then created to manage communication between the code and this cluster. For more information, feel free to visit the dask documentation and the tutorial How to use dask.\n\n# we are interested in the performance the code will have\nst = time.time()\n\ncluster = LocalCluster()\nclient = cluster.get_client()\nclient\n\n\n     \n    \n        Client\n        Client-e208f7b9-aa0d-11f0-93b4-56b7a1fe0ab7\n        \n\n\n\nConnection method: Cluster object\nCluster type: distributed.LocalCluster\n\n\nDashboard: http://127.0.0.1:8787/status\n\n\n\n\n\n\n        \n\n        \n            \n            Cluster Info\n            \n    \n    \n    \n        LocalCluster\n        7ce7a983\n        \n\n\n\nDashboard: http://127.0.0.1:8787/status\nWorkers: 4\n\n\nTotal threads: 4\nTotal memory: 15.62 GiB\n\n\nStatus: running\nUsing processes: True\n\n\n\n\n\n        \n            \n                Scheduler Info\n            \n\n            \n    \n         \n        \n            Scheduler\n            Scheduler-4d487ac2-3564-4816-9807-29f820becf91\n            \n\n\n\nComm: tcp://127.0.0.1:40203\nWorkers: 0\n\n\nDashboard: http://127.0.0.1:8787/status\nTotal threads: 0\n\n\nStarted: Just now\nTotal memory: 0 B\n\n\n\n\n        \n    \n\n    \n        \n            Workers\n        \n\n        \n        \n             \n            \n            \n                \n                    Worker: 0\n                \n                \n\n\n\nComm: tcp://127.0.0.1:32879\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:45469/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:33729\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-gesbs9hd\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 1\n                \n                \n\n\n\nComm: tcp://127.0.0.1:45855\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:39761/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:40559\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-6vf6lh6m\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 2\n                \n                \n\n\n\nComm: tcp://127.0.0.1:43193\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:36411/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:46483\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-sult12wf\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 3\n                \n                \n\n\n\nComm: tcp://127.0.0.1:36819\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:40129/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:38049\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-mx55e5h4\n\n\n\n\n            \n            \n        \n        \n\n    \n\n\n        \n    \n\n            \n        \n\n    \n\n\n\n\n\nEstablish a connection to the EOPF STAC Catalog\nData is retrieved from the EOPF STAC Catalogue endpoint. Once the connection is established, we can query the catalog based on specific search criteria.\n\neopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\" #root starting point\neopf_catalog = Client.open(url=eopf_stac_api_root_endpoint) # calls the selected url\neopf_catalog\n\n\n\n\n\n\n    &lt;Client id=eopf-sample-service-stac-api&gt;\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Catalog\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"eopf-sample-service-stac-api\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"STAC catalog of the EOPF Sentinel Zarr Samples Service\"\n        \n    \n                \n            \n                \n                    \n        links[] 20 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"conformance\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/conformance\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC/OGC conformance classes implemented by this server\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"POST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-2A\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lfr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l2-ocn\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-2 OCN\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l2-lst\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-2 LST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-grd\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 GRD\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l1c\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-1C\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-slc\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 SLC\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l1-rbt\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-1 RBT\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-efr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 EFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-err\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 ERR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lrr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LRR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \n        \n            \n                \n        \n            rel\n            \"service-desc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/vnd.oai.openapi+json;version=3.0\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service description\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \n        \n            \n                \n        \n            rel\n            \"service-doc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api.html\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service documentation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        conformsTo[] 21 items\n        \n            \n        \n            \n                \n        \n            0\n            \"http://www.opengis.net/spec/cql2/1.0/conf/basic-cql2\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-text\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/geojson\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/oas30\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/features-filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \"https://api.stacspec.org/v1.0.0-rc.2/item-search#filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \"https://api.stacspec.org/v1.0.0/collections\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \"https://api.stacspec.org/v1.0.0/collections/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \"https://api.stacspec.org/v1.0.0/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \"https://api.stacspec.org/v1.0.0/item-search\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \"https://api.stacspec.org/v1.0.0/item-search#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \"https://api.stacspec.org/v1.0.0/item-search#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \"https://api.stacspec.org/v1.0.0/item-search#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"\n        \n    \n                \n            \n        \n    \n\n\n\n\n\n\nDefine search paramters\n\n# The timeframe and area of interest for our filtering\nfire_d = '2025-06-11'\nfire_d_s3 = '2025-06-10'\ndef_collection = ''\n\nsearch_bbox = (8.847198,40.193395,8.938865,40.241895)\n\n# Definition of the transformer parameters for reprojection and correct overlay of layers\ntransformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32632\", always_xy=True)\nt_utm_to_deg = Transformer.from_crs(\"EPSG:32632\",\"EPSG:4326\", always_xy=True)\n\n# Defining a larger bounding box for better visualisation:\nbbox_vis = (8.649555,40.073583,9.127893,40.343840)\n\n# A fixed geographic bounding box to highlight the AOI in the map format\nmap_box = search_bbox\n\n# A new list with the converted UTM coordinates\nbbox_utm = lat_lon_to_utm_box((bbox_vis[0], bbox_vis[1]),(bbox_vis[2], bbox_vis[3]), transformer)\n\n# # Convert the coordinates of the map_box\n# map_box = lat_lon_to_utm_box((map_box[0], map_box[1]),(map_box[2], map_box[3]))",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 2</span>"
    ]
  },
  {
    "objectID": "62_sardinia_s3_lst.html#overview-of-processing-steps",
    "href": "62_sardinia_s3_lst.html#overview-of-processing-steps",
    "title": "Fire in Sardinia 2025 - Part 2",
    "section": "Overview of processing steps",
    "text": "Overview of processing steps\nIn the following, we will go through three main processing steps:\n\nStep 1: Retrieving and visualising Land Surface Temperature from Sentinel-3 SLSTR L2 data\nStep 2: Creating a True-Color composite of Sentinel-2 L2A data, and\nStep 3: Overlaying both datasets, the True-Color composite with the Land Surface Temperature information\n\n\nRetrieve Land Surface Temperature (LST) from Sentinel-3 SLSTR L2\nLand Surface Temperature (LST) data, can be retrieved from the Sentinel-3 SLSTR L2 collection. This data helps to identify temperature anomalies over the Earth’s Surface, which can be a strong indicator of an active fire.\nIn the following, we query the EOPF STAC Catalog to retrieve Land Surface Temperature from Sentinel-3 SLSTR L2 data.\nThe search below introduces a new argument to the search: query. This argument allows us to go into the .zarr attributes metadata and filter based on specific parameters of the items we are interested in. We will filter for “Non-Time Critical” items.\n\n# Specifying the Sentinel-3 SLSTR L2 LST collection name\ndef_collection = 'sentinel-3-slstr-l2-lst'\n\n# Search the catalog for items matching the criteria:\ns3_l2 = list(eopf_catalog.search(\n                bbox= search_bbox,  # A bounding box input to define the area of interest\n                datetime= fire_d_s3, # A datetime string input to specify the time range\n                collections=def_collection, # The collection name to search within\n                query = {\"product:timeliness_category\": {'eq':'NT'}} # A query to filter by timeliness category\n                                                                     # in the Catalog\n                ).item_collection())\n\n# Extract the URLs for the product assets from the search results\nav_urls = [item.assets[\"product\"].href for item in s3_l2]\n\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-3 SLSRT over Sardinia:  ',len(av_urls))\n\nSearch Results:\nTotal Items Found for Sentinel-3 SLSRT over Sardinia:   5\n\n\nAfter filtering the catalog, we open the first available Sentinel-3 SLSTR item, which corresponds to our specific timeframe of the selected day.\nFor optimising the subsequent plotting, we can extract key information from the retrieved item, such as the date and the specific item time. Afterwards, we access the Land Surface Temperature (LST) asset. The LST data is available under the group measurements.\n\n# Open the last item from the list of URLs as a Zarr data tree\nlst_zarr = xr.open_datatree(\n    av_urls[-1], # Input: URL of the last Zarr item in the av_urls list\n    engine=\"zarr\" # Specify the Zarr engine for opening the file\n    )\n\n# Extract the start date and time from the data tree's metadata\ndate_zarr_lst = lst_zarr.attrs['stac_discovery']['properties']['start_datetime'][:10]\ntime_zarr_lst = lst_zarr.attrs['stac_discovery']['properties']['start_datetime'][11:19]\n\n# Access the 'measurements' group within the data tree\nmeas_lst = lst_zarr.measurements\n# The output is the measurements data group\nmeas_lst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DatasetView&gt; Size: 65MB\nDimensions:    (rows: 1200, columns: 1500)\nCoordinates:\n    latitude   (rows, columns) float64 14MB ...\n    longitude  (rows, columns) float64 14MB ...\n    x          (rows, columns) float64 14MB ...\n    y          (rows, columns) float64 14MB ...\nDimensions without coordinates: rows, columns\nData variables:\n    lst        (rows, columns) float32 7MB ...xarray.DataTreeGroups: (1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DatasetView&gt; Size: 8MB\nDimensions:    (rows: 1200, columns: 1500, orphan_pixels: 187)\nCoordinates:\n    latitude   (rows, orphan_pixels) float64 2MB ...\n    longitude  (rows, orphan_pixels) float64 2MB ...\n    x          (rows, orphan_pixels) float64 2MB ...\n    y          (rows, orphan_pixels) float64 2MB ...\nDimensions without coordinates: rows, columns, orphan_pixels\nData variables:\n    lst        (rows, orphan_pixels) float32 898kB ...orphanGroups: (0)Dimensions:rows: 1200columns: 1500orphan_pixels: 187Coordinates: (4)latitude(rows, orphan_pixels)float64...long_name :Latitude of detector FOV centre on the earth's surfaceshort_name :latitude_orphanstandard_name :latitudeunits :degrees_northvalid_max :90000000valid_min :-90000000[224400 values with dtype=float64]longitude(rows, orphan_pixels)float64...long_name :Longitude of detector FOV centre on the earth's surfaceshort_name :longitude_orphanstandard_name :longitudeunits :degrees_eastvalid_max :180000000valid_min :-180000000[224400 values with dtype=float64]x(rows, orphan_pixels)float64...long_name :Geolocated x (across track) coordinate of detector FOV centreshort_name :x_orphanunits :mvalid_max :1000000valid_min :-500000[224400 values with dtype=float64]y(rows, orphan_pixels)float64...long_name :Geolocated y (along track) coordinate of detector FOV centreshort_name :y_orphanunits :mvalid_max :100000000valid_min :-1000000[224400 values with dtype=float64]Data variables: (1)lst(rows, orphan_pixels)float32..._eopf_attrs :{'coordinates': ['x', 'y', 'latitude', 'longitude'], 'dimensions': ['rows', 'orphan_pixels'], 'long_name': 'ungridded land surface temperature', 'standard_name': 'surface_temperature', 'units': 'K'}long_name :ungridded land surface temperatureshort_name :lst_orphanstandard_name :surface_temperatureunits :Kvalid_max :32767valid_min :-32767[224400 values with dtype=float32]Attributes: (0)Dimensions:rows: 1200columns: 1500Coordinates: (4)latitude(rows, columns)float64...long_name :Latitude of detector FOV centre on the earth's surfaceshort_name :latitudestandard_name :latitudeunits :degrees_northvalid_max :90000000valid_min :-90000000[1800000 values with dtype=float64]longitude(rows, columns)float64...long_name :Longitude of detector FOV centre on the earth's surfaceshort_name :longitudestandard_name :longitudeunits :degrees_eastvalid_max :180000000valid_min :-180000000[1800000 values with dtype=float64]x(rows, columns)float64...long_name :Geolocated x (across track) coordinate of detector FOV centreshort_name :xunits :mvalid_max :1000000valid_min :-500000[1800000 values with dtype=float64]y(rows, columns)float64...long_name :Geolocated y (along track) coordinate of detector FOV centreshort_name :yunits :mvalid_max :100000000valid_min :-1000000[1800000 values with dtype=float64]Inherited coordinates: (0)Data variables: (1)lst(rows, columns)float32..._eopf_attrs :{'coordinates': ['x', 'y', 'latitude', 'longitude'], 'dimensions': ['rows', 'columns'], 'long_name': 'gridded land surface temperature', 'standard_name': 'surface_temperature', 'units': 'K'}long_name :gridded land surface temperatureshort_name :lststandard_name :surface_temperatureunits :Kvalid_max :32767valid_min :-32767[1800000 values with dtype=float32]Attributes: (0)\n\n\nTo effectively overlay the data, we first need to process the Land Surface Temperature (LST) asset to cover the same area of interest. We can accomplish this by applying our pre-defined masking functions. Since the LST data is presented in EPSG:4326, we will use the zarr_mask_latlon() function to generate the boolean mask of interest over the data, followed by the mask_sub_latlon() function, which clips it to our area of interest.\n\n# The zarr_mask_latlon function is used to create a mask based on a bounding box and the measurements data\ncols_lst , rows_lst = zarr_mask_latlon(\n    bbox_vis, # The input bounding box\n    meas_lst # The measurements group from the zarr data tree\n    )\n# The mask_sub_latlon function then clips the land surface temperature data\nlst_clip = mask_sub_latlon(\n    meas_lst.lst, # The land surface temperature band from the measurements group\n    rows_lst, # The row indices for the mask\n    cols_lst # The column indices for the mask\n    ).values\n\n# The latitude data is clipped using the same mask indices\nlat_lst = mask_sub_latlon(meas_lst['latitude'],rows_lst, cols_lst).values\n# The longitude data is clipped using the same mask indices\nlon_lst = mask_sub_latlon(meas_lst['longitude'],rows_lst, cols_lst).values\n\nAfter clipping the data to our defined area of interest, we apply the temperature threshold to the data, filtering for only those pixels with temperatures above 312 Kelvin. This temperature range is a strong indicator of heat anomalies, which are often associated with active or developing fires.\n\n# To clip the data and prepare the array for an overlay with the TCI:\nlstf_clip = np.where(\n    lst_clip &lt;= 312, # values less than or equal to 312 K\n    np.nan, # The value to assign if the condition is true\n    lst_clip # The value to assign if the condition is false\n    )\n\nCreating a custom colour map that uses shades of red, with the most vibrant red indicating the hottest areas will enhance our visualisation. This colour map is applied to the LST data, allowing us to clearly and intuitively see the heat signatures that correspond with potential fire activity when the two layers are overlayed.\n\n# For colour ramp:\ncol_map = ListedColormap([[1., 140./255., 0],[178./255., 34./255., 34./255.],[1, 0, 0]]) # red composite shades\n# Define the boundaries for each colour in the ramp\nbounds = [300, 305, 310, 315]\n# Calculate the number of colours, which is one less than the number of bounds\nncolors = len(bounds) - 1\n# Create a normalisation object to map data values to colours based on the defined bounds\nnorm = BoundaryNorm(bounds, col_map.N)\n\n# Use the box() function to create a polygon from the coordinates\nmap_box = box(map_box[0],map_box[1],map_box[2],map_box[3])\n\nThe final step of the Sentinel-3 SLSTR data processing is to visualise the temperature anomalies. We will prepare the filtered LST data to be overlaid over the True-Color composite of Sentinel-2 L2 data.\n\n\n# Create a figure to plot\nfig, axs = plt.subplots(1, 2)\naxs[0].imshow(lst_clip)\naxs[0].set_title('Clipped LST')\n# Plot the filtered land surface temperature data on the second subplot\naxs[1].imshow(lstf_clip)\naxs[1].set_title('Filtered LST') # Add a title for clarity\n# Adjust the layout\nfig.tight_layout()\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCreate Sentinel-2 L2A True-Color composite\nFollowing the parameters we defined before and the workflow described in the first part of this notebook series, we will filter the Sentinel-2 L2A data collection to match our event and AOI. This ensures that the visualisations we create are directly relevant to the fire event and set the stage for comparing it with the Land Surface Temperature data from Sentinel-3.\n\n# Interest timeframe parameters for the filtering\ndate_p = fire_d_s3 + 'T00:00:00Z/' + fire_d_s3 + 'T23:59:59.999999Z' # interest period\ndef_collection = 'sentinel-2-l2a' # collection\n\ns2_col = list(eopf_catalog.search(\n                bbox= search_bbox, # area\n                datetime= date_p, #time frame\n                collections=def_collection # collection\n                ).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_col]\n\nprint(av_urls)\n\n[]\n\n\nAs we can see, there is no capture available for the day on which the fire occurred. This is because Sentinel-2 L2A has a revisit time of five days at the equator, making it possible that, even when the constellation is synchronously retrieving data, the day in question may not be available. In this case, we define the capture date as the one closest to the event, the 11th June 2025.\n\n# Interest timeframe parameters for the filtering\ndate_p = fire_d + 'T00:00:00Z/' + fire_d + 'T23:59:59.999999Z' # interest period\ndef_collection = 'sentinel-2-l2a' # collection\ns2_col = list(eopf_catalog.search(\n                bbox= search_bbox, # area\n                datetime= date_p, #time frame\n                collections=def_collection # collection\n                ).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_col] \nav_urls\n\n['https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202506-s02msil2a/11/products/cpm_v256/S2C_MSIL2A_20250611T101041_N0511_R022_T32TMK_20250611T175918.zarr']\n\n\nOnce we have obtained the available items from the Sentinel-2 L2A collection, we can open the asset as a xarray.DataTree.\nTo prepare the data for further processing, we will extract key metadata like the collection, date, time, and the spectral bands needed for the visualisation (which are conveniently grouped under r20m group).\nThese True-Color composite processing steps include: - Masking of invalid pixels - Clipping to AOI - Band selection - Normalisation - Composite creation - Equalisation\n\nMasking out invalid pixels\n\n# We are interested in the datasets contained in the measurements bands for True Colour and False Colour Composites.\ns2_zarr = xr.open_datatree(\n    av_urls[0], engine=\"zarr\", #we always get the earliest one (the first available item goes last)\n    chunks={},\n    decode_timedelta=False\n    )\n\n# Store interest parameters for further plotting:\ndate = s2_zarr.attrs['stac_discovery']['properties']['start_datetime'][:10]\ntime_zarr = s2_zarr.attrs['stac_discovery']['properties']['start_datetime'][11:19]\ntarget_crs = s2_zarr.attrs[\"stac_discovery\"][\"properties\"][\"proj:epsg\"]\n# Extract the resolution group we are interested to analyse over:\nzarr_meas = s2_zarr.measurements.reflectance.r20m\n\n# Extract the cloud free mask at 20m resolution:\nl2a_class_20m = s2_zarr.conditions.mask.l2a_classification.r20m.scl\nvalid_mask = validate_scl(l2a_class_20m)  # Boolean mask (10980x10980)\n\n\n\nClipping to AOI\nIn a next step, we clip the retrieved item to our defined area of interest (AOI).\n\n# True colour channels we are interested to retrieve coposite:\ntc_red  = 'b04'\ntc_green= 'b03'\ntc_blue = 'b02'\n\n# Boolean mask for the 'x' dimension (longitude/easting)\nx_mask = (zarr_meas['x'] &gt;= bbox_utm[0]) & (zarr_meas['x'] &lt;= bbox_utm[2])\n# Boolean mask for the 'y' dimension (latitude/northing)\ny_mask = (zarr_meas['y'] &gt;= bbox_utm[1]) & (zarr_meas['y'] &lt;= bbox_utm[3])\n\n# Combined mask for the bounding box\nbbox_mask = x_mask & y_mask\n\n# Extract row and column indices where the mask is True\ncols, rows = np.where(bbox_mask)\n\n\n\nBand selection, normalisation composite creation and equalisation\nIn the next step, we proceed to select the relevant bands from the item, apply normalisation and equalisation, in order to visualise the True-Color composite of 11 June 2025 over the Nuoto region in Sardinia.\n\n# The tc_red, tc_green, and tc_blue variables are inputs specifying the band names\nred = zarr_meas[tc_red].where(valid_mask)\ngre =  zarr_meas[tc_green].where(valid_mask)\nblu =  zarr_meas[tc_blue].where(valid_mask)\n\n# The mask_sub_utm() function takes the bands and masks them to the valid rows and columns\nred = mask_sub_utm(red,rows, cols).values\ngre = mask_sub_utm(gre,rows, cols).values\nblu = mask_sub_utm(blu,rows, cols).values\n\n# The zarr_meas group is the input dataset containing the dimensions\n# by slicing the 'y' dimension array based on the minimum and maximum row indices\ny_zarr = zarr_meas['y'].isel(y=slice(rows.min(), rows.max() + 1)).values\n# also, the same for the 'x' dimension array based on the minimum and maximum column indices\nx_zarr = zarr_meas['x'].isel(x=slice(cols.min(), cols.max() + 1)).values\n\nmap_ext_deg = list(t_utm_to_deg.transform(np.nanmin(x_zarr),np.nanmin(y_zarr)) + \n                   t_utm_to_deg.transform(np.nanmax(x_zarr),np.nanmax(y_zarr)))\n\n# Input: percentile range for contrast stretching\ncontrast_stretch_percentile=(2, 98)\n# Input: gamma correction value\ngamma=1.8\n\n# Apply normalisation to the red, green and blue bands using the specified percentile and gamma values\nred_processed = normalisation_str_gm(red, *contrast_stretch_percentile, gamma)\ngreen_processed = normalisation_str_gm(gre, *contrast_stretch_percentile, gamma)\nblue_processed = normalisation_str_gm(blu, *contrast_stretch_percentile, gamma)\n\n# We stack the processed red, green, and blue arrays\nrgb_composite_sm = np.dstack((red_processed, green_processed, blue_processed)).astype(np.float32)\n\n#Adding equalisation from skimage:\nfire_tc = exposure.equalize_adapthist(rgb_composite_sm)\n\n\nplt.imshow(fire_tc)\nplt.title('Equalised Composite') # Add a title for clarity\n\nText(0.5, 1.0, 'Equalised Composite')\n\n\n\n\n\n\n\n\n\n\n\n\nOverlay Sentinel-2 True-Color composite with Sentinel-3 LST data\nAnd finally, we can georeference and overlay the two datasets, the True-Color composite from Sentinel-2 as well as the Land Surface Temperature information from Sentinel-3.\n\n#Overlay\nplt.figure(figsize=(14, 8))\n# Define the coordinate reference system (CRS) for latitude/longitude\ndata_ll = ccrs.PlateCarree()\n\nax = plt.axes(projection=data_ll)\n# Display the Sentinel-2 true-colour composite (TCI) image\nimg = ax.imshow(fire_tc, origin='upper',\n                extent=[map_ext_deg[0],map_ext_deg[2],map_ext_deg[1],map_ext_deg[3]],  # item\n                transform=data_ll)\n# Display the land surface temperature (LST) data as an overlay\nim2 = ax.imshow(lstf_clip, origin='upper',\n                extent=[np.nanmin(lon_lst), np.nanmax(lon_lst),\n                        np.nanmin(lat_lst), np.nanmax(lat_lst)],\n                transform=data_ll, # coordinates\n                cmap=col_map,  norm=norm) # The custom colour map for LST\ncbar = plt.colorbar(im2,ticks=bounds, shrink=0.3)\ncbar.set_label(\"Land Surface Temperature (K)\")\n\n\n# features\nax.add_geometries(map_box, crs=data_ll, facecolor='none', edgecolor='yellow', linewidth=2, linestyle='-')\nax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # Add gridlines and labels\n\n# Adjust title and plot parameters for a tight layout\nplt.title(f'Sentinel-2 L2A TCI + LST for the {fire_d_s3}', fontsize=16)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe Sentinel-2 L2A provides the geographical context of the landscape, while the Sentinel-3 SLSTR LST information provides an indication of the hottest areas on that day. This allows for a more accurate and immediate understanding of a fire’s behaviour during the event. We can see that the hottest detected spot over the area of interest is indeed aligned with the fire event location.\nThe overlay provides additional information, especially in conditions where optical views are limited. For example, during less light hours or through heavy smoke, the thermal data can still reveal the fire’s true footprint.\n\n\nCalculating processing time\n\net = time.time()\n\ntotal_t = et - st\n\nprint('Total Running Time: ', total_t,' seconds')\n\nTotal Running Time:  29.198652982711792  seconds\n\n\nA significant takeaway from this process is its remarkable speed. The entire workflow, from data access to visualisation, is completed in under two minutes. Here is the key evident advantage of using .zarr encoding for wildfire detection.  EOPF enables us to quickly access and combine Sentinel data directly from the cloud without the need to download large volumes of data.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 2</span>"
    ]
  },
  {
    "objectID": "62_sardinia_s3_lst.html#conclusion",
    "href": "62_sardinia_s3_lst.html#conclusion",
    "title": "Fire in Sardinia 2025 - Part 2",
    "section": "Conclusion",
    "text": "Conclusion\nBy integrating items from Sentinel-2 with critical thermal data from Sentinel-3 through the EOPF STAC Catalog Collections, this notebook has demonstrated a complete and efficient workflow for analysing a real-world wildfire event. \nWe were able to create a powerful overlay that not only shows the geographical context of the burnt area but also precisely identifies the active heat signatures associated with the fire. This approach proves that combining different types of satellite data is essential for gaining a complete understanding of complex environmental events.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 2</span>"
    ]
  },
  {
    "objectID": "62_sardinia_s3_lst.html#whats-next",
    "href": "62_sardinia_s3_lst.html#whats-next",
    "title": "Fire in Sardinia 2025 - Part 2",
    "section": "What’s next?",
    "text": "What’s next?\nBuilding on our visual analysis, the next tutorial will introduce a quantitative method to assess fire severity. We will calculate the Normalised Burn Ratio (NBR) using data from Sentinel-2 satellite imagery.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 2</span>"
    ]
  },
  {
    "objectID": "63_sardinia_dNBR.html",
    "href": "63_sardinia_dNBR.html",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "",
    "text": "Introduction\n🚀 Launch this notebook in JupyterLab\nThis notebook introduces the Normalised Burn Ratio (NBR), a key index used in satellite remote sensing to assess burn severity. The NBR quantifies the severity of damage from wildfires. The NBR is calculated using near-infrared and shortwave infrared bands from Sentinel-2 Level 2 data to highlight vegetation and burned areas.\nBased on the NBR, we can calculate the differenced Normalized Burn Ratio (dNBR) which is a strong indicator of the severity of a fire’s impact on vegetation. The index can be interpreted as follows:\nTo calculate the dNBR, we will first calculate the NBR before and after a fire event. The post-fire NBR image is then subtracted from the pre-fire NBR image to produce the dNBR image.\nThis notebook is the second a series of three notebooks:",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "63_sardinia_dNBR.html#setting-up-the-environment",
    "href": "63_sardinia_dNBR.html#setting-up-the-environment",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "Setting up the environment",
    "text": "Setting up the environment\n\nInitiate a Dask cluster\nThe first step is to initiate a virtual Dask cluster consisting of a scheduler that manages tasks and multiple workers that process them.\n\ncluster = LocalCluster()\nclient = cluster.get_client()\nclient\n\n\n     \n    \n        Client\n        Client-f8eab11f-aa0d-11f0-9464-56b7a1fe0ab7\n        \n\n\n\nConnection method: Cluster object\nCluster type: distributed.LocalCluster\n\n\nDashboard: http://127.0.0.1:8787/status\n\n\n\n\n\n\n        \n\n        \n            \n            Cluster Info\n            \n    \n    \n    \n        LocalCluster\n        33f58ec0\n        \n\n\n\nDashboard: http://127.0.0.1:8787/status\nWorkers: 4\n\n\nTotal threads: 4\nTotal memory: 15.62 GiB\n\n\nStatus: running\nUsing processes: True\n\n\n\n\n\n        \n            \n                Scheduler Info\n            \n\n            \n    \n         \n        \n            Scheduler\n            Scheduler-b0e70839-d600-404e-93ee-0a4ce1fb0a31\n            \n\n\n\nComm: tcp://127.0.0.1:40939\nWorkers: 0\n\n\nDashboard: http://127.0.0.1:8787/status\nTotal threads: 0\n\n\nStarted: Just now\nTotal memory: 0 B\n\n\n\n\n        \n    \n\n    \n        \n            Workers\n        \n\n        \n        \n             \n            \n            \n                \n                    Worker: 0\n                \n                \n\n\n\nComm: tcp://127.0.0.1:36427\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:43943/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:40141\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-h2j9x58h\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 1\n                \n                \n\n\n\nComm: tcp://127.0.0.1:37501\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:33403/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:37205\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-9ipouy4l\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 2\n                \n                \n\n\n\nComm: tcp://127.0.0.1:40911\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:42437/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:33429\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-njaxf90t\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 3\n                \n                \n\n\n\nComm: tcp://127.0.0.1:37675\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:44967/status\nMemory: 3.91 GiB\n\n\nNanny: tcp://127.0.0.1:43233\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-k4h_tm44\n\n\n\n\n            \n            \n        \n        \n\n    \n\n\n        \n    \n\n            \n        \n\n    \n\n\n\n\n\nDefine workflow variables\nFollowing Part 1 of, we need to define the specific spatial and temporal parameters for our analysis. We will set the same area of interest over the Province of Nuoro Sardinia, Italy. We define the dates for our pre-fire and post-fire period.\nAccording to EFFIS’s definition, the severity for each fire is calculated after 30 days of the date of the fire, and it can be classified as follows:\n\n\n\nClass\ndNBR range (multiplied by 1000)\n\n\n\n\nUnburned or Regrowth\n&lt; 100\n\n\nLow severity\n100 - 270\n\n\nModerate low severity\n270 - 440\n\n\nModerate high severity\n440 - 660\n\n\nHigh severity\n&gt;= 660\n\n\n\nFor the pre-fire state, we will use an image from 3rd of June 2025, and due to data avilability, the closest available image for post fire state is set to 3rd July 2025. Additional information such as CRS and the relevant Sentinel-2 Level 2 bands, Near Infra Red (NIR) (B8a) and Short Wave Infrared (SWIR) (B12), are set.\n\n# Dates of interest\n# Before the fire:\npre_f  = '2025-06-03'\n# After the fire:\npost_f = '2025-07-03'\n\n# The area of interest for our filtering\nbbox = (8.847198,40.193395,\n        8.938865,40.241895)\n\n# Definition of the transformer parameters for reprojection and correct overlay of layers\ntransformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32632\", always_xy=True)\nt_utm_to_deg = Transformer.from_crs(\"EPSG:32632\",\"EPSG:4326\", always_xy=True)\n\n# The false colour channels we are interested to retrieve coposite:\nswir = 'b12'\nnir =  'b8a'\n\n# Defining a larger bounding box for better visualisation:\nbbox_vis = (8.649555,40.073583,\n          9.127893,40.343840)\n\n# A fixed geographic bounding box to highlight the AOI in the map format\nmap_box = bbox\n# A new list with the converted UTM coordinates\nbbox_utm = lat_lon_to_utm_box((bbox_vis[0], bbox_vis[1]),(bbox_vis[2], bbox_vis[3]),transformer)\n\ndef_collection = 'sentinel-2-l2a' #collection\n\n# we are interested in the performance the code will have\nst = time.time()\n\n\n\nEstablish a connection to the EOPF STAC Catalog\nAdditionally, we also need to establish a connection to the EOPF STAC catalog.\n\neopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\" #root starting point\neopf_catalog = Client.open(url=eopf_stac_api_root_endpoint) # calls the selected url\neopf_catalog\n\n\n\n\n\n\n    &lt;Client id=eopf-sample-service-stac-api&gt;\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Catalog\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"eopf-sample-service-stac-api\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"STAC catalog of the EOPF Sentinel Zarr Samples Service\"\n        \n    \n                \n            \n                \n                    \n        links[] 20 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"conformance\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/conformance\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC/OGC conformance classes implemented by this server\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"POST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-2A\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lfr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l2-ocn\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-2 OCN\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l2-lst\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-2 LST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-grd\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 GRD\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l1c\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-1C\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-slc\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 SLC\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l1-rbt\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-1 RBT\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-efr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 EFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-err\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 ERR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lrr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LRR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \n        \n            \n                \n        \n            rel\n            \"service-desc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/vnd.oai.openapi+json;version=3.0\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service description\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \n        \n            \n                \n        \n            rel\n            \"service-doc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api.html\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service documentation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        conformsTo[] 21 items\n        \n            \n        \n            \n                \n        \n            0\n            \"http://www.opengis.net/spec/cql2/1.0/conf/basic-cql2\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-text\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/geojson\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/oas30\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/features-filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \"https://api.stacspec.org/v1.0.0-rc.2/item-search#filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \"https://api.stacspec.org/v1.0.0/collections\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \"https://api.stacspec.org/v1.0.0/collections/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \"https://api.stacspec.org/v1.0.0/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \"https://api.stacspec.org/v1.0.0/item-search\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \"https://api.stacspec.org/v1.0.0/item-search#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \"https://api.stacspec.org/v1.0.0/item-search#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \"https://api.stacspec.org/v1.0.0/item-search#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "63_sardinia_dNBR.html#calculation-of-nbr---pre-fire",
    "href": "63_sardinia_dNBR.html#calculation-of-nbr---pre-fire",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "Calculation of NBR - Pre-Fire",
    "text": "Calculation of NBR - Pre-Fire\nNow we can use our defined parameters to query the STAC catalog and to retrieve all available Sentinel-2 imagery that correspond to our query arguments.\n\n# We define the search over the whole day, from 12:00 am to 11:59 pm\ndate_pre = pre_f + 'T00:00:00Z/' + pre_f + 'T23:59:59.999999Z' # interest period\n\ns2_pre = list(eopf_catalog.search(\n                bbox= bbox, \n                datetime= date_pre,\n                collections=def_collection).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_pre]\nav_urls\n\n['https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202506-s02msil2a/03/products/cpm_v256/S2A_MSIL2A_20250603T101041_N0511_R022_T32TMK_20250603T134103.zarr']\n\n\nNow we open the retrieved item as a xarray.DataTree. This image will serve as our baseline for the pre-fire conditions, providing a clean snapshot of the landscape before the event. We extract the r20m group under measurements group, as this is the resolution we will be focusing on. We also mask out all invalid pixels by applying the function validate_scl().\n\n# Open the last Zarr item from the list of URLs as a data tree.\npre_zarr = xr.open_datatree(\n    av_urls[0], engine=\"zarr\",\n    chunks={},\n    )\n\n# Select the 20m reflectance measurements from the data tree.\nzarr_meas_pre = pre_zarr.measurements.reflectance.r20m\n\n# Extractthe cloud free mask at 20m resolution:\nl2a_class_20m_pre = pre_zarr.conditions.mask.l2a_classification.r20m.scl\nvalid_mask_pre = validate_scl_w(l2a_class_20m_pre)  # Boolean mask\n\nTo calculate the Normalised Burn Ratio (NBR), we will access the specific spectral bands we need: the Near-Infrared (NIR) band (B8A) and the Shortwave Infrared (SWIR) band (B12).\nOnce we access them, we need to ensure our data features our area of interest (AOI). We will apply the same masking and clipping functions used in our previous tutorial to clip the imagery to our precise bbox_utm.\n\n# Create UTM masks for rows and columns based on the bounding box.\ncols_pre, rows_pre= zarr_mask_utm (bbox_utm, zarr_meas_pre)\n\n# Extract and slice the y-dimension values from the Zarr measurement.\ny_zarr = zarr_meas_pre['y'].isel(y=slice(rows_pre.min(), rows_pre.max() + 1)).values\n# Extract and slice the x-dimension values from the Zarr measurement.\nx_zarr = zarr_meas_pre['x'].isel(x=slice(cols_pre.min(), cols_pre.max() + 1)).values\n\n# Select the red, green, and blue bands and apply the valid mask.\nswir_pre = zarr_meas_pre[swir].where(valid_mask_pre)\nnir_pre =  zarr_meas_pre[nir].where(valid_mask_pre)\n\n# Mask and clip the selected bands using the row and column indices.\nswir_pre = mask_sub_utm(swir_pre,rows_pre, cols_pre).values\nnir_pre = mask_sub_utm(nir_pre,rows_pre, cols_pre).values\n\nOnce we obtain the masked assets, we can visualise them before calculating the NBR.\n\n# Create a figure to plot\nfig, axs = plt.subplots(1, 2)\naxs[0].imshow(nir_pre)\naxs[0].set_title(f'NIR (b8) for the {pre_f}')\n# Plot the filtered land surface temperature data on the second subplot\naxs[1].imshow(swir_pre)\naxs[1].set_title(f'SWIR (b12) for the {pre_f}') # Add a title for clarity\n# Adjust the layout\nfig.tight_layout()\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nWith our swir_pre and nir_pre bands ready, we can now calculate the pre-fire NBR image. We will apply the following NBR formula:\n\\[\\frac{(NIR - SWIR)} {(NIR + SWIR)}\\]\nAn important consideration for this process is the possibility of division by zero when calculating the composite. To prevent this, we create a mask that assigns a value of 1 to any pixel that is 0, while keeping the original values for all other pixels.\n\n# We calculate the nbr for our pre fire event\npre_difference = nir_pre - swir_pre\n\n# to deal with 0 divisions on the NBR formula\n\npre_addition = nir_pre + swir_pre\n\n# we create a mask to detect possible 0 values\nzero_mask = (pre_addition == 0)\npre_z= pre_addition.copy()\n\npre_z = da.where(pre_addition == 0, 1, pre_z)\n\n\n# Calculatig our NBR for the moment before the fire:\n\nnbr_pre  = da.where(pre_addition == 0, 0, pre_difference / pre_z)\n\nNow, we can visualise the calculated pre-fire NBR image.\n\n# Visualising the clipped red band:\nplt.imshow(nbr_pre, vmin=-1.0, vmax=1.0)\nplt.title(f'NBR from the {pre_f}')\n\nText(0.5, 1.0, 'NBR from the 2025-06-03')",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "63_sardinia_dNBR.html#calculation-of-nbr---post-fire",
    "href": "63_sardinia_dNBR.html#calculation-of-nbr---post-fire",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "Calculation of NBR - Post-Fire",
    "text": "Calculation of NBR - Post-Fire\nThe next step is to repeat the same steps as above and to calculate a post-fire NBR image.\nWe first query the EOPF STAC catalog for items avialble on 3 July 2025, open the retrieved item as xarray.DataTree and mask out invalid pixels.\n\n# We define the search over the whole day, from 12:00 am to 11:59 pm\ndate_post = post_f + 'T00:00:00Z/' + post_f + 'T23:59:59.999999Z' # interest period\n\ns2_post = list(eopf_catalog.search(\n                bbox= bbox, \n                datetime= date_post,\n                collections=def_collection).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_post]\n\npost_zarr = xr.open_datatree(\n    av_urls[-1], engine=\"zarr\", #we always get the earliest one (last)\n    chunks={},\n    )\n\nzarr_meas_post = post_zarr.measurements.reflectance.r20m\n\n# Extractthe cloud free mask at 20m resolution:\nl2a_class_20m_post = post_zarr.conditions.mask.l2a_classification.r20m.scl\nvalid_mask_post = validate_scl_w(l2a_class_20m_post)  # Boolean mask\n\nIn a next step, we follow the same masking and clipping functions to this new dataset to ensure it is focused on our area of interest.\n\n# Create UTM masks for rows and columns based on the bounding box.\ncols_post, rows_post= zarr_mask_utm(bbox_utm, zarr_meas_post)\n\n# Slice the y-dimension values using the new row indices.\ny_zarr = zarr_meas_post['y'].isel(y=slice(rows_post.min(), rows_post.max() + 1)).values\n# Slice the x-dimension values using the new column indices.\nx_zarr = zarr_meas_post['x'].isel(x=slice(cols_post.min(), cols_post.max() + 1)).values\n\n# define our zarr extracted coordinates\nmap_ext_deg = list(t_utm_to_deg.transform(np.nanmin(x_zarr),np.nanmin(y_zarr)) + \n                   t_utm_to_deg.transform(np.nanmax(x_zarr),np.nanmax(y_zarr)))\n\n# Select the red, green, and blue bands and apply the valid mask.\nswir_post = zarr_meas_post[swir].where(valid_mask_post)\nnir_post =  zarr_meas_post[nir].where(valid_mask_post)\n\n# Mask and clip the selected bands using the row and column indices.\nswir_post = mask_sub_utm(swir_post,rows_post, cols_post).values\nnir_post = mask_sub_utm(nir_post,rows_post, cols_post).values\n\nAfter our masking, we obtain the following bands\n\n# Create a figure to plot\nfig, axs = plt.subplots(1, 2)\naxs[0].imshow(nir_post)\naxs[0].set_title(f'NIR (b8) for the {post_f}')\n# Plot the filtered land surface temperature data on the second subplot\naxs[1].imshow(swir_post)\naxs[1].set_title(f'SWIR (b12) for the {post_f}') # Add a title for clarity\n# Adjust the layout\nfig.tight_layout()\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nWith our post-fire bands, we can now calculate the Post-Fire NBR. We apply the 0 division consideration masking and the NBR formula again to these bands to get the post-fire NBR image.\n\n# We calculate the nbr for our post fire event\npost_difference = nir_post - swir_post\n\n# to deal with 0 divisions on the NBR formula\npost_addition = nir_post + swir_post\n\n# we create a mask to detect possible 0 values\nzero_mask = (post_addition == 0)\npost_z= post_addition.copy()\n\npost_z = da.where(post_addition == 0, 1, post_z)\n\nnbr_post  = da.where(post_addition == 0, 0, post_difference / post_z)\n\n# Visualising the clipped red band:\nplt.imshow(nbr_post, vmin=-1.0, vmax=1.0)\nplt.title(f'NBR from the {post_f}')\n\nText(0.5, 1.0, 'NBR from the 2025-07-03')",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "63_sardinia_dNBR.html#calculate-differenced-nbr-dnbr",
    "href": "63_sardinia_dNBR.html#calculate-differenced-nbr-dnbr",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "Calculate Differenced NBR (dNBR)",
    "text": "Calculate Differenced NBR (dNBR)\nThe last calculation step for our analysis is the delta NBR (dNBR). This index is calculated by subtracting the post-fire NBR from the pre-fire NBR. Higher dNBR values indicate more severe damage, providing a quantitative measure of the fire’s impact.\n\\[dNBR = prefireNBR - postfireNBR\\]\n\n# Calculate the delta Normalised Burn Ratio (dNBR) by subtracting the post-fire NBR from the pre-fire NBR.\ndNBR = (nbr_pre - nbr_post) * 1000\n\n# bringing the dNBR to memory\ndNBR_c = dNBR.compute()\n\nAs our calculation was based on dask array for a faster computation, we bring it back to memory and multiply it by 1000 to be able to compare it to Key & Benson (2006) severity thresholds, proposed by EFFIS.\n\n# Visualising the clipped red band:\n# plt.imshow(dNBR)\nplt.imshow(dNBR, vmin=-1000.0, vmax=1000.0)\nplt.title(f'Calculated dNBR')\n\nText(0.5, 1.0, 'Calculated dNBR')\n\n\n\n\n\n\n\n\n\nFinally, we will plot our results to visualise the burn severity. Using the cartopy library, we can create a georeferenced map that accurately displays our data based on its CRS and geospatial bounding box.\nThe dNBR data will be presented on this map using a colour scheme that clearly highlights the most affected areas by the fire.\n\n# Creating the Geometry\nmap_box = box(map_box[0],map_box[1],map_box[2],map_box[3])\n\n#Overlay\nplt.figure(figsize=(15, 10))\n# Create a figure with a specified size.\ndata_ll = ccrs.PlateCarree()\n# Set up the plot with a defined projection.\nax = plt.axes(projection=data_ll)\n\n# Display the Differenced Normalised Burn Ratio (dNBR)\nim = ax.imshow(dNBR_c, origin='upper',\n                extent=(bbox_vis[0],bbox_vis[2],\n                        bbox_vis[1],bbox_vis[3]),  # item\n                         vmin=-1000.0, vmax=1000.0,\n                transform=data_ll)\n\n# features\nplt.colorbar(im, ax=ax, label='dNBR Value')\nax.add_geometries([map_box], crs=data_ll, facecolor='none', edgecolor='yellow', linewidth=2, linestyle='-')\nax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # Add gridlines and labels\n\n\n# Set the title of the plot.\nplt.title(f'Sentinel-2 L2A Differenced Normalised Burn ratio between {pre_f} and {post_f}', fontsize=16)\n# Adjust plot to ensure all elements fit without overlapping.\nplt.tight_layout()\n# Show the final plot.\nplt.show()\n\n\n\n\n\n\n\n\nAs the plot shows, the burn scar provides a spectral response through dNBR, even after the asset was clipped to remove clouds and water bodies. The severity values are over 750, which classifies this as being in the high-severity range of Key & Benson (2006).\n\n\n\nClass\ndNBR range (multiplied by 1000)\n\n\n\n\nUnburned or Regrowth\n&lt; 100\n\n\nLow severity\n100 - 270\n\n\nModerate low severity\n270 - 440\n\n\nModerate high severity\n440 - 660\n\n\nHigh severity\n&gt;= 660\n\n\n\n\nCalculating processing time\nBesides the asset’s accessibility, it is important to note the time efficiency of this monitoring workflow. The entire process, from defining the area of interest to searching, accessing, processing, and visualising the data takes less than 30 seconds.\n\net = time.time()\ntotal_t = et - st\nprint('Total Running Time: ', total_t,' seconds')\n\nTotal Running Time:  31.889089107513428  seconds",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "63_sardinia_dNBR.html#conclusion",
    "href": "63_sardinia_dNBR.html#conclusion",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "Conclusion",
    "text": "Conclusion\nThis series of notebooks demonstrated a complete workflow for monitoring fire events using data from the Sentinel-2 and Sentinel-3 missions, providing a comprehensive view of the wildfire stages, before, during and after.\nBy leveraging the cloud-optimised zarr format, we have shown how visual and quantitative composites, plus multisource integration can provide a clear and repeatable method for assessing the severity of a wildfire occurrence.\nUnlike previous workflows, which required the local downloading and processing of large .TIFF images, the .zarr format, available through the EOPF STAC Catalog, enables users to filter and access data without having to manage massive datasets locally. Furthermore, the ability to replicate defined steps at various points in time provides a robust framework for comprehending the entire fire life cycle.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "63_sardinia_dNBR.html#whats-next",
    "href": "63_sardinia_dNBR.html#whats-next",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "What’s next?",
    "text": "What’s next?\nIn the following workflow, we will demonstrate how to use Sentinel-1 GDR data to map flood extents in Valencia, Spain.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "64_flood_mapping_valencia.html",
    "href": "64_flood_mapping_valencia.html",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "",
    "text": "Introduction\n🚀 Launch this notebook in JupyterLab\nSentinel-1 GDR data is particularly valuable to detect water and underwater areas. Synthetic Aperture Radar (SAR) can capture images day and night, in any weather, a feature especially important for flooding events, where cloudy and rainy weather can persist for weeks. This makes it far more reliable than optical sensors during storms.\nWith its frequent revisits, wide coverage, and free high-resolution data, Sentinel-1 enables the rapid mapping of flood extents, as will be demonstrated in this workflow. VV polarization is preferred for flood mapping due to its sensitivity to water surfaces, which typically appear darker in the images compared to land surfaces.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "64_flood_mapping_valencia.html#data-pre-processing",
    "href": "64_flood_mapping_valencia.html#data-pre-processing",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "Data pre-processing",
    "text": "Data pre-processing\nTo search and load the data needed for the analysis, we will follow the processes we presented in Sentinel-1 GRD structure tutorial and S1 basic operations tutorial.\nOnce we defined our interest Sentinel-1 GRD items, we can see that they contain both VH and VV polarizations. For this flood mapping context, VV polarization is the choice of interest, as water backscatter is much more visible with it, rather than with VH.\n\nLoading the datatree\nThe list below shows the names of the products we will use for the flood mapping and time series analysis. As we have seen in previous chapters, these names already contain valuable information that can be used to search for specific products within the EOPF STAC catalogue.\n\nscenes = [\"S1A_IW_GRDH_1SDV_20241007T180256_20241007T180321_056000_06D943_D46B\", \n          \"S1A_IW_GRDH_1SDV_20241019T180256_20241019T180321_056175_06E02E_2D52\", \n          \"S1A_IW_GRDH_1SDV_20241031T180256_20241031T180321_056350_06E71E_479F\", \n          \"S1A_IW_GRDH_1SDV_20241112T180255_20241112T180320_056525_06EE16_DC29\", \n          \"S1A_IW_GRDH_1SDV_20241124T180254_20241124T180319_056700_06F516_BA27\", \n          \"S1A_IW_GRDH_1SDV_20241206T180253_20241206T180318_056875_06FBFD_25AD\", \n          \"S1A_IW_GRDH_1SDV_20241218T180252_20241218T180317_057050_0702F2_0BC2\", \n          \"S1A_IW_GRDH_1SDV_20241230T180251_20241230T180316_057225_0709DD_15AC\", \n          \"S1A_IW_GRDH_1SDV_20250111T180250_20250111T180315_057400_0710C7_ADBB\", \n          \"S1A_IW_GRDH_1SDV_20250123T180249_20250123T180314_057575_0717B9_A784\", \n          \"S1A_IW_GRDH_1SDV_20250204T180249_20250204T180314_057750_071EA2_4373\", \n          \"S1A_IW_GRDH_1SDV_20250216T180248_20250216T180313_057925_0725AE_8AC7\", \n          \"S1A_IW_GRDH_1SDV_20250312T180248_20250312T180313_058275_0733E6_4F5B\", \n          \"S1A_IW_GRDH_1SDV_20250324T180248_20250324T180313_058450_073AD0_04B7\", \n          ]\n\nzarr_paths = []\nfor scene in scenes:\n    zarr_paths.append(f\"https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:notebook-data/tutorial_data/cpm_v260/{scene}.zarr\")\n\nNext, we will load all zarr datasets as xarray.Datatrees. Here we are not reading the entire dataset from the store; but, creating a set of references to the data, which enables us to access it efficiently later in the analysis.\n\nclient = Client()  # Set up local cluster on your laptop\nclient\n\n@dask.delayed\ndef load_datatree_delayed(path):\n    return xr.open_datatree(path, consolidated=True, chunks=\"auto\")\n\n# Create delayed objects\ndelayed_datatrees = [load_datatree_delayed(path) for path in zarr_paths]\n# Compute in parallel\ndatatrees = dask.compute(*delayed_datatrees)\n\nEach element inside the datatree list is a datatree and corresponds to a Sentinel-1 GRD scene datatree present on the list above.\n\n# Each element inside the datatree list is a datatree and corresponds to a Sentinel-1 GRD scene datatree present on the list above\ntype(datatrees[0]) \n\nxarray.core.datatree.DataTree\n\n\n\n\nDefining variables\n\n# Number of scenes we are working with for the time series analysis\nDATASET_NUMBER = len(datatrees) \n\nIf we run the following commented out code line we will be able to see how each datatree is organized within its groups and subgroups (as explained in this section). From this datatree, we took the groups and subgroups constant ID numbers used to open specific grouos and variables such as: - Measurements group = 7 so, in order to open this group, on the first element of our list of scenes, over the first polarization VV, we do datatrees[0][datatrees[0].groups[7]] - Calibration group = 33 so, in order to open this group, on the first element of our list of scenes, over the first polarization VV, we do datatrees[0][datatrees[0].groups[33]]\nOver the course of this notebook these IDs will be used to call variables and compute some other functions.\n\n# Opening the measurements group from the datatree\ndatatrees[0][datatrees[0].groups[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DatasetView&gt; Size: 870MB\nDimensions:       (azimuth_time: 16677, ground_range: 26061)\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 133kB 2024-10-07T18:02:56.455...\n  * ground_range  (ground_range) float64 208kB 0.0 10.0 ... 2.606e+05 2.606e+05\n    line          (azimuth_time) int64 133kB dask.array&lt;chunksize=(16677,), meta=np.ndarray&gt;\n    pixel         (ground_range) int64 208kB dask.array&lt;chunksize=(26061,), meta=np.ndarray&gt;\nData variables:\n    grd           (azimuth_time, ground_range) uint16 869MB dask.array&lt;chunksize=(4096, 8192), meta=np.ndarray&gt;xarray.DataTreeGroups: (0)Dimensions:azimuth_time: 16677ground_range: 26061Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2024-10-07T18:02:56.455660 ... 2...array(['2024-10-07T18:02:56.455660000', '2024-10-07T18:02:56.457159057',\n       '2024-10-07T18:02:56.458658115', ..., '2024-10-07T18:03:21.450952884',\n       '2024-10-07T18:03:21.452451942', '2024-10-07T18:03:21.453951000'],\n      shape=(16677,), dtype='datetime64[ns]')ground_range(ground_range)float640.0 10.0 ... 2.606e+05 2.606e+05array([0.0000e+00, 1.0000e+01, 2.0000e+01, ..., 2.6058e+05, 2.6059e+05,\n       2.6060e+05], shape=(26061,))line(azimuth_time)int64dask.array&lt;chunksize=(16677,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n130.29 kiB\n130.29 kiB\n\n\nShape\n(16677,)\n(16677,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         16677 1\n\n\n\n\npixel(ground_range)int64dask.array&lt;chunksize=(26061,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n203.60 kiB\n203.60 kiB\n\n\nShape\n(26061,)\n(26061,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         26061 1\n\n\n\n\nInherited coordinates: (0)Data variables: (1)grd(azimuth_time, ground_range)uint16dask.array&lt;chunksize=(4096, 8192), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :measurement data set for GRD IW\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n828.97 MiB\n81.01 MiB\n\n\nShape\n(16677, 26061)\n(4389, 9677)\n\n\nDask graph\n12 chunks in 2 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n              26061 16677\n\n\n\n\nAttributes: (0)\n\n\n\n# Some other important constant ID numbers \nMEASUREMENTS_GROUP_ID = 7\nGCP_GROUP_ID = 28\nCALIBRATION_GROUP_ID = 33\n\nWe now define the thresholds that will be used for the flood mapping analysis. These values are not fixed and they can be calibrated and adjusted to achieve a better fit for different regions or flood events.\nIn SAR imagery, open water surfaces typically appear very dark because they reflect the radar signal away from the sensor. This results in low backscatter values. In our case, pixels with a backscatter lower than approximately –15 dB are likely to correspond to water.\n\nWATER_THRESHOLD_DB = -15\n\nIt is interesting to study the flood event over a specific point within the area of interest. Therefore, we are storing the coordinates of an anchor point inside the area which is not usually covered by water. After the heavy rain, it became flooded for a few weeks.\n\nTARGET_LAT = 39.28\nTARGET_LONG = -0.30",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "64_flood_mapping_valencia.html#extracting-information-from-the-.zarr",
    "href": "64_flood_mapping_valencia.html#extracting-information-from-the-.zarr",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "Extracting information from the .zarr",
    "text": "Extracting information from the .zarr\nAs explained in the S1 basic operations tutorial, we will perform over all the selected data the following operations:\n\nSlicing the data to meet our area of interest and decimate it\nAssigning latitude and longitude coordinates to the dataset\nComputing the backscatter\n\n\nSlicing and decimating GRD variable\nTo begin with, we access all our .zarr items measurements groups by creating a list storing all of them.\n\nmeasurements = []\n# Looping to populate the measurements list with only the measurements groups of each dataset on the datatree list\nfor i in range(DATASET_NUMBER):\n    measurements.append(datatrees[i][datatrees[i].groups[MEASUREMENTS_GROUP_ID]].to_dataset())\n\nWe continue by decimating gdr’s data. As we are only interested into a specific area (Valencia).\nBecause we haven’t assigned latitude and longitude coordinates yet, we can not crop the data acording to coordinates. On top of this, even though different products have the same shape and dimensions (azimuth_time and ground_range), the values for the same indexes number don’t match so either ways, it wouldn’t be doable to slice the data acording to coordinate values (which would always be different for different products).\n\n# Plotting the first decimated GRD product from our list, corresponding to the whole scene\nmeasurements[0].grd.isel(\n        azimuth_time=slice(None, None, 20),\n        ground_range=slice(None, None, 20)).plot(vmax=300)\nplt.show()\n\n\n\n\n\n\n\n\n\nprint(\"Azimuth time has\", measurements[0].grd.shape[0], \"values.\")\nprint(\"Ground range has\", measurements[0].grd.shape[1], \"values.\")\n\nAzimuth time has 16677 values.\nGround range has 26061 values.\n\n\nThe solution found is to slice the data by the coordinates index positon using isel() function. Just before, a rought plotting was done in order to visualize the whole image. it was also plotted the azimuth_time and ground_range shape. Considering the are we are interested, and after a few tests and direct proportion calculations, we see that we need: - for azimuth_time, more or less from the last 10000 positions to the last 4500; - for ground_range, more or less from the last 7000 positions to the last 2000;\n\ngrd = []\n# Looping to populate the grd list with only the grd subgroups of each dataset on the \n# datatree list while simultaneaously slicing the data to match our AOI and decimating it\nfor i in range(DATASET_NUMBER):\n    grd_group = measurements[i].grd\n    azimuth_time_len = grd_group.sizes['azimuth_time']\n    ground_range_len = grd_group.sizes['ground_range']\n    \n    grd.append(grd_group.isel(\n        azimuth_time=slice((azimuth_time_len - 10000),    # beginning of the slice\n                           (azimuth_time_len - 4500),     # end of the slice\n                           10),                           # interval of the slice/decimation\n        ground_range=slice((ground_range_len - 7000), \n                           (ground_range_len - 2000), \n                           10)\n    ))\n\n\ngrd[1].shape\n\n(550, 500)\n\n\n\n# Plotting the second sliced and decimated GRD product from our list \ngrd[1].plot(vmax=300)\nplt.title(\"Sliced GRD product for the area of interest\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAssigning latitude and longitude coordinates\nWe will execute the following step to assign latitude and longitude coordinates to our datasets: 1. Creating a gcp dataset interpolated with the grd dataset; 2. Assigning the latitude and longitude coordinates to the grd dataset;\nThese steps are very important because we are computing a georeferenced image, which allows direct comparison with other spatial datasets. Until now, the image coordinates were expressed in azimuth_time and ground_range, which makes sense in a SAR context but not for geographical analyses.\n\ngcp = []\n\n# Looping to populate the gcp list with only the gcp subgroups of each dataset on the datatree list\nfor i in range(DATASET_NUMBER):\n    gcp.append(datatrees[i][datatrees[i].groups[GCP_GROUP_ID]].to_dataset())\n    gcp[i] = gcp[i].interp_like(grd[i]) # interpolate gcp to match the decimation done before\n\n\n# Looping to assign the latitude and longitude coordinates to grd \nfor i in range(DATASET_NUMBER):\n    grd[i] = grd[i].assign_coords({\"latitude\": gcp[i].latitude, \n                                   \"longitude\": gcp[i].longitude})\n\n\n# Plotting the third sliced and decimated GRD product from our list with latitude and longitude coordinates\ngrd[2].plot(x=\"longitude\", y=\"latitude\", vmax=300)\nplt.title(\"GRD product with latitude and longitude coordinates\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nComputing backscatter\nAgain, the following steps are just recreating what was done before, but this time over more datasets. For further detailed information, take a look at this chapter.\nFirstly we access the variables concerning the calibration values. These are the values that are going to be used for the backscatter computation. Because we´ve decimated the gdr dataset, we also need to decimate the calibration variables in the same way.\nAfter it, using the xarray_sentinel library, we compute the backscatter for each dataset. As input varialbes, we use the gdr dataset and the calibration variables we´ve just accessed.\n\ncalibration = []\n# Looping to populate the calibration list with only the calibration groups of each dataset on the datatree list\nfor i in range(DATASET_NUMBER):\n    calibration.append(datatrees[i][datatrees[i].groups[CALIBRATION_GROUP_ID]].to_dataset())\n    calibration[i] = calibration[i].interp_like(grd[i]) # interpolate calibration to match the decimation done before\n\n\nintensity = []\n# Looping to populate the intensity list with the calibrated intensity array originated from xarray_sentinel.calibrate_intensity function\nfor i in range(DATASET_NUMBER):\n    intensity.append(xarray_sentinel.calibrate_intensity(\n        grd[i], \n        calibration[i].beta_nought, \n        as_db=True))\n\n\n# Plotting the backscatter intensity for the second dataset on the list\nintensity[1].plot(x=\"longitude\", y=\"latitude\", vmin=-25, vmax=5)\nplt.title(\"Computed backscatter intensity\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCreate a datacube to prepare for time series analysis\nSince we are performing a time series with .zarr, instead of analysing individual items stored in a list, we can create a combined dataset, containing all the data, stacked together by a new dimension time. Through the stacking, we are building a three-dimensional datacube.\nTo get values for the new dimension time, we need to extract the acquisiton dates for each product.\n\ndata = []\n# Looping to populate the data list with all the acquisition dates from the datatree\nfor i in range(DATASET_NUMBER):\n    data.append(intensity[i].azimuth_time.values[1].astype('datetime64[D]'))\ndata\n\n[np.datetime64('2024-10-07'),\n np.datetime64('2024-10-19'),\n np.datetime64('2024-10-31'),\n np.datetime64('2024-11-12'),\n np.datetime64('2024-11-24'),\n np.datetime64('2024-12-06'),\n np.datetime64('2024-12-18'),\n np.datetime64('2024-12-30'),\n np.datetime64('2025-01-11'),\n np.datetime64('2025-01-23'),\n np.datetime64('2025-02-04'),\n np.datetime64('2025-02-16'),\n np.datetime64('2025-03-12'),\n np.datetime64('2025-03-24')]\n\n\n\n\nCoregistration\nThe next step is sensitive. In order to stack data into an array, the dimension values need to match perfectly, which is not the case (Sentinel-1 GRD data dimension values differ from one product to the other).\nThis problem resembles the coregistrations problem. This refers to the process of aligning two or more images, in a way that each pixel in one image corresponds to the exact same ground location in the others. To have a deeper overview of this process you can take a look here.\nThere are only a few software programmes and packages that can perform coregistration, and most of the time, these processes are very time-consuming and resource-intensive.\nSince the GRD images we are working with already have the same dimensions (cropped during the initial steps of the tutorial), we can perform our own coregistration. Such process involves: - Keeping the coordinates of one intensity dataset as the reference - Resetting the coordinates of the other ones - Reassigning the coordinates to match the reference dataset and that they can all overlay perfectly.\nTo do so we will use the function reset_coords() to reset the original coordinates and then use the assign_coords function after.\n\nreference_coords = intensity[0].coords # setting the first coordinate values as reference\n\ndatasets_aligned = []\n\n# Looping to populate the datasets_aligned list with the newly assigned coordinate values\nfor ds in intensity:\n    ds_no_coords = ds.reset_coords(drop=True)\n    datasets_aligned.append(ds_no_coords.assign_coords(reference_coords))\n\nNow, the data is fully prepared to be stacked into a new array that contains all the datasets. They share the same coordinate values and everything is aligned along a third dimension, time. To stack all the datasets into only one we will use the concat() function from the xarray library.\n\n# Creating the data cube, stacking all the datasets over a new time dimension\nintensity_data_cube = xr.concat(datasets_aligned, dim=xr.DataArray(data, dims=\"time\"))\n\n# There is a new dimension coordinate (time) \nintensity_data_cube\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 14, azimuth_time: 550, ground_range: 500)&gt; Size: 15MB\ndask.array&lt;concatenate, shape=(14, 550, 500), dtype=float32, chunksize=(1, 398, 500), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 4kB 2024-10-07T18:03:06.46487...\n  * ground_range  (ground_range) float64 4kB 1.906e+05 1.907e+05 ... 2.405e+05\n    line          (azimuth_time) float64 4kB dask.array&lt;chunksize=(550,), meta=np.ndarray&gt;\n    pixel         (ground_range) float64 4kB dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;\n    latitude      (azimuth_time, ground_range) float64 2MB dask.array&lt;chunksize=(550, 500), meta=np.ndarray&gt;\n    longitude     (azimuth_time, ground_range) float64 2MB dask.array&lt;chunksize=(550, 500), meta=np.ndarray&gt;\n  * time          (time) datetime64[s] 112B 2024-10-07 2024-10-19 ... 2025-03-24\nAttributes:\n    _eopf_attrs:  {'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_r...\n    dtype:        &lt;u2\n    long_name:    beta nought calibration vector (this array contains the cou...\n    units:        dBxarray.DataArraytime: 14azimuth_time: 550ground_range: 500dask.array&lt;chunksize=(1, 152, 500), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.69 MiB\n777.34 kiB\n\n\nShape\n(14, 550, 500)\n(1, 398, 500)\n\n\nDask graph\n28 chunks in 451 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                     500 550 14\n\n\n\n\nCoordinates: (7)azimuth_time(azimuth_time)datetime64[ns]2024-10-07T18:03:06.464870182 .....array(['2024-10-07T18:03:06.464870182', '2024-10-07T18:03:06.479860762',\n       '2024-10-07T18:03:06.494851342', ..., '2024-10-07T18:03:14.664717374',\n       '2024-10-07T18:03:14.679707954', '2024-10-07T18:03:14.694698534'],\n      shape=(550,), dtype='datetime64[ns]')ground_range(ground_range)float641.906e+05 1.907e+05 ... 2.405e+05array([190610., 190710., 190810., ..., 240310., 240410., 240510.], shape=(500,))line(azimuth_time)float64dask.array&lt;chunksize=(550,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n4.30 kiB\n4.30 kiB\n\n\nShape\n(550,)\n(550,)\n\n\nDask graph\n1 chunks in 11 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         550 1\n\n\n\n\npixel(ground_range)float64dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n3.91 kiB\n3.91 kiB\n\n\nShape\n(500,)\n(500,)\n\n\nDask graph\n1 chunks in 11 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         500 1\n\n\n\n\nlatitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(550, 500), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.10 MiB\n2.10 MiB\n\n\nShape\n(550, 500)\n(550, 500)\n\n\nDask graph\n1 chunks in 22 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         500 550\n\n\n\n\nlongitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(550, 500), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.10 MiB\n2.10 MiB\n\n\nShape\n(550, 500)\n(550, 500)\n\n\nDask graph\n1 chunks in 22 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         500 550\n\n\n\n\ntime(time)datetime64[s]2024-10-07 ... 2025-03-24array(['2024-10-07T00:00:00', '2024-10-19T00:00:00', '2024-10-31T00:00:00',\n       '2024-11-12T00:00:00', '2024-11-24T00:00:00', '2024-12-06T00:00:00',\n       '2024-12-18T00:00:00', '2024-12-30T00:00:00', '2025-01-11T00:00:00',\n       '2025-01-23T00:00:00', '2025-02-04T00:00:00', '2025-02-16T00:00:00',\n       '2025-03-12T00:00:00', '2025-03-24T00:00:00'], dtype='datetime64[s]')Indexes: (3)azimuth_timePandasIndexPandasIndex(DatetimeIndex(['2024-10-07 18:03:06.464870182',\n               '2024-10-07 18:03:06.479860762',\n               '2024-10-07 18:03:06.494851342',\n               '2024-10-07 18:03:06.509841922',\n               '2024-10-07 18:03:06.524832502',\n               '2024-10-07 18:03:06.539823082',\n               '2024-10-07 18:03:06.554813661',\n               '2024-10-07 18:03:06.569804241',\n               '2024-10-07 18:03:06.584794821',\n               '2024-10-07 18:03:06.599785401',\n               ...\n               '2024-10-07 18:03:14.559783315',\n               '2024-10-07 18:03:14.574773895',\n               '2024-10-07 18:03:14.589764475',\n               '2024-10-07 18:03:14.604755054',\n               '2024-10-07 18:03:14.619745634',\n               '2024-10-07 18:03:14.634736214',\n               '2024-10-07 18:03:14.649726794',\n               '2024-10-07 18:03:14.664717374',\n               '2024-10-07 18:03:14.679707954',\n               '2024-10-07 18:03:14.694698534'],\n              dtype='datetime64[ns]', name='azimuth_time', length=550, freq=None))ground_rangePandasIndexPandasIndex(Index([190610.0, 190710.0, 190810.0, 190910.0, 191010.0, 191110.0, 191210.0,\n       191310.0, 191410.0, 191510.0,\n       ...\n       239610.0, 239710.0, 239810.0, 239910.0, 240010.0, 240110.0, 240210.0,\n       240310.0, 240410.0, 240510.0],\n      dtype='float64', name='ground_range', length=500))timePandasIndexPandasIndex(DatetimeIndex(['2024-10-07', '2024-10-19', '2024-10-31', '2024-11-12',\n               '2024-11-24', '2024-12-06', '2024-12-18', '2024-12-30',\n               '2025-01-11', '2025-01-23', '2025-02-04', '2025-02-16',\n               '2025-03-12', '2025-03-24'],\n              dtype='datetime64[s]', name='time', freq=None))Attributes: (4)_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :beta nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)units :dB",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "64_flood_mapping_valencia.html#flood-mapping-and-time-series-analysis",
    "href": "64_flood_mapping_valencia.html#flood-mapping-and-time-series-analysis",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "Flood mapping and time series analysis",
    "text": "Flood mapping and time series analysis\nThe last step is to perform the time series and flood mapping analysis.\n\nSimple visualisation of all datasets selected\nFirst, we can plot all the datasets simply to create a visualisation of the flood. In addition to these plots, we are also plotting a chosen latitude and longitude point (as defined at beginning of this tutorial). The coordinate serves as a measure of comparison between all the datasets and from within different analysis methods.\nWhen we look over all the items plotted, we can clearly see that the significant flood event happened between the 19th and the 31st of October (it occurred on the 29th of October 2024).\nAdditionally, we can see that the backscatter displaying the water presence was only going back to normal ranges around mid-February 2025.\n\ncols = 4    # setting up column number\nrows = int(np.ceil(DATASET_NUMBER / cols))  # setting up row number according to clumn number\nfig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))  \naxes = axes.flatten()  \n\nfor i in range(DATASET_NUMBER):\n    ax = axes[i]\n    intensity_data_cube[i].plot(    # plotting all the datasets stored in the data cube\n        x=\"longitude\", y=\"latitude\",\n        vmin=-25, vmax=5,\n        ax=ax,  \n        add_colorbar=False  \n    )\n    ax.scatter(TARGET_LONG, TARGET_LAT, color=\"red\", marker=\"o\", s=10, label=\"Selected Point\")  # also plotting the known point defined before\n    ax.legend()\n\nfor j in range(i+1, len(axes)):\n    axes[j].axis('off')     # to avoid having empty cells\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCreate a flood map based on threshold values\nIt is known through literature and other sources that water appears as darker pixels, typically with values lower than -15 dB. This is a very good method for identifying water because separating the pixels within this threshold value will give us almost a True and False map for pixels which are greater or smaller than the defined threshold.\nIn the plots below, we classify the pixels with backscatter values equal to or lower than -15 in yellow. Conversely, in purple, we see the pixels that have backscatter values greater than -15.\nThis type of visualisation allows us to easily identify flooded and non-flooded areas.\n\nfig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))  \naxes = axes.flatten()  \n\nfor i in range(DATASET_NUMBER):\n    ax = axes[i]\n    water_mask = (intensity_data_cube[i] &lt;= WATER_THRESHOLD_DB)     # defining the water mask from the threshold\n    water_mask.plot(        # plotting all the water masks \n        x=\"longitude\", y=\"latitude\",\n        ax=ax,  \n        add_colorbar=False  \n    )\n    ax.scatter(TARGET_LONG, TARGET_LAT, color=\"red\", marker=\"o\", s=10, label=\"Selected Point\") # again plotting the known point defined before\n    ax.legend()\n\nfor j in range(i+1, len(axes)):\n    axes[j].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCreate a map showing differences between two images\nKnowing the exact flood date, which we have, and from the images plotted previously, we can easily see that the second image is the one right before the flood event and that the third image is the one directly after it. These two images show significant differences in the flooded areas and backscatter values, ranging from -5 dB (in the image before the event) to -20 dB (in the image directly after the event).\nFor this reason, when we compute the difference between the two images, we will mostly get: - Values around 0 dB for areas that did not change - Values ranging from -15 dB to -20 dB in the precise flooded areas.\nThis is an excellent way to determine precisely which areas were flooded. As we are comparing an image from before the event with another one taken at the highest possible flooding point, the differences between them will be extreme.\n\ndif = (intensity_data_cube[1]-intensity_data_cube[2])   # computing the difference between third and second dataset\ndif.plot(x=\"longitude\", y=\"latitude\", vmin=-10, vmax=20)\nplt.title(\"Flooded area right after the heavy rains\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCreate a time-series plot of one location within the flood\nTaking advantage of the data cube we have created over a new time dimension, it is much easier to plot the data over this new dimension, as in a time series plot. As our data now shares same dimensions and shape, we can choose to plot a backscatter analysis over the specific latitude and longitude point we defined earlier.\nAs these coordinates might not be exactly the ones shown on the dimension values, we need to perform some operations to find the closest values to the desired coordinates. We will now change the latitude and longitude coordinate values and see how the corresponding azimuth_time and ground_range values and indexes change.\n\n# Find how far each pixel's latitude and longitude is from the target point\nabs_error = np.abs(intensity_data_cube.latitude - TARGET_LAT) + np.abs(intensity_data_cube.longitude - TARGET_LONG)  \n\n# Get the indexes of the closest point\ni, j = np.unravel_index(np.argmin(abs_error.values), abs_error.shape)\nazimuth_time_index = i\nground_range_index = j\n\n# Get the coordinate values of the closest point\nazimuth_time_value = intensity_data_cube.azimuth_time[i].values\nground_range_value = intensity_data_cube.ground_range[j].values\n\nprint(\"Nearest azimuth_time:\", azimuth_time_value, \", with index:\", azimuth_time_index)\nprint(\"Nearest ground_range:\", ground_range_value, \", with index:\", ground_range_index)\n\n# Slice the data cube in order to get only the pixel that corresponds to the target point\ntarget_point = intensity_data_cube.isel(ground_range=ground_range_index, \n                                        azimuth_time=azimuth_time_index)\n\nNearest azimuth_time: 2024-10-07T18:03:10.977034725 , with index: 301\nNearest ground_range: 217810.0 , with index: 272\n\n\nNow we can plot the data cube, showing the backscatter intensity over the target point we defined earlier. Since the datasets are stacked along the time dimension, it becomes much easier to plot the evolution of water backscatter at a specific location. This provides an effective way to monitor the flooding status at that point.\nWe can also add a line representing the water threshold we defined. Any point with a backscatter value below this threshold will be classified as water, thus flooded.\n\n# Plot the sliced data cube\ntarget_point.plot(label='Time series backscatter') \n\nx = target_point[target_point.dims[0]].values   # getting the x axis values (time)\ny = target_point.values                         # getting the y axis values (backscatter intensity)\n\n# Creating the trend line\nx_num = np.arange(len(x))   \nz = np.polyfit(x_num, y, 6)\np = np.poly1d(z)\n\nplt.plot(x, p(x_num), 'r--', label='Trend line')\nplt.plot(x, [-15] * len(x), 'g--', label='Flood threshold')\nplt.legend()\nplt.show()",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "64_flood_mapping_valencia.html#challenges",
    "href": "64_flood_mapping_valencia.html#challenges",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "Challenges",
    "text": "Challenges\nWhile using the optimised .zarr format saves a lot of time and makes creating workflows relatively simple and achievable, there are still a few challenges to handle and to keep in mind:\n\nSentinel-1 GRD Data Availability: For Sentinel-1 GRD, most of the datasets are not yet available on the STAC catalogue. This makes searching and data handling harder because, in the end, only a few products are correctly converted.\nBackscatter Computation Libraries: There are only a few working Python libraries that handle backscatter computation. When considering the .zarr format, the list becomes even smaller. xarray_sentinel is a very good library that handles intensity backscatter computation with .zarr.\nTerrain Correction: With the available libraries, it is very difficult to perform geometric and radiometric terrain correction. The existing tools that support the .zarr format are not yet fully operational and do not accept the format as it is.\nImage Coregistration: As discussed previously, the .zarr format is perfect for handling multiple datasets simultaneously and, thus, for time series analysis. The problem is that there is no library or package that performs coregistration of Sentinel images, especially with the .zarr format. And it remains a significant problem because coregistering multiple Sentinel images is an important step for most SAR workflows.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "64_flood_mapping_valencia.html#conclusion",
    "href": "64_flood_mapping_valencia.html#conclusion",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "Conclusion",
    "text": "Conclusion\nThe .zarr format is particularly well suited for hazard analysis because it enables multiple datasets to be combined into a single structure, either as a data cube or as a list of datatrees. This makes it ideal for rapid, multi-temporal, and multi-spatial monitoring. Unlike the .SAFE format, which required downloading entire products, .zarr only loads the specific groups needed, while the rest is accessed on the fly. As a result, both data handling and subsequent operations are much faster and more efficient.\nAlthough the ecosystem for .zarr is still evolving, there are already promising developments. In the past, .SAFE products could be fully processed on applications like SNAP, but similar completeness has not yet been reached for .zarr. Nevertheless, libraries such as xarray_sentinel and are beginning to cover essential SAR operations. This potential is illustrated in the Valencia flood case study, where Sentinel-1 backscatter sensitivity to water enabled clear mapping of flood extent and duration. The same workflow can be adapted to other flood events by adjusting the relevant thresholds and parameters to match local conditions.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "64_flood_mapping_valencia.html#whats-next",
    "href": "64_flood_mapping_valencia.html#whats-next",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "What’s next?",
    "text": "What’s next?\nThis online resource is under active development. So stay tuned for regular updates 🛰️.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "Here we introduce some helpful terms that are mentioned throughout the EOPF 101.\n\n\n\n\n\n\n\nAcronym\nDefinition\n\n\n\n\nEOPF\nEarth Observation Processing Framework\n\n\nCDSE\nCopernicus Data Space Ecosystem\n\n\nCOG\nCloud Optimised GeoTIFF\n\n\nCMP\nCore Python Modules\n\n\nCRS\nCoordinate Reference System\n\n\ndNBR\nDelta Normalized Burn Ratio\n\n\nDN\nDigital Number\n\n\nEO\nEarth Observation\n\n\nEFFIS\nEuropean Forest Fire Information System\n\n\nFCI\nFalse Colour Image\n\n\nGCP\nGround Control Points\n\n\nGDR\nGround Range Detected\n\n\nHEALPix\nHierarchical Equal Area isoLatitude Pixelation\n\n\nLST\nLand Surface Temperature\n\n\nNBR\nNormalized Burnt Ratio\n\n\nNIR\nNear-Infrared\n\n\nNRB\nNormalized Radar Backscatter\n\n\nSAFE\nStandard Archive Format for Europe\n\n\nSAR\nSynthetic Aperture Radar\n\n\nSCL\nScene Classification Layer\n\n\nSLC\nSingle Look Complex\n\n\nSLSTR\nSea and Land Surface Temperature Radiometer\n\n\nSNAP\nSentinel Application Platform\n\n\nSTAC\nSpatio Temporal Asset Catalog\n\n\nSWIR\nShort-Wave Infrared\n\n\nTCI\nTrue Colour Image\n\n\nZarr\nCloud-optimised version for netCDF and HDF5 formats, specifically designed for storing and accessing large n-dimensional arrays",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>**Glossary**</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "The table below provides a categorized overview of key resources used during the development of the EOPF 101 book.\n\n\n\nCategory\nResource Title\nDescription & Context\nLink\n\n\n\n\nSentinel Mission & Product Specifications\nSentinel-1 Level 1 Product Specification\nDetailed specifications for Sentinel-1 Level 1 products.\nAvailable here\n\n\n\nSentinel-2 - MSI - Level 2A Products\nAuxiliary and data product specifications for Sentinel-2 MSI Level 2A products.\nAvailable here\n\n\n\nSentinel-3 – Documentation (via CDSE)\nComprehensive documentation for Sentinel-3 data products and mission.\nAvailable here\n\n\nEOPF Platform & Modules\nSupported Products Formats — EOPF - Core Python Modules\nGuide to the product formats supported by the Earth Observation Processing Framework’s (EOPF) Core Python Modules.\nAvailable here\n\n\n\nEOPF Sentinel Zarr Samples Service STAC Catalog\nA STAC (Spatio Temporal Asset Catalog) for accessing Sentinel Zarr samples hosted by EOPF.\nAvailable here\n\n\n\nEOPF Sentinel Zarr Samples\nDirect access to Sentinel data samples stored in Zarr format within the EOPF ecosystem.\nAvailable here\n\n\nData Formats & Standards\nZarr Documentation\nOfficial documentation for the Zarr format, a cloud-optimised standard for n-dimensional arrays.\nAvailable here\n\n\n\nIntroduction to the Zarr Format | Copernicus Marine Help Center\nAn introductory guide to the Zarr format, provided by the Copernicus Marine Help Center.\nAvailable here\n\n\n\nZarr + STAC\nArticle discussing the integration and benefits of combining Zarr data with STAC catalogs.\nAvailable here\n\n\n\nIs Zarr the new COG?\nAn insightful discussion comparing Zarr with Cloud Optimised GeoTIFF (COG) for cloud-native geospatial data.\nAvailable here\n\n\n\nAbout STAC\nGeneral information and principles behind the Spatio Temporal Asset Catalog (STAC) specification.\nAvailable here\n\n\nCloud-Native Geospatial Initiatives\nCloud-Native Geospatial Forum (CNG)\nThe official website for the Cloud-Native Geospatial Forum, promoting cloud-native approaches in geospatial.\nAvailable here\n\n\n\nCloud-Optimized Geospatial Formats Guide - Zarr\nCloud Native Geo’s comprehensive Zarr guide\nAvailable here\n\n\n\nCloud Native Geospatial Formats Explained\nMatt Forrest’s overview of modern formats\nAvailable here\n\n\n\nZarr Takes Cloud-Native Geospatial by Storm\nEarthmover’s analysis of Zarr adoption\nAvailable here\n\n\nChunking Strategy Guides\nTo Compress or Not to Compress — A Zarr Question\nAriel Lubonja’s compression analysis\nAvailable here\n\n\n\nDask Array Best Practices\nOfficial Dask chunking guidelines\nAvailable here\n\n\n\nChoosing Good Chunk Sizes in Dask\nDask team’s chunking recommendations\nAvailable here\n\n\n\nFederated and Reusable Processing of Earth Observation Data\nNature Scientific Data paper\nAvailable here",
    "crumbs": [
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>**References**</span>"
    ]
  }
]