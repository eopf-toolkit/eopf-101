[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ESA EOPF 101",
    "section": "",
    "text": "Your community guide for working with EOPF Sentinel Zarr data in the cloud\n\nExplore EOPF 101, an open community resource designed to help Sentinel data users explore EOPF Sentinel Zarr data in the cloud. With our step-by-step and hands-on tutorials, you‚Äôll learn how to effectively use EOPF Sentinel Zarr products and build Earth Observation workflows that scale.\n\nüöÄ Ready to explore EOPF 101?\n\nEOPF 101 is designed for Sentinel data users who are new to cloud-optimised geospatial formats and cloud-based workflows. It introduces you to fundamental cloud-native geospatial concepts, the Earth Observation Processing Framework (EOPF) activities by ESA, re-processed EOPF Sentinel Zarr data, as well as tools and libraries to work with EOPF Sentinel Zarr data in the cloud.\nAcross five chapters, EOPF 101 gradually introduces you to the EOPF Sentinel Zarr products, how you can search and access these, relevant tools and plugins to use EOPF Sentinel Zarr data in different working environments, as well as practical end-to-end application workflows highlighting the benefits of EOPF Sentinel Zarr data.\n\nChapter 1 - About EOPF\n\nIntroduction to the EOPF\nAbout Cloud-Optimised Formats\nEOPF Sentinel Zarr products\n\nChapter 2 - About EOPF Zarr\n\nOverview of the EOPF Zarr format\nDiscover EOPF Zarr - Sentinel-1 GRD\nOperations with EOPF Zarr - Sentinel-1 GRD\nDiscover EOPF Zarr - Sentinel-2 L2A\nDiscover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST\n\nChapter 3 - About Chunking\n\nAn introduction to Chunking\nBest practices and Chunking optimisation in EOPF\n\nChapter 4 - EOPF and STAC\n\nIntroduction to STAC\nExplore the web interface of the EOPF Zarr STAC Catalog\nAccess the EOPF Zarr STAC API with Python\nFrom STAC to Data: Accessing EOPF Zarr with xarray\n\nChapter 5 - Tools to work with EOPF Zarr ‚Äì more coming soon!\n\nAccess the EOPF Zarr STAC API with R\nAccess the EOPF Zarr STAC API with QGIS\nAccess and analyse EOPF STAC Zarr data with R \n\nChapter 6 - EOPF Zarr in Action\n\nFire in Sardinia 2025 - Part 1\nFire in Sardinia 2025 - Part 2\nFire in Sardinia 2025 - Part 3\nFlood Mapping - Time Series Analysis in Valencia\nZarr Overviews - Part 1\nZarr Overviews - Part 2\nReservoir Surface Monitoring\nAnalysing Forest Vegetation Anomalies\n\n\n\nüí° How best to use EOPF 101\n\nYou can use EOPF 101 as a reference online resource to get example code and workflows for working with Zarr data, the EOPF STAC Catalogue, and different libraries and plugins facilitating the use of EOPF Sentinel Zarr data.\nIf you would like to execute the notebooks through the JupyterHub, simply follow the Launch Button available in all the executable notebooks:\n\n\n\nBeyond this browsable version, you can also set up our Docker images within your own JupyterHub Server and test workkflows yourself!\nWhen starting your server, you will be able to select the Docker image you want to work with. The EOPF Toolkit has designed updated environments to support your development!\nYou can select: Specify an existing docker image.\n\n\n\nOnce you click, the following box is displayed:\n\n\n\nIn the box, you can copy and paste the following custom lines:\n\nIf you would like to develop your workflow in Python: 4zm3809f.c1.de1.container-registry.ovh.net/eopf-toolkit-python/eopf-toolkit-python:competition\nOr, if you prefer to use R: 4zm3809f.c1.de1.container-registry.ovh.net/eopf-toolkit-r/eopf-toolkit-r:competition\n\nAnd select Start.\n\nüì¢ How to get involved\n\nEOPF 101 is an open community resource under active development. Our activities are designed to engage with Sentinel users and to gather feedback on EOPF Sentinel Zarr products. There are different ways you can get involved and engaged:\n\nJoin the EOPF Toolkit Notebook Competition\n\nGet ready and participate in the EOPF Toolkit Notebook Competition! The competition will kick-off in October 2025 and run until March 2026. It is your chance to get hands-on with EOPF Zarr products, get expert input and guidance to show the community the great work you can do.\n\nHow to Participate?\n\n\nStep 1: Launch & Registration\n\nThe competition officially begins with its launch at Big Data from Space 2025 on 30 September 2025. During this stage, you will be able to register your interest to receive updates!\n\nStep 2: Learning & Development\nExplore this resource and build your own notebook! The EOPF Sentinel Zarr Sample Service JupyterLab will be your primary development environment. Once you access with your CDSE credentials, you will get the chance to choose the language you want to develop with!\nTo get some ideas on how to get started with your development, watch the introductory session here.\n\nStep 3: Notebook Submission\n\nSubmit your completed Jupyter Notebook via GitHub once complete, between 1 November 2025 and 15 March 2026 (23:59 UTC+1). Stay tuned!\n\nJudging & Evaluation\n\nA panel of expert judges will evaluate each submission based on technical soundness, effective use of the EOPF Zarr data and plugins and educational quality.\n\nAwards & Showcase\n\nThe competition culminates in an online awards taking during April 2026! Winners and highly commended entries will be announced.\nThe top notebooks will be featured in the EOPF 101 as new case studies and you will be given the chance to be a co-author of a publication on EOPF 101.\nFor futher details, please visit the notebook competition repository!\n\nIdeas & Feedback?\n\nIs there a plugin or library missing that you would like to see integrated? Do you have feedback on EOPF 101? Please submit an issue and we will review your request.\n\nAbout the ESA EOPF Toolkit project\n\nEOPF 101 is a community resource developed as part of the EOPF Toolkit project funded by the European Space Agency. EOPF 101 is brought to you by Development Seed, thriveGEO and SparkGeo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>**ESA EOPF 101**</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/11_about_eopf.html",
    "href": "01_about_eopf/11_about_eopf.html",
    "title": "Introduction to the EOPF",
    "section": "",
    "text": "Introduction\nIn this chapter, we will introduce the European Space Agency‚Äôs (ESA) Earth Observation Processor Framework (EOPF) initiative. This project marks a significant step towards modernising how we handle satellite data, specifically by moving away from the traditional .SAFE data format to a more efficient, cloud-optimised format. We will take a closer look at the new structure ESA has developed for this purpose.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to the EOPF</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/11_about_eopf.html#what-is-eopf",
    "href": "01_about_eopf/11_about_eopf.html#what-is-eopf",
    "title": "Introduction to the EOPF",
    "section": "What is EOPF?",
    "text": "What is EOPF?\nThe Earth Observation Processor Framework (EOPF) is an initiative led by the European Space Agency (ESA) designed to modernise and harmonise data from the Copernicus Sentinel Missions.\nWith the upcoming Copernicus Expansion missions in 2028, the amount of data produced daily will significantly increase. EOPF is ESA‚Äôs solution to organise Sentinel data in a way that works seamlessly with modern cloud technology. This will make it easier to find, access, and process the information you need. The new approach provides user-friendly access, simplifies maintenance, and helps keep costs down, guaranteeing reliable access to Sentinel data in the long run.\nThe Sentinel-1, Sentinel-2, and Sentinel-3 missions are the first to be updated with this new system.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to the EOPF</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/11_about_eopf.html#the-eopf-data-model",
    "href": "01_about_eopf/11_about_eopf.html#the-eopf-data-model",
    "title": "Introduction to the EOPF",
    "section": "The EOPF Data Model",
    "text": "The EOPF Data Model\nThe EOPF data model has been defined by following a set of principles:\n\nOpen standards: Following common and community-approved data standards ensures sustainability and user uptake.\nInteroperability: Harmonised with a clear and organised structure that describes the data itself.\nCloud optimisation: Designed for efficient access and handling in cloud environments.\nConversion flexibility: Providing tools to adjust the data for different applications.\n\nUnder EOPF, there are four key areas of activities: (i) EOPF product structure, (ii) EOPF metadata structure, (iii) EOPF encoding structure and (iv) the EOPF Processor Framework:\n\nEOPF product structure\nAs part of the EOPF, ESA is actively working on a common data structure for Sentinel data products to define a common meta-model that can be used across all Sentinel and other EO missions. This approach ensures that data from several missions is consistent.\nThe EOPF product structure consists of the following components:\n\nMeasurements: The actual sensor readings (like how much light is reflected or the temperature), at different levels of detail.\nQuality indicators: Details that help understand how reliable the measurements are.\nConditions: Information about the environment or technical aspects when the data was collected.\nAttributes: Global metadata, such as when it was acquired and the sensor‚Äôs orbit.\n\n\n\n\nEOPF product structure\n\n\n\n\n\n\n\n\nNote\n\n\n\nLearn more about the EOPF Zarr product structure here.\n\n\n\n\nEOPF metadata structure\nMetadata provides all relevant information required to uniquely describe each Sentinel product. The EOPF metadata structure is organised as follows:\n\nDiscovery Metadata: Following the metadata structure defined by the SpatioTemporal Asset Catalogue (STAC), which helps to keep things consistent across different missions.\nProcessing History Metadata: Keeping a record of how the data has been processed.\nOther Metadata: Information like the status of the sensor and details about the satellite‚Äôs orbit.\n\n\n\n\n\n\n\nNote\n\n\n\nEOPF and STAC: Learn more about EOPF and STAC here.\n\n\n\n\nEOPF encoding structure\nAn encoding structure can be seen as the specific method used to package and store data and its associated metadata in a digital format. Building on the consistent data structure and clear metadata, the new storage system must be capable of handling various aspects of current Sentinel data (such as manifest files and tile structures from the .SAFE format) while remaining fully compatible with cloud environments.\nESA chose .zarr as encoding format as it allows for instant access to data, efficient processing of massive amounts of data, and seamless integration with other datasets. The EOPF Sentinel Zarr data encoding allows you to work with data from multiple missions more effectively.\n\n\n\n\n\n\nNote\n\n\n\nLearn more about the EOPF Sentinel Zarr format here. And learn more about cloud-optimised geospatial data formats in general in the Cloud-Optimised Geospatial Data Formats Guide\n\n\n\n\nEOPF processor framework\nThe way Sentinel data is processed is being updated to take advantage of modern cloud computing. This will make the processing faster and more efficient, and at the same time ensure the scientific quality and accuracy of the Sentinel data remains the same.\n\n\n\n\n\n\nNote\n\n\n\nTo learn more about the EOPF processor framework, visit https://eopf.copernicus.eu/eopf/",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to the EOPF</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/11_about_eopf.html#conclusion",
    "href": "01_about_eopf/11_about_eopf.html#conclusion",
    "title": "Introduction to the EOPF",
    "section": "Conclusion",
    "text": "Conclusion\nThroughout this section, we explored the EOPF initiative and its adoption of the .zarrformat. This new approach is set to significantly improve and simplify how we access and work with data from the satellite missions Sentinel-1, Sentinel-2, and Sentinel-3.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to the EOPF</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/11_about_eopf.html#whats-next",
    "href": "01_about_eopf/11_about_eopf.html#whats-next",
    "title": "Introduction to the EOPF",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following section, we learn why EO data needs to be cloud-optimised when processed in the cloud.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to the EOPF</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/12_about_cloudoptimized_formats.html",
    "href": "01_about_eopf/12_about_cloudoptimized_formats.html",
    "title": "About cloud-optimised formats",
    "section": "",
    "text": "Introduction\nIn this section, we will dive into cloud-optimised geospatial formats. We explore why these new formats are important and will introduce you to two common cloud-optimised data formats specifically for raster files.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/12_about_cloudoptimized_formats.html#why-to-cloud-optimise-geospatial-data-formats",
    "href": "01_about_eopf/12_about_cloudoptimized_formats.html#why-to-cloud-optimise-geospatial-data-formats",
    "title": "About cloud-optimised formats",
    "section": "Why to cloud-optimise geospatial data formats?",
    "text": "Why to cloud-optimise geospatial data formats?\nThe volume of EO data has grown exponentially in recent years. The Copernicus programme alone generates ~16TB daily from the Sentinel missions. Traditional file formats, like .SAFE (where each file can be hundreds of megabytes), are optimised for efficient archiving and distributing data. This means that we often download the data from an entire overpass, even if we only need to access a small part of it. For example, if we want to do an analysis of the area of a single city over a decade.\nWith growing data volumes, this becomes a challenge. To picture the different nature of challenges we come across, let us compare a traditional local workflow with a cloud-based workflow:\n\nTraditional local workflow: When working locally, we download much more data than we need, and we are constrained by the compute and storage capacity of the local system. However, an advantage of working locally is that data and compute are close together, meaning that there is not much delay in accessing the data.\nCloud-based workflow: Cloud environments overcome the limitations local workflows have. A cloud environment offers limitless storage and compute capacity. On the contrary, data storage, compute, and you the destination are far apart. There is an additional time for data to travel between the storage location, processing resources and us. This time is referred to as data latency.\n\n\n\n\n\n\n\nNote\n\n\n\nData latency refers to the time it takes for data to be transmitted or processed from cloud storage to your computer. In local workflows, data latency is minimal, whereas in cloud-based workflows, data latency needs to be optimised.\n\n\n\nAnalogy: Comparing local and cloud-based workflows with ordering a pizza\nTo understand the principal concept, let us compare local and cloud-based workflows with ordering a pizza. Local workflows are similar to placing an order at a pizza store on your street. It is quick since the data (pizza) is easily accessible, but we can only choose from what the local pizza store offers.\nOn the other hand, cloud-based workflows are comparable to ordering a pizza from a pizza store in a different city or even country. This option allows you to order different types of pizzas, which are not available in the pizza store on your street. While we might have more options to choose from, the time between order and delivery can become a challenge. The time until your pizza from a different town or country arrives at your house is called data latency.\nHence, the overall goal with cloud-based workflows is to minimise data latency as much as possible. This is why traditional data formats need to be cloud-optimised.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/12_about_cloudoptimized_formats.html#characteristics-of-cloud-optimised-formats",
    "href": "01_about_eopf/12_about_cloudoptimized_formats.html#characteristics-of-cloud-optimised-formats",
    "title": "About cloud-optimised formats",
    "section": "Characteristics of cloud-optimised formats",
    "text": "Characteristics of cloud-optimised formats\nCloud-optimised formats are optimised to minimise data latency. By allowing for an efficient retrieval of smaller, specific chunks of information rather than downloading an entire file. Accessing a smaller data subset also reduces the costs associated with data transfer and data processing.\nCloud-optimised geospatial data formats have the following characteristics:\n\nData is accessible over an HTTP protocol.\nRead-Oriented, as it supports partial and parallel reads.\nData is organised in internal groupings (such as chunks, tiles, shards) for efficient subsetting, distributed processing and data access in memory.\nMetadata can be accessed in one read.\n\n\n\n\n\n\n\nNote\n\n\n\nWhen accessing data over the internet (e.g.¬†through object stores in the cloud), latency is high compared to local storage, so it is recommended to fetch lots of data in fewer reads.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/12_about_cloudoptimized_formats.html#cloud-optimised-geospatial-raster-formats",
    "href": "01_about_eopf/12_about_cloudoptimized_formats.html#cloud-optimised-geospatial-raster-formats",
    "title": "About cloud-optimised formats",
    "section": "Cloud-Optimised Geospatial Raster Formats",
    "text": "Cloud-Optimised Geospatial Raster Formats\nFor satellite data, two main cloud-optimised formats are being used:\n\nCloud-Optimised GeoTIFF (COG): Optimised for 2D image data and originates from the traditional GeoTIFF format, and\nZarr: Used and designed for complex, n-dimensional data structures and originates from the traditional formats netCDF and HDF5.\n\n\nCloud-optimised GeoTIFF (COG)\nCOGs have been widely used as a cloud-native format for satellite imagery and improve the standard GeoTIFF format by:\n\nOrganising data into tiles: Dividing the data into smaller, manageable squares (like 512x512 pixels).\nIncluding lower-resolution previews: Having pre-generated, less detailed versions of the data. This allows for fast and efficient data visualisations.\n\nA key feature of COGs is the Internal File Directory (IFD), which acts like an internal index. This allows for retrieving only the parts of the data needed using simple web requests. For example, it is possible to access just the tiles covering Paris from a large Sentinel-2 image of Europe.\n\n\n\nCOG structure. Retrieved from CNG documentation\n\n\n\n\nMulti-dimensional Array Storage with Zarr\nZarr is the cloud-optimised version for the traditional formats netCDF and HDF5, and is specifically designed for storing and accessing large n-dimensional arrays in the cloud by:\n\nChunking: Breaking large arrays into smaller pieces that can be accessed independently\nCompression: Each chunk can be compressed individually for efficient storage\nHierarchical Organisation: Arrays are organised in groups, similar to folders in a filesystem\nCloud-Native Access: Optimised for reading partial data over HTTP\nParallel I/O: Multiple chunks can be read or written simultaneously\nSelf-Description: Rich metadata is stored alongside the data using JSON\n\nThis makes Zarr particularly well-suited as a storage format for processing Earth observation data in the cloud.\n\n\n\nZarr‚Äôs hierarchical organization showing stores, groups, arrays, and chunks\n\n\n\n\nWhen to use COG versus Zarr?\nThe table below compares some features of COG and Zarr:\n\n\n\n\n\n\n\n\nFeature\nZarr\nCOG\n\n\n\n\nStructure\nMulti-file chunks\nSingle file\n\n\nAccess\nParallel\nSequential\n\n\nCompression\nDifferently per-chunk\nWhole-file\n\n\nScales\nMulti-scale in single file\nSeparate, pre-generated lower-resolution files\n\n\n\n Based on the structure and capabilities for each format, COGs are used when:\n\nYou work with two-dimensional raster data (like satellite images or elevation models)\nYou need to easily visualise or access specific geographic areas without loading the entire dataset.\nInteroperability with existing GIS software is important, as COG is a widely adopted standard.\n\nOn the other hand, Zarr is more often used when:\n\nYou deal with large, multi-dimensional datasets that might be updated or modified.\nYou are performing complex analyses that involve accessing different parts of the data in parallel.\nAn efficient handling of different resolutions or variables within a single dataset is required.\n\n\n\n\n\n\n\nNote\n\n\n\nZarr vs COG: Want to learn more about the differences and similarities of COG and Zarr? Then we recommend the following blog post by Julia Signell and Jarrett Keifer from Element84, where they discuss ‚ÄúIs Zarr the new COG?‚Äù",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/12_about_cloudoptimized_formats.html#conclusion",
    "href": "01_about_eopf/12_about_cloudoptimized_formats.html#conclusion",
    "title": "About cloud-optimised formats",
    "section": "Conclusion",
    "text": "Conclusion\nIn this section, we explored the fundamental concepts of cloud-optimised geospatial formats. By understanding the core characteristics of these formats and by looking at specific examples like Zarr, you now have a solid foundation for appreciating how these innovations are making geospatial data more accessible, efficient, and powerful in the cloud.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/12_about_cloudoptimized_formats.html#whats-next",
    "href": "01_about_eopf/12_about_cloudoptimized_formats.html#whats-next",
    "title": "About cloud-optimised formats",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nNow that we have an idea of the available cloud-optimised formats for satellite imagery and the reason why we need to optimise traditional formats for the cloud, in the next section, we will explore the EOPF data products that are being re-processed as part of the EOPF Zarr Sample Service.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>About cloud-optimised formats</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/13_overview_eopf_datasets.html",
    "href": "01_about_eopf/13_overview_eopf_datasets.html",
    "title": "Overview of EOPF Zarr Products",
    "section": "",
    "text": "Introduction\nIn the previous section, we introduced the Earth Observation Processing Framework (EOPF) initiative and explored the advantages of cloud-optimised formats like Zarr. Now, it is time to discover which data products will be available and where you can access them.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Overview of EOPF Zarr Products</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/13_overview_eopf_datasets.html#available-eopf-zarr-products",
    "href": "01_about_eopf/13_overview_eopf_datasets.html#available-eopf-zarr-products",
    "title": "Overview of EOPF Zarr Products",
    "section": "Available EOPF Zarr products",
    "text": "Available EOPF Zarr products\nRe-engineered EOPF Zarr products are available for exploration via the EOPF Sentinel Zarr Sample Service STAC Catalog. Data from Sentinel-1, Sentinel-2 and Sentinel-3 missions are being reprocessed and made available.\n\n\n\n\n\n\nImportant\n\n\n\nThe re-processing from the Sentinel missions is an ongoing activity as part of the EOPF Sentinel Zarr Sample Service. This page and our tutorials will continuously be updated as soon as new data products are available.\n\n\nAn overview of the datasets that are being re-engineered for different processing levels is given below.\n\nSentinel-1\nSentinel-1 is a radar imaging mission that is composed of a constellation of two polar-orbiting satellites providing continuous all-weather, day and night imagery.\n\n\n\nProduct\nInstrument\nDescription\nAvailable at\n\n\n\n\nLevel-1 GRD\nGround Range Detected\nThe Sentinel-1 Level-1 GRD products consist of focused SAR data that has been detected, multi-looked and projected to ground range using the Earth ellipsoid model WGS84.\nthis link\n\n\nLevel-1 SLC\nSingle Look Complex\nThe Sentinel-1 Level-1 SLC products consist of focused SAR data, geo-referenced using orbit and attitude data from the satellite, and provided in slant-range geometry.\nthis link\n\n\nLevel-2 OCN\nOcean\nThe Sentinel-1 Level-2 OCN products for wind, wave and currents applications may contain the following geophysical components derived from the SAR data: Ocean Wind field (OWI), Ocean Swell spectra (OSW), Surface Radial Velocity (RVL).\nthis link\n\n\n\n\n\nSentinel-2\nSentinel-2 acquires optical imagery at high spatial resolution (10m to 60m) over land and coastal waters. The mission supports applications such as agricultural monitoring, emergency management, land cover classifications, and water quality.\n\n\n\nProduct\nInstrument\nDescription\nAvailable at\n\n\n\n\nLevel-1C\nMulti-Spectral Instrument\nThe Sentinel-2 Level-1C product is composed of 110x110 km2 tiles (ortho-images in UTM/WGS84 projection). Earth is subdivided into a predefined set of tiles, defined in UTM/WGS84 projection and using a 100 km step.\nthis link\n\n\nLevel-2A\nMulti-Spectral Instrument\nThe Sentinel-2 Level-2A Collection 1 product provides orthorectified Surface Reflectance (Bottom-Of-Atmosphere: BOA), with sub-pixel multispectral and multitemporal registration accuracy.\nthis link\n\n\n\n\n\nSentinel-3\nSentinel-3 is a mission that regularly measures our Earth‚Äôs oceans, land, rivers, lakes, ice on land, sea ice, and the atmosphere. Its goal is to keep track of and help us understand how these large parts of our planet change over long periods.\n\nOcean and Land Colour Instrument\n\n\n\nProduct\nProduct\nDescription\nAvailable at\n\n\n\n\nLevel-1 EFR\nEarth Full Resolution\nProvides TOA radiances at full resolution for each pixel in the instrument grid, each view and each OLCI channel, plus annotation data associated with OLCI pixels.\nthis link\n\n\nLevel-1 ERR\nEarth Reduced Resolution\nThe Sentinel-3 OLCI L1 ERR product provides TOA radiances at reduced resolution for each pixel in the instrument grid, each view and each OLCI channel, plus annotation data associated with OLCI pixels.\nthis link\n\n\nLevel-2 LFR\nLand Full Resolution\nThe Sentinel-3 OLCI L2 LFR product provides land and atmospheric geophysical parameters computed for full resolution.\nthis link\n\n\nLevel-2 LRR\nLand Reduced Resolution\nThe Sentinel-3 OLCI L2 LRR product provides land and atmospheric geophysical parameters computed for reduced resolution.\nthis link\n\n\n\n\n\nSea and Land Surface Temperature Radiometer\n\n\n\nProduct\nData\nDescription\nAvailable at\n\n\n\n\nLevel-1 RBT\nRadiance Brightness Temperature\nThe Sentinel-3 SLSTR Level-1B RBT product provides radiances and brightness temperatures for each pixel in a regular image grid for each view and SLSTR channel.\nthis link\n\n\nLevel-2 LST\nLST: Land Surface Temperature\nThe Sentinel-3 SLSTR Level-2 LST product provides land surface temperature.\nthis link",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Overview of EOPF Zarr Products</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/13_overview_eopf_datasets.html#conclusion",
    "href": "01_about_eopf/13_overview_eopf_datasets.html#conclusion",
    "title": "Overview of EOPF Zarr Products",
    "section": "Conclusion",
    "text": "Conclusion\nIn this section, we provide an overview of the available Sentinel Missions that will be re-processed and made available as EOPF Zarr products.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Overview of EOPF Zarr Products</span>"
    ]
  },
  {
    "objectID": "01_about_eopf/13_overview_eopf_datasets.html#whats-next",
    "href": "01_about_eopf/13_overview_eopf_datasets.html#whats-next",
    "title": "Overview of EOPF Zarr Products",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following chapter, we will dive deep into EOPF Zarr format and understand why it can provide an optimal and efficient application.",
    "crumbs": [
      "**About EOPF**",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Overview of EOPF Zarr Products</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/21_what_is_zarr.html",
    "href": "02_about_eopf_zarr/21_what_is_zarr.html",
    "title": "Overview of the EOPF Zarr format",
    "section": "",
    "text": "Introduction\nIn our journey to understand cloud-optimised Earth Observation (EO) data, we have frequently mentioned the Zarr format. Now, we will take a closer look and truly understand what Zarr is and why it is such a game-changer for large datasets like those from ESA‚Äôs Sentinel missions. This chapter will break down the essential building blocks of Zarr, explaining how it organises data to make it incredibly efficient for cloud-based analysis.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/21_what_is_zarr.html#what-is-zarr",
    "href": "02_about_eopf_zarr/21_what_is_zarr.html#what-is-zarr",
    "title": "Overview of the EOPF Zarr format",
    "section": "What Is Zarr?",
    "text": "What Is Zarr?\nZarr is an open-source, cloud-native protocol for storing multi-dimensional arrays. It is specifically designed to work well with cloud storage and larger-scale computing systems and can be seen as a cloud-native alternative to older formats like HDF5 or NetCDF.\nKey advantage to traditional formats is that the Zarr specification stores large multi-dimensional arrays in chunks, which are smaller pieces of the larger array. Chunks can be accessed individually, or multiple chunks can be read and written in parallel, making data access highly efficient.\nZarr works across different storage systems, including local file systems, cloud object storage, as well as distributed file systems, offering a greater flexibility compared to traditional file formats.\nIn addition, Zarr embeds metadata directly alongside the data. This makes Zarr self-descriptive, as each data array contains descriptive information about itself, such as data type, dimensions or additional attributes.\n\n\n\n\n\n\nNote\n\n\n\nPro tip: Learn more about Zarr in the official Zarr Documentation and the Zarr V3 storage specification",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/21_what_is_zarr.html#components-of-zarr",
    "href": "02_about_eopf_zarr/21_what_is_zarr.html#components-of-zarr",
    "title": "Overview of the EOPF Zarr format",
    "section": "Components of Zarr",
    "text": "Components of Zarr\nZarr is organised in a human-readable, hierarchical structure using simple JSON metadata files and is composed of groups and stores, chunks and metadata:\n\nGroups and Stores\nGroups and stores are concepts that allow Zarr to differentiate between (i) where the data is stored (stores) and (ii) how it is organised (groups). A group is a container for logically organising the data, similar to folders in a file system. A store defines where the data is stored; it can be, e.g.¬†a bucket in the cloud or a directory on a disk.\n\n\nChunks\nZarr divides arrays into smaller, independent pieces (chunks). Through chunking, it is possible to retrieve and process specific areas without loading the complete dataset. Its organisation into chunks is the main reason for Zarr‚Äôs high performance. Chunks are saved as binary files inside a /c directory and are further organised through nested folder paths based on their index, e.g.¬†c/0/0/0 for the chunk position [0,0.0].\n\n\nMetadata\nZarr uses descriptive metadata to describe the individual arrays but also the full hierarchy of the dataset. Metadata is stored in zarr.json files and is available on the array, group and store levels. This structured metadata approach makes Zarr datasets self-descriptive and easy to navigate.\nThe graphic below shows an overview of all relevant Zarr components.\n\n\n\nZarr conceptual structure and overview of Zarr components",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/21_what_is_zarr.html#eopf-zarr-structure",
    "href": "02_about_eopf_zarr/21_what_is_zarr.html#eopf-zarr-structure",
    "title": "Overview of the EOPF Zarr format",
    "section": "EOPF Zarr Structure",
    "text": "EOPF Zarr Structure\nThe ESA EOPF defines Zarr as the encoding format for the EOPF Sentinel Zarr Samples Service. The Zarr encoding is well aligned with ESA‚Äôs objective of enhancing the accessibility of Sentinel data by modernising the previous .SAFE encoding into a flexible, cloud-native structure. The cloud-native nature of zarr is expected to broaden the applications of the Sentinel data within the geospatial community while maintaining data quality and established algorithms.\nEOPF Zarr products consist of four main groups:\n\n\n\n\n\n\n\nGroup\nDescription\n\n\n\n\nAttributes\nSTAC format metadata for the Zarr element\n\n\nMeasurements\nMain retrieved variables\n\n\nConditions\nMeasurement context (geometric angles, meteorological/instrumental data)\n\n\nQuality\nFlags and quality information for measurement filtering\n\n\n\n\nEOPF Zarr product example: Sentinel-2 L2A\nLet us imagine a Sentinel-2 L2A tile. The tile has dimensions of approximately 10,980 by 10,980 pixels, and includes 12 spectral bands (B01 to B12, excluding B10) at different resolutions, plus additional data arrays such as a Scene Classification Map (SCL) and Atmospheric Optical Thickness (AOT).\nFor efficient handling, the data is divided into 1,024 by 1,024-pixel chunks. This chunking strategy allows for optimal performance when reading specific spatial regions of interest.\nThe figure below gives a graphical overview of how an EOPF Zarr Sentinel-2 L2A product file is organised. \nThe table below provides a more detailed outline of what content is available in the different groups.\n\n\n\n\n\n\n\n\nGroup\n\nContent\n\n\n\n\nAttributes\n\nProcessing history metadata  Chunking configuration  Global metadata (acquisition time, sensing time, etc.)  Product-specific metadata‚âà\n\n\nMeasurements\n10m resolution (r10)\nB02 (Blue, 490nm)  B03 (Green, 560nm)  B04 (Red, 665nm) B08 (NIR, 842nm)\n\n\n\n20m resolution (r20)\nB05 (Red Edge 1, 705nm) B06 (Red Edge 2, 740nm) B07 (Red Edge 3, 783nm) B8A (Narrow NIR, 865nm) B11 (SWIR 1, 1610nm) B12 (SWIR 2, 2190nm)\n\n\n\n60m resolution (r60)\nB01 (Coastal aerosol, 443nm) &lt;br?B09 (Water vapour, 945nm)\n\n\nConditions\n\nSun angles (zenith, azimuth)  Viewing angles  Mean solar irradiance  Atmospheric parameters such as (i) Aerosol Optical Thickness (AOT), (ii) Water Vapour (WV) and (iii) Cloud and snow probability\n\n\nQuality\n\nScene Classification Layer (SCL)  Quality flags for each band  Detector footprint  Defective pixels masks\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nZarr Deep Dive: Dive deeper into the benefits of Zarr in a blog post by Lindsey Nield from the Earthmover team: Fundamentals: What is Zarr? A Cloud-Native Format for Tensor Data.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/21_what_is_zarr.html#conclusion",
    "href": "02_about_eopf_zarr/21_what_is_zarr.html#conclusion",
    "title": "Overview of the EOPF Zarr format",
    "section": "Conclusion",
    "text": "Conclusion\nThe EOPF Zarr structure allows for efficient access to individual bands or specific spatial regions without loading the entire dataset, making it ideal for large-scale geospatial analysis. It further ensures all relevant metadata is co-located with the data, enhancing data discoverability and usability.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/21_what_is_zarr.html#whats-next",
    "href": "02_about_eopf_zarr/21_what_is_zarr.html#whats-next",
    "title": "Overview of the EOPF Zarr format",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nNow that you have a theoretical grasp of the Zarr format, the next notebook Discover EOPF Zarr - Sentinel-1 GRD will provide a first hands-on experience opening an EOPF Zarr product. We will transition to our first Jupyter Notebook where you will directly interact with a Zarr store.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Overview of the EOPF Zarr format</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html",
    "href": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nIn this section, we will discover how to search and access Sentinel-1 GRD data through EOPF Zarr samples services and how the SAR data is structured inside the groups and subgroups of a .zarr product.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html#sentinel-1-grd-structure",
    "href": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html#sentinel-1-grd-structure",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "Sentinel-1 GRD structure",
    "text": "Sentinel-1 GRD structure\n\nOpening the Zarr groups and subgroups\nWe start by unwrapping Sentinel-1 GRD .zarr products. You can use the xarray functions open_datatree()and open_dataset() to do this.\nLet‚Äôs keep in mind the following: - set engine = \"zarr\", specifically designed for the encoding chosen for the EOPF by ESA. - chunks = {}, to keep the original chunking size defined in the .zarrfile metadata\n\nproductID = \"S1A_IW_GRDH_1SDV_20170508T164830_20170508T164855_016493_01B54C_8604\"\nurl = f\"https://objectstore.eodc.eu:2222/e05ab01a9d56408d82ac32d69a5aae2a:sample-data/tutorial_data/cpm_b716/{productID}.zarr\"\n\ndt = xr.open_datatree(\n    url, \n    engine='zarr', \n    chunks={}\n)\n\nprint_gen_structure(dt, indent=\"\") # So we can visualize the data structure easily\n\nNone\n  S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH\n    conditions\n      antenna_pattern\n      attitude\n      azimuth_fm_rate\n      coordinate_conversion\n      doppler_centroid\n      gcp\n      orbit\n      reference_replica\n      replica\n      terrain_height\n    measurements\n    quality\n      calibration\n      noise\n      noise_range\n  S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VV\n    conditions\n      antenna_pattern\n      attitude\n      azimuth_fm_rate\n      coordinate_conversion\n      doppler_centroid\n      gcp\n      orbit\n      reference_replica\n      replica\n      terrain_height\n    measurements\n    quality\n      calibration\n      noise\n      noise_range\n\n\nAs we can see, Sentinel-1 GRD data is organised in a slightly different way compared to Sentinel-2 and Sentinel 3.\nThere are two main groups with the same subgroups, which correspond to the polarisation information. To identify each polarization you need to check the last two letters of each group.\nFor example: * S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH corresponds to the VH polarization, and * S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VV corresponds to the VV polarization.\nEach polarization group contains the conditions, measurements and quality subgroups. We can list all the groups for the VH polarisation calling .groups.\n\nvh = dt.S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH.groups\nvh\n\n('/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/measurements',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/antenna_pattern',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/attitude',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/azimuth_fm_rate',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/coordinate_conversion',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/doppler_centroid',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/gcp',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/orbit',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/reference_replica',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/replica',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/terrain_height',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/calibration',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/noise',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/noise_range')\n\n\n\n\nBrowsing information inside Zarr\nNow that we know how to access each polarisation group, we can check where some of the relevant information is stored. These variables will help us visualise results.\nFor example, to access the measurements subgroup, we can used the .open_dataset() function. Important is to specify the group we are interested in with the help of the group keyword argument.\n\nmeasurements = xr.open_dataset(\n    url,\n    engine=\"zarr\",\n    group=\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/measurements\",\n    chunks={}\n)\nmeasurements\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 877MB\nDimensions:       (azimuth_time: 16694, ground_range: 26239)\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 134kB 2017-05-08T16:48:30.467...\n    line          (azimuth_time) int64 134kB dask.array&lt;chunksize=(16694,), meta=np.ndarray&gt;\n  * ground_range  (ground_range) float64 210kB 0.0 10.0 ... 2.624e+05 2.624e+05\n    pixel         (ground_range) int64 210kB dask.array&lt;chunksize=(26239,), meta=np.ndarray&gt;\nData variables:\n    grd           (azimuth_time, ground_range) uint16 876MB dask.array&lt;chunksize=(2557, 26239), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 16694ground_range: 26239Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:30.469413574',\n       '2017-05-08T16:48:30.470911148', ..., '2017-05-08T16:48:55.463923851',\n       '2017-05-08T16:48:55.465421425', '2017-05-08T16:48:55.466919000'],\n      shape=(16694,), dtype='datetime64[ns]')line(azimuth_time)int64dask.array&lt;chunksize=(16694,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n130.42 kiB\n130.42 kiB\n\n\nShape\n(16694,)\n(16694,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         16694 1\n\n\n\n\nground_range(ground_range)float640.0 10.0 ... 2.624e+05 2.624e+05array([0.0000e+00, 1.0000e+01, 2.0000e+01, ..., 2.6236e+05, 2.6237e+05,\n       2.6238e+05], shape=(26239,))pixel(ground_range)int64dask.array&lt;chunksize=(26239,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n204.99 kiB\n204.99 kiB\n\n\nShape\n(26239,)\n(26239,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         26239 1\n\n\n\n\nData variables: (1)grd(azimuth_time, ground_range)uint16dask.array&lt;chunksize=(2557, 26239), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :measurement data set for GRD IW\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n835.48 MiB\n127.97 MiB\n\n\nShape\n(16694, 26239)\n(2557, 26239)\n\n\nDask graph\n7 chunks in 2 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n               26239 16694\n\n\n\n\n\n\n\nAnother way to open a subgroup is converting the information showed on the data tree to a data set information, using .to_dataset() function.\n\nmeasurements2 = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/measurements\"].to_dataset()\nif measurements == measurements2:\n    print(\"Yes, it's the same!\")\n\nmeasurements2\n\nYes, it's the same!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 877MB\nDimensions:       (azimuth_time: 16694, ground_range: 26239)\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 134kB 2017-05-08T16:48:30.467...\n    line          (azimuth_time) int64 134kB dask.array&lt;chunksize=(16694,), meta=np.ndarray&gt;\n  * ground_range  (ground_range) float64 210kB 0.0 10.0 ... 2.624e+05 2.624e+05\n    pixel         (ground_range) int64 210kB dask.array&lt;chunksize=(26239,), meta=np.ndarray&gt;\nData variables:\n    grd           (azimuth_time, ground_range) uint16 876MB dask.array&lt;chunksize=(2557, 26239), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 16694ground_range: 26239Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:30.469413574',\n       '2017-05-08T16:48:30.470911148', ..., '2017-05-08T16:48:55.463923851',\n       '2017-05-08T16:48:55.465421425', '2017-05-08T16:48:55.466919000'],\n      shape=(16694,), dtype='datetime64[ns]')line(azimuth_time)int64dask.array&lt;chunksize=(16694,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n130.42 kiB\n130.42 kiB\n\n\nShape\n(16694,)\n(16694,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         16694 1\n\n\n\n\nground_range(ground_range)float640.0 10.0 ... 2.624e+05 2.624e+05array([0.0000e+00, 1.0000e+01, 2.0000e+01, ..., 2.6236e+05, 2.6237e+05,\n       2.6238e+05], shape=(26239,))pixel(ground_range)int64dask.array&lt;chunksize=(26239,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n204.99 kiB\n204.99 kiB\n\n\nShape\n(26239,)\n(26239,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         26239 1\n\n\n\n\nData variables: (1)grd(azimuth_time, ground_range)uint16dask.array&lt;chunksize=(2557, 26239), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :measurement data set for GRD IW\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n835.48 MiB\n127.97 MiB\n\n\nShape\n(16694, 26239)\n(2557, 26239)\n\n\nDask graph\n7 chunks in 2 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n               26239 16694",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html#understanding-and-visualizing-sar-products",
    "href": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html#understanding-and-visualizing-sar-products",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "Understanding and visualizing SAR products",
    "text": "Understanding and visualizing SAR products\nWe can do the same for other subgroups that contain SAR information.\n\nGround Range Detected\nA Ground Range Detected (GRD) product shows us the amplitude of a SAR image. The amplitude reflects the intensity of the radar backscatter, which is the same thing as saying that the amplitude shows how much energy is reflected or absorbed by the surface.\nBecause the grd variable is very heavy for plotting, we need to decimate it. Applying the .isel() method is useful in this case because we can decimate the image for a faster and more effiecient plotting, without losing visual information. We will use the dataset created before for measurements to access the grd variable.\n\ngrd = measurements.grd\ngrd_decimated = grd.isel(\n    azimuth_time=slice(None, None, 10), ground_range=slice(None, None, 10)\n)\n\n\ngrd_decimated.plot(vmax=200)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSigma Nought and Digital Number\nWe can find the calibration subgroup inside the quality subgroup. It is valuable to take a look at it, as it provides data concerning:\n\nsigma_noughtor backscatter coefficient: It represents the strength of the radar signal backscattered (or reflected back) from a target on Earth‚Äôs surface. See it as how much radar energy is reflected back toward the satellite from a unit area on the ground (ground range or horizontal area). This information is rescaled to decibels (dB) in a common workflow.\ndn: A digital number representing the raw intensity data measured by the SAR sensor.\nbeta_nought and gamma: Conceptually they describe the same as sigma_nought but with different ‚Äúgeometries‚Äù. The beta_nought corresponds to the raw calibrated radar brightness, same as sigma_nought but still containing the incident angle infornmation, meaning before any terain correction is applied. The gamma or gamma nought is normalized to the area perpendicular to the radar look direction. Both of these variables are much more influenced by the terrain features than the sigma_nought.\n\n\ncalibration = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/calibration\"].to_dataset()\ncalibration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 292kB\nDimensions:       (azimuth_time: 27, ground_range: 657)\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 216B 2017-05-08T16:48:30.4679...\n    line          (azimuth_time) uint32 108B dask.array&lt;chunksize=(27,), meta=np.ndarray&gt;\n  * ground_range  (ground_range) float64 5kB 0.0 6.677e+06 ... 4.38e+09\n    pixel         (ground_range) uint32 3kB dask.array&lt;chunksize=(657,), meta=np.ndarray&gt;\nData variables:\n    beta_nought   (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;\n    dn            (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;\n    gamma         (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;\n    sigma_nought  (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 27ground_range: 657Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...dimensions :['azimuth_time']dtype :&lt;M8[us]long_name :zero doppler azimuth time at which calibration vector appliesarray(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:31.467916000',\n       '2017-05-08T16:48:32.467916000', '2017-05-08T16:48:33.467916000',\n       '2017-05-08T16:48:34.467916000', '2017-05-08T16:48:35.467916000',\n       '2017-05-08T16:48:36.467916000', '2017-05-08T16:48:37.467916000',\n       '2017-05-08T16:48:38.467916000', '2017-05-08T16:48:39.467916000',\n       '2017-05-08T16:48:40.467916000', '2017-05-08T16:48:41.467916000',\n       '2017-05-08T16:48:42.467916000', '2017-05-08T16:48:43.467916000',\n       '2017-05-08T16:48:44.467916000', '2017-05-08T16:48:45.467916000',\n       '2017-05-08T16:48:46.467916000', '2017-05-08T16:48:47.467916000',\n       '2017-05-08T16:48:48.467916000', '2017-05-08T16:48:49.467916000',\n       '2017-05-08T16:48:50.467916000', '2017-05-08T16:48:51.467916000',\n       '2017-05-08T16:48:52.467916000', '2017-05-08T16:48:53.467916000',\n       '2017-05-08T16:48:54.467916000', '2017-05-08T16:48:55.467916000',\n       '2017-05-08T16:48:56.467916000'], dtype='datetime64[ns]')line(azimuth_time)uint32dask.array&lt;chunksize=(27,), meta=np.ndarray&gt;dimensions :['azimuth_time']dtype :&lt;u4long_name :image line at which the calibration vector applies\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n108 B\n108 B\n\n\nShape\n(27,)\n(27,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         27 1\n\n\n\n\nground_range(ground_range)float640.0 6.677e+06 ... 4.38e+09dimensions :['ground_range']dtype :&lt;f8array([0.000000e+00, 6.677200e+06, 1.335440e+07, ..., 4.366889e+09,\n       4.373566e+09, 4.379909e+09], shape=(657,))pixel(ground_range)uint32dask.array&lt;chunksize=(657,), meta=np.ndarray&gt;dimensions :['ground_range']dtype :&lt;u4long_name :image pixel at which the calibration vector applies (this array contains the count attribute number of integer values (i.e. one value per point in the noise vector); the maximum length of this array is one value for every pixel in an image line, however in general the vector is subsampled)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.57 kiB\n2.57 kiB\n\n\nShape\n(657,)\n(657,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         657 1\n\n\n\n\nData variables: (4)beta_nought(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'beta nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :beta nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\ndn(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'digital number calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :digital number calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\ngamma(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'gamma calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :gamma calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\nsigma_nought(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'sigma nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :sigma nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\n\n\n\nLet‚Äôs isolate the different backscatter coefficients in numpy arrays and then plot them to see the differences (comparing it also with the xarray plot).\n\n# Isolating the three calibration parameters into numpy arrays\nbeta0 = calibration.beta_nought.data\ngamma = calibration.gamma.data\nsigma0 = calibration.sigma_nought.data\n\n# Plotting the three calibration parameters \nprint(\"beta nought array:\", beta0)\nprint(\"\\n\")\nprint(\"gamma array:\", gamma)\nprint(\"\\n\")\nprint(\"sigma nought array:\", sigma0)\n\nbeta nought array: dask.array&lt;open_dataset-beta_nought, shape=(27, 657), dtype=float32, chunksize=(27, 657), chunktype=numpy.ndarray&gt;\n\n\ngamma array: dask.array&lt;open_dataset-gamma, shape=(27, 657), dtype=float32, chunksize=(27, 657), chunktype=numpy.ndarray&gt;\n\n\nsigma nought array: dask.array&lt;open_dataset-sigma_nought, shape=(27, 657), dtype=float32, chunksize=(27, 657), chunktype=numpy.ndarray&gt;\n\n\n\n# Analyzing the three calibration parameters with respect to their unique values and shape\nprint(\"Number of unique values on beta nought array:\", len(np.unique_values(beta0)), \"and shape of it:\", beta0.shape)\nprint(\"Number of unique values on gamma nought array:\", len(np.unique_values(gamma)), \"and shape of it:\", gamma.shape)\nprint(\"Number of unique values on sigma nought array:\", len(np.unique_values(sigma0)), \"and shape of it:\", sigma0.shape)\n\nNumber of unique values on beta nought array: 1 and shape of it: (27, 657)\n\n\nNumber of unique values on gamma nought array: 657 and shape of it: (27, 657)\nNumber of unique values on sigma nought array: 657 and shape of it: (27, 657)\n\n\n\n# Plotting the three calibration parameters to visually see the differences\nfig, axes = plt.subplots(2, 3, figsize=(15, 6))\n\naxes[0, 0].plot(beta0)\naxes[0, 0].set_title(\"beta nought (numpy plot)\")\n\naxes[0, 1].plot(gamma)\naxes[0, 1].set_title(\"gamma (numpy plot))\")\n\naxes[0, 2].plot(sigma0)\naxes[0, 2].set_title(\"sigma nought (numpy plot)\")\n\ncalibration.beta_nought.plot(ax=axes[1, 0])\naxes[1, 0].set_title(\"beta nought (xarray plot)\")\n\ncalibration.gamma.plot(ax=axes[1, 1])\naxes[1, 1].set_title(\"gamma (xarray plot)\")\n\ncalibration.sigma_nought.plot(ax=axes[1, 2])\naxes[1, 2].set_title(\"sigma nought (xarray plot)\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nWe see that all the variables are different and we can conclude the following: 1. first of all, the actual values on each backscatter coeficient array differ from each other. 2. even though beta_nought has the same shape as the other components, is an array with one repeated value. 3. gamma and sigma_nought have 657 different values, which means that the variation of the values happens on the ground_range range.\n\n\nGCP\nThe gcp subgroup inside conditions is also important. GCP stands for ground control points which are known and precise geolocated references on the Earth‚Äôs surface. They can be used later to georeference the GRD image.\n\ngcp = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/gcp\"].to_dataset()\ngcp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 12kB\nDimensions:               (azimuth_time: 10, ground_range: 21)\nCoordinates:\n  * azimuth_time          (azimuth_time) datetime64[ns] 80B 2017-05-08T16:48:...\n    line                  (azimuth_time) uint32 40B dask.array&lt;chunksize=(10,), meta=np.ndarray&gt;\n  * ground_range          (ground_range) float64 168B 0.0 ... 2.624e+05\n    pixel                 (ground_range) uint32 84B dask.array&lt;chunksize=(21,), meta=np.ndarray&gt;\nData variables:\n    azimuth_time_gcp      (azimuth_time, ground_range) datetime64[ns] 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    elevation_angle       (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    height                (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    incidence_angle       (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    latitude              (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    longitude             (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    slant_range_time_gcp  (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 10ground_range: 21Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:33.469054000',\n       '2017-05-08T16:48:36.470192000', '2017-05-08T16:48:39.471330000',\n       '2017-05-08T16:48:42.472469000', '2017-05-08T16:48:45.473607000',\n       '2017-05-08T16:48:48.474745000', '2017-05-08T16:48:51.475884000',\n       '2017-05-08T16:48:54.477022000', '2017-05-08T16:48:55.466919000'],\n      dtype='datetime64[ns]')line(azimuth_time)uint32dask.array&lt;chunksize=(10,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n40 B\n40 B\n\n\nShape\n(10,)\n(10,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         10 1\n\n\n\n\nground_range(ground_range)float640.0 1.312e+04 ... 2.624e+05array([     0.,  13120.,  26240.,  39360.,  52480.,  65600.,  78720.,  91840.,\n       104960., 118080., 131200., 144320., 157440., 170560., 183680., 196800.,\n       209920., 223040., 236160., 249280., 262380.])pixel(ground_range)uint32dask.array&lt;chunksize=(21,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n84 B\n84 B\n\n\nShape\n(21,)\n(21,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         21 1\n\n\n\n\nData variables: (7)azimuth_time_gcp(azimuth_time, ground_range)datetime64[ns]dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\ndatetime64[ns] numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nelevation_angle(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nheight(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nincidence_angle(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nlatitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nlongitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nslant_range_time_gcp(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\n\n\n\n\ngcp.plot.scatter(x=\"longitude\", y=\"latitude\", hue=\"height\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nOrbit\norbit subgroup inside conditions is a variable that reflects how the orbital trajectory of the satellite behaved during the flight.\n\norbit = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/orbit\"].to_dataset()\norbit\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 952B\nDimensions:       (azimuth_time: 17, axis: 3)\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 136B 2017-05-08T16:47:24.0541...\nDimensions without coordinates: axis\nData variables:\n    position      (azimuth_time, axis) float64 408B dask.array&lt;chunksize=(17, 3), meta=np.ndarray&gt;\n    velocity      (azimuth_time, axis) float64 408B dask.array&lt;chunksize=(17, 3), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 17axis: 3Coordinates: (1)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:47:24.054129 ... 2...dimensions :['azimuth_time']dtype :&lt;M8[us]long_name :time stamp at which orbit state vectors applyarray(['2017-05-08T16:47:24.054129000', '2017-05-08T16:47:34.054128000',\n       '2017-05-08T16:47:44.054128000', '2017-05-08T16:47:54.054128000',\n       '2017-05-08T16:48:04.054129000', '2017-05-08T16:48:14.054128000',\n       '2017-05-08T16:48:24.054128000', '2017-05-08T16:48:34.054128000',\n       '2017-05-08T16:48:44.054129000', '2017-05-08T16:48:54.054128000',\n       '2017-05-08T16:49:04.054128000', '2017-05-08T16:49:14.054128000',\n       '2017-05-08T16:49:24.054129000', '2017-05-08T16:49:34.054128000',\n       '2017-05-08T16:49:44.054128000', '2017-05-08T16:49:54.054128000',\n       '2017-05-08T16:50:04.054129000'], dtype='datetime64[ns]')Data variables: (2)position(azimuth_time, axis)float64dask.array&lt;chunksize=(17, 3), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time'], 'dimensions': ['azimuth_time', 'axis'], 'dtype': '&lt;f8', 'long_name': 'position vector', 'units': 'm'}dtype :&lt;f8long_name :position vectorunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n408 B\n408 B\n\n\nShape\n(17, 3)\n(17, 3)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 17\n\n\n\n\nvelocity(azimuth_time, axis)float64dask.array&lt;chunksize=(17, 3), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time'], 'dimensions': ['azimuth_time', 'axis'], 'dtype': '&lt;f8', 'long_name': 'velocity vector', 'units': 'm/s'}dtype :&lt;f8long_name :velocity vectorunits :m/s\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n408 B\n408 B\n\n\nShape\n(17, 3)\n(17, 3)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 17\n\n\n\n\n\n\n\n\n# Extract position components (X, Y, Z coordinates in space)\npos_x = orbit.position[:, 0]\npos_y = orbit.position[:, 1] \npos_z = orbit.position[:, 2]\n\n# Extract velocity components and calculate magnitude\nvel_x = orbit.velocity[:, 0]\nvel_y = orbit.velocity[:, 1]\nvel_z = orbit.velocity[:, 2]\nvelocity_magnitude = np.sqrt(vel_x**2 + vel_y**2 + vel_z**2)\n\n# Convert time to numeric for potential use in point sizing\ntime_numeric = (orbit.azimuth_time - orbit.azimuth_time[0]) / np.timedelta64(1, 's')\n\nfig = plt.figure(figsize=(12, 10))\nax = fig.add_subplot(111, projection='3d')\n\n# 3D scatter plot: X, Y, Z positions colored by velocity magnitude\nscatter = ax.scatter(pos_x, pos_y, pos_z,\n                    c=velocity_magnitude, cmap='plasma', s=60)\n\nax.set_xlabel('Position X (m)')\nax.set_ylabel('Position Y (m)')\nax.set_zlabel('Position Z (m)')\nplt.colorbar(scatter, label='Velocity Magnitude (m/s)')\nax.set_title('Satellite 3D Orbital Trajectory (colored by velocity magnitude)')\n\n# Set a good viewing angle\nax.view_init(elev=10, azim=70)\nplt.show()",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html#now-it-is-your-turn",
    "href": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html#now-it-is-your-turn",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nWith everything we have learnt so far, you are now able to explore Sentinel-1 GRD items and plot their visuals.\n\nTask 1: Reproduce the workflow with your dataset\nDefine an area of interest, search and filter the Sentinel-1 GRD collection for the area where you live. Explore the data tree, and the structure of one of the items.\n\n\nTask 2: Explore other variables\nWe‚Äôve learnt how to look, explore and plot some specific variables inside the .zarr subgroups, but there are many more. Try to explore and understand what are some other variables, like terrain_height our noise_range.\n\n\nTask 3: Play with the image plotting\nThere are many ways to plot an image. Try to play with the variables you are plotting, changing the axis coordinates, maximum values shown or hue values.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html#conclusion",
    "href": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html#conclusion",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial provided the basics to explore and understand how the Sentinel-1 GRD is structured inside the .zarr format and what to expect to find inside of it.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html#whats-next",
    "href": "02_about_eopf_zarr/22_zarr_structure_S1GRD.html#whats-next",
    "title": "Discover EOPF Zarr - Sentinel-1 GRD",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nThe next notebook shows how to perform basic operations on .zarr Sentinel-1 GRD data, using some of the variables we have discovered in this section.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/23_S1_basic_operations.html",
    "href": "02_about_eopf_zarr/23_S1_basic_operations.html",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nIn this notebook, we will explore additional functionalities that can be applied to Sentinel-1 GRD data. Continuing to access the data through the EOPF Zarr sample services, we will learn how to visualize and carry out basic SAR operations, such as georeferencing and backscatter calibration, using the .zarr format.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/23_S1_basic_operations.html#georeferencing-grd-product",
    "href": "02_about_eopf_zarr/23_S1_basic_operations.html#georeferencing-grd-product",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "Georeferencing GRD product",
    "text": "Georeferencing GRD product\nAs seen in the previous chapter, plotting a Sentinel-1 GRD item displays an image with azimuth_time and ground_rangecoordinates. While these are indeed valid coordinates for Sentinel-1 products, they are only meaningful within the context of image acquisition. \nTo compare them with other geospatial datasets or to examine their actual location on Earth, the data needs to be georeferenced using geographic coordinates, such as latitude and longitude.\n\nOpening the product\nAs usual, the first step is to open the Sentinel-1 GRD product we are going to work with. Using the well known functions open_datatree() and open_dataset(), we open the .zarr product.\n\nurl = \"https://objectstore.eodc.eu:2222/e05ab01a9d56408d82ac32d69a5aae2a:sample-data/tutorial_data/cpm_b716/S1A_IW_GRDH_1SDV_20170508T164830_20170508T164855_016493_01B54C_8604.zarr\"\ndt = xr.open_datatree(url, engine='zarr', chunks={})\n\nWe can access .groups and explore what is inside the polarisation group, as it corresponds to the information we will be working with. This is going to help us later opening specific subgroups, such as measurementssubgroup.\n\ndt.S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH.groups\n\n('/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/measurements',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/antenna_pattern',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/attitude',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/azimuth_fm_rate',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/coordinate_conversion',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/doppler_centroid',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/gcp',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/orbit',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/reference_replica',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/replica',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/terrain_height',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/calibration',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/noise',\n '/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/noise_range')\n\n\n\nmeasurements = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/measurements\"].to_dataset()\n\nAs the measurements.grd array is large to be directly plotted, we need to slice it. Applying the .isel()method is useful in this case. We observe that the grd product coordinates azimuth_time and ground_range are not stored in geographical coordinates.\n\ngrd = measurements.grd.isel(\n    azimuth_time=slice(None, None, 10), ground_range=slice(None, None, 10)\n)\ngrd.plot(vmax=300)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSetting the GCP\nIn order to georeference the image with the correspondent latitude and longitude coordinates, we need to access and use the ground control points stored into the .zarr structure.\nThese are well known points that contain both the latitude and longitude coordinates but also the azimuth time and ground range coordinates, making it possible to georeference the grd image.\n\nground_control_point = dt[\"S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/conditions/gcp\"].to_dataset()\nground_control_point\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 12kB\nDimensions:               (azimuth_time: 10, ground_range: 21)\nCoordinates:\n  * azimuth_time          (azimuth_time) datetime64[ns] 80B 2017-05-08T16:48:...\n    line                  (azimuth_time) uint32 40B dask.array&lt;chunksize=(10,), meta=np.ndarray&gt;\n  * ground_range          (ground_range) float64 168B 0.0 ... 2.624e+05\n    pixel                 (ground_range) uint32 84B dask.array&lt;chunksize=(21,), meta=np.ndarray&gt;\nData variables:\n    azimuth_time_gcp      (azimuth_time, ground_range) datetime64[ns] 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    elevation_angle       (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    height                (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    incidence_angle       (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    latitude              (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    longitude             (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;\n    slant_range_time_gcp  (azimuth_time, ground_range) float64 2kB dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 10ground_range: 21Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:33.469054000',\n       '2017-05-08T16:48:36.470192000', '2017-05-08T16:48:39.471330000',\n       '2017-05-08T16:48:42.472469000', '2017-05-08T16:48:45.473607000',\n       '2017-05-08T16:48:48.474745000', '2017-05-08T16:48:51.475884000',\n       '2017-05-08T16:48:54.477022000', '2017-05-08T16:48:55.466919000'],\n      dtype='datetime64[ns]')line(azimuth_time)uint32dask.array&lt;chunksize=(10,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n40 B\n40 B\n\n\nShape\n(10,)\n(10,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         10 1\n\n\n\n\nground_range(ground_range)float640.0 1.312e+04 ... 2.624e+05array([     0.,  13120.,  26240.,  39360.,  52480.,  65600.,  78720.,  91840.,\n       104960., 118080., 131200., 144320., 157440., 170560., 183680., 196800.,\n       209920., 223040., 236160., 249280., 262380.])pixel(ground_range)uint32dask.array&lt;chunksize=(21,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n84 B\n84 B\n\n\nShape\n(21,)\n(21,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         21 1\n\n\n\n\nData variables: (7)azimuth_time_gcp(azimuth_time, ground_range)datetime64[ns]dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\ndatetime64[ns] numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nelevation_angle(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nheight(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nincidence_angle(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nlatitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nlongitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\nslant_range_time_gcp(azimuth_time, ground_range)float64dask.array&lt;chunksize=(10, 21), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.64 kiB\n1.64 kiB\n\n\nShape\n(10, 21)\n(10, 21)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         21 10\n\n\n\n\n\n\n\nSince we previously downsampled the grd product, the coordinate grid (azimuth time and ground range) was processed accordingly. To ensure that the ground control points (latitude and longitude arrays) align properly with this modified grid, we need to apply the same downsample interpolation to them.\nWe can achieve this using the .interp_like() method from xarray. This function interpolates the ground control point data to match the dimensions and coordinates of the grd product, specifically over the current azimuth_time and ground_range.\n\ngcp = ground_control_point.interp_like(grd)\n\n\n\nGeoreferencing the product\nThe final step is to assign the corresponding decimated latitude and longitude values (interpolated from the ground control points) to the grd product. This can be done using the .assign_coords() method.\nAfter assigning the coordinates, the grd dataset will include latitude and longitude as new entries in its coordinate system. When plotting the grd image, you can then specify longitude as the x axis and latitude as the y axis. This will display a properly georeferenced image, allowing it to be compared directly with other spatial datasets.\n\ngrd = grd.assign_coords({\"latitude\": gcp.latitude, \"longitude\": gcp.longitude})\ngrd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'grd' (azimuth_time: 1670, ground_range: 2624)&gt; Size: 9MB\ndask.array&lt;getitem, shape=(1670, 2624), dtype=uint16, chunksize=(256, 2624), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 13kB 2017-05-08T16:48:30.4679...\n    line          (azimuth_time) float64 13kB dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n  * ground_range  (ground_range) float64 21kB 0.0 100.0 ... 2.622e+05 2.623e+05\n    pixel         (ground_range) float64 21kB dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n    latitude      (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\n    longitude     (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\nAttributes:\n    _eopf_attrs:  {'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_r...\n    dtype:        &lt;u2\n    long_name:    measurement data set for GRD IWxarray.DataArray'grd'azimuth_time: 1670ground_range: 2624dask.array&lt;chunksize=(256, 2624), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n8.36 MiB\n1.28 MiB\n\n\nShape\n(1670, 2624)\n(256, 2624)\n\n\nDask graph\n7 chunks in 3 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n               2624 1670\n\n\n\n\nCoordinates: (6)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:30.482891740',\n       '2017-05-08T16:48:30.497867480', ..., '2017-05-08T16:48:55.432474797',\n       '2017-05-08T16:48:55.447450537', '2017-05-08T16:48:55.462426277'],\n      shape=(1670,), dtype='datetime64[ns]')line(azimuth_time)float64dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 kiB\n13.05 kiB\n\n\nShape\n(1670,)\n(1670,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         1670 1\n\n\n\n\nground_range(ground_range)float640.0 100.0 ... 2.622e+05 2.623e+05array([0.000e+00, 1.000e+02, 2.000e+02, ..., 2.621e+05, 2.622e+05, 2.623e+05],\n      shape=(2624,))pixel(ground_range)float64dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n20.50 kiB\n20.50 kiB\n\n\nShape\n(2624,)\n(2624,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1\n\n\n\n\nlatitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nlongitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nAttributes: (3)_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :measurement data set for GRD IW\n\n\n\ngrd.plot(x=\"longitude\", y=\"latitude\", vmax=300)\nplt.show()",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/23_S1_basic_operations.html#calibrating-intensity-and-amplitude",
    "href": "02_about_eopf_zarr/23_S1_basic_operations.html#calibrating-intensity-and-amplitude",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "Calibrating intensity and amplitude",
    "text": "Calibrating intensity and amplitude\nIn Sentinel-1 GRD products, only the amplitude of the signal is stored, while the phase information is discarded, unlike Single Look Complex (SLC) products, which preserve both. Therefore, it is essential to calibrate the amplitude using the raw Digital Number (DN) values and the additional metadata provided in the calibration subgroup, with components such as beta_nought, gamma and sigma_nought.\nThe relationship between intensity and amplitude is given by: \\[\n\\text{Intensity} = |\\text{Amplitude}|^2\n\\]\n\nSetting calibration subgroup\n\ncalibration = dt[\"/S01SIWGRD_20170508T164830_0025_A094_8604_01B54C_VH/quality/calibration\"].to_dataset()\ncalibration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 292kB\nDimensions:       (azimuth_time: 27, ground_range: 657)\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 216B 2017-05-08T16:48:30.4679...\n    line          (azimuth_time) uint32 108B dask.array&lt;chunksize=(27,), meta=np.ndarray&gt;\n  * ground_range  (ground_range) float64 5kB 0.0 6.677e+06 ... 4.38e+09\n    pixel         (ground_range) uint32 3kB dask.array&lt;chunksize=(657,), meta=np.ndarray&gt;\nData variables:\n    beta_nought   (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;\n    dn            (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;\n    gamma         (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;\n    sigma_nought  (azimuth_time, ground_range) float32 71kB dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;xarray.DatasetDimensions:azimuth_time: 27ground_range: 657Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...dimensions :['azimuth_time']dtype :&lt;M8[us]long_name :zero doppler azimuth time at which calibration vector appliesarray(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:31.467916000',\n       '2017-05-08T16:48:32.467916000', '2017-05-08T16:48:33.467916000',\n       '2017-05-08T16:48:34.467916000', '2017-05-08T16:48:35.467916000',\n       '2017-05-08T16:48:36.467916000', '2017-05-08T16:48:37.467916000',\n       '2017-05-08T16:48:38.467916000', '2017-05-08T16:48:39.467916000',\n       '2017-05-08T16:48:40.467916000', '2017-05-08T16:48:41.467916000',\n       '2017-05-08T16:48:42.467916000', '2017-05-08T16:48:43.467916000',\n       '2017-05-08T16:48:44.467916000', '2017-05-08T16:48:45.467916000',\n       '2017-05-08T16:48:46.467916000', '2017-05-08T16:48:47.467916000',\n       '2017-05-08T16:48:48.467916000', '2017-05-08T16:48:49.467916000',\n       '2017-05-08T16:48:50.467916000', '2017-05-08T16:48:51.467916000',\n       '2017-05-08T16:48:52.467916000', '2017-05-08T16:48:53.467916000',\n       '2017-05-08T16:48:54.467916000', '2017-05-08T16:48:55.467916000',\n       '2017-05-08T16:48:56.467916000'], dtype='datetime64[ns]')line(azimuth_time)uint32dask.array&lt;chunksize=(27,), meta=np.ndarray&gt;dimensions :['azimuth_time']dtype :&lt;u4long_name :image line at which the calibration vector applies\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n108 B\n108 B\n\n\nShape\n(27,)\n(27,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         27 1\n\n\n\n\nground_range(ground_range)float640.0 6.677e+06 ... 4.38e+09dimensions :['ground_range']dtype :&lt;f8array([0.000000e+00, 6.677200e+06, 1.335440e+07, ..., 4.366889e+09,\n       4.373566e+09, 4.379909e+09], shape=(657,))pixel(ground_range)uint32dask.array&lt;chunksize=(657,), meta=np.ndarray&gt;dimensions :['ground_range']dtype :&lt;u4long_name :image pixel at which the calibration vector applies (this array contains the count attribute number of integer values (i.e. one value per point in the noise vector); the maximum length of this array is one value for every pixel in an image line, however in general the vector is subsampled)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.57 kiB\n2.57 kiB\n\n\nShape\n(657,)\n(657,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         657 1\n\n\n\n\nData variables: (4)beta_nought(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'beta nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :beta nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\ndn(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'digital number calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :digital number calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\ngamma(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'gamma calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :gamma calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\nsigma_nought(azimuth_time, ground_range)float32dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'sigma nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :sigma nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\n\n\n\n\n\nIntensity calibration\nFor the intensity calibration we need to use sigma_nought component because it‚Äôs the one that presents the backscatter normalized to ground-range area, taking into consideration the true geometry of the terrain.\nWe could use the calibrate_intensity method from the xarray_sentinel library but, because of the way the zarr values are stored and the existence of some incorrect values on the sigma_nought component, we can not use this useful library on this stage.\nOn the other hand, we can simulate the intensity calibration using the sigma_nought component manually, using the line and pixel dimensions as reference for values interpolation - instead of using the already known ground_range and azimuth_time.\n\n# sigma_nought is one of the three coefficients we could use\n# we could also have used gamma or beta_nought but these two components don't take into account the incidence angle\n\nsigma_nought = calibration.sigma_nought \nsigma_nought\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'sigma_nought' (azimuth_time: 27, ground_range: 657)&gt; Size: 71kB\ndask.array&lt;open_dataset-sigma_nought, shape=(27, 657), dtype=float32, chunksize=(27, 657), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 216B 2017-05-08T16:48:30.4679...\n    line          (azimuth_time) uint32 108B dask.array&lt;chunksize=(27,), meta=np.ndarray&gt;\n  * ground_range  (ground_range) float64 5kB 0.0 6.677e+06 ... 4.38e+09\n    pixel         (ground_range) uint32 3kB dask.array&lt;chunksize=(657,), meta=np.ndarray&gt;\nAttributes:\n    _eopf_attrs:  {'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_r...\n    dtype:        &lt;f4\n    long_name:    sigma nought calibration vector (this array contains the co...xarray.DataArray'sigma_nought'azimuth_time: 27ground_range: 657dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\nCoordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...dimensions :['azimuth_time']dtype :&lt;M8[us]long_name :zero doppler azimuth time at which calibration vector appliesarray(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:31.467916000',\n       '2017-05-08T16:48:32.467916000', '2017-05-08T16:48:33.467916000',\n       '2017-05-08T16:48:34.467916000', '2017-05-08T16:48:35.467916000',\n       '2017-05-08T16:48:36.467916000', '2017-05-08T16:48:37.467916000',\n       '2017-05-08T16:48:38.467916000', '2017-05-08T16:48:39.467916000',\n       '2017-05-08T16:48:40.467916000', '2017-05-08T16:48:41.467916000',\n       '2017-05-08T16:48:42.467916000', '2017-05-08T16:48:43.467916000',\n       '2017-05-08T16:48:44.467916000', '2017-05-08T16:48:45.467916000',\n       '2017-05-08T16:48:46.467916000', '2017-05-08T16:48:47.467916000',\n       '2017-05-08T16:48:48.467916000', '2017-05-08T16:48:49.467916000',\n       '2017-05-08T16:48:50.467916000', '2017-05-08T16:48:51.467916000',\n       '2017-05-08T16:48:52.467916000', '2017-05-08T16:48:53.467916000',\n       '2017-05-08T16:48:54.467916000', '2017-05-08T16:48:55.467916000',\n       '2017-05-08T16:48:56.467916000'], dtype='datetime64[ns]')line(azimuth_time)uint32dask.array&lt;chunksize=(27,), meta=np.ndarray&gt;dimensions :['azimuth_time']dtype :&lt;u4long_name :image line at which the calibration vector applies\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n108 B\n108 B\n\n\nShape\n(27,)\n(27,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         27 1\n\n\n\n\nground_range(ground_range)float640.0 6.677e+06 ... 4.38e+09dimensions :['ground_range']dtype :&lt;f8array([0.000000e+00, 6.677200e+06, 1.335440e+07, ..., 4.366889e+09,\n       4.373566e+09, 4.379909e+09], shape=(657,))pixel(ground_range)uint32dask.array&lt;chunksize=(657,), meta=np.ndarray&gt;dimensions :['ground_range']dtype :&lt;u4long_name :image pixel at which the calibration vector applies (this array contains the count attribute number of integer values (i.e. one value per point in the noise vector); the maximum length of this array is one value for every pixel in an image line, however in general the vector is subsampled)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.57 kiB\n2.57 kiB\n\n\nShape\n(657,)\n(657,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nuint32 numpy.ndarray\n\n\n\n\n         657 1\n\n\n\n\nAttributes: (3)_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;f4', 'long_name': 'sigma nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)'}dtype :&lt;f4long_name :sigma nought calibration vector (this array contains the count attribute number of floating point values; the values in this vector are aligned with the pixel vector)\n\n\n\n# we reacreate the sigma_nought array with line and pixel dimensions for easier interpolation\nsigma_nought_line_pixel = xr.DataArray(\n    data=sigma_nought.data,\n    dims=[\"line\", \"pixel\"],\n    coords=dict(\n        line=([\"line\"], sigma_nought.line.values),\n        pixel=([\"pixel\"], sigma_nought.pixel.values),\n    ),\n)\n\nsigma_nought_line_pixel \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'open_dataset-sigma_nought-8bcf01bd8af6fc59735108ba54b440fa' (\n                                                                                line: 27,\n                                                                                pixel: 657)&gt; Size: 71kB\ndask.array&lt;open_dataset-sigma_nought, shape=(27, 657), dtype=float32, chunksize=(27, 657), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * line     (line) uint32 108B 0 668 1335 2003 2671 ... 15358 16026 16694 17361\n  * pixel    (pixel) uint32 3kB 0 40 80 120 160 ... 26120 26160 26200 26238xarray.DataArray'open_dataset-sigma_nought-8bcf01bd8af6fc59735108ba54b440fa'line: 27pixel: 657dask.array&lt;chunksize=(27, 657), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.29 kiB\n69.29 kiB\n\n\nShape\n(27, 657)\n(27, 657)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         657 27\n\n\n\n\nCoordinates: (2)line(line)uint320 668 1335 ... 16026 16694 17361array([    0,   668,  1335,  2003,  2671,  3339,  4006,  4674,  5342,  6010,\n        6677,  7345,  8013,  8681,  9348, 10016, 10684, 11352, 12019, 12687,\n       13355, 14023, 14690, 15358, 16026, 16694, 17361], dtype=uint32)pixel(pixel)uint320 40 80 120 ... 26160 26200 26238array([    0,    40,    80, ..., 26160, 26200, 26238],\n      shape=(657,), dtype=uint32)\n\n\nWe can see that the new array created for the sigma_nought component is basically the same as the ‚Äúregular‚Äù sigma_nought with the exception that sigma_nought_line_pixel has as coordinates only pixel and line.\nNow, we‚Äôll do the same for the grd variable, in order to eneable the later interpolation.\n\n# just like for the sigma_nought, we reacreate the grd array with line and pixel dimensions for easier interpolation\ngrd_line_pixel = xr.DataArray(\n    data=grd.data,\n    dims=[\"line\", \"pixel\"],\n    coords=dict(\n        line=([\"line\"], grd.line.values),\n        pixel=([\"pixel\"], grd.pixel.values),\n    ),\n)\n\n# we interpolate the sigma_nought with the grd geometry\nsigma_nought_interp_line_pixel = sigma_nought_line_pixel.interp_like(grd_line_pixel, method=\"linear\")\n\nFinally we recreate the sigma_nought array with correct dimensions, adding the original azimuth_time and ground_range coordinates from the grd dataarray. This can be seen as a correct version of the sigma_nought component.\n\nsigma_nought_interp = xr.DataArray(\n    data=sigma_nought_interp_line_pixel.data,\n    dims=[\"azimuth_time\", \"ground_range\"],\n    coords=dict(\n        azimuth_time=([\"azimuth_time\"], grd.azimuth_time.values),\n        ground_range=([\"ground_range\"], grd.ground_range.values),\n    ),\n)\n\nNow, we just need to compute the actual values for the linear intensity:\n\\[\n\\text{Intensity} = \\frac{|S_{\\rm grd}|^2}{\\rm sigmaNought^2}\n\\]\n\nintensity = ((abs(grd.astype(np.float32)) ** 2) / (sigma_nought_interp**2))\nintensity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (azimuth_time: 1670, ground_range: 2624)&gt; Size: 18MB\ndask.array&lt;truediv, shape=(1670, 2624), dtype=float32, chunksize=(256, 2624), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 13kB 2017-05-08T16:48:30.4679...\n    line          (azimuth_time) float64 13kB dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n  * ground_range  (ground_range) float64 21kB 0.0 100.0 ... 2.622e+05 2.623e+05\n    pixel         (ground_range) float64 21kB dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n    latitude      (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\n    longitude     (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\nAttributes:\n    _eopf_attrs:  {'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_r...\n    dtype:        &lt;u2\n    long_name:    measurement data set for GRD IWxarray.DataArrayazimuth_time: 1670ground_range: 2624dask.array&lt;chunksize=(256, 2624), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.72 MiB\n2.56 MiB\n\n\nShape\n(1670, 2624)\n(256, 2624)\n\n\nDask graph\n7 chunks in 29 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n               2624 1670\n\n\n\n\nCoordinates: (6)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:30.482891740',\n       '2017-05-08T16:48:30.497867480', ..., '2017-05-08T16:48:55.432474797',\n       '2017-05-08T16:48:55.447450537', '2017-05-08T16:48:55.462426277'],\n      shape=(1670,), dtype='datetime64[ns]')line(azimuth_time)float64dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 kiB\n13.05 kiB\n\n\nShape\n(1670,)\n(1670,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         1670 1\n\n\n\n\nground_range(ground_range)float640.0 100.0 ... 2.622e+05 2.623e+05array([0.000e+00, 1.000e+02, 2.000e+02, ..., 2.621e+05, 2.622e+05, 2.623e+05],\n      shape=(2624,))pixel(ground_range)float64dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n20.50 kiB\n20.50 kiB\n\n\nShape\n(2624,)\n(2624,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1\n\n\n\n\nlatitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nlongitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nAttributes: (3)_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :measurement data set for GRD IW\n\n\nWe‚Äôll also see that we can compute the intensity for with a dB scale:\n\\[\nIntensity_{\\text{dB}} = 10 \\cdot \\log_{10}(Intensity_{\\text{linear}})\n\\]\n\nintensity_db = 10 * np.log10(np.maximum(intensity, 1e-10))\nintensity_db\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (azimuth_time: 1670, ground_range: 2624)&gt; Size: 18MB\ndask.array&lt;mul, shape=(1670, 2624), dtype=float32, chunksize=(256, 2624), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 13kB 2017-05-08T16:48:30.4679...\n    line          (azimuth_time) float64 13kB dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n  * ground_range  (ground_range) float64 21kB 0.0 100.0 ... 2.622e+05 2.623e+05\n    pixel         (ground_range) float64 21kB dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n    latitude      (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\n    longitude     (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\nAttributes:\n    _eopf_attrs:  {'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_r...\n    dtype:        &lt;u2\n    long_name:    measurement data set for GRD IWxarray.DataArrayazimuth_time: 1670ground_range: 2624dask.array&lt;chunksize=(256, 2624), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.72 MiB\n2.56 MiB\n\n\nShape\n(1670, 2624)\n(256, 2624)\n\n\nDask graph\n7 chunks in 32 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n               2624 1670\n\n\n\n\nCoordinates: (6)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:30.482891740',\n       '2017-05-08T16:48:30.497867480', ..., '2017-05-08T16:48:55.432474797',\n       '2017-05-08T16:48:55.447450537', '2017-05-08T16:48:55.462426277'],\n      shape=(1670,), dtype='datetime64[ns]')line(azimuth_time)float64dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 kiB\n13.05 kiB\n\n\nShape\n(1670,)\n(1670,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         1670 1\n\n\n\n\nground_range(ground_range)float640.0 100.0 ... 2.622e+05 2.623e+05array([0.000e+00, 1.000e+02, 2.000e+02, ..., 2.621e+05, 2.622e+05, 2.623e+05],\n      shape=(2624,))pixel(ground_range)float64dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n20.50 kiB\n20.50 kiB\n\n\nShape\n(2624,)\n(2624,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1\n\n\n\n\nlatitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nlongitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nAttributes: (3)_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :measurement data set for GRD IW\n\n\n\n# plotting both linear intensity and dB intensity results\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\n\nintensity.plot(ax=axes[0], vmin=0.0, vmax=0.1)\naxes[0].set_title(\"Linear intensity\")\n\nintensity_db.plot(ax=axes[1], vmin=-30, vmax=5)\naxes[1].set_title(\"dB intensity\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAmplitude calibration\nWith the intensity calibrated, the amplitude calibration is very straightforward, since it is the square root of the intensity.\n\namplitude = np.sqrt(intensity)\namplitude\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (azimuth_time: 1670, ground_range: 2624)&gt; Size: 18MB\ndask.array&lt;sqrt, shape=(1670, 2624), dtype=float32, chunksize=(256, 2624), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth_time  (azimuth_time) datetime64[ns] 13kB 2017-05-08T16:48:30.4679...\n    line          (azimuth_time) float64 13kB dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n  * ground_range  (ground_range) float64 21kB 0.0 100.0 ... 2.622e+05 2.623e+05\n    pixel         (ground_range) float64 21kB dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n    latitude      (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\n    longitude     (azimuth_time, ground_range) float64 35MB dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;\nAttributes:\n    _eopf_attrs:  {'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_r...\n    dtype:        &lt;u2\n    long_name:    measurement data set for GRD IWxarray.DataArrayazimuth_time: 1670ground_range: 2624dask.array&lt;chunksize=(256, 2624), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.72 MiB\n2.56 MiB\n\n\nShape\n(1670, 2624)\n(256, 2624)\n\n\nDask graph\n7 chunks in 30 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n               2624 1670\n\n\n\n\nCoordinates: (6)azimuth_time(azimuth_time)datetime64[ns]2017-05-08T16:48:30.467916 ... 2...array(['2017-05-08T16:48:30.467916000', '2017-05-08T16:48:30.482891740',\n       '2017-05-08T16:48:30.497867480', ..., '2017-05-08T16:48:55.432474797',\n       '2017-05-08T16:48:55.447450537', '2017-05-08T16:48:55.462426277'],\n      shape=(1670,), dtype='datetime64[ns]')line(azimuth_time)float64dask.array&lt;chunksize=(1670,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 kiB\n13.05 kiB\n\n\nShape\n(1670,)\n(1670,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         1670 1\n\n\n\n\nground_range(ground_range)float640.0 100.0 ... 2.622e+05 2.623e+05array([0.000e+00, 1.000e+02, 2.000e+02, ..., 2.621e+05, 2.622e+05, 2.623e+05],\n      shape=(2624,))pixel(ground_range)float64dask.array&lt;chunksize=(2624,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n20.50 kiB\n20.50 kiB\n\n\nShape\n(2624,)\n(2624,)\n\n\nDask graph\n1 chunks in 10 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1\n\n\n\n\nlatitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nlongitude(azimuth_time, ground_range)float64dask.array&lt;chunksize=(1670, 2624), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'ground_range', 'line', 'pixel'], 'dimensions': ['azimuth_time', 'ground_range']}\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n33.43 MiB\n33.43 MiB\n\n\nShape\n(1670, 2624)\n(1670, 2624)\n\n\nDask graph\n1 chunks in 20 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         2624 1670\n\n\n\n\nAttributes: (3)_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :measurement data set for GRD IW\n\n\n\n# plotting amplitude with both linear intensity and dB intensity results\nfig, axes = plt.subplots(1, 3, figsize=(15, 6))\n\n# not that we keep the same max and min values for better comparison\namplitude.plot(ax=axes[0], vmin=0.0, vmax=0.1) # changing vmax to 0.8 and removing vmin would allow to see different details\naxes[0].set_title(\"Amplitude\")\n\nintensity.plot(ax=axes[1], vmin=0.0, vmax=0.1)\naxes[1].set_title(\"Linear intensity\")\n\nintensity_db.plot(ax=axes[2], vmin=-30, vmax=5)\naxes[2].set_title(\"dB intensity\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nGeoreferenced intensity and amplitude\nBecause we had already georefefenced the images, we can now also plot theresults with latitude and longitude coordinates.\n\n# plotting amplitude with both linear intensity and dB intensity results georeferenced\nfig, axes = plt.subplots(1, 3, figsize=(15, 6))\n\namplitude.plot(ax=axes[0], x=\"longitude\", y=\"latitude\", vmin=0.0, vmax=0.1) \naxes[0].set_title(\"Amplitude\")\n\nintensity.plot(ax=axes[1], x=\"longitude\", y=\"latitude\", vmin=0.0, vmax=0.1)\naxes[1].set_title(\"Linear intensity\")\n\nintensity_db.plot(ax=axes[2], x=\"longitude\", y=\"latitude\", vmin=-30, vmax=5)\naxes[2].set_title(\"dB intensity\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nComparing results with xarray_sentinel\n\ncalibrate_amplitude = xarray_sentinel.calibrate_amplitude(\n    grd, calibration.beta_nought)\n\ncalibrate_intensity = xarray_sentinel.calibrate_intensity(\n    grd, calibration.beta_nought)\n\ncalibrate_intensity_db = xarray_sentinel.calibrate_intensity(\n    grd, calibration.beta_nought, as_db=True)\n\n\n# plotting amplitude with both linear intensity and dB intensity results vs with xarray_sentinel calibration functions\nfig, axes = plt.subplots(2, 3, figsize=(15, 6))\n\namplitude.plot(ax=axes[0, 0], vmin=0.0, vmax=0.1) \naxes[0, 0].set_title(\"Amplitude\")\n\nintensity.plot(ax=axes[0, 1], vmin=0.0, vmax=0.1)\naxes[0, 1].set_title(\"Linear intensity\")\n\nintensity_db.plot(ax=axes[0, 2], vmin=-30, vmax=5)\naxes[0, 2].set_title(\"dB intensity\")\n\ncalibrate_amplitude.plot(ax=axes[1, 0], vmin=0.0, vmax=0.1) \naxes[1, 0].set_title(\"Amplitude with xarray_sentinel\")\n\ncalibrate_intensity.plot(ax=axes[1, 1], vmin=0.0, vmax=0.1)\naxes[1, 1].set_title(\"Linear intensity with xarray_sentinel\")\n\ncalibrate_intensity_db.plot(ax=axes[1, 2], vmin=-30, vmax=5)\naxes[1, 2].set_title(\"dB intensity\")\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/23_S1_basic_operations.html#now-it-is-your-turn",
    "href": "02_about_eopf_zarr/23_S1_basic_operations.html#now-it-is-your-turn",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nThe following exercises will help you to better understand the calibration processes studied before.\n\nTask 1: Reproduce this workflow on a different area\nUsing what you‚Äôve already learned about the STAC catalog and Sentinel-1 GRD products, repeat this workflow with a different Sentinel-1 GRD scene. Try to use a scene from the area where you live, just like you did on the previous chapter. Then, observe how the geographical coordinates of the georeferenced image differ between products.\n\n\nTask 2: Explore intensity and amplitude values\nDiscover what happens when the maximum and minimum value on x and y axis change. These will create new results, especially when considering the plots on amplitude and intensity calibration.\n\n\nTask 3: Compare the intensity values with other datasets\nTry to calibrate and plot some grd products from other datasets and see how the intensity values change over different areas, textures and surfaces.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/23_S1_basic_operations.html#conclusion",
    "href": "02_about_eopf_zarr/23_S1_basic_operations.html#conclusion",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "Conclusion",
    "text": "Conclusion\nDuring this tutorial we‚Äôve learnt how to compute amplitude and intensity calibration on Sentinel-1 GRD data and how to georeference measurements.grd variable into geographical coordinates.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/23_S1_basic_operations.html#whats-next",
    "href": "02_about_eopf_zarr/23_S1_basic_operations.html#whats-next",
    "title": "Operations with EOPF Zarr - Sentinel-1 GRD",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nNow that you have been introduced to the .zarr encoding format, learned its core concepts, and understood the basics of how to explore it, you are prepared for the next step. In the following notebook we will introduce you to the Sentinel-2 L-2A .zarr structure. As we go along, we are more and more transition from theory to practice, providing you with hands-on tutorials working with EOPF .zarr products.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Operations with EOPF Zarr - Sentinel-1 GRD</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html",
    "href": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nThis tutorial introduces you to the structure of an EOPF Zarr product sample for Sentinel-2 L2A data. We will demonstrate how to access and open a .zarr product sample with xarray, how to visualise the zarr encoding structure, explore embedded information, and retrieve relevant metadata for further processing.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#open-a-zarr-store",
    "href": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#open-a-zarr-store",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "Open a Zarr Store",
    "text": "Open a Zarr Store\nIn a first step, we use the open_datatree() function from the xarray library to open a .zarr store as a DataTree. Inside, we need to define the following key word arguments:\n\nfilename_or_obj: path leading to a .zarr store\nengine: zarr, as it is the encoding structure of the file.\nchunks: loads the data with Dask using the engine‚Äôs preferred chunk size. If {} the loaded chunks are identical to the format‚Äôs original chunk size.\n\nThe final print of the DataTree object is commented out, as the display can be quite extensive, showing the entire content within the .zarr. An alternative is to apply a helper function that only displays the higher-level structure as shown in the next code cell.\n\nurl = 'https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:202505-s02msil2a/30/products/cpm_v256/S2B_MSIL2A_20250530T101559_N0511_R065_T32TPT_20250530T130924.zarr'\n\ns2l2a_zarr_sample= xr.open_datatree(\n    url, \n    engine=\"zarr\")  # storage format\n\nIf we apply the helper function print_gen_structure on the root of the DataTree object, we will get a listing of the tree-like structure of the object. We can see all Zarr groups, such as measurements, quality and conditions, their sub-groups and content.\n\nprint(\"Zarr Sentinel 2 L2A Structure\")\nprint_gen_structure(s2l2a_zarr_sample.root) \nprint(\"-\" * 30)\n\nZarr Sentinel 2 L2A Structure\nNone\n  conditions\n    geometry\n    mask\n      detector_footprint\n        r10m\n        r20m\n        r60m\n      l1c_classification\n        r60m\n      l2a_classification\n        r20m\n        r60m\n    meteorology\n      cams\n      ecmwf\n  measurements\n    reflectance\n      r10m\n      r20m\n      r60m\n  quality\n    atmosphere\n      r10m\n      r20m\n      r60m\n    l2a_quicklook\n      r10m\n      r20m\n      r60m\n    mask\n      r10m\n      r20m\n      r60m\n    probability\n      r20m\n------------------------------",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#extract-information-from-zarr-groups",
    "href": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#extract-information-from-zarr-groups",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "Extract information from Zarr groups",
    "text": "Extract information from Zarr groups\nIn the next step, we can explore the content of individually contained .zarr groups. By specifying the name of the group and subgroup and adding it into square brackets, we can extract the content of the relevant group. Let us for example, extract the content of the subgroup reflectance under measurements.\nAs a result, it is visible that there are three subgroups of the parent node measurements/reflectance: r10, r20 and r60, which are the DataArrays with the three different resolutions of the Sentinel-2 L2A data.\nThe xarray.DataTree structure allows the exploration of additional group-related metadata and information. For example, we can find the chunksize of each array and the coordinates.\n\n# # Retrieving the reflectance groups:\n# s2l2a_zarr_sample[\"measurements/reflectance\"] # Run it yourself for an inteactive overview",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#extract-zarr-metadata-on-different-levels",
    "href": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#extract-zarr-metadata-on-different-levels",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "Extract Zarr metadata on different levels",
    "text": "Extract Zarr metadata on different levels\nThrough s2l2a_zarr_sample.attrs[] we are able to visualise both the stac_discovery and other_metadata included in the zarr store.   For the properties inside stac_discovery for example we can get the parameters included:\n\n# STAC metadata style:\nprint(list(s2l2a_zarr_sample.attrs[\"stac_discovery\"].keys()))\n\n['assets', 'bbox', 'geometry', 'id', 'links', 'properties', 'stac_extensions', 'stac_version', 'type']\n\n\nWe are also, able to retrieve specific information by diving deep into the stac_discovery metadata, such as:\n\nprint('Date of Item Creation: ', s2l2a_zarr_sample.attrs['stac_discovery']['properties']['created'])\nprint('Item Bounding Box    : ', s2l2a_zarr_sample.attrs['stac_discovery']['bbox'])\nprint('Item ESPG            : ', s2l2a_zarr_sample.attrs['stac_discovery']['properties']['proj:epsg'])\nprint('Sentinel Platform    : ', s2l2a_zarr_sample.attrs['stac_discovery']['properties']['platform'])\nprint('Item Processing Level: ', s2l2a_zarr_sample.attrs['stac_discovery']['properties']['processing:level'])\n\nDate of Item Creation:  2025-05-30T13:09:24+00:00\nItem Bounding Box    :  [11.802846682924509, 46.83277247146806, 10.31188688551243, 47.84592105208886]\nItem ESPG            :  32632\nSentinel Platform    :  sentinel-2b\nItem Processing Level:  L2A\n\n\nAnd from other_metadata, we are able to retrieve the information specific to the instrument variables.\n\n# Complementing metadata:\nprint(list(s2l2a_zarr_sample.attrs[\"other_metadata\"].keys()))\n\n['AOT_retrieval_model', 'L0_ancillary_data_quality', 'L0_ephemeris_data_quality', 'NUC_table_ID', 'SWIR_rearrangement_flag', 'UTM_zone_identification', 'absolute_location_assessment_from_AOCS', 'band_description', 'declared_accuracy_of_AOT_model', 'declared_accuracy_of_radiative_transfer_model', 'declared_accuracy_of_water_vapour_model', 'electronic_crosstalk_correction_flag', 'eopf_category', 'geometric_refinement', 'history', 'horizontal_CRS_code', 'horizontal_CRS_name', 'mean_sensing_time', 'mean_sun_azimuth_angle_in_deg_for_all_bands_all_detectors', 'mean_sun_zenith_angle_in_deg_for_all_bands_all_detectors', 'mean_value_of_aerosol_optical_thickness', 'mean_value_of_total_water_vapour_content', 'meteo', 'multispectral_registration_assessment', 'onboard_compression_flag', 'onboard_equalization_flag', 'optical_crosstalk_correction_flag', 'ozone_source', 'ozone_value', 'percentage_of_degraded_MSI_data', 'planimetric_stability_assessment_from_AOCS', 'product_quality_status', 'reflectance_correction_factor_from_the_Sun-Earth_distance_variation_computed_using_the_acquisition_date', 'spectral_band_of_reference']",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#now-it-is-your-turn",
    "href": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#now-it-is-your-turn",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nAs we are able to retrieve several items from the EOPF Sentinel Zarr Samples Service STAC API, let us try the following:\n\nTask\nGo to the Sentinel-2 Level-2A collection and:\n\nChoose an item of interest.\nReplicate the workflow and explore the item‚Äôs metadata. When was it retrieved?\nWhat are the dimensions?\nWhat is the detailed location of the item?",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#conclusion",
    "href": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#conclusion",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial provides an initial understanding of the .zarr structure for a Sentinel-2 L2A product sample. By using the xarray library, we can effectively navigate and inspect the different components within the .zarr format, including its metadata and array organisation.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#whats-next",
    "href": "02_about_eopf_zarr/24_zarr_struct_S2L2A.html#whats-next",
    "title": "Discover EOPF Zarr - Sentinel-2 L2A",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nNow that you have been introduced to the .zarr encoding format, learned its core concepts, and understood the basics of how to explore it, you are prepared for the next step. In the following notebook we will introduce you to the Sentinel-3 SLSTR Level-2 LST .zarr structure. As we go along, we are more and more transition from theory to practice, providing you with hands-on tutorials working with EOPF .zarr products.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-2 L2A</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/25_zarr_struct_S3.html",
    "href": "02_about_eopf_zarr/25_zarr_struct_S3.html",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nThis tutorial introduces you to the structure of an EOPF Zarr product sample for Sentinel-3 SLSTR Level-2 Land Surface Temperature data. We will demonstrate how to access and open a .zarr product sample with xarray, how to visualise the zarr encoding structure, explore embedded information, and retrieve relevant metadata for further processing.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/25_zarr_struct_S3.html#open-the-zarr-store",
    "href": "02_about_eopf_zarr/25_zarr_struct_S3.html#open-the-zarr-store",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "Open the zarr Store",
    "text": "Open the zarr Store\nIn a first step, we use the open_datatree() function from the xarray library to open a .zarr store as a DataTree. Inside, we need to define the following key word arguments:\n\nfilename_or_obj: path leading to a .zarr store\nengine: zarr, as it is the encoding structure of the file.\nchunks: loads the data with Dask using the engine‚Äôs preferred chunk size. If {} the loaded chunks are identical to the format‚Äôs original chunk size.\n\nThe final print of the DataTree object is commented out, as the display can be quite extensive, showing the entire content within the .zarr. An alternative is to apply a helper function that only displays the higher-level structure as shown in the next code cell.\n\n# Defining the storage path:\nurl = 'https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:202505-s03slslst/29/products/cpm_v256/S3B_SL_2_LST____20250529T093001_20250529T093301_20250623T143718_0179_107_093_2340_ESA_O_NT_004.zarr'\n\n# Opening the .zarr's data tree:\ns3_lst_zarr_sample= xr.open_datatree(\n    url, engine=\"zarr\")\n\nIf we apply the helper function print_gen_structure on the root of the DataTree object, we will get a listing of the tree-like structure of the object. We can see all Zarr groups, such as measurements, quality and conditions, their sub-groups and content.\n\nprint(\"Zarr Sentinel-3 SLSTR Level-2 LST\")\nprint_gen_structure(s3_lst_zarr_sample.root) \nprint(' ', 'attributes', list(s3_lst_zarr_sample.attrs.keys()))\n\nZarr Sentinel-3 SLSTR Level-2 LST\nNone\n  conditions\n    auxiliary\n      orphan\n    geometry\n    meteorology\n    processing\n      orphan\n    time\n  measurements\n    orphan\n  quality\n    orphan\n  attributes ['other_metadata', 'stac_discovery']",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/25_zarr_struct_S3.html#extract-information-from-zarr-groups",
    "href": "02_about_eopf_zarr/25_zarr_struct_S3.html#extract-information-from-zarr-groups",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "Extract information from Zarr groups",
    "text": "Extract information from Zarr groups\nIn the next step, we can explore the content of individual .zarr groups. By specifying the name of the group and subgroup and adding it into square brackets, we can extract the content of the relevant group. Let us extract the content of the subgroup orphan under measurements.\nAs a result, it is visible that Land Surface Temperature is stored as lst, with its respective coordinates in both x and y (EPSG: Respective to UTM zone) and latitude and longitude (EPSG:4326).\nThe xarray.DataTree structure allows the exploration of additional group-related metadata and information. For example, we can find the chunksize of each array and the coordinates.\n\n# Retrieving the group where LST is stored:\ns3_lst_zarr_sample[\"measurements/orphan\"] # Run it yourself for an inteactive overview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataTree 'orphan'&gt;\nGroup: /measurements/orphan\n    Dimensions:    (rows: 1200, columns: 1500, orphan_pixels: 187)\n    Coordinates:\n        latitude   (rows, orphan_pixels) float64 2MB ...\n        longitude  (rows, orphan_pixels) float64 2MB ...\n        x          (rows, orphan_pixels) float64 2MB ...\n        y          (rows, orphan_pixels) float64 2MB ...\n    Dimensions without coordinates: rows, columns, orphan_pixels\n    Data variables:\n        lst        (rows, orphan_pixels) float32 898kB ...xarray.DataTree'orphan'Dimensions:rows: 1200columns: 1500orphan_pixels: 187Coordinates: (4)latitude(rows, orphan_pixels)float64...long_name :Latitude of detector FOV centre on the earth's surfaceshort_name :latitude_orphanstandard_name :latitudeunits :degrees_northvalid_max :90000000valid_min :-90000000[224400 values with dtype=float64]longitude(rows, orphan_pixels)float64...long_name :Longitude of detector FOV centre on the earth's surfaceshort_name :longitude_orphanstandard_name :longitudeunits :degrees_eastvalid_max :180000000valid_min :-180000000[224400 values with dtype=float64]x(rows, orphan_pixels)float64...long_name :Geolocated x (across track) coordinate of detector FOV centreshort_name :x_orphanunits :mvalid_max :1000000valid_min :-500000[224400 values with dtype=float64]y(rows, orphan_pixels)float64...long_name :Geolocated y (along track) coordinate of detector FOV centreshort_name :y_orphanunits :mvalid_max :100000000valid_min :-1000000[224400 values with dtype=float64]Data variables: (1)lst(rows, orphan_pixels)float32..._eopf_attrs :{'coordinates': ['x', 'y', 'latitude', 'longitude'], 'dimensions': ['rows', 'orphan_pixels'], 'long_name': 'ungridded land surface temperature', 'standard_name': 'surface_temperature', 'units': 'K'}long_name :ungridded land surface temperatureshort_name :lst_orphanstandard_name :surface_temperatureunits :Kvalid_max :32767valid_min :-32767[224400 values with dtype=float32]",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/25_zarr_struct_S3.html#extract-zarr-metadata-on-different-levels",
    "href": "02_about_eopf_zarr/25_zarr_struct_S3.html#extract-zarr-metadata-on-different-levels",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "Extract Zarr metadata on different levels",
    "text": "Extract Zarr metadata on different levels\nThrough s3a_lst_zarr_sample.attrs[] we are able to visualise both the stac_discovery and other_metadata included in the zarr store.   For the properties inside stac_discovery for example we can get the parameters included:\n\n# STAC metadata style:\nprint(list(s3_lst_zarr_sample.attrs[\"stac_discovery\"].keys()))\n\n['assets', 'bbox', 'collection', 'geometry', 'id', 'links', 'properties', 'stac_extensions', 'stac_version', 'type']\n\n\nWe are also, able to retrieve specific information by diving deep into the stac_discovery metadata, such as:\n\nprint('Date of Item Creation: ', s3_lst_zarr_sample.attrs['stac_discovery']['properties']['created'])\nprint('Item Bounding Box    : ', s3_lst_zarr_sample.attrs['stac_discovery']['bbox'])\nprint('Sentinel Platform    : ', s3_lst_zarr_sample.attrs['stac_discovery']['properties']['platform'])\nprint('Item Processing Level: ', s3_lst_zarr_sample.attrs['stac_discovery']['properties']['processing:level'])\nprint('Class ID.            : ', s3_lst_zarr_sample.attrs['stac_discovery']['properties']['product:timeliness_category'])\n\nDate of Item Creation:  2025-06-23T14:37:18+00:00\nItem Bounding Box    :  [20.6857, 28.6806, 1.68414, 41.9899]\nSentinel Platform    :  sentinel-3b\nItem Processing Level:  L2\nClass ID.            :  NT\n\n\nAnd from other_metadata, we are able to retrieve the information specific to the instrument variables.\n\n# Complementing metadata:\nprint(list(s3_lst_zarr_sample.attrs[\"other_metadata\"].keys()))\n\n['L0_offset_between_scan_index_and_ISP_scan_count_in', 'absolute_pass_number', 'band_description', 'cycle_number', 'data_information', 'eopf_category', 'ephemeris', 'history', 'i_nadir_first_acquired_pixel', 'i_oblique_first_acquired_pixel', 'in_scan_period_in_microseconds', 'meteo', 'phase_identifier', 'pixel_time_sampling_interval_along_scan_i_in_microseconds', 'product_unit', 'relative_pass_number', 'single_meteofield_synoptic_time_UTC_hours']\n\n\nSome relevant information included:\n\nprint('i Nadir First Pixel   :', s3_lst_zarr_sample.attrs['other_metadata']['i_nadir_first_acquired_pixel'])\nprint('i Oblique First Pixel :',s3_lst_zarr_sample.attrs['other_metadata']['i_oblique_first_acquired_pixel'])\nprint('Phase Identifier      :',s3_lst_zarr_sample.attrs['other_metadata']['phase_identifier'])\n\ni Nadir First Pixel   : 2469\ni Oblique First Pixel : 1124\nPhase Identifier      : 4",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/25_zarr_struct_S3.html#now-it-is-your-turn",
    "href": "02_about_eopf_zarr/25_zarr_struct_S3.html#now-it-is-your-turn",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nAs we are able to retrieve several items from the EOPF Sentinel Zarr Samples Service STAC API, let us try the following:\n\nTask\nGo to the Sentinel-3 SLSTR Level-2 LST collection and:\n\nChoose an item of interest.\nReplicate the workflow and explore the item‚Äôs metadata. When was it retrieved?\nWhat are the dimensions of the LST group?\nWhat are the values of the bbox (location) of the item?",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/25_zarr_struct_S3.html#conclusion",
    "href": "02_about_eopf_zarr/25_zarr_struct_S3.html#conclusion",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial provides an initial understanding of the .zarr structure for a Sentinel-3 SLSTR Level-2 LST product sample. By using the xarray library, we can effectively navigate and inspect the different components within the .zarr format, including its metadata and array organisation.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "02_about_eopf_zarr/25_zarr_struct_S3.html#whats-next",
    "href": "02_about_eopf_zarr/25_zarr_struct_S3.html#whats-next",
    "title": "Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nNow that you have been introduced to the .zarr encoding format, learned its core concepts, and understood the basics of how to explore it, you are prepared for the next step. In the following chapter we will dive into the chunks concept for zarr and why is it relevant for EO.",
    "crumbs": [
      "**About EOPF Zarr**",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Discover EOPF Zarr - Sentinel-3 SLSTR Level-2 LST</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/31_zarr_chunking_intro.html",
    "href": "03_about_chunking/31_zarr_chunking_intro.html",
    "title": "An introduction to Chunking",
    "section": "",
    "text": "Introduction\nChunking is the secret sauce that makes .zarr format incredibly efficient for Earth Observation data processing. Understanding chunking allows us to transform the way we work with massive satellite datasets. This means somehow, turning memory-crushing, slow operations into fast, scalable analysis workflows.\nThis introduction takes you from chunking basics to advanced optimisation strategies specifically tailored for EOPF (Earth Observation Processing Framework) datasets.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/31_zarr_chunking_intro.html#what-are-chunks",
    "href": "03_about_chunking/31_zarr_chunking_intro.html#what-are-chunks",
    "title": "An introduction to Chunking",
    "section": "What are chunks?",
    "text": "What are chunks?\nZarr revolutionises how we store and access large multidimensional arrays by breaking them into smaller, manageable pieces called chunks. Think of chunks as rectangular tiles that together compose a complete dataset, but with a significant difference: they allow us to access and process each of the components independently.\n\nA chunk is .zarr‚Äôs fundamental storage unit: an equally-sized block of array data that gets compressed and stored as a separate object.\n\nFor example, when we have a massive 10,000 √ó 10,000 pixel satellite image, zarr might divide it into 100 chunks of 1,000 √ó 1,000 pixels each. Then, each chunk becomes a separate compressed file or object in our storage system.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/31_zarr_chunking_intro.html#why-chunks-transform-performance",
    "href": "03_about_chunking/31_zarr_chunking_intro.html#why-chunks-transform-performance",
    "title": "An introduction to Chunking",
    "section": "Why chunks transform performance",
    "text": "Why chunks transform performance\nChunking addresses three critical performance bottlenecks in large-scale data processing:\n\nMemory efficiency: Instead of loading entire datasets into RAM, chunks allow us to only load the specific data we need. This allows us to work with datasets larger than our available memory, like a 100 GB satellite time series. It can be processed on a machine with just 8 GB of RAM.\nI/O optimisation: Chunking minimises data transfer, as it only reads relevant sections. When we need data from one geographic region, zarr loads only those chunks covering that area. For cloud storage, this translates to fewer, more efficient HTTP requests instead of downloading massive files. It also reduces data latency.\nParallel processing: Different chunks can be processed simultaneously by multiple CPU cores or distributed workers. This transforms compute-intensive operations from sequential bottlenecks into scalable parallel workflows.\n\n\nChunk sizes for performance\nChunk size selection fundamentally determines the performance characteristics over our dataset. The choice of chunking size affects memory usage, I/O efficiency, parallel scaling, and network transfer costs. That is the reason, it is one of the most critical optimisation decisions in Earth Observation data processing.\nThere are three levels of chunk sizes:\n\n\n\n\n\n\n\n\nChunk size\nAdvantages\nDisadvantages\n\n\n\n\nSmall chunks (1-10 MB)\nFine-grained access patterns, minimise memory usage per operation, and enable high granularity for parallel processing.\nHigh metadata overhead, requires numerous network requests for cloud storage, and creates complex task graphs.\n\n\nMedium chunks (10-100 MB)\nOptimal balance for most Earth Observation applications, works well with cloud storage byte-range requests, enables efficient compression ratios, and supports good parallelisation without excessive overhead.\nDepend exclusively on the dataset size, making it difficult to replicate\n\n\nLarge chunks (&gt;100 MB)\nMaximises compression efficiency, minimises network request count, and dramatically reduces metadata overhead for massive datasets.\nIncreases memory requirements, may transfer unnecessary data for sparse access patterns, and can limit parallel efficiency.\n\n\n\n\n\nA simple chunking example\nWe can explore chunking with a simple 2D raster dataset example. Imagine we have a 6√ó6 grid representing temperature data. This simple dataset can be chunked in different ways, each with its own advantages and tradeoffs:\n\n\n\nChunking sizes over the same dataset\n\n\n\n\n\n\n\n\n\n\n1√ó1 Chunks\n2√ó2 Chunks\n3√ó3 Chunks\n\n\n\n\n- Each pixel is a chunk- Maximum flexibility but high overhead- 36 total chunks- Good for random access to individual cells- Poor for operations that need adjacent cells\n- Each chunk contains 4 cells- Balanced approach- 9 total chunks- Good for small region operations- Reasonable compression potential\n- Each chunk contains 9 cells- More efficient storage- 4 total chunks- Better compression- Less granular access\n\n\n\n\n\nCompression of chunks\nCompression interactions significantly affect optimal chunk sizes. Larger chunks generally achieve better compression ratios, which are important for spectral data with high spatial correlation. However, compressed chunks must be fully decompressed when accessed, potentially increasing memory usage beyond the nominal chunk size. Balance compression benefits with memory requirements for your specific workflows.\nThe available compression algorithms for zarr are the following.\n\n\n\n\n\n\n\nCompression Algorithm\nDescription\n\n\n\n\nBlosc with LZ4\nProvides excellent speed with moderate compression ratios, making it ideal for interactive applications where decompression speed matters more than maximum storage efficiency. LZ4 typically achieves 2-5√ó compression on satellite data with very fast decompression.\n\n\nZstandard (Zstd)\nOffers an exceptional balance between compression ratio and speed, making it the preferred choice for many Earth Observation applications. Zstd often achieves 3-8√ó compression on spectral data while maintaining reasonable decompression performance.\n\n\nSpecialised algorithms\nSuch as JPEG 2000, provide excellent compression for certain data types but may not integrate well with general-purpose array processing workflows. Consider format compatibility when selecting compression approaches.\n\n\n\nCompression effectiveness depends heavily on network characteristics:\n\nBandwidth-limited environments benefit tremendously from aggressive compression since decompression is typically faster than network transfer. In these cases, higher compression ratios directly translate to reduced analysis time.\nHigh-bandwidth, low-latency networks may make compression counterproductive if decompression becomes the bottleneck. Profile your specific network environment to determine optimal compression levels.\nCloud storage considerations include both transfer costs and access speed. Compressed data reduces both storage costs and transfer times, but increases CPU usage. For most Earth Observation applications, compression provides net benefits.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/31_zarr_chunking_intro.html#why-is-it-relevant-to-chunk-eo-data",
    "href": "03_about_chunking/31_zarr_chunking_intro.html#why-is-it-relevant-to-chunk-eo-data",
    "title": "An introduction to Chunking",
    "section": "Why is it relevant to chunk EO data",
    "text": "Why is it relevant to chunk EO data\nEarth Observation datasets exhibit characteristics that significantly influence optimal chunking strategies. We can consider their structure, sizes, processing workflows and spatial and temporal resolutions.\n\nMulti-dimensional complexity: Satellite data combines spatial dimensions (often tens of thousands of pixels per side), spectral dimensions (multiple wavelength bands), and temporal dimensions (time series spanning years or decades). Each dimension has different access patterns and computational requirements.\nScale characteristics: Modern satellites generate massive data volumes. The Sentinel-2 mission alone, for example, produces approximately 1.6 TB per orbit, with the full archive exceeding 25 petabytes and growing rapidly. Processing workflows must handle this scale efficiently.\nAccess patterns: Unlike general-purpose arrays, EO data has predictable access patterns. Spatial analysis typically accesses rectangular geographic regions. Spectral analysis needs multiple bands for the same locations. Time series analysis follows individual pixels or regions through time.\nHeterogeneous resolutions: Many instruments capture data at multiple spatial resolutions simultaneously. Some missions require coordinated chunking strategies that balance storage efficiency with processing convenience.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/31_zarr_chunking_intro.html#now-it-is-your-turn",
    "href": "03_about_chunking/31_zarr_chunking_intro.html#now-it-is-your-turn",
    "title": "An introduction to Chunking",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nFor a deep dive into the chunking theory and further technical resources, we recommend going through the following resources:\n\nChunks and Chunkability: Tyranny of the Chunk\nChoosing Good Chunk Sizes in Dask - Dask team‚Äôs chunking recommendations\nOptimization Practices - Chunking - ESIP Fed‚Äôs chunking best practices\nOptimal Chunking Strategies for Cloud-based Storage - Research on geospatial chunking",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/31_zarr_chunking_intro.html#conclusion",
    "href": "03_about_chunking/31_zarr_chunking_intro.html#conclusion",
    "title": "An introduction to Chunking",
    "section": "Conclusion",
    "text": "Conclusion\nThis chapter introduced the logic behind data chunking and its relevance for scalable analysis workflows. We explored how optimising the size, compression and considering the transfer of these chunks significantly enhances the efficiency of data retrieval.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/31_zarr_chunking_intro.html#whats-next",
    "href": "03_about_chunking/31_zarr_chunking_intro.html#whats-next",
    "title": "An introduction to Chunking",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following section , we will go over optimal chunking strategies and relevant considerations when aiming for making Earth Observation workflows more efficient.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>An introduction to Chunking</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/32_zarr_chunking_strat.html",
    "href": "03_about_chunking/32_zarr_chunking_strat.html",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "",
    "text": "Introduction\nIn the previous section, we explored the fundamentals of Zarr chunking and its significance for Earth Observation data. Now we will delve into the specifications and challenges that address geospatial multi-resolution datasets.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/32_zarr_chunking_strat.html#what-we-will-learn",
    "href": "03_about_chunking/32_zarr_chunking_strat.html#what-we-will-learn",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "What we will learn",
    "text": "What we will learn\n\nüöÄ The workflow for choosing an optimal chunking strategy for EO\nüîé The EOPF Sentinel‚Äôs missions chunking structure\nüí™ How to choose the optimal chunk size depending on a data application",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/32_zarr_chunking_strat.html#fundamental-optimisation-principles",
    "href": "03_about_chunking/32_zarr_chunking_strat.html#fundamental-optimisation-principles",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Fundamental optimisation principles",
    "text": "Fundamental optimisation principles\nSuccessful Zarr chunking for Earth Observation applications requires balancing multiple competing factors while understanding the specific characteristics of the data, access patterns, and computational environment.\n\nPrinciple 1: Start with proven defaults and optimize based on measured performance. Most defaults consider 100MB target chunk sizes for initial implementations, employ consolidated metadata, and enable compression with balanced algorithms. These defaults work well for most Earth Observation applications and provide a solid foundation for further optimisation.\nPrinciple 2: Measure actual performance rather than relying on theoretical expectations. Use monitoring tools to track memory usage, I/O throughput, task duration, and parallel efficiency. The Dask dashboard provides excellent visualisation of performance characteristics, including task streams, memory usage patterns, and worker utilisation.\nPrinciple 3: Align with access patterns by designing chunks around how your applications actually use the data. Spatial analysis applications should use large spatial chunks. Time series analysis should favour temporal chunking. Visualisation applications should align with tile boundaries and zoom levels.\nPrinciple 4: Consider computational overhead relative to chunk processing time. Each chunk access involves ~1ms of scheduling overhead, so chunks should require significantly more computation time to maintain efficiency. For most Earth Observation algorithms, this translates to a minimum 10-100ms processing per chunk, supporting the 10-100 MB chunk size recommendation.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/32_zarr_chunking_strat.html#implementation-workflow",
    "href": "03_about_chunking/32_zarr_chunking_strat.html#implementation-workflow",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Implementation workflow",
    "text": "Implementation workflow\nFollow a systematic approach to chunking optimisation:\n\nAssess your data and analysis objectives: total size, dimensionality optimisation, access patterns, and storage environment\nIdentify computational requirements: available memory, processing power, and network bandwidth\nStart with conservative defaults: 100MB chunks, consolidated metadata, moderate compression\nImplement monitoring: track key performance metrics throughout your workflow\nOptimise iteratively: adjust chunk sizes and strategies based on measured performance\nValidate improvements: ensure optimizations actually improve real-world performance",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/32_zarr_chunking_strat.html#default-eopf-chunking-structure",
    "href": "03_about_chunking/32_zarr_chunking_strat.html#default-eopf-chunking-structure",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Default EOPF Chunking Structure",
    "text": "Default EOPF Chunking Structure\n\nSentinel-1 Level-1 GRD\nThe grd variable in the EOPF Sentinel-1 GRD dataset structure is particularly relevant for chunking. It is contained inside each of the VH and VV groups measurements respectiveley storing the variable as multidimensional arrays.\n\nChunking organisation\nEach contained grd array is chunked along both:\n\nazimuth_time : 7 - 9 chunks (depends on the item).\nground_range : No chunking along the dimension.\n\n\n\n\nSentinel-2\nThe measurements group in the EOPF Sentinel-2 dataset structure is particularly relevant for chunking. It contains the reflectance group, which is further divided into three different spatial resolutions: 10m, 20m, and 60m, respectively, containing spectral bands (e.g., B02, B03, B04) stored as multidimensional arrays.\n\nChunking organisation of Level-2A:\n\nr10m: Variables like B02, B03, and B04 are chunked into 1830√ó1830 pixel blocks, optimizing for high-resolution spatial analysis.\nr20m: Variables such as B05, B06, and B07 use 915√ó915 pixel chunks, balancing storage efficiency and processing convenience for medium-resolution data.\nr60m: Variables like B01 and B09 are chunked into 305√ó305 pixel blocks, aligning with the coarser resolution requirements of atmospheric correction bands.\n\nThis chunking ensures the three resolutions are chunked into 36 pieces (6√ó6) chunks each. This strategy provides efficient access and processing across different resolutions, tailored to the specific structure of Sentinel-2 data.\n\n\n\nSentinel-3 (LST)\nThis section is under development üõ∞Ô∏è\n\nChunking organisation of SLSTR\nThis section is under development üõ∞Ô∏è",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/32_zarr_chunking_strat.html#use-case-specific-optimisation",
    "href": "03_about_chunking/32_zarr_chunking_strat.html#use-case-specific-optimisation",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Use case-specific optimisation",
    "text": "Use case-specific optimisation\nDifferent Earth Observation applications have dramatically different optimal chunking strategies:\n\nScientific analysis workflows should align chunks with computational patterns.\nFor time series analysis, the recommendation relies on large spatial chunks but small temporal chunks to optimize pixel-by-pixel processing.\nFor spatial analysis algorithms, reverse this pattern with large temporal chunks and smaller spatial chunks. Consider algorithm-specific requirements.\nVisualisation and display applications benefit from tile-aligned chunking that matches web mapping standards. The usual sizes are 256√ó256 or 512√ó512 pixel chunks aligned with standard tile pyramid levels. This enables efficient zoom and pan operations by loading only visible tiles. Progressive loading with smaller chunks (1-10 MB) creates responsive user interfaces.\nTiling and map service workflows require careful alignment with tile boundaries and zoom levels. Web Mercator tiling works best with chunks that are multiples of 256√ó256 pixels. Consider different chunk sizes for different zoom levels to optimise both overview generation and detail rendering.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/32_zarr_chunking_strat.html#do-not-forget-to-consider",
    "href": "03_about_chunking/32_zarr_chunking_strat.html#do-not-forget-to-consider",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Do not forget to consider‚Ä¶",
    "text": "Do not forget to consider‚Ä¶\n\nOver-chunking: too many small chunks create scheduler overhead and poor parallel efficiency. Symptoms include excessive white space in task streams and slow computation startup. Solution: increase chunk sizes to reduce task graph complexity.\nUnder-chunking: too few large chunks causes memory exhaustion and poor parallelisation. Watch for memory spilling indicators and idle workers. Solution: decrease chunk sizes to better utilise available parallelism.\nIgnoring storage alignment: creates poor I/O performance when Zarr chunks don‚Äôt align with underlying storage chunk boundaries. Always ensure your chunk dimensions are multiples of storage format chunks.\nFrequent rechunking: Some operations are expensive and should be avoided through careful initial chunk selection. Plan your chunking strategy around your complete workflow rather than optimising individual operations in isolation.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/32_zarr_chunking_strat.html#conclusion",
    "href": "03_about_chunking/32_zarr_chunking_strat.html#conclusion",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "Conclusion",
    "text": "Conclusion\nThis chapter presented the specific workflow for setting up an optimal data chunking strategy for EO applications. We reviewed the default chunking strategies available in the EOPF STAC Catalog for Sentinel missions as well as discussing key considerations required based on the type of application and use case. We also presented some considerations that, if overlooked, could lead to a loss of optimisation.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "03_about_chunking/32_zarr_chunking_strat.html#whats-next",
    "href": "03_about_chunking/32_zarr_chunking_strat.html#whats-next",
    "title": "Best practices and Chunking optimisation in EOPF",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nNow that you have been introduced to the .zarr chunking reasoning and strategies, you are prepared for the next step. In the following chapter we will introduce you to STAC and the EOPF Zarr STAC Catalog. As we go along, we are more and more transitioning from theory to practice, providing you with hands-on tutorials working with EOPF .zarr products.",
    "crumbs": [
      "**About Chunking**",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Best practices and Chunking optimisation in EOPF</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/41_stac_intro.html",
    "href": "04_eopf_and_stac/41_stac_intro.html",
    "title": "Introduction to STAC",
    "section": "",
    "text": "Introduction\nWelcome to the chapter on EOPF and STAC. In the following section, we will introduce you to the Spatio-Temporal Asset Catalog (STAC). We will explain its fundamental principles and, most importantly, we will explore its structure and core components. Understanding the fundamentals of STAC is key in order to be able to effectively discover and access data from STAC catalogs.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/41_stac_intro.html#about-stac",
    "href": "04_eopf_and_stac/41_stac_intro.html#about-stac",
    "title": "Introduction to STAC",
    "section": "About STAC",
    "text": "About STAC\nThe Spatio-Temporal Asset Catalog (STAC) is a standardised way to catalog and describe geospatial (raster) data. STAC makes it easier to discover, access, and work with geospatial data, in particular satellite data, as it provides a common language for describing spatial and temporal characteristics of the data. This common language improves interoperability between different data providers and software tools.\nThe main goal of STAC is to allow data providers to share their data easily, making it universal for users to understand the where, when, how, and what of the collected data.\nSTAC uses JSON (JavaScript Object Notation) to structure the metadata of geo-referenced datasets. JSON makes it machine-readable. Through its design, STAC is simple and extensible in its design as it is based on a network of JSON files.\nSTAC has evolved into a well-recognised community standard. The key benefit supporting its wide adoption is that one can use the same code and API to access data from different data repositories.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/41_stac_intro.html#the-stac-ecosystem",
    "href": "04_eopf_and_stac/41_stac_intro.html#the-stac-ecosystem",
    "title": "Introduction to STAC",
    "section": "The STAC ecosystem",
    "text": "The STAC ecosystem\nSTAC has evolved into a vast ecosystem offering various resources and tools for accessing, managing, and building STAC catalogs. Below is a non-exclusive list of tools and plug-ins that will help to explore the STAC ecosystem:\n\n\n\nCategory\nTool/Plugin\nDescription\nLanguage\n\n\n\n\nSTAC Tools\nSTAC Browser\nA user-friendly web interface for visually exploring and interacting with various STAC catalogs.\nWeb interface\n\n\n\nSTAC Server\nA reference implementation for serving STAC catalogs and collections.\nPython\n\n\nSTAC libraries and plug-ins\nSTAC Validator\nA tool for programmatically validating STAC Catalogs, Collections, and Items to ensure compliance with the STAC specification.\nPython\n\n\n\nPySTAC\nA Python library for reading, writing, and validating STAC objects, facilitating the creation and manipulation of STAC data.\nPython\n\n\n\npystac-client\nA Python library that provides a convenient and powerful interface for searching and accessing STAC data from STAC API servers.\nPython\n\n\n\nrstac\nAn R package that provides functionalities for interacting with STAC APIs and working with STAC objects within the R environment.\nR\n\n\n\nSTAC.jl\nA Julia package designed for working with STAC, enabling users to interact with STAC catalogs and process geospatial data.\nJulia\n\n\n\nSTACCube.jl\nA Julia package that facilitates the creation and management of STAC-compliant data cubes from various geospatial datasets.\nJulia",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/41_stac_intro.html#stac-components",
    "href": "04_eopf_and_stac/41_stac_intro.html#stac-components",
    "title": "Introduction to STAC",
    "section": "STAC components",
    "text": "STAC components\nNow, let us start exploring the structure of STAC. STAC consists of four main components: (i) Catalog, (ii) Collection, (iii) Item and (iv) Asset. See the figure below for the principal organisation of the STAC components.\n\n\n\nSTAC structure\n\n\n\nLet us now explore in more detail the individual components:\n\nCatalog\nA Catalog serves as the initial entry point of a STAC. A catalog is a very simple construct; it simply provides links to Collections or Items. The closest analogue is a folder on your computer. A Catalog can be a folder for Items, but it can also be a folder for Collections or other Catalogs. When searching for specific data, you first establish a connection to a valid STAC catalog.\n\n\nCollection\nCollections are containers that support the grouping of Items. The Collection entity shares most fields with the Catalog entity but has several additional fields, such as license, extent (spatial and temporal), providers, keywords and summaries. Every Item in a Collection links back to its Collection. Collection is often used to provide additional structure in a STAC catalog.\n\n\n\n\n\n\nNote\n\n\n\nBut when to use a Collection versus a Catalog? A Collection generally consists of a set of assets that share the same properties and share higher-level metadata. For example, data from the same satellite sensor or constellation would typically be in one Collection.\nCatalogs, in turn, are used to split overly large Collections into groups and to group collections into a catalog of Collections (e.g.¬†as an entry point for navigation to several Collections).\nIt is recommended to use Collections for what you want users to find and Catalogs for structuring and grouping Collections.\n\n\n\n\nItem\nAn Item is the fundamental element of STAC and typically represents a single scene at one place and time. It is a GeoJSON supplemented with additional metadata, which serves as an index to Assets.\n\n\n\nItem entity\n\n\n\n\nAsset\nAn Asset is the smallest element inside a STAC and represents the individual data file that is linked in a STAC Item.\n\n\nAnalogy: Organising a drinks menu as a STAC\nTo better understand the relation of STAC components, let us imagine a Drinks menu as a STAC. How would you structure Drinks as a STAC?\nLet us start with the Drinks category itself. The menu is analogous to a STAC Catalog, as it serves as the top-level entry point, providing an overview of all beverages available.\nWithin this Drinks catalog, we can create different categories, such as hot and cold beverages, and caffeinated and non-caffeinated drinks. These categories represent Collections in STAC. For our analogy, let us say the menu is divided into two main collections:\n\nCaffeinated Drinks Collection: This section groups all beverages that contain caffeine.\nNon-Caffeinated Drinks Collection: This section groups all beverages that do not contain caffeine.\n\nEach of these collections contains specific drinks, which are analogous to STAC Items. Drink Items could be, e.g.¬†Juices or Milks. Both represent again a group of specific juices and milks, which are analogous to Assets in STAC. For the Drink Items defined, theirAssets` might include:\n\n\n\nItem\nAssets\n\n\n\n\nMilks\nOat Milk  Regular Milk\n\n\nJuices\nApple Juice  Organge Juice  ‚Ä¶\n\n\n\nThe STAC structure allows us to easily navigate a vast amount of data, just as a well-organised menu helps a customer quickly find their desired drink.\n\n\n\nDrinks Menu as a STAC analogy",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/41_stac_intro.html#conclusion",
    "href": "04_eopf_and_stac/41_stac_intro.html#conclusion",
    "title": "Introduction to STAC",
    "section": "Conclusion",
    "text": "Conclusion\nIn this section, you got an introduction to the Spatio-Temporal Asset Catalog (STAC) and learned what STAC is and explored the main components of a STAC. Understanding the distinction between Catalog, Collection, Items and Assets is important to effectively navigating through STAC APIs.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/41_stac_intro.html#whats-next",
    "href": "04_eopf_and_stac/41_stac_intro.html#whats-next",
    "title": "Introduction to STAC",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following section, we will explore the web interface of the EOPF Sentinel Zarr Samples Service STAC Catalog.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Introduction to STAC</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html",
    "href": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "",
    "text": "Introduction\nThis section introduces you to the EOPF Sentinel Zarr Samples Service STAC Catalog, which offers access to the re-engineered Sentinel-1, Sentinel-2 and Sentinel-3 data products. We will guide you through its web interface, inspect the various levels of STAC components, and demonstrate how to access the underlying Sentinel Zarr data.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#our-starting-point",
    "href": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#our-starting-point",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "Our Starting Point",
    "text": "Our Starting Point\nThe first step is to access the main homepage of the EOPF Sentinel Zarr Samples Service STAC Catalog. The landing page offers you a comprehensive overview of the available data collections. This serves as our initial entry point into the catalog.\n\n\n\nHome page\n\n\nThree main areas can be identified: (i) the API and URL section, (ii) Search bar and (iii) Collections Display. \nAs outlined in detail in the book section The EOPF Available Datasets, the catalog displays the 11 distinct collections available from the Sentinel-1, Sentinel-2, and Sentinel-3 missions.  The user interface provides an intuitive way to browse through all of these collections. It is possible to filter them by specific criteria or select them manually, allowing precise control over the displayed data.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#exploring-sentinel-collections",
    "href": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#exploring-sentinel-collections",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "Exploring Sentinel Collections",
    "text": "Exploring Sentinel Collections\nLet us now select one of the 11 Collection available, e.g.¬†let us select the Sentinel 2-Level-2A collection. Once you have selected the Collection, you will be directed to the interface of a specific Collection.\n\n\n\nWeb interface of the Sentinel-2 Level-2A Collection of the EOPF Sentinel Zarr Samples Service STAC Catalog\n\n\nThe interface can be divided into five principal sections:\n\nDescription: The name and a brief introduction to the available collection. This includes crucial details such as the temporal extent (the period over which the data was acquired)\nAPI and URL: for further application.\nSpatial Extent: The geographical area of the displayed items is shown on the map.\nAvailable Items: On the right-hand side of the page, a list of links for the items contained within the collection corresponds to the selected collection.\nCollection Metadata: A general overview of the Collection‚Äôs metadata, its providers, instruments, and the corresponding DOIs for research.\nMetadata: Specific information about the bands and instruments, such as backscatter or reflectance information.\nAssets in Items: The Assets structure is available for the Items available in the Collection.\n\n\nFiltering Collections\nAny selected Collection (in this case Sentinel-2 Level-2A) allows us to filter the items of our interest by temporal and spatial extent. We can access this tab by clicking on Show Filters on the right side under the Items section.\n\n\n\nOverview of interface that opens when clicking in Show Filters\n\n\nThe interface that opens allows us to select on the calendar a specific period we are interested in. This is particularly useful when we are interested in a temporal analysis. Let us search over the available items captured between May 1st and May 5th 2024.\n\n\n\nFiltering over time\n\n\nAdditionally, we can select a location we are interested in by checking the Filter by spatial extent box. This allows us to refine our search over an area of interest. Once you tick the box, a map activates and allows us to draw a bounding box that we can drag and drop. Let us select Europe as our area of interest.\n\n\n\nFiltering over spatial extent\n\n\nOnce we select the desired period and area via the filters, we can sort the items that match our search by ID, Date and Time, or select the number of resulting items we are interested in per page. In this case, we select 2, so the overview is digestible. Then, we click Submit.\n\n\n\nResulting Items\n\n\nUnder the window, we can now see that two items appear. For example: S2B_MSIL2A_20250504T131719_N0511_R124_T27VVL_20250504T165710\nWe can select any of the resulting items, and this will enable us to access an Item inside the Collection.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#exploring-items",
    "href": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#exploring-items",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "Exploring Items",
    "text": "Exploring Items\nWhen a specific Item sparks our interest, clicking on it will bring us to a detailed overview page for that selected Item. \nThis Item interface is composed of:\n\nDescription: The name of the Item. Depending on the mission and collection it belongs to, the composition of the name changes.\nSpatial Extent: The geographical footprint of the selected Item is shown on the map.\nCollection Metadata: A general overview of the Collection‚Äôs metadata, its providers, instruments, resolution, grid and the corresponding DOIs for research.\nAPI and URL: Allows the entry point for further retrieval of the individual assets.\nAssets menu: lists all the Assets that are part of the selected Item.\n\n\n\n\nThe item selected inside the Sentinel-2 Level-2A Collection\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAt this level of the STAC structure, we are already diving deep into the STAC levels, and have explored the Catalog, Collection and Item components described in the Introduction to STAC section.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#assets",
    "href": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#assets",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "Assets",
    "text": "Assets\nInside the selected Item, we will get an overview of the available Assets that belong to the Item. By expanding the dropdown menu for any Asset of interest, you can access its specific metadata and, most importantly, the actual data. \n\n\n\nOverview of the web interface on Asset level\n\n\nIn the case of the Sentinel-2 Level-2A collection, each asset corresponds to one of the 13 spectral bands available. The array information provides details about the structure and content of the data, hinting at the actual values contained within the asset. It also contains the chunking grid specification and all the crucial metadata necessary to structure and process the data through a wide range of geospatial methodologies.\n\nAccessing Assets\nFor direct data access of Assets and therefore the actual data, there are two options provided via the web interface: * Download: It is possible to download only one asset separately in .zarr format by clicking the Download option associated with an Asset, and * Copy URL: We can also retrieve the unique URL of the specified Asset, which allows us to directly integrate the link into programmatic workflows, without the need to download the Asset. We can get it by simply clicking on the Copy URL option under the Asset of our interest.\n\n\n\nData access options via the web interface",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#now-it-is-your-turn",
    "href": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#now-it-is-your-turn",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nYour task now is to explore the web interface of the EOPF Sentinel Zarr Samples Service STAC Catalog on your own and explore other Collections than the one we showcased.\n\nTask 1: Discover Sentinel-1 GRD Data\nNavigate to the Sentinel-1 Level-1 GRD Collection.\n\nHow many items can you find for the most recent two years available in the catalogue?\nTry filtering by different periods and observe how the results change. How many items are available for September 2023?\n\n\n\nTask 2: Mapping Your Interests\nExplore the interactive map within the Sentinel-1 Level-1 GRD and the Sentinel-2 Level-2A collections.\n\nCan you identify and list the names of at least three distinct geographical areas where a significant number of items are available? (Hint: Look for clusters of the displayed items!)\n\n\n\nTask 3: Unpacking an Asset\nSelect an item from any collection that looks interesting to you. Click on it to view its details. Then, expand one of the assets.\n\nWhat kind of array information is provided?\nWho is the data provider?\nHow would this information be useful if you were to process this data?",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#conclusion",
    "href": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#conclusion",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "Conclusion",
    "text": "Conclusion\nThis section walked you through the web interface of the EOPF Sentinel Zarr Samples Service STAC Catalog. We have demonstrated how to navigate its interface, from the initial overview of the available Collections to the detailed inspection of specific Items and Assets. By understanding the structure and components of a STAC catalog, we are able to efficiently access re-engineered EOPF Zarr assets.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#whats-next",
    "href": "04_eopf_and_stac/42_eopf_stac_zarr_tutorial.html#whats-next",
    "title": "Explore the web interface of the EOPF Zarr STAC Catalog",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following notebook, we will explore how to programmatically connect to and search through the EOPF Sentinel Zarr Samples Service STAC API with the help of the pystac and the pystac-client Python libraries.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Explore the web interface of the EOPF Zarr STAC Catalog</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/43_eopf_stac_connection.html",
    "href": "04_eopf_and_stac/43_eopf_stac_connection.html",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nIn this section, we will dive into the programmatic access of EOPF Zarr Collections available in the EOPF Sentinel Zarr Sample Service STAC Catalog. We will introduce Python libraries that enable us to effectively access and search through STAC catalogs.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/43_eopf_stac_connection.html#establish-a-connection-to-the-eopf-zarr-stac-catalog",
    "href": "04_eopf_and_stac/43_eopf_stac_connection.html#establish-a-connection-to-the-eopf-zarr-stac-catalog",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "Establish a connection to the EOPF Zarr STAC Catalog",
    "text": "Establish a connection to the EOPF Zarr STAC Catalog\nOur first step is to establish a connection to the EOPF Sentinel Zarr Sample Service STAC Catalog. For this, you need the Catalog‚Äôs base URL, which you can find on the web interface under the API & URL tab. By clicking on üîóSource, you will get the address of the STAC metadata file - which is available here.\n\n\n\nEOPF API url for connection\n\n\nCopy paste the URL: https://stac.core.eopf.eodc.eu/.\nWith the Client.open() function, we can create the access to the starting point of the Catalog by providing the specific url. If the connection was successful, you will see the description of the STAC catalog and additional information.\n\neopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\" #root starting point\neopf_catalog = Client.open(url=eopf_stac_api_root_endpoint) # calls the selected url\neopf_catalog\n\n\n\n\n\n\n    &lt;Client id=eopf-sample-service-stac-api&gt;\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Catalog\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"eopf-sample-service-stac-api\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"STAC catalog of the EOPF Sentinel Zarr Samples Service\"\n        \n    \n                \n            \n                \n                    \n        links[] 21 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"conformance\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/conformance\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC/OGC conformance classes implemented by this server\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"POST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-2A\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-grd\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 GRD\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l1-rbt\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-1 RBT\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lfr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l2-lst\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-2 LST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l2-frp\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-2 FRP\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lrr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LRR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-efr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 EFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l1c\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-1C\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-slc\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 SLC\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-err\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 ERR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l2-ocn\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-2 OCN\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \n        \n            \n                \n        \n            rel\n            \"service-desc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/vnd.oai.openapi+json;version=3.0\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service description\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \n        \n            \n                \n        \n            rel\n            \"service-doc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api.html\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service documentation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        conformsTo[] 21 items\n        \n            \n        \n            \n                \n        \n            0\n            \"http://www.opengis.net/spec/cql2/1.0/conf/basic-cql2\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-text\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/geojson\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/oas30\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/features-filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \"https://api.stacspec.org/v1.0.0-rc.2/item-search#filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \"https://api.stacspec.org/v1.0.0/collections\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \"https://api.stacspec.org/v1.0.0/collections/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \"https://api.stacspec.org/v1.0.0/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \"https://api.stacspec.org/v1.0.0/item-search\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \"https://api.stacspec.org/v1.0.0/item-search#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \"https://api.stacspec.org/v1.0.0/item-search#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \"https://api.stacspec.org/v1.0.0/item-search#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"\n        \n    \n                \n            \n        \n    \n\n\n\n\nCongratulations. We successfully connected to the EOPF Zarr STAC Catalog, and we can now start exploring its content.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/43_eopf_stac_connection.html#explore-available-collections",
    "href": "04_eopf_and_stac/43_eopf_stac_connection.html#explore-available-collections",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "Explore available collections",
    "text": "Explore available collections\nOnce a connection established, the next logical step is to get an overview of all the collections the STAC catalog offers. We can do this with the function get_all_collections(). The result is a list, which we can loop through to print the relevant collection IDs.\nPlease note: Since the EOPF Zarr STAC Catalog is still in active development, we need to test whether a collection is valid, otherwise you might get an error message. The code below is testing for validity and for one collection, it throws an error.\nYou see, that so far, we can browse through 10 available collections\n\ntry:\n    for collection in eopf_catalog.get_all_collections():\n        print(collection.id)\n\nexcept Exception:\n    print(\n        \"* [https://github.com/EOPF-Sample-Service/eopf-stac/issues/18 appears to not be resolved]\"\n    )\n\nsentinel-2-l2a\nsentinel-1-l1-grd\nsentinel-3-slstr-l1-rbt\nsentinel-3-olci-l2-lfr\nsentinel-3-slstr-l2-lst\nsentinel-3-slstr-l2-frp\nsentinel-3-olci-l2-lrr\nsentinel-3-olci-l1-efr\nsentinel-2-l1c\nsentinel-1-l1-slc\nsentinel-3-olci-l1-err\nsentinel-1-l2-ocn\n\n\nIn a next step, we can select one collection and retrieve certain metadata that allow us to get more information about the selected collection, such as keywords, the ID and useful links for resources.\n\nS2l2a_coll = eopf_catalog.get_collection('sentinel-2-l2a')\nprint('Keywords:        ',S2l2a_coll.keywords)\nprint('Catalog ID:      ',S2l2a_coll.id)\nprint('Available Links: ',S2l2a_coll.links)\n\nKeywords:         ['Copernicus', 'Sentinel', 'EU', 'ESA', 'Satellite', 'Global', 'Imagery', 'Reflectance']\nCatalog ID:       sentinel-2-l2a\nAvailable Links:  [&lt;Link rel=items target=https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a/items&gt;, &lt;Link rel=parent target=https://stac.core.eopf.eodc.eu/&gt;, &lt;Link rel=root target=&lt;Client id=eopf-sample-service-stac-api&gt;&gt;, &lt;Link rel=self target=https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a&gt;, &lt;Link rel=license target=https://sentinel.esa.int/documents/247904/690755/Sentinel_Data_Legal_Notice&gt;, &lt;Link rel=cite-as target=https://doi.org/10.5270/S2_-znk9xsj&gt;, &lt;Link rel=http://www.opengis.net/def/rel/ogc/1.0/queryables target=https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a/queryables&gt;]",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/43_eopf_stac_connection.html#searching-inside-the-eopf-stac-api",
    "href": "04_eopf_and_stac/43_eopf_stac_connection.html#searching-inside-the-eopf-stac-api",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "Searching inside the EOPF STAC API",
    "text": "Searching inside the EOPF STAC API\nWith the .search() function of the pystac-client library, we can search inside a STAC catalog we established a connection with. We can filter based on a series of parameters to tailor the search for available data for a specific time period and geographic bounding box.\n\nFilter for temporal extent\nLet us search on the datetime parameter. For this, we specify the datetime argument for a time period we are interested in, e.g.¬†from 1 May 2020 to 31 May 2023. In addition, we also specify the collection parameter indicating that we only want to search for the Sentinel-2 L2A collection.\nWe apply the helper function list_found_elements which constructs a list from the search result. If we check the length of the final list, we can see that for the specified time period, 196 items were found.\n\ntime_frame = eopf_catalog.search(  #searching the catalog\n    collections='sentinel-2-l2a',\n    datetime=\"2020-05-01T00:00:00Z/2023-05-31T23:59:59.999999Z\")  # the interval we are interested in, separated by '/'\n\n# we apply the helper function `list_found_elements`\ntime_items=list_found_elements(time_frame)\nprint(time_frame)\n\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-2 L-2A between May 1, 2020, and May 31, 2023:  ',len(time_items[0]))\n\n&lt;pystac_client.item_search.ItemSearch object at 0x7faadd177740&gt;\nSearch Results:\nTotal Items Found for Sentinel-2 L-2A between May 1, 2020, and May 31, 2023:   1797\n\n\n\n\nFilter for spatial extent\nNow, let us filter based on a specific area of interest. We can use the bbox argument, which is composed by providing the top-left and bottom-right corner coordinates. It is similar to drawing the extent in the interactive map of the EOPF browser interface.\nFor example, we defined a bounding box of the outskirts of Innsbruck, Austria. We then again apply the helper function list_found_elements and see that for the defined area, only 39 items are available.\n\nbbox_search =  eopf_catalog.search(  #searching the catalog\n    collections='sentinel-2-l2a',\n    bbox=(\n        11.124756, 47.311058, #top left\n        11.459839, 47.463624  #bottom-right\n        )\n)\n\ninnsbruck_sets=list_found_elements(bbox_search) #we apply our constructed function that stores internal information\n\n#Results\nprint(\"Search Result:\")\nprint('Total Items Found:  ',len(innsbruck_sets[0]))\n\nSearch Result:\nTotal Items Found:   140\n\n\n\n\nCombined filtering: Collection + temporal extent + spatial extent\nAs a usual workflow, we often look for datasets within an AOI and a specific period of time. The search() function allows us also to combine the collection, bbox and datetime arguments in one search request.\nLet us now search for Items available for the AOI around Innsbruck within the previously defined timeframe for the Sentinel-2 Level-2A collection. As a result, we get 27 Items that are available for our selection.\n\ninnsbruck_s2 = eopf_catalog.search( \n    collections= 'sentinel-2-l2a', # interest Collection,\n    bbox=(11.124756, 47.311058, # AOI extent\n          11.459839,47.463624),\n    datetime='2020-05-01T00:00:00Z/2025-05-31T23:59:59.999999Z' # interest period\n)\n\ncombined_ins =list_found_elements(innsbruck_s2)\n\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-2 L-2A over Innsbruck:  ',len(combined_ins[0]))\n\nSearch Results:\nTotal Items Found for Sentinel-2 L-2A over Innsbruck:   27\n\n\nLet‚Äôs repeat a combined search for a different collection. We define a new AOI for the coastal area of Rostock, Germany and we search over the Sentinel-3 SLSTR-L2 collection for the same time period as above.\nAs a result, 14 Items are available for the specified search.\n\nrostock_s3 = eopf_catalog.search(\n    bbox=(11.766357,53.994566, # AOI extent\n          12.332153,54.265086),\n    collections= ['sentinel-3-slstr-l2-lst'], # interest Collection\n    datetime='2020-05-01T00:00:00Z/2025-05-31T23:59:59.999999Z' # interest period\n)\n\ncombined_ros=list_found_elements(rostock_s3)\n\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-3 SLSTR-L2 over Rostock Coast:  ',len(combined_ros[0]))\n\nSearch Results:\nTotal Items Found for Sentinel-3 SLSTR-L2 over Rostock Coast:   18\n\n\n\n\nRetrieve Asset URLs for accessing the data\nSo far, we have made a search among the STAC catalog and browsed over the general metadata of the collections. To access the actual EOPF Zarr Items, we need to get their storage location in the cloud.\nThe relevant information we can find inside the .items argument by the .get_assets() function. Inside, it allows us to specify the .MediaType we are interested in. In our example, we want to obtain the location of the .zarr file.\nLet us retrieve the url of the 27 available items over Innsbruck. The resulting URL we can then use to directly access an asset in our workflow.\n\ndef get_item_cleaned(collection, item_id):\n    \"\"\"\n    Retrieve an item from a collection and clean assets with missing href.\n    Workaround for STAC API issues where some assets lack href attribute.\n    \"\"\"\n    import requests\n    \n    # Build the item URL and fetch raw JSON\n    items_href = collection.get_single_link(\"items\").href\n    item_url = f\"{items_href.rstrip('/')}/{item_id}\"\n    \n    response = requests.get(item_url)\n    response.raise_for_status()\n    item_dict = response.json()\n    \n    # Clean assets with missing href\n    if \"assets\" in item_dict:\n        item_dict[\"assets\"] = {\n            key: asset for key, asset in item_dict[\"assets\"].items() if \"href\" in asset\n        }\n    \n    return Item.from_dict(item_dict)\n\n# Retrieve assets for Innsbruck items\nassets_loc = []\nfor item_id in combined_ins[0]:\n    item = get_item_cleaned(S2l2a_coll, item_id)\n    zarr_assets = item.get_assets(media_type=MediaType.ZARR)\n    assets_loc.append(zarr_assets)\n\nfirst_item = assets_loc[0]  # we select the first item from our list\n\nprint(\"Search Results:\")\nprint('URL for accessing', combined_ins[0][0], 'item:  ', first_item['product'])\n\nSearch Results:\nURL for accessing S2B_MSIL2A_20250530T101559_N0511_R065_T32TPT_20250530T130924 item:   &lt;Asset href=https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202505-s02msil2a/30/products/cpm_v256/S2B_MSIL2A_20250530T101559_N0511_R065_T32TPT_20250530T130924.zarr&gt;\n\n\n\n\nRetrieve Item metadata\nFinally, once you selected an Item, you can also explore the relevant metadata on Item level. For example with the keys() function, you can retrieve the available assets of the selected Item.\n\nprint('Available Assets: ', list(first_item.keys()))\n\nAvailable Assets:  ['SR_10m', 'SR_20m', 'SR_60m', 'AOT_10m', 'B01_20m', 'B02_10m', 'B03_10m', 'B04_10m', 'B05_20m', 'B06_20m', 'B07_20m', 'B08_10m', 'B09_60m', 'B11_20m', 'B12_20m', 'B8A_20m', 'SCL_20m', 'TCI_10m', 'WVP_10m', 'product']",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/43_eopf_stac_connection.html#now-it-is-your-turn",
    "href": "04_eopf_and_stac/43_eopf_stac_connection.html#now-it-is-your-turn",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nThe following expercises will help you master the STAC API and understand how to find the data you need.\n\nTask 1: Explore Your Area of Interest\n\nGo to http://bboxfinder.com/ and select an area of interest (AOI) (e.g.¬†your hometown, a research site, etc.)\nCopy the bounding box coordinates of your area of interest\nChange the provided code above to search for data over your AOI\n\n\n\nTask 2: Temporal Analysis\n\nCompare data availability across different years for the Sentinel-2 L-2A Collection.\nSearch for items in the year 2022\nRepeat the search for the year 2024\n\n\n\nTask 3: Explore the SAR Mission and combine multiple criteria\n\nDo the same for a different Collection, the Sentinel-1 Level-1 GRD, e.g.¬†you can use the ID sentinel-1-l1-grd\nHow many assets are available for the year 2024?",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/43_eopf_stac_connection.html#conclusion",
    "href": "04_eopf_and_stac/43_eopf_stac_connection.html#conclusion",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial has provided a clear and practical introduction on how you can programmatically access and search through EOPF Sentinel Zarr Sample Service STAC API.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/43_eopf_stac_connection.html#whats-next",
    "href": "04_eopf_and_stac/43_eopf_stac_connection.html#whats-next",
    "title": "Access the EOPF Zarr STAC API with Python",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following notebook, we will explore how to retrieve an Item of our interest, based on several parameters and load the actual data array as xarray.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with Python</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html",
    "href": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nIn this tutorial we will demonstrate how to access EOPF Zarr products directly from the EOPF Sentinel Zarr Sample Service STAC Catalog.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#establish-a-connection-to-the-eopf-zarr-stac-catalog",
    "href": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#establish-a-connection-to-the-eopf-zarr-stac-catalog",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Establish a connection to the EOPF Zarr STAC Catalog",
    "text": "Establish a connection to the EOPF Zarr STAC Catalog\nOur first step is to a connection to the EOPF Zarr STAC Catalog. This involves defining the url of the STAC endpoint. See the previous section for a more detailed explanation how to retrieve the end point url.\nThrough the Client.open() function, we can establish the connection to the EOPF Zarr STAC catalog by providing the specific url.\n\nmax_description_length = 100\n\neopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\" #root starting point\neopf_catalog = Client.open(url=eopf_stac_api_root_endpoint)\n\n# eopf_catalog  #print to have an interative visualisation",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#filtering-for-items-of-interest",
    "href": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#filtering-for-items-of-interest",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Filtering for items of interest",
    "text": "Filtering for items of interest\nFor this tutorial, we will focus on the Sentinel-2 L2A Collection. The EOPF STAC Catalog corresponding id is: sentinel-2-l2a.\nAs we are interested in retrieving and exploring an Item from the collection, we will focus again over the Innsbruck area we have defined in the previous tutorial.\n\ninnsbruck_s2 = eopf_catalog.search( # searching in the Catalog\n    collections= 'sentinel-2-l2a', # interest Collection,\n    bbox=(11.124756, 47.311058, # AOI extent\n          11.459839,47.463624),\n    datetime='2020-05-01T00:00:00Z/2025-05-31T23:59:59.999999Z' # interest period\n)\n\ncombined_ins =list_found_elements(innsbruck_s2)\n\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-2 L-2A over Innsbruck:  ',len(combined_ins[0]))\n\nSearch Results:\nTotal Items Found for Sentinel-2 L-2A over Innsbruck:   27\n\n\nLet us now select the first Item in the list of 27 Items.\n\nfirst_item_id=combined_ins[0][0]\nprint(first_item_id)\n\nS2B_MSIL2A_20250530T101559_N0511_R065_T32TPT_20250530T130924\n\n\nIn a next step, we retrieve the url of the cloud location for the specific item and load the selected Item with the help of xarray.\n\nc_sentinel2 = eopf_catalog.get_collection('sentinel-2-l2a')\n#Choosing the first item available to be opened:\nitem= c_sentinel2.get_item(id=first_item_id)\nitem_assets = item.get_assets(media_type=MediaType.ZARR)\n\ncloud_storage = item_assets['product'].href\n\nprint('Item cloud storage URL for retrieval:',cloud_storage)\n\nItem cloud storage URL for retrieval: https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202505-s02msil2a/30/products/cpm_v256/S2B_MSIL2A_20250530T101559_N0511_R065_T32TPT_20250530T130924.zarr",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#examining-dataset-structure",
    "href": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#examining-dataset-structure",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Examining Dataset Structure",
    "text": "Examining Dataset Structure\nIn the following step, we open the cloud-optimised Zarr dataset using xarray.open_datatree supported by the zarr engine.\nThe subsequent loop then prints out all the available groups within the opened DataTree, providing a comprehensive overview of the hierarchical structure of the EOPF Zarr products.\n\nclient = DaskClient()  # Set up local dask cluster\nclient\n\ndt = xr.open_datatree(\n    cloud_storage,     # the cloud storage url from the Item we are interested in\n    engine=\"zarr\",\n    chunks=\"auto\"      # automatically determine chunk sizes using dask\n)\n\nfor dt_group in sorted(dt.groups):\n    print(\"DataTree group {group_name}\".format(group_name=dt_group)) # getting the available groups\n\nDataTree group /\nDataTree group /conditions\nDataTree group /conditions/geometry\nDataTree group /conditions/mask\nDataTree group /conditions/mask/detector_footprint\nDataTree group /conditions/mask/detector_footprint/r10m\nDataTree group /conditions/mask/detector_footprint/r20m\nDataTree group /conditions/mask/detector_footprint/r60m\nDataTree group /conditions/mask/l1c_classification\nDataTree group /conditions/mask/l1c_classification/r60m\nDataTree group /conditions/mask/l2a_classification\nDataTree group /conditions/mask/l2a_classification/r20m\nDataTree group /conditions/mask/l2a_classification/r60m\nDataTree group /conditions/meteorology\nDataTree group /conditions/meteorology/cams\nDataTree group /conditions/meteorology/ecmwf\nDataTree group /measurements\nDataTree group /measurements/reflectance\nDataTree group /measurements/reflectance/r10m\nDataTree group /measurements/reflectance/r20m\nDataTree group /measurements/reflectance/r60m\nDataTree group /quality\nDataTree group /quality/atmosphere\nDataTree group /quality/atmosphere/r10m\nDataTree group /quality/atmosphere/r20m\nDataTree group /quality/atmosphere/r60m\nDataTree group /quality/l2a_quicklook\nDataTree group /quality/l2a_quicklook/r10m\nDataTree group /quality/l2a_quicklook/r20m\nDataTree group /quality/l2a_quicklook/r60m\nDataTree group /quality/mask\nDataTree group /quality/mask/r10m\nDataTree group /quality/mask/r20m\nDataTree group /quality/mask/r60m\nDataTree group /quality/probability\nDataTree group /quality/probability/r20m",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#root-dataset-metadata",
    "href": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#root-dataset-metadata",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Root Dataset Metadata",
    "text": "Root Dataset Metadata\nWe specifically look for groups containing data variables under /measurements/reflectance/r20m (which corresponds to Sentinel-2 bands at 20m resolution). The output provides key information about the selected group, including its dimensions, available data variables (the different spectral bands), and coordinates.\n\n# Get /measurements/reflectance/r20m group\ngroups = list(dt.groups)\ninteresting_groups = [\n    group for group in groups if group.startswith('/measurements/reflectance/r20m')\n    and dt[group].ds.data_vars\n]\nprint(f\"\\nüîç Searching for groups with data variables in '/measurements/reflectance/r20m'...\")\n\n\nüîç Searching for groups with data variables in '/measurements/reflectance/r20m'...\n\n\n\nif interesting_groups:\n    sample_group = interesting_groups[0]\n    group_ds = dt[sample_group].ds\n    \n    print(f\"Group '{sample_group}' Information\")\n    print(\"=\" * 50)\n    print(f\"Dimensions: {dict(group_ds.dims)}\")\n    print(f\"Data Variables: {list(group_ds.data_vars.keys())}\")\n    print(f\"Coordinates: {list(group_ds.coords.keys())}\")\n\nelse:\n    print(\"No groups with data variables found in the first 5 groups.\")\n\nGroup '/measurements/reflectance/r20m' Information\n==================================================\nDimensions: {'y': 5490, 'x': 5490}\nData Variables: ['b01', 'b02', 'b03', 'b04', 'b05', 'b06', 'b07', 'b11', 'b12', 'b8a']\nCoordinates: ['x', 'y']\n\n\nIn a next step, we inspect the attributes of the root dataset within the DataTree. Attributes often contain important high-level metadata about the entire product, such as processing details, STAC discovery information, and more. We print the first few attributes to get an idea of the available metadata.\n\n# Examine the root dataset\nroot_dataset = dt.ds\n\nprint(\"Root Dataset Metadata\")\n\nif root_dataset.attrs:\n    print(f\"\\nAttributes (first 3):\")\n    for key, value in list(root_dataset.attrs.items())[:3]:\n        print(f\"   {key}: {str(value)[:80]}{'...' if len(str(value)) &gt; 80 else ''}\")\n\nRoot Dataset Metadata\n\nAttributes (first 3):\n   other_metadata: {'AOT_retrieval_model': 'SEN2COR_DDV', 'L0_ancillary_data_quality': '4', 'L0_eph...\n   stac_discovery: {'assets': {'analytic': {'eo:bands': [{'center_wavelength': 0.4423, 'common_name...",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#visualising-the-rgb-quicklook-composite",
    "href": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#visualising-the-rgb-quicklook-composite",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Visualising the RGB quicklook composite",
    "text": "Visualising the RGB quicklook composite\nEOPF Zarr Assets include a quick-look RGB composite, which we now want to open and visuliase. We open the Zarr dataset again, but this time, we specifically target the quality/l2a_quicklook/r20m group and its variables.\nThis group typically contains a true colour (RGB) quick-look composite, which is a readily viewable representation of the satellite image.\nWe use xr.open_dataset() and specify the following set of arguments in order to load the quick-look.\n\n## Visualising the RGB quicklook composite:\nds = dt['quality/l2a_quicklook/r20m'].to_dataset()\nds_20_ql= ds['tci']\n\nAs soon as we load the selected group, we can create a simple plot with imshow() to see the quick-look.\n\nds_20_ql.plot.imshow(rgb=\"band\")\nplt.title('RGB Quicklook')\nplt.xlabel('X-coordinate')\nplt.ylabel('Y-coordinate')\nplt.grid(False) # Turn off grid for image plots\nplt.axis('tight') # Ensure axes fit the data tightly\n\n(np.float64(600000.0),\n np.float64(709800.0),\n np.float64(5190240.0),\n np.float64(5300040.0))",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#simple-data-analysis-calculating-ndvi",
    "href": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#simple-data-analysis-calculating-ndvi",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Simple Data Analysis: Calculating NDVI",
    "text": "Simple Data Analysis: Calculating NDVI\nLet us now do a simple analysis with the data from the EOPF Zarr STAC Catalog. Let us calculate the Normalized Difference Vegetation Index (NDVI).\nFirst, we access the /measurements/reflectance/r20m group, as the bands we are interested in are at 20m resolution: the Red (B04) and Near-InfraRed (B08A) bands, which are ones needed for the calculation of the NDVI.\n\n# Visualising the NIR reflectance band and select a subsample region with a specific bounding box and a specific resolution.\nresolution = 2000  # in meters\nred_nir = dt ['/measurements/reflectance/r20m'].to_dataset()\nred_nir.isel(\n    x=slice(\n        red_nir['x'].min().values.flat[0],\n        int(red_nir['x'].min().values.flat[0] + 100000),\n        int(resolution/20),\n    ),\n    y=slice(\n        red_nir['y'].min().values.flat[0],\n        int(red_nir['y'].min().values.flat[0] + 100000),\n        int(resolution/20),\n    )\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 0B\nDimensions:  (y: 0, x: 0)\nCoordinates:\n  * y        (y) int64 0B \n  * x        (x) int64 0B \nData variables:\n    b01      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b02      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b03      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b04      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b05      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b06      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b07      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b11      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b12      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;\n    b8a      (y, x) float64 0B dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;xarray.DatasetDimensions:y: 0x: 0Coordinates: (2)y(y)int64array([], dtype=int64)x(x)int64array([], dtype=int64)Data variables: (10)b01(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b01 442.3 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b01 442.3 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb02(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b02 492.3 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b02 492.3 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb03(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b03 559.0 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b03 559.0 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb04(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b04 665.0 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b04 665.0 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb05(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b05 703.8 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b05 703.8 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb06(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b06 739.1 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b06 739.1 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb07(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b07 779.7 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b07 779.7 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb11(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b11 1610.4 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b11 1610.4 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb12(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b12 2185.7 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b12 2185.7 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nb8a(y, x)float64dask.array&lt;chunksize=(0, 0), meta=np.ndarray&gt;_eopf_attrs :{'add_offset': -0.1, 'coordinates': ['x', 'y'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band b8a 864.0 nm', 'scale_factor': 0.0001, 'units': 'digital_counts'}dtype :&lt;u2fill_value :0long_name :BOA reflectance from MSI acquisition at spectral band b8a 864.0 nmproj:bbox :[600000.0, 5190240.0, 709800.0, 5300040.0]proj:epsg :32632proj:shape :[5490, 5490]proj:transform :[20.0, 0.0, 600000.0, 0.0, -20.0, 5300040.0, 0.0, 0.0, 1.0]proj:wkt2 :PROJCS[\"WGS 84 / UTM zone 32N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32632\"]]units :digital_countsvalid_max :65535valid_min :1\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n0 B\n0 B\n\n\nShape\n(0, 0)\n(0, 0)\n\n\nDask graph\n1 chunks in 3 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\n\n\n\nIn a next step, we cast the red (B04) and Near-Infrared (B08a) arrays. This is important for accurate mathematical operations, which we will conduct in the next cell.\n\nred_f = red_nir['b04']\nnir_f = red_nir['b8a']\n\nNow, we perform the initial steps for NDVI calculation: - sum_bands: Calculates the sum of the Near-Infrared and Red bands. - diff_bands: Calculates the difference between the Near-Infrared and Red bands.\nTo prevent division by zero errors in areas where both red and NIR bands might be zero (e.g., water bodies or clouds), this line replaces any NaN values resulting from division by zero with the 0 value. This ensures a clean and robust NDVI product.\n\nsum_bands = nir_f + red_f\n\nzero_mask = (sum_bands == 0) # to avoid 0 division\nsum_bands_z= sum_bands.copy()\nsum_bands_z = da.where(sum_bands_z == 0, 1, sum_bands_z)\n\ndiff_bands = nir_f - red_f\n\nndvi = da.where(sum_bands == 0, 0, diff_bands / sum_bands_z)\n\nIn a final step, we can visualise the calculated NDVI.\n\nplt.imshow(ndvi,cmap='RdYlGn', vmin=-1, vmax=1)\nplt.title('Normalized Difference Vegetation Index (NDVI)')\nplt.xlabel('X-coordinate')\nplt.ylabel('Y-coordinate')\nplt.grid(False) # Turn off grid for image plots\nplt.axis('tight') # Ensure axes fit the data tightly\n\n# Display the plot\nplt.show()",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#now-it-is-your-turn",
    "href": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#now-it-is-your-turn",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nWith the foundations learned so far, you are now equipped to access products from the EOPF Zarr STAC catalog. These are your tasks:\n\nTask 1: Explore five additional Sentinel-2 Items for Innsbruck\nReplicate the RGB quick-look and have an overview of the spatial changes.\n\n\nTask 2: Calculate NDVI\nReplicate the NDVI calculation for the additional Innsbruck items.\n\n\nTask 3: Applying more advanced analysis techniques\nThe EOPF STAC Catalog offers a wealth of data beyond Sentinel-2. Replicate the search and data access for data from other collections.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#conclusion",
    "href": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#conclusion",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "Conclusion",
    "text": "Conclusion\nIn this section we established a connection to the EOPF Sentinel Zarr Sample Service STAC Catalog and directly accessed an EOPF Zarr item with xarray. In the tutorial you are guided through the process of opening hierarchical EOPF Zarr products using xarray‚Äôs DataTree, a library designed for accessing complex hierarchical data structures.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#whats-next",
    "href": "04_eopf_and_stac/44_eopf_stac_xarray_tutorial.html#whats-next",
    "title": "From STAC to Data: Accessing EOPF Zarr with xarray",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following chapter we will present several tools, that will allow us to integrate the available Sentinel Products in the EOPF Sentinel Zarr Sample Service STAC Catalog to EO workflows developed through tools like R and Qgis.",
    "crumbs": [
      "**EOPF and STAC**",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>From STAC to Data: Accessing EOPF Zarr with xarray</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/51_eopf_stac_r.html",
    "href": "05_zarr_tools/51_eopf_stac_r.html",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nIn this section, we will explore programmatic access of the EOPF Zarr Collections available in the EOPF Sentinel Zarr Sample Service STAC Catalog using R. We will introduce R packages that enable us to effectively access and search through STAC catalogs.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/51_eopf_stac_r.html#connect-to-the-eopf-sample-service-stac-api",
    "href": "05_zarr_tools/51_eopf_stac_r.html#connect-to-the-eopf-sample-service-stac-api",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "Connect to the EOPF Sample Service STAC API",
    "text": "Connect to the EOPF Sample Service STAC API\nTo access the EOPF Sample Service STAC catalog in R, we need to give the URL of the STAC API source (https://stac.core.eopf.eodc.eu/) using the function stac().\nThe object stac_source is a query containing information used to connect to the API, but it does not actually make any requests. To make requests to the API, we will always need to use get_request() or put_request(), as appropriate. Running get_request() on stac_source actually retrieves the catalogue:\n\nstac_source &lt;- stac(\"https://stac.core.eopf.eodc.eu/\")\n\nstac_source |&gt;\n  get_request()\n\n###Catalog\n- id: eopf-sample-service-stac-api\n- description: STAC catalog of the EOPF Sentinel Zarr Samples Service\n- field(s): \ntype, id, title, description, stac_version, conformsTo, links, stac_extensions",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/51_eopf_stac_r.html#browse-collections",
    "href": "05_zarr_tools/51_eopf_stac_r.html#browse-collections",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "Browse collections",
    "text": "Browse collections\nA STAC Collection exists to relate similar data sets together through space, time, and shared metadata. Each Sentinel mission and the downstream analysis-ready data are examples of STAC Collections. To browse STAC Collections, the collections() function is used. We can see that there are 12 collections available in the API:\n\nstac_collections &lt;- stac_source |&gt;\n  collections() |&gt;\n  get_request()\n\nstac_collections\n\n###Collections\n- collections (12 item(s)):\n  - sentinel-2-l2a\n  - sentinel-1-l1-grd\n  - sentinel-3-slstr-l1-rbt\n  - sentinel-3-olci-l2-lfr\n  - sentinel-3-slstr-l2-lst\n  - sentinel-3-slstr-l2-frp\n  - sentinel-3-olci-l2-lrr\n  - sentinel-3-olci-l1-efr\n  - sentinel-2-l1c\n  - sentinel-1-l1-slc\n  - sentinel-3-olci-l1-err\n  - sentinel-1-l2-ocn\n- field(s): collections, links, numberMatched, numberReturned\n\n\nThe default printing of the stac_collections() object summarises what‚Äôs been returned, but does not give all of the information. To see more about what‚Äôs been returned, we use str().\n\nstac_collections |&gt;\n  str(max.level = 1)\n\nList of 4\n $ collections   :List of 12\n $ links         :List of 3\n  ..- attr(*, \"class\")= chr [1:2] \"doc_links\" \"list\"\n $ numberMatched : int 12\n $ numberReturned: int 12\n - attr(*, \"class\")= chr [1:3] \"doc_collections\" \"rstac_doc\" \"list\"\n\n\nHere, we can see that there is an entry \"collections\" within stac_collections, which we access to return the collections themselves (using head() to only return a few). This shows additional details about each collection, such as the collection id, title, description, and additional fields in the collections.\n\nstac_collections[[\"collections\"]] |&gt;\n  head(3)\n\n[[1]]\n###Collection\n- id: sentinel-2-l2a\n- title: Sentinel-2 Level-2A\n- description: \nThe Sentinel-2 Level-2A Collection 1 product provides orthorectified Surface Reflectance (Bottom-Of-Atmosphere: BOA), with sub-pixel multispectral and multitemporal registration accuracy. Scene Classification (including Clouds and Cloud Shadows), AOT (Aerosol Optical Thickness) and WV (Water Vapour) maps are included in the product.\n- field(s): \nid, type, links, title, assets, extent, license, keywords, providers, summaries, description, item_assets, stac_version, stac_extensions\n\n[[2]]\n###Collection\n- id: sentinel-1-l1-grd\n- title: Sentinel-1 Level-1 GRD\n- description: \nThe Sentinel-1 Level-1 Ground Range Detected (GRD) products consist of focused SAR data that has been detected, multi-looked and projected to ground range using the Earth ellipsoid model WGS84. The ellipsoid projection of the GRD products is corrected using the terrain height specified in the product general annotation. The terrain height used varies in azimuth and it is constant in range (For IW/EW modes only the terrain height of first subswath is considered)\n- field(s): \nid, type, links, title, assets, extent, license, keywords, providers, summaries, description, item_assets, stac_version, stac_extensions\n\n[[3]]\n###Collection\n- id: sentinel-3-slstr-l1-rbt\n- title: Sentinel-3 SLSTR Level-1 RBT\n- description: \nThe Sentinel-3 SLSTR Level-1B RBT product provides radiances and brightness temperatures for each pixel in a regular image grid for each view and SLSTR channel. In addition, it also contains annotations data associated with each image pixels.\n- field(s): \nid, type, links, title, assets, extent, license, keywords, providers, summaries, description, item_assets, stac_version, stac_extensions\n\n\nThe Sentinel-2 Level-2A collection can be accessed by getting the first entry in stac_collections()[[\"collections\"]]\n\nstac_collections[[\"collections\"]][[1]]\n\n###Collection\n- id: sentinel-2-l2a\n- title: Sentinel-2 Level-2A\n- description: \nThe Sentinel-2 Level-2A Collection 1 product provides orthorectified Surface Reflectance (Bottom-Of-Atmosphere: BOA), with sub-pixel multispectral and multitemporal registration accuracy. Scene Classification (including Clouds and Cloud Shadows), AOT (Aerosol Optical Thickness) and WV (Water Vapour) maps are included in the product.\n- field(s): \nid, type, links, title, assets, extent, license, keywords, providers, summaries, description, item_assets, stac_version, stac_extensions\n\n\nHowever, the best way to access a specific collection is to search for it directly using the collection ID. The ID, ‚Äúsentinel-2-l2a‚Äù, is visible in the Collection output above. It is also accessible in the browsable STAC catalog of the EOPF Sentinel Zarr Samples Service, on the page for that collection, under ‚ÄúSource.‚Äù\n\nThe collection ID can be supplied directly in the collections() function. If we look at the query without getting the result, we can see that it has been formed using the collection_id, ‚Äúsentinel-2-l2a‚Äù, as a filter parameter.\n\nsentinel_2_l2a_query &lt;- stac_source |&gt;\n  collections(collection_id = \"sentinel-2-l2a\")\n\nsentinel_2_l2a_query\n\n###rstac_query\n- url: https://stac.core.eopf.eodc.eu/\n- params:\n  - collection_id: sentinel-2-l2a\n- field(s): version, base_url, endpoint, params, verb, encode\n\n\nAnd that running get_request() will return the collection itself:\n\nsentinel_2_l2a_query |&gt;\n  get_request()\n\n###Collection\n- id: sentinel-2-l2a\n- title: Sentinel-2 Level-2A\n- description: \nThe Sentinel-2 Level-2A Collection 1 product provides orthorectified Surface Reflectance (Bottom-Of-Atmosphere: BOA), with sub-pixel multispectral and multitemporal registration accuracy. Scene Classification (including Clouds and Cloud Shadows), AOT (Aerosol Optical Thickness) and WV (Water Vapour) maps are included in the product.\n- field(s): \nid, type, links, title, assets, extent, license, keywords, providers, summaries, description, item_assets, stac_version, stac_extensions",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/51_eopf_stac_r.html#browse-items",
    "href": "05_zarr_tools/51_eopf_stac_r.html#browse-items",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "Browse items",
    "text": "Browse items\nWithin collections, there are items. Items are the building blocks for STAC. At their core, they are GeoJSON data, along with additional metadata which ensures data provenance is maintained and specific data attributes are captured. A single capture from a Sentinel mission is an example of a STAC item. To get an overview of items within a collection, the items() function is used.\nAn important thing to note with rstac is that you cannot continue to build queries on top of ones that have already had their results returned (via get_request()). It may make sense for a typical workflow in R to ‚Äúget‚Äù the collection, then to try to get the items from it, but this will produce an error:\n\n# sentinel_2_l2a_collection &lt;- stac_source |&gt;\n#   collections(collection_id = \"sentinel-2-l2a\") |&gt;\n#   get_request()\n# \n# sentinel_2_l2a_collection |&gt;\n#   items()\n\nError: Invalid rstac_query value.\nIf you see this error ‚Äî \"Invalid rstac_query value\" ‚Äî ensure that you are running get_request() at the very end of your query building functions. Using items() this way, we can see that it returns a summary of the collection‚Äôs items:\n\nsentinel_2_l2a_collection_items &lt;- stac_source |&gt;\n  collections(collection_id = \"sentinel-2-l2a\") |&gt;\n  items() |&gt;\n  get_request()\n\nsentinel_2_l2a_collection_items\n\n###Items\n- features (10 item(s)):\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UFA_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UEC_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UEB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UEA_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UDC_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UDB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UDA_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UCB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UCA_20260212T104509\n- assets: \nAOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m, zipped_product\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nThe first 10 items are returned. This number can be changed via the limit argument in items()\n\nstac_source |&gt;\n  collections(collection_id = \"sentinel-2-l2a\") |&gt;\n  items(limit = 20) |&gt;\n  get_request()\n\n###Items\n- features (20 item(s)):\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UFA_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UEC_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UEB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UEA_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UDC_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UDB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UDA_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UCB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UCA_20260212T104509\n  - ... with 10 more feature(s).\n- assets: \nAOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m, zipped_product\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\n\nItem properties\nWe can look closer at individual items to see the metadata attached to them. Items are stored under \"features\":\n\nsentinel_2_l2a_collection_items[[\"features\"]] |&gt;\n  head(2)\n\n[[1]]\n###Item\n- id: S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509\n- collection: sentinel-2-l2a\n- bbox: xmin: 22.40872, ymin: 50.43472, xmax: 23.75129, ymax: 51.21636\n- datetime: 2026-02-12T09:46:41.024000Z\n- assets: \nSR_10m, SR_20m, SR_60m, AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, SCL_20m, TCI_10m, WVP_10m, product, zipped_product, product_metadata\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n[[2]]\n###Item\n- id: S2A_MSIL2A_20260212T094641_N0512_R036_T34UFA_20260212T104509\n- collection: sentinel-2-l2a\n- bbox: xmin: 22.39259, ymin: 49.72290, xmax: 23.54807, ymax: 50.54374\n- datetime: 2026-02-12T09:46:41.024000Z\n- assets: \nSR_10m, SR_20m, SR_60m, AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, SCL_20m, TCI_10m, WVP_10m, product, zipped_product, product_metadata\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nAnd an individual item contains a lot of information, such as its bounding box:\n\nsentinel_2_l2a_first_item &lt;- sentinel_2_l2a_collection_items[[\"features\"]][[1]]\n\nsentinel_2_l2a_first_item[[\"bbox\"]]\n\n[1] 22.40872 50.43472 23.75129 51.21636\n\n\nAnd many more additional properties, with their properties under \"properties\" in an individual item.\n\nsentinel_2_l2a_first_item[[\"properties\"]] |&gt;\n  names()\n\n [1] \"gsd\"                                  \n [2] \"created\"                              \n [3] \"mission\"                              \n [4] \"sci:doi\"                              \n [5] \"updated\"                              \n [6] \"datetime\"                             \n [7] \"platform\"                             \n [8] \"grid:code\"                            \n [9] \"proj:bbox\"                            \n[10] \"proj:code\"                            \n[11] \"providers\"                            \n[12] \"published\"                            \n[13] \"deprecated\"                           \n[14] \"instruments\"                          \n[15] \"end_datetime\"                         \n[16] \"product:type\"                         \n[17] \"constellation\"                        \n[18] \"eo:snow_cover\"                        \n[19] \"mgrs:utm_zone\"                        \n[20] \"proj:centroid\"                        \n[21] \"eo:cloud_cover\"                       \n[22] \"start_datetime\"                       \n[23] \"sat:orbit_state\"                      \n[24] \"eopf:datatake_id\"                     \n[25] \"mgrs:grid_square\"                     \n[26] \"processing:level\"                     \n[27] \"view:sun_azimuth\"                     \n[28] \"eopf:datastrip_id\"                    \n[29] \"mgrs:latitude_band\"                   \n[30] \"processing:lineage\"                   \n[31] \"processing:version\"                   \n[32] \"product:timeliness\"                   \n[33] \"sat:absolute_orbit\"                   \n[34] \"sat:relative_orbit\"                   \n[35] \"view:sun_elevation\"                   \n[36] \"processing:facility\"                  \n[37] \"processing:software\"                  \n[38] \"eopf:instrument_mode\"                 \n[39] \"product:timeliness_category\"          \n[40] \"sat:platform_international_designator\"\n\n\nFor example, the EOPF instrument mode:\n\nsentinel_2_l2a_first_item[[\"properties\"]][[\"eopf:instrument_mode\"]]\n\n[1] \"INS-NOBS\"\n\n\nFor the rest of the tutorial, we will use a small helper function that accesses a given property for the first item returned in a search.\n\nget_first_item_property &lt;- function(search_results, property) {\n  search_results[[\"features\"]][[1]][[\"properties\"]][[property]]\n}\n\nsentinel_2_l2a_collection_items |&gt;\n  get_first_item_property(\"eopf:instrument_mode\")\n\n[1] \"INS-NOBS\"\n\n\n\n\nSearch for items\nIf the goal is to access data from a specific mission, it is best to search within a collection‚Äôs items, using some of the properties explored above. It‚Äôs possible to search based on a number of criteria, including a bounding box, time frame, and other mission properties.\n\nSearch by a bounding box\nTo narrow down items based on a bounding box or time frame, the stac_search() function is used. The collection ID is provided in the collections() argument, and bounding box and time frame are bbox and datetime, respectively.\nThe bounding box values take the sequence of: minimum longitude, minimum latitude, maximum longitude, and maximum latitude, and their coordinate reference system is WGS84. For items whose bounding boxes intersect with Vienna:\n\nstac_source |&gt;\n  stac_search(\n    collections = \"sentinel-2-l2a\",\n    bbox = c(16.1736, 48.1157, 16.5897, 48.3254)\n  ) |&gt;\n  get_request()\n\n###Items\n- features (10 item(s)):\n  - S2C_MSIL2A_20260210T095141_N0512_R079_T33UXP_20260210T132914\n  - S2C_MSIL2A_20260210T095141_N0512_R079_T33UWP_20260210T132914\n  - S2B_MSIL2A_20260208T100049_N0512_R122_T33UXP_20260208T134756\n  - S2B_MSIL2A_20260208T100049_N0512_R122_T33UWP_20260208T134756\n  - S2B_MSIL2A_20260205T095109_N0512_R079_T33UXP_20260205T152522\n  - S2B_MSIL2A_20260205T095109_N0512_R079_T33UWP_20260205T152522\n  - S2C_MSIL2A_20260203T100221_N0511_R122_T33UXP_20260203T132812\n  - S2C_MSIL2A_20260203T100221_N0511_R122_T33UWP_20260203T132812\n  - S2C_MSIL2A_20260131T095231_N0511_R079_T33UXP_20260131T135211\n  - S2C_MSIL2A_20260131T095231_N0511_R079_T33UWP_20260131T135211\n- assets: \nAOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m, zipped_product\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nThis does ‚Äì again by default ‚Äì return the first 10 items, but the number returned can be increased via the limit argument in stac_search().\n\n\nSearch by a time frame\nWhen searching for a specific time frame, items that have a datetime property that intersects with the given time frame will be returned. It‚Äôs therefore best to search for a closed or open interval, rather than a specific date and time (which might be difficult to match exactly to an item‚Äôs time!). The date-time must be given in RFC 3339 format.\nTo search for a closed interval, separate two date-times by a ‚Äú/‚Äù, e.g.¬†\"2024-12-01T01:00:00Z/2024-12-01T05:00:00Z\":\n\nmatching_timeframe_items &lt;- stac_source |&gt;\n  stac_search(\n    collections = \"sentinel-2-l2a\",\n    datetime = \"2024-12-01T01:00:00Z/2024-12-01T05:00:00Z\"\n  ) |&gt;\n  get_request()\n\nmatching_timeframe_items\n\n###Items\n- features (10 item(s)):\n  - S2A_MSIL2A_20241201T045911_N0511_R133_T44HKD_20241201T065447\n  - S2A_MSIL2A_20241201T045911_N0511_R133_T44HKC_20241201T065447\n  - S2A_MSIL2A_20241201T045911_N0511_R133_T43HGU_20241201T065447\n  - S2A_MSIL2A_20241201T045911_N0511_R133_T43HGT_20241201T065447\n  - S2A_MSIL2A_20241201T045911_N0511_R133_T43HGS_20241201T065447\n  - S2A_MSIL2A_20241201T045911_N0511_R133_T43HFU_20241201T065447\n  - S2A_MSIL2A_20241201T045911_N0511_R133_T43HFT_20241201T065447\n  - S2A_MSIL2A_20241201T045911_N0511_R133_T43HFS_20241201T065447\n  - S2A_MSIL2A_20241201T045911_N0511_R133_T43HEV_20241201T065447\n  - S2A_MSIL2A_20241201T045911_N0511_R133_T43HEU_20241201T065447\n- assets: \nAOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nWe can access the matching item‚Äôs datetime property to see that it falls within the specified interval:\n\nmatching_timeframe_items |&gt;\n  get_first_item_property(\"datetime\")\n\n[1] \"2024-12-01T04:59:11.024000Z\"\n\n\nTo search by an open interval, ‚Äú..‚Äù is used to indicate the open end, e.g.¬†\"../2024-01-01T23:00:00Z\" representing prior to that date-time, and \"2024-01-01T23:00:00Z/..\" representing after it:\n\nstac_source |&gt;\n  stac_search(\n    collections = \"sentinel-2-l2a\",\n    datetime = \"2025-01-01T23:00:00Z/..\"\n  ) |&gt;\n  get_request()\n\n###Items\n- features (10 item(s)):\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UFA_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UEC_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UEB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UEA_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UDC_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UDB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UDA_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UCB_20260212T104509\n  - S2A_MSIL2A_20260212T094641_N0512_R036_T34UCA_20260212T104509\n- assets: \nAOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m, zipped_product\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\n\n\nSearch by other item properties\nAs shown above, there are a number of other properties attached to STAC items. We can also search using these properties. The stac_search() function is limited to properties like bounding box and time frame, so instead we use ext_filter(). This is a function that makes use of the Common Query Language (CQL2) filter extension, and allows us to do more complicated searching and querying using SQL-like language. It is also important to note that when using ext_filter(), we switch to using post_request() instead of get_request().\nFor this searching, it is helpful to know the data type for an item property in advance, as this will impact what operation to use within ext_filter(). We create an additional helper function for this:\n\nget_item_property_type &lt;- function(property = NULL) {\n  api_res &lt;- rstac:::make_get_request(\"https://stac.core.eopf.eodc.eu/api\") |&gt;\n    rstac:::content_response_json()\n  item_properties_schema &lt;- api_res[[\"components\"]][[\"schemas\"]][[\"ItemProperties\"]][[\"properties\"]]\n\n  property_types &lt;- lapply(item_properties_schema, function(x) {\n    x[[\"anyOf\"]][[1]][[\"type\"]]\n  })\n\n  if (is.null(property)) {\n    property_types\n  } else {\n    property_types[[property]]\n  }\n}\n\nWhen no argument is passed to this function, it will return all of the properties and their types:\n\nget_item_property_type()\n\n$title\n[1] \"string\"\n\n$description\n[1] \"string\"\n\n$datetime\n[1] \"string\"\n\n$created\n[1] \"string\"\n\n$updated\n[1] \"string\"\n\n$start_datetime\n[1] \"string\"\n\n$end_datetime\n[1] \"string\"\n\n$license\n[1] \"string\"\n\n$providers\n[1] \"array\"\n\n$platform\n[1] \"string\"\n\n$instruments\n[1] \"array\"\n\n$constellation\n[1] \"string\"\n\n$mission\n[1] \"string\"\n\n$gsd\n[1] \"number\"\n\n\nWhen the name of a property is passed, it will return the type of that property. We can see, for example, that platform is a string, while instruments is an array.\n\nget_item_property_type(\"platform\")\n\n[1] \"string\"\n\nget_item_property_type(\"instruments\")\n\n[1] \"array\"\n\n\nSince platform is a string, we use == to indicate equality. For example, to search for items whose platform is ‚Äúsentinel-2b‚Äù:\n\nsentinel_2b_platform_results &lt;- stac_source |&gt;\n  stac_search(collections = \"sentinel-2-l2a\") |&gt;\n  ext_filter(platform == \"sentinel-2b\") |&gt;\n  post_request()\n\nsentinel_2b_platform_results\n\n###Items\n- features (10 item(s)):\n  - S2B_MSIL2A_20260212T094029_N0512_R036_T37WEU_20260212T115326\n  - S2B_MSIL2A_20260212T094029_N0512_R036_T37WET_20260212T115326\n  - S2B_MSIL2A_20260212T094029_N0512_R036_T37WES_20260212T115326\n  - S2B_MSIL2A_20260212T094029_N0512_R036_T37WDU_20260212T115326\n  - S2B_MSIL2A_20260212T094029_N0512_R036_T37WDT_20260212T115326\n  - S2B_MSIL2A_20260212T094029_N0512_R036_T37WDS_20260212T115326\n  - S2B_MSIL2A_20260212T094029_N0512_R036_T37WDR_20260212T115326\n  - S2B_MSIL2A_20260212T094029_N0512_R036_T37WDQ_20260212T115326\n  - S2B_MSIL2A_20260212T094029_N0512_R036_T37WCV_20260212T115326\n  - S2B_MSIL2A_20260212T094029_N0512_R036_T36WXV_20260212T115326\n- assets: \nAOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m, zipped_product\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\nsentinel_2b_platform_results |&gt;\n  get_first_item_property(\"platform\")\n\n[1] \"sentinel-2b\"\n\n\nIf the search value is contained in another variable, the variable must be escaped in the search by using double curly braces:\n\nsearch_platform &lt;- \"sentinel-2b\"\n\nsentinel_2b_platform_results &lt;- stac_source |&gt;\n  stac_search(collections = \"sentinel-2-l2a\") |&gt;\n  ext_filter(platform == {{ search_platform }}) |&gt;\n  post_request()\n\nsentinel_2b_platform_results |&gt;\n  get_first_item_property(\"platform\")\n\n[1] \"sentinel-2b\"\n\n\nNote also that there is no limit argument in ext_filter(). To limit the number of items returned, the limit is supplied in stac_search() beforehand, since these search functions build upon one another:\n\nstac_source |&gt;\n  stac_search(collections = \"sentinel-2-l2a\", limit = 1) |&gt;\n  ext_filter(platform == {{ search_platform }}) |&gt;\n  post_request()\n\n###Items\n- features (1 item(s)):\n  - S2B_MSIL2A_20260212T094029_N0512_R036_T37WEU_20260212T115326\n- assets: \nAOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, product, product_metadata, SCL_20m, SR_10m, SR_20m, SR_60m, TCI_10m, WVP_10m, zipped_product\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nTo search for items with cloud cover of less than 40, we use &lt;=:\n\nstac_source |&gt;\n  stac_search(collections = \"sentinel-2-l2a\") |&gt;\n  ext_filter(`eo:cloud_cover` &lt;= 40) |&gt;\n  post_request() |&gt;\n  get_first_item_property(\"eo:cloud_cover\")\n\n[1] 36.98742\n\n\nIf we want to search for items where instruments is ‚Äúmsi‚Äù, we use the a_contains() function. We need to use this instead of == because instruments is an array, as seen above. This means it operates like a list within R, and can contain multiple values ‚Äì a_contains() searches for the value \"msi\" within the list of values that is instruments.\n\nstac_source |&gt;\n  stac_search(collections = \"sentinel-2-l2a\") |&gt;\n  ext_filter(a_contains(instruments, \"msi\")) |&gt;\n  post_request() |&gt;\n  get_first_item_property(\"instruments\")\n\n[1] \"msi\"\n\n\nNote that there is currently a bug with how the rstac package converts the API‚Äôs data to an R object. This bug makes it unclear that instruments is a list that needs to be searched within (instead of a single value). There is an issue to fix this bug in the rstac github repository. We hope that the helper function get_item_property_type() will be helpful in the meantime to determine which filtering operation to use.\nThe documentation for ext_filter() contains information on how to construct many more searches than we‚Äôve shown here.\n\n\nCombine search criteria\nYou can combine multiple filter criteria by specifying them together. We have already seen how to combine multiple criteria (collection ID and bounding box, for example) in stac_search() by using the named arguments. We can also filter by bounding box and datetime in the same way. Multiple criteria in ext_filter() are separated by &&:\n\nmultiple_criteria_items &lt;- stac_source |&gt;\n  stac_search(\n    collections = \"sentinel-2-l2a\",\n    bbox = c(16.1736, 48.1157, 16.5897, 48.3254),\n    datetime = \"../2025-06-01T23:00:00Z\"\n  ) |&gt;\n  ext_filter(\n    platform == \"sentinel-2a\" &&\n      `eo:cloud_cover` &lt;= 40\n  ) |&gt;\n  post_request()\n\nmultiple_criteria_items |&gt;\n  get_first_item_property(\"datetime\")\n\n[1] \"2025-05-31T10:00:51.024000Z\"\n\nmultiple_criteria_items |&gt;\n  get_first_item_property(\"platform\")\n\n[1] \"sentinel-2a\"\n\nmultiple_criteria_items |&gt;\n  get_first_item_property(\"eo:cloud_cover\")\n\n[1] 8.41613",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/51_eopf_stac_r.html#browse-assets",
    "href": "05_zarr_tools/51_eopf_stac_r.html#browse-assets",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "Browse assets",
    "text": "Browse assets\nFinally, assets fall under STAC items and direct users to the actual data itself. Each asset refers to data associated with the Item that can be downloaded or streamed.\nWe will look at the assets for a specific item from the Sentinel-2 Level-2A collection. Like collections, items can be filtered by their IDs. Their IDs are also available through the API:\n\nsentinel_2_l2a_collection_items[[\"features\"]][[1]]\n\n###Item\n- id: S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509\n- collection: sentinel-2-l2a\n- bbox: xmin: 22.40872, ymin: 50.43472, xmax: 23.75129, ymax: 51.21636\n- datetime: 2026-02-12T09:46:41.024000Z\n- assets: \nSR_10m, SR_20m, SR_60m, AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, SCL_20m, TCI_10m, WVP_10m, product, zipped_product, product_metadata\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nOr through the STAC catalog of the EOPF Sentinel Zarr Samples Service, on the page for that item, under ‚ÄúSource‚Äù:\n\nTo select a single item, supply its ID in the items() function:\n\nexample_item &lt;- stac_source |&gt;\n  collections(\"sentinel-2-l2a\") |&gt;\n  items(sentinel_2_l2a_collection_items[[\"features\"]][[1]][[\"id\"]]) |&gt;\n  get_request()\n\nexample_item\n\n###Item\n- id: S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509\n- collection: sentinel-2-l2a\n- bbox: xmin: 22.40872, ymin: 50.43472, xmax: 23.75129, ymax: 51.21636\n- datetime: 2026-02-12T09:46:41.024000Z\n- assets: \nSR_10m, SR_20m, SR_60m, AOT_10m, B01_20m, B02_10m, B03_10m, B04_10m, B05_20m, B06_20m, B07_20m, B08_10m, B09_60m, B11_20m, B12_20m, B8A_20m, SCL_20m, TCI_10m, WVP_10m, product, zipped_product, product_metadata\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nThere are a number of helpful functions for working with an item‚Äôs assets, such as items_assets() which lists them:\n\n# List the assets in an item\nexample_item |&gt;\n  items_assets()\n\n [1] \"SR_10m\"           \"SR_20m\"           \"SR_60m\"           \"AOT_10m\"         \n [5] \"B01_20m\"          \"B02_10m\"          \"B03_10m\"          \"B04_10m\"         \n [9] \"B05_20m\"          \"B06_20m\"          \"B07_20m\"          \"B08_10m\"         \n[13] \"B09_60m\"          \"B11_20m\"          \"B12_20m\"          \"B8A_20m\"         \n[17] \"SCL_20m\"          \"TCI_10m\"          \"WVP_10m\"          \"product\"         \n[21] \"zipped_product\"   \"product_metadata\"\n\n\nAnd assets_select() which allows us to select specific assets (in this case, the ‚ÄúSurface Reflectance - 10m‚Äù asset):\n\nsr_10m &lt;- example_item |&gt;\n  assets_select(asset_names = \"SR_10m\")\n\nsr_10m\n\n###Item\n- id: S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509\n- collection: sentinel-2-l2a\n- bbox: xmin: 22.40872, ymin: 50.43472, xmax: 23.75129, ymax: 51.21636\n- datetime: 2026-02-12T09:46:41.024000Z\n- assets: SR_10m\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nFor example, the ‚Äúproduct‚Äù asset will be useful to working with EOPF Sample Service Zarr data, as this is the top-level Zarr hierarchy. We can select this asset, and then use assets_url() to get its URL:\n\nexample_item |&gt;\n  assets_select(asset_names = \"product\") |&gt;\n  assets_url()\n\n[1] \"https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202602-s02msil2a-eu/12/products/cpm_v262/S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509.zarr\"\n\n\nIt is also helpful to know which assets actually contain Zarr data. Assets can be Zarr groups, which share common dimensions and coordinates, and contain Zarr arrays within them. An asset can also be an individual Zarr array.\nTo look more at this, we will extract metadata attached to the Zarr assets. The \"assets\" entry of example_item contains a lot of useful information, but it is a bit difficult to read and manipulate:\n\nnames(example_item[[\"assets\"]])\n\n [1] \"SR_10m\"           \"SR_20m\"           \"SR_60m\"           \"AOT_10m\"         \n [5] \"B01_20m\"          \"B02_10m\"          \"B03_10m\"          \"B04_10m\"         \n [9] \"B05_20m\"          \"B06_20m\"          \"B07_20m\"          \"B08_10m\"         \n[13] \"B09_60m\"          \"B11_20m\"          \"B12_20m\"          \"B8A_20m\"         \n[17] \"SCL_20m\"          \"TCI_10m\"          \"WVP_10m\"          \"product\"         \n[21] \"zipped_product\"   \"product_metadata\"\n\nexample_item[[\"assets\"]][[\"SR_10m\"]]\n\n$gsd\n[1] 10\n\n$href\n[1] \"https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202602-s02msil2a-eu/12/products/cpm_v262/S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509.zarr/measurements/reflectance/r10m\"\n\n$type\n[1] \"application/vnd+zarr\"\n\n$bands\n$bands[[1]]\n$bands[[1]]$name\n[1] \"B02\"\n\n$bands[[1]]$description\n[1] \"Blue (band 2)\"\n\n$bands[[1]]$`eo:common_name`\n[1] \"blue\"\n\n$bands[[1]]$`eo:center_wavelength`\n[1] 0.49\n\n$bands[[1]]$`eo:full_width_half_max`\n[1] 0.098\n\n\n$bands[[2]]\n$bands[[2]]$name\n[1] \"B03\"\n\n$bands[[2]]$description\n[1] \"Green (band 3)\"\n\n$bands[[2]]$`eo:common_name`\n[1] \"green\"\n\n$bands[[2]]$`eo:center_wavelength`\n[1] 0.56\n\n$bands[[2]]$`eo:full_width_half_max`\n[1] 0.045\n\n\n$bands[[3]]\n$bands[[3]]$name\n[1] \"B04\"\n\n$bands[[3]]$description\n[1] \"Red (band 4)\"\n\n$bands[[3]]$`eo:common_name`\n[1] \"red\"\n\n$bands[[3]]$`eo:center_wavelength`\n[1] 0.665\n\n$bands[[3]]$`eo:full_width_half_max`\n[1] 0.038\n\n\n$bands[[4]]\n$bands[[4]]$name\n[1] \"B08\"\n\n$bands[[4]]$description\n[1] \"NIR 1 (band 8)\"\n\n$bands[[4]]$`eo:common_name`\n[1] \"nir\"\n\n$bands[[4]]$`eo:center_wavelength`\n[1] 0.842\n\n$bands[[4]]$`eo:full_width_half_max`\n[1] 0.145\n\n\n\n$roles\n[1] \"data\"        \"reflectance\" \"dataset\"    \n\n$title\n[1] \"Surface Reflectance - 10m\"\n\n$`xarray:open_dataset_kwargs`\n$`xarray:open_dataset_kwargs`$chunks\nnamed list()\n\n$`xarray:open_dataset_kwargs`$engine\n[1] \"eopf-zarr\"\n\n$`xarray:open_dataset_kwargs`$op_mode\n[1] \"native\"\n\n\nSo, we will reformat it to be easier to work with. To do so, we first load the tidyverse package for data manipulation (installing it first, if necessary):\n\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nWe will retain only the title and roles of each asset.\n\nasset_metadata &lt;- example_item[[\"assets\"]] |&gt;\n  map(\\(asset) {\n    asset[c(\"title\", \"roles\")]\n  })\n\nhead(asset_metadata, 5)\n\n$SR_10m\n$SR_10m$title\n[1] \"Surface Reflectance - 10m\"\n\n$SR_10m$roles\n[1] \"data\"        \"reflectance\" \"dataset\"    \n\n\n$SR_20m\n$SR_20m$title\n[1] \"Surface Reflectance - 20m\"\n\n$SR_20m$roles\n[1] \"data\"        \"reflectance\" \"dataset\"    \n\n\n$SR_60m\n$SR_60m$title\n[1] \"Surface Reflectance - 60m\"\n\n$SR_60m$roles\n[1] \"data\"        \"reflectance\" \"dataset\"    \n\n\n$AOT_10m\n$AOT_10m$title\n[1] \"Aerosol optical thickness (AOT)\"\n\n$AOT_10m$roles\n[1] \"data\"\n\n\n$B01_20m\n$B01_20m$title\n[1] \"Coastal aerosol (band 1) - 20m\"\n\n$B01_20m$roles\n[1] \"data\"        \"reflectance\"\n\n\nThen, we can filter to only keep assets who have the roles ‚Äúdataset‚Äù (these are Zarr groups):\n\nasset_metadata |&gt;\n  keep(\\(asset) {\n    \"dataset\" %in% asset[[\"roles\"]]\n  })\n\n$SR_10m\n$SR_10m$title\n[1] \"Surface Reflectance - 10m\"\n\n$SR_10m$roles\n[1] \"data\"        \"reflectance\" \"dataset\"    \n\n\n$SR_20m\n$SR_20m$title\n[1] \"Surface Reflectance - 20m\"\n\n$SR_20m$roles\n[1] \"data\"        \"reflectance\" \"dataset\"    \n\n\n$SR_60m\n$SR_60m$title\n[1] \"Surface Reflectance - 60m\"\n\n$SR_60m$roles\n[1] \"data\"        \"reflectance\" \"dataset\"    \n\n\nOr to those who have roles ‚Äúdata‚Äù, but not ‚Äúdataset‚Äù or ‚Äúmetadata‚Äù (these are individual Zarr arrays):\n\nzarr_arrays &lt;- asset_metadata |&gt;\n  keep(\\(asset) {\n    \"data\" %in% asset[[\"roles\"]] &\n      !(\"dataset\" %in% asset[[\"roles\"]] | \"metadata\" %in% asset[[\"roles\"]])\n  })\n\nnames(zarr_arrays)\n\n [1] \"AOT_10m\" \"B01_20m\" \"B02_10m\" \"B03_10m\" \"B04_10m\" \"B05_20m\" \"B06_20m\"\n [8] \"B07_20m\" \"B08_10m\" \"B09_60m\" \"B11_20m\" \"B12_20m\" \"B8A_20m\" \"SCL_20m\"\n[15] \"TCI_10m\" \"WVP_10m\"\n\nhead(zarr_arrays, 3)\n\n$AOT_10m\n$AOT_10m$title\n[1] \"Aerosol optical thickness (AOT)\"\n\n$AOT_10m$roles\n[1] \"data\"\n\n\n$B01_20m\n$B01_20m$title\n[1] \"Coastal aerosol (band 1) - 20m\"\n\n$B01_20m$roles\n[1] \"data\"        \"reflectance\"\n\n\n$B02_10m\n$B02_10m$title\n[1] \"Blue (band 2) - 10m\"\n\n$B02_10m$roles\n[1] \"data\"        \"reflectance\"",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/51_eopf_stac_r.html#now-it-is-your-turn",
    "href": "05_zarr_tools/51_eopf_stac_r.html#now-it-is-your-turn",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nThe following expercises will help you master the STAC API and understand how to find the data you need.\n\nTask 1: Explore Your Area of Interest\n\nGo to http://bboxfinder.com/ and select an area of interest (AOI) (e.g.¬†your hometown, a research site, etc.)\nCopy the bounding box coordinates of your area of interest\nChange the provided code above to search for data over your AOI\n\n\n\nTask 2: Temporal Analysis\n\nCompare data availability across different years for the Sentinel-2 L-2A Collection.\nSearch for items in the year 2022\nRepeat the search for the year 2024\n\n\n\nTask 3: Explore the SAR Mission and combine multiple criteria\n\nDo the same for a different Collection, the Sentinel-1 Level-1 GRD, e.g.¬†you can use the ID sentinel-1-l1-grd\nHow many assets are available for the year 2024?",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/51_eopf_stac_r.html#conclusion",
    "href": "05_zarr_tools/51_eopf_stac_r.html#conclusion",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial has provided a clear and practical introduction on how you can programmatically access and search through EOPF Sentinel Zarr Sample Service STAC API using R.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/51_eopf_stac_r.html#whats-next",
    "href": "05_zarr_tools/51_eopf_stac_r.html#whats-next",
    "title": "Access the EOPF Zarr STAC API with R",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following section, we will provide a glimpse of the actual status on how to integrate the Sentinel Products of the EOPF Sentinel Zarr Sample Service STAC Catalog in Qgis",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Access the EOPF Zarr STAC API with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/52_eopf_stac_qgis.html",
    "href": "05_zarr_tools/52_eopf_stac_qgis.html",
    "title": "Access EOPF Zarr in QGIS Using STAC",
    "section": "",
    "text": "Introduction\nThe following page will demonstrate how to access the EOPF STAC Catalog in QGIS. We will utilise QGIS‚Äôs native STAC capabilities to add Sentinel-2 L2A Zarr items delivered from EOPF STAC Catalog to a QGIS project.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Access EOPF Zarr in QGIS Using STAC</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/52_eopf_stac_qgis.html#about-stac-in-qgis",
    "href": "05_zarr_tools/52_eopf_stac_qgis.html#about-stac-in-qgis",
    "title": "Access EOPF Zarr in QGIS Using STAC",
    "section": "About STAC in QGIS",
    "text": "About STAC in QGIS\nQGIS users may already be familiar with the STAC API Browser plugin. Since its release in 2022 this plugin provided basic STAC API support. However, since QGIS 3.40 (released October 2024) STAC support has been steadily growing within the QGIS core product. QGIS STAC users are advised to use QGIS core STAC functionality rather than the plugin.\nWhen new to STAC, we suggest having a look at the Introduction to STAC chapter for more information about STAC and its components.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Access EOPF Zarr in QGIS Using STAC</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/52_eopf_stac_qgis.html#add-stac-connection",
    "href": "05_zarr_tools/52_eopf_stac_qgis.html#add-stac-connection",
    "title": "Access EOPF Zarr in QGIS Using STAC",
    "section": "Add STAC Connection",
    "text": "Add STAC Connection\nSTAC access in QGIS is managed with connections, similar to other remote data sources such as WMS, WFS, and ArcGIS REST Servers. A STAC connection can be created by right-clicking on the Browser pane‚Äôs STAC entry.\n\n\n\nSTAC Connection Context Menu\n\n\nTo identify the connection, we suggest providing a suitable name, such as EOPF Sample Service, and https://stac.core.eopf.eodc.eu/ for the service‚Äôs URL. Until now, this service does not require authentication, but we suggest following the ongoing discussions on the EOPF forum to keep track of EOPF‚Äôs STAC Catalog updates.\n\n\n\nEOPF STAC Connection Details",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Access EOPF Zarr in QGIS Using STAC</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/52_eopf_stac_qgis.html#discover-data",
    "href": "05_zarr_tools/52_eopf_stac_qgis.html#discover-data",
    "title": "Access EOPF Zarr in QGIS Using STAC",
    "section": "Discover Data",
    "text": "Discover Data\nOnce connected, we can expand the new connection to explore available STAC collections and STAC items. Each entry provides a tooltip on mouse-over.\nThe Browser pane‚Äôs nested view shows a limited number of STAC items, as they are ordered in the collection. Additional batches of items will be fetched if available when Double-click to fetch more items... is double-clicked. The STAC items can also be filtered in the Data Source Manager, which is discussed further in Data Source Manager, though this is not possible in the Browser pane.\n\n\n\nSTAC Collections and STAC Items",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Access EOPF Zarr in QGIS Using STAC</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/52_eopf_stac_qgis.html#add-data-to-a-project",
    "href": "05_zarr_tools/52_eopf_stac_qgis.html#add-data-to-a-project",
    "title": "Access EOPF Zarr in QGIS Using STAC",
    "section": "Add Data to a Project",
    "text": "Add Data to a Project\nOnce we expand a STAC item in the Browser pane, all assets associated with the item are listed.\nAssets with cloud-optimised data types like Zarr, COG, COPC, etc., can be added as project layers from the Browser pane. These assets‚Äô icons reflect their data type, such as the raster icon . Assets that are not cloud-optimised (GeoJSON, GeoPackage, Shapefile, etc.) must first be downloaded before they can be added as project layers using QGIS‚Äôs standard Layer ‚Üí Add Layer menu. These assets will have a download icon .\n\n\n\n\n\n\nNote\n\n\n\nRemember: Cloud-optimised assets cannot be downloaded.\n\n\nCloud-optimised assets can be dragged from the Browser pane into the Layers pane. STAC items with one or more cloud-optimised assets can also be dragged into the Layers pane, which will add all cloud-optimised assets as layers.\n\n\n\nSTAC Asset Dragged to Layers Pane",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Access EOPF Zarr in QGIS Using STAC</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/52_eopf_stac_qgis.html#correct-spatial-reference",
    "href": "05_zarr_tools/52_eopf_stac_qgis.html#correct-spatial-reference",
    "title": "Access EOPF Zarr in QGIS Using STAC",
    "section": "Correct Spatial Reference",
    "text": "Correct Spatial Reference\nDue to differences in how EOPF, GDAL and QGIS define spatial references in the Zarr format, QGIS is not able to automatically recognise an EOPF Zarr layer‚Äôs spatial reference (CRS). This may be fixed by a future release of either QGIS or by the EOPF Zarr format structure. For now, we can solve this issue by manually correcting the spatial reference.\nEOPF STAC item metadata provides the EPSG code that georeferences all of the item‚Äôs assets. We can access this metadata via the Details entry in the item‚Äôs context menu.\n\n\n\nSTAC Item Context Menu Details\n\n\nThen, we scroll down to the proj:code property and observe the EPSG:-prefixed numeric value.\n\n\n\nSTAC Item Context Menu proj:code\n\n\nAfter closing the Details window, we open one of our Zarr layers‚Äô Properties window, and click on the Source tab. Under Assigned Coordinate Reference System (CRS) we will see ‚Äúinvalid projection‚Äù in the dropdown.\nIf while following these steps, the EPSG code from the STAC item Details window is already assigned, the issue has been resolved and we can skip this step.\n\n\n\nLayer Invalid CRS\n\n\nTo correct the metadata for a smooth integration in QGIS, we can click ‚ÄúSelect CRS‚Äù and type the STAC item‚Äôs EPSG code in the Filter text box. We then select the appropriate CRS entry and apply the change.\n\n\n\nLayer Set CRS",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Access EOPF Zarr in QGIS Using STAC</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/52_eopf_stac_qgis.html#view-data",
    "href": "05_zarr_tools/52_eopf_stac_qgis.html#view-data",
    "title": "Access EOPF Zarr in QGIS Using STAC",
    "section": "View Data",
    "text": "View Data\nAfter correcting any invalid CRS configurations we will safely view EOPF Zarr data alongside other spatially referenced data.\n\n\n\nMultiple Band EOPF Zarr Data Display",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Access EOPF Zarr in QGIS Using STAC</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/52_eopf_stac_qgis.html#data-source-manager",
    "href": "05_zarr_tools/52_eopf_stac_qgis.html#data-source-manager",
    "title": "Access EOPF Zarr in QGIS Using STAC",
    "section": "Data Source Manager",
    "text": "Data Source Manager\nQGIS‚Äôs Data Source Manager can be used instead of the Browser pane to manage STAC connections and discover STAC data.\n\n\n\nQGIS Data Source Manager\n\n\nThe Data Source Manager supports basic filters to refine which STAC items are available for access.\n\n\n\nData Source Manager Filters\n\n\nIn the following example a bounding box filter is applied to items within a single collection. The format of the bounding box needs to follow:\nminimum x (longitude), maximum x, minimum y (latitude), maximum y [EPSG:4326]\nWe can also temporally filter a STAC connection via a calendar-style date picker.\n\n\n\nApplied STAC Item Filters\n\n\nOnce we right-click a search result, we can see the available actions we can follow, which include the Add Layer nested menu. This menu includes all cloud-optimised assets inside the item. Selecting an asset here is equivalent to dragging the asset to the Layers pane as described in the Add Data to a Project section.\n\n\n\nFilter Result Context Menu",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Access EOPF Zarr in QGIS Using STAC</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/52_eopf_stac_qgis.html#now-it-is-your-turn",
    "href": "05_zarr_tools/52_eopf_stac_qgis.html#now-it-is-your-turn",
    "title": "Access EOPF Zarr in QGIS Using STAC",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\n\nTask 1: Discover Additional Layers\n\nAdd a STAC item‚Äôs EOPF Product group asset to a QGIS project from either the Browser pane or the Data Source Manager\nReview the arrays available within this group, noting that many are not published as STAC item assets\nAdd arrays as layers to the QGIS project\n\n\n\nTask 2: Apply Temporal Filters\n\nApply filters in the Data Source Manager STAC tab using the calendar-style date picker\nNote that STAC items are filtered according to their datetime property, whose partial value also appears in the item‚Äôs ID\nAdd layers from a STAC item that was created yesterday",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Access EOPF Zarr in QGIS Using STAC</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/52_eopf_stac_qgis.html#conclusion",
    "href": "05_zarr_tools/52_eopf_stac_qgis.html#conclusion",
    "title": "Access EOPF Zarr in QGIS Using STAC",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial demonstrated how to integrate and visualise EOPF Zarr items in QGIS using STAC. We also offered a work-around to the current CRS issue and explored EOPF Zarr data.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Access EOPF Zarr in QGIS Using STAC</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/52_eopf_stac_qgis.html#whats-next",
    "href": "05_zarr_tools/52_eopf_stac_qgis.html#whats-next",
    "title": "Access EOPF Zarr in QGIS Using STAC",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following notebook we will explore the use of rstac, terra and stars to showcase the calculation of Vegegation Indices with Sentinel-2 L2A Products and R.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Access EOPF Zarr in QGIS Using STAC</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/53_eopf_zarr_r.html",
    "href": "05_zarr_tools/53_eopf_zarr_r.html",
    "title": "Access and analyse EOPF STAC Zarr data with R",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nIn this tutorial, we will demonstrate how to access EOPF Zarr products directly from the EOPF Sentinel Zarr Sample Service STAC Catalog using R. We will introduce R packages that enable us to effectively get an overview of and read Zarr arrays.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Access and analyse EOPF STAC Zarr data with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/53_eopf_zarr_r.html#access-zarr-data-from-the-stac-catalog",
    "href": "05_zarr_tools/53_eopf_zarr_r.html#access-zarr-data-from-the-stac-catalog",
    "title": "Access and analyse EOPF STAC Zarr data with R",
    "section": "Access Zarr data from the STAC Catalog",
    "text": "Access Zarr data from the STAC Catalog\nThe first step of accessing Zarr data is to understand the assets within the EOPF Sample Service STAC catalog. The first tutorial goes into detail on this, so we recommend reviewing it if you have not already.\nFor the first part of this tutorial, we will be using data from the Sentinel-2 Level-2A Collection. We fetch the ‚Äúproduct‚Äù asset under a given item, and can look at its URL:\n\nfirst_item &lt;- stac(\"https://stac.core.eopf.eodc.eu/\") |&gt;\n  collections(collection_id = \"sentinel-2-l2a\") |&gt;\n  items(limit = 1) |&gt;\n  get_request()\n\nfirst_item_id &lt;- first_item[[\"features\"]][[1]][[\"id\"]]\n\ns2_l2a_item &lt;- stac(\"https://stac.core.eopf.eodc.eu/\") |&gt;\n  collections(collection_id = \"sentinel-2-l2a\") |&gt;\n  items(feature_id = first_item_id) |&gt;\n  get_request()\n\ns2_l2a_product &lt;- s2_l2a_item |&gt;\n  assets_select(asset_names = \"product\")\n\ns2_l2a_product_url &lt;- s2_l2a_product |&gt;\n  assets_url()\n\ns2_l2a_product_url\n\n[1] \"https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202602-s02msil2a-eu/12/products/cpm_v262/S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509.zarr\"\n\n\nThe product is the ‚Äútop level‚Äù Zarr asset, which contains the full Zarr product hierarchy. We can use zarr_overview() to get an overview of it, setting as_data_frame to TRUE so that we can see the entries in a data frame instead of printed directly to the console. Each entry is a Zarr array; we remove product_url from the path to get a better idea of what each array is. Since this is something we will want to do multiple times throughout the tutorial, we create a helper function for this.\n\nderive_store_array &lt;- function(store, product_url) {\n  store |&gt;\n    mutate(array = str_remove(path, product_url)) |&gt;\n    relocate(array, .before = path)\n}\n\nzarr_store &lt;- s2_l2a_product_url |&gt;\n  zarr_overview(as_data_frame = TRUE) |&gt;\n  derive_store_array(s2_l2a_product_url)\n\nzarr_store\n\n# A tibble: 124 √ó 8\n   array           path  data_type endianness compressor dim   chunk_dim nchunks\n   &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;      &lt;lis&gt; &lt;list&gt;    &lt;list&gt; \n 1 /conditions/ge‚Ä¶ http‚Ä¶ unicode2‚Ä¶ little     blosc      &lt;int&gt; &lt;int [1]&gt; &lt;dbl&gt;  \n 2 /conditions/ge‚Ä¶ http‚Ä¶ unicode96 little     blosc      &lt;int&gt; &lt;int [1]&gt; &lt;dbl&gt;  \n 3 /conditions/ge‚Ä¶ http‚Ä¶ unicode96 little     blosc      &lt;int&gt; &lt;int [1]&gt; &lt;dbl&gt;  \n 4 /conditions/ge‚Ä¶ http‚Ä¶ float64   little     blosc      &lt;int&gt; &lt;int [1]&gt; &lt;dbl&gt;  \n 5 /conditions/ge‚Ä¶ http‚Ä¶ float64   little     blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n 6 /conditions/ge‚Ä¶ http‚Ä¶ float64   little     blosc      &lt;int&gt; &lt;int [3]&gt; &lt;dbl&gt;  \n 7 /conditions/ge‚Ä¶ http‚Ä¶ float64   little     blosc      &lt;int&gt; &lt;int [5]&gt; &lt;dbl&gt;  \n 8 /conditions/ge‚Ä¶ http‚Ä¶ float32   little     blosc      &lt;int&gt; &lt;int [1]&gt; &lt;dbl&gt;  \n 9 /conditions/ge‚Ä¶ http‚Ä¶ float32   little     blosc      &lt;int&gt; &lt;int [1]&gt; &lt;dbl&gt;  \n10 /conditions/ma‚Ä¶ http‚Ä¶ uint8     &lt;NA&gt;       blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n# ‚Ñπ 114 more rows\n\n\nThis shows us the path to access the Zarr array, the number of chunks it contains, the type of data, as well as its dimensions and chunking structure.\nWe can also look at overviews of individual arrays. First, let‚Äôs narrow down to measurements taken at 20-metre resolution:\n\nr20m &lt;- zarr_store |&gt;\n  filter(str_starts(array, \"/measurements/reflectance/r20m/\"))\n\nr20m\n\n# A tibble: 12 √ó 8\n   array           path  data_type endianness compressor dim   chunk_dim nchunks\n   &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;      &lt;lis&gt; &lt;list&gt;    &lt;list&gt; \n 1 /measurements/‚Ä¶ http‚Ä¶ uint16    little     blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n 2 /measurements/‚Ä¶ http‚Ä¶ uint16    little     blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n 3 /measurements/‚Ä¶ http‚Ä¶ uint16    little     blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n 4 /measurements/‚Ä¶ http‚Ä¶ uint16    little     blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n 5 /measurements/‚Ä¶ http‚Ä¶ uint16    little     blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n 6 /measurements/‚Ä¶ http‚Ä¶ uint16    little     blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n 7 /measurements/‚Ä¶ http‚Ä¶ uint16    little     blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n 8 /measurements/‚Ä¶ http‚Ä¶ uint16    little     blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n 9 /measurements/‚Ä¶ http‚Ä¶ uint16    little     blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n10 /measurements/‚Ä¶ http‚Ä¶ uint16    little     blosc      &lt;int&gt; &lt;int [2]&gt; &lt;dbl&gt;  \n11 /measurements/‚Ä¶ http‚Ä¶ float32   little     blosc      &lt;int&gt; &lt;int [1]&gt; &lt;dbl&gt;  \n12 /measurements/‚Ä¶ http‚Ä¶ float32   little     blosc      &lt;int&gt; &lt;int [1]&gt; &lt;dbl&gt;  \n\n\nThen, we select the B02 array and examine its dimensions and chunking:\n\nr20m |&gt;\n  filter(str_ends(array, \"b02\")) |&gt;\n  select(path, nchunks, dim, chunk_dim) |&gt;\n  as.list()\n\n$path\n[1] \"https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202602-s02msil2a-eu/12/products/cpm_v262/S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509.zarr/measurements/reflectance/r20m/b02\"\n\n$nchunks\n$nchunks[[1]]\n[1] 6 6\n\n\n$dim\n$dim[[1]]\n[1] 5490 5490\n\n\n$chunk_dim\n$chunk_dim[[1]]\n[1] 915 915\n\n\nWe can also see an overview of individual arrays using zarr_overview(). With the default setting (where as_data_frame is FALSE), this prints information on the array directly to the console, in a more digestible way:\n\nr20m_b02 &lt;- r20m |&gt;\n  filter(str_ends(array, \"b02\")) |&gt;\n  pull(path)\n\nr20m_b02 |&gt;\n  zarr_overview()\n\nType: Array\nPath: https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202602-s02msil2a-eu/12/products/cpm_v262/S2A_MSIL2A_20260212T094641_N0512_R036_T34UFB_20260212T104509.zarr/measurements/reflectance/r20m/b02\nShape: 5490 x 5490\nChunk Shape: 915 x 915\nNo. of Chunks: 36 (6 x 6)\nData Type: uint16\nEndianness: little\nCompressor: blosc\n\n\nThe above overview tells us that the data is two-dimensional, with dimensions 5490 x 5490. Zarr data is split up into chunks, which are smaller, independent piece of the larger array. Chunks can be accessed individually, without loading the entire array. In this case, there are 36 chunks in total, with 6 along each of the dimensions, each of size 915 x 915.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Access and analyse EOPF STAC Zarr data with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/53_eopf_zarr_r.html#simple-data-analysis-calculating-ndvi",
    "href": "05_zarr_tools/53_eopf_zarr_r.html#simple-data-analysis-calculating-ndvi",
    "title": "Access and analyse EOPF STAC Zarr data with R",
    "section": "Simple Data Analysis: Calculating NDVI",
    "text": "Simple Data Analysis: Calculating NDVI\nLet us now do a simple analysis with the data from the EOPF Zarr STAC Catalog. Let us calculate the Normalized Difference Vegetation Index (NDVI).\nFirst, we access the Red (B04) and Near-InfraRed (B08A) bands, which are needed for calculation of the NDVI, at 20m resolution:\n\nr20m_b04 &lt;- r20m |&gt;\n  filter(str_ends(array, \"b04\")) |&gt;\n  pull(path) |&gt;\n  read_zarr_array()\n\nr20m_b04[1:5, 1:5]\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    0    0\n[2,]    0    0    0    0    0\n[3,]    0    0    0    0    0\n[4,]    0    0    0    0    0\n[5,]    0    0    0    0    0\n\nr20m_b8a &lt;- r20m |&gt;\n  filter(str_ends(array, \"b8a\")) |&gt;\n  pull(path) |&gt;\n  read_zarr_array()\n\nr20m_b8a[1:5, 1:5]\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    0    0\n[2,]    0    0    0    0    0\n[3,]    0    0    0    0    0\n[4,]    0    0    0    0    0\n[5,]    0    0    0    0    0\n\n\nThe function st_as_stars() is used to get our data into a format that makes data manipulation and visualisation easy.\nThis format is also beneficial because it allows for a quick summary of the data and its attributes, providing information such as the median and mean values of the bands and information on the grid:\n\nndvi_data &lt;- st_as_stars(B04 = r20m_b04, B08A = r20m_b8a) |&gt;\n  st_set_dimensions(1, names = \"X\", values = r20m_x) |&gt;\n  st_set_dimensions(2, names = \"Y\", values = r20m_y)\n\nndvi_data\n\nstars object with 2 dimensions and 2 attributes\nattribute(s), summary of first 1e+05 cells:\n      Min. 1st Qu. Median     Mean 3rd Qu.  Max.\nB04      0    4425 6651.5 5393.742    7748 10739\nB08A     0    4369 6362.0 5185.833    7410 10637\ndimension(s):\n  from   to  offset delta point x/y\nX    1 5490   6e+05    20 FALSE [x]\nY    1 5490 5699990   -20 FALSE [y]\n\n\nNow, we perform the initial steps for NDVI calculation:\n\nsum_bands: Calculates the sum of the Near-Infrared and Red bands.\ndiff_bands: Calculates the difference between the Near-Infrared and Red bands.\n\n\nndvi_data &lt;- ndvi_data |&gt;\n  mutate(\n    sum_bands = B04 + B08A,\n    diff_bands = B04 - B08A\n  )\n\nThen, we calculate the NDVI, which is diff_bands / sum_bands. To prevent division by zero errors in areas where both red and NIR bands might be zero (e.g., water bodies or clouds), we also replace any NaN values resulting from division by zero with 0. This ensures a clean and robust NDVI product.\n\nndvi_data &lt;- ndvi_data |&gt;\n  mutate(\n    ndvi = diff_bands / sum_bands,\n    ndvi = ifelse(sum_bands == 0, 0, ndvi)\n  )\n\nIn a final step, we can visualise the calculated NDVI.\n\nplot(ndvi_data, as_points = FALSE, axes = TRUE, breaks = \"equal\", col = hcl.colors)",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Access and analyse EOPF STAC Zarr data with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/53_eopf_zarr_r.html#now-it-is-your-turn",
    "href": "05_zarr_tools/53_eopf_zarr_r.html#now-it-is-your-turn",
    "title": "Access and analyse EOPF STAC Zarr data with R",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nThe following exercises will help you master the STAC API and understand how to find the data you need.\n\nTask 1: Explore five additional Sentinel-2 Items\nReplicate the RGB quick-look for five additional items from your area of interest and review the spatial changes.\n\n\nTask 2: Calculate NDVI\nReplicate the NDVI calculation for the additional items.\n\n\nTask 3: Applying more advanced analysis techniques\nThe EOPF STAC Catalog offers a wealth of data beyond Sentinel-2. Replicate the search and data access for data from other collections.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Access and analyse EOPF STAC Zarr data with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/53_eopf_zarr_r.html#conclusion",
    "href": "05_zarr_tools/53_eopf_zarr_r.html#conclusion",
    "title": "Access and analyse EOPF STAC Zarr data with R",
    "section": "Conclusion",
    "text": "Conclusion\nIn this tutorial we established a connection to the EOPF Sentinel Zarr Sample Service STAC Catalog and directly accessed an EOPF Zarr array with Rarr. We explored how to review the full Zarr store, read individual arrays, and gave an understanding of Zarr array chunking and dimensions. We also did a simple calculation and visualisation of NDVI using the stars package.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Access and analyse EOPF STAC Zarr data with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/53_eopf_zarr_r.html#whats-next",
    "href": "05_zarr_tools/53_eopf_zarr_r.html#whats-next",
    "title": "Access and analyse EOPF STAC Zarr data with R",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following notebook we will present a workflow that makes use of rstac and gdalcubes in R to create a raster data cube and visualize an aggregated RGB plot!",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Access and analyse EOPF STAC Zarr data with R</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/57_rstac_gdalcubes.html",
    "href": "05_zarr_tools/57_rstac_gdalcubes.html",
    "title": "Creating a raster cube from STAC items of the EOPF Sentinel Zarr Samples Service using rstac and gdalcubes",
    "section": "",
    "text": "Introduction\nThis notebook demonstrates how to create a raster data cube from STAC items of the EOPF Sentinel Zarr Samples Service using the rstac and gdalcubes packages in R. We will search for Sentinel-2 images roughly covering the ‚ÄúM√ºnsterland‚Äù region in Germany for June 2025, and retrieve corresponding STAC items with rstac. We will then use gdalcubes to create a raster data cube and visualize an RGB plot aggregating the data to one image (using median), and compute the NDVI for that image.\nThe gdalcubes package facilitates the creation of regular raster cubes from irregular image collections with differing spatial and temporal resolutions, partial spatial overlap or differing projections etc. It first collects images in so-called image collections and creates data cubes from them, where the spatio-temporal geometry is defined via a data cube view. It also has a function to directly create image collections from STAC items, which we will use here. For details on the functionality and concepts, see the gdalcubes documentation and specifically Marius¬¥ tutorial on the example of the Sentinel-2 COG catalog on Amazon Web Services (AWS).",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Creating a raster cube from STAC items of the EOPF Sentinel Zarr Samples Service using `rstac` and `gdalcubes`</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/57_rstac_gdalcubes.html#now-it-is-your-turn",
    "href": "05_zarr_tools/57_rstac_gdalcubes.html#now-it-is-your-turn",
    "title": "Creating a raster cube from STAC items of the EOPF Sentinel Zarr Samples Service using rstac and gdalcubes",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\n\nüîç Task: Perform a simple NDVI change analysis between April and June 2025.\n‚ÑπÔ∏è gdalcubes can also be used to compute more complex analyses, such as change analysis between two time periods. For a task like this however, it is probably more straightforward to create two separate cubes for both months, derive cloud-free composite NDVI images from them, and then use another package like terra to compute the difference image. You can apply the same approach as above to create a composite NDVI image for the same area in April. Export both NDVI images (April and June) using write_tif() and use the function rast() of the package terra to load the output. You can then simply subtract both objects to compute a simple difference image highlighting changes between the two months.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Creating a raster cube from STAC items of the EOPF Sentinel Zarr Samples Service using `rstac` and `gdalcubes`</span>"
    ]
  },
  {
    "objectID": "05_zarr_tools/57_rstac_gdalcubes.html#conclusion",
    "href": "05_zarr_tools/57_rstac_gdalcubes.html#conclusion",
    "title": "Creating a raster cube from STAC items of the EOPF Sentinel Zarr Samples Service using rstac and gdalcubes",
    "section": "Conclusion",
    "text": "Conclusion\nIn this notebook, we have demonstrated how to create a raster data cube from STAC items of the EOPF Sentinel Zarr Samples Service using the rstac and gdalcubes packages in R. We retrieved Sentinel-2 images for a specified area and time range, created an image collection from these items, and then constructed a raster cube with a defined spatio-temporal geometry. We visualized an RGB composite and computed the NDVI for the area of interest. We have seen that currently some manual adjustments are necessary to work with the EOPF Sentinel Zarr Samples Service using gdalcubes, but this will be streamlined in future releases of the package.\nIn the following chapter we will present several end-to-end workflows, where we will showcase the application of the available Sentinel Products in the EOPF Sentinel Zarr Sample Service STAC Catalog.",
    "crumbs": [
      "**Tools to work with EOPF Zarr**",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Creating a raster cube from STAC items of the EOPF Sentinel Zarr Samples Service using `rstac` and `gdalcubes`</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html",
    "href": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nCommunities and ecosystems worldwide are under increasing threat from wildfires, a problem that is being made worse by climate change.\nMonitoring these events is crucial, and satellite imagery is an invaluable tool in this effort. The Sentinel satellite missions offer valuable insights into the different stages of a fire. A True Colour Composite of Sentinel-2 data can be used to track smoke, False Colour Composites can clearly distinguish healthy vegetation from damaged or burnt areas. Furthermore, True- or False color composites can be combined with other data sources, such as Land Surface Temperature (LST) from Sentinel-3. Temperature anomalies retrieved from Sentinel-3 data are useful information to get a more comprehensive picture of a fire event.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#setting-up-the-environment",
    "href": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#setting-up-the-environment",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Setting up the environment",
    "text": "Setting up the environment\n\nDefining parameters for querying the EOPF STAC catalog\nAs a first step, we need to define specific parameters for our query, including:\n\ntwo key dates for our comparison: one date for a pre-fire view, 3rd of June 2025 (one week before the event) and a second for the post-fire view on 21st June 2025 (10 days after)\nthe data collection we are interested in, and\nbounding box information for the area of interest.\n\nIn addition, we set the appropriate re-projection parameters to ensure a smooth and efficient workflow.\n\n# The timeframe and area of interest for our filtering\ndef_collection = 'sentinel-2-l2a' # collection\n# Before the fire:\npre_f  = '2025-06-03'\n# After the fire:\npost_f = '2025-06-21'\n\nsearch_bbox = (8.847198,40.193395,8.938865,40.241895)\n\n# Definition of the transformer parameters from lat/lon to UTM that ensure\n# correct overlay of layers\ntransformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32632\", always_xy=True)\n\nt_utm_to_deg = Transformer.from_crs(\"EPSG:32632\",\"EPSG:4326\", always_xy=True)\n\n\n\nInitiate a Dask cluster\nIn a next step we initiate a virtual Dask cluster. This cluster consists of a scheduler (the ‚Äúbrain‚Äù) and several workers (the ‚Äúhands‚Äù), which enables faster processing of large datasets by breaking down tasks and running them in parallel.  A client is then created to manage communication between the code and this cluster.\nFor more information, feel free to visit the dask documentation and the tutorial How to use dask.\n\n# To track the the performance the code will have\nst = time.time()\n\ncluster = LocalCluster()\nclient = cluster.get_client()\nclient\n\n\n     \n    \n        Client\n        Client-d996d1a4-0816-11f1-9a99-e24da843f2da\n        \n\n\n\nConnection method: Cluster object\nCluster type: distributed.LocalCluster\n\n\nDashboard: http://127.0.0.1:8787/status\n\n\n\n\n\n\n        \n            \n                Launch dashboard in JupyterLab\n            \n        \n\n        \n            \n            Cluster Info\n            \n    \n    \n    \n        LocalCluster\n        c256ec7c\n        \n\n\n\nDashboard: http://127.0.0.1:8787/status\nWorkers: 4\n\n\nTotal threads: 8\nTotal memory: 31.35 GiB\n\n\nStatus: running\nUsing processes: True\n\n\n\n\n\n        \n            \n                Scheduler Info\n            \n\n            \n    \n         \n        \n            Scheduler\n            Scheduler-dd311aee-adf5-4611-beac-b7ab5c87de73\n            \n\n\n\nComm: tcp://127.0.0.1:32771\nWorkers: 0\n\n\nDashboard: http://127.0.0.1:8787/status\nTotal threads: 0\n\n\nStarted: Just now\nTotal memory: 0 B\n\n\n\n\n        \n    \n\n    \n        \n            Workers\n        \n\n        \n        \n             \n            \n            \n                \n                    Worker: 0\n                \n                \n\n\n\nComm: tcp://127.0.0.1:41179\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:33071/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:45391\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-631rkflu\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 1\n                \n                \n\n\n\nComm: tcp://127.0.0.1:40675\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:45693/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:33105\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-00t01tc3\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 2\n                \n                \n\n\n\nComm: tcp://127.0.0.1:41433\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:37699/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:38007\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-_5yvjxk1\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 3\n                \n                \n\n\n\nComm: tcp://127.0.0.1:36173\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:43769/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:34343\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-apva5w46\n\n\n\n\n            \n            \n        \n        \n\n    \n\n\n        \n    \n\n            \n        \n\n    \n\n\n\n\n\nEstablish a connection to the EOPF STAC Catalog\nData is retrieved from the endpoint of the EOPF STAC Catalog. We can do this with the function Client.open() from the pystac_client library.\n\neopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\" #root starting point\neopf_catalog = Client.open(url=eopf_stac_api_root_endpoint) # calls the selected url",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#pre-fire-visualisation",
    "href": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#pre-fire-visualisation",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Pre-Fire Visualisation",
    "text": "Pre-Fire Visualisation\nThe first step is to create a visual representation of our area of interest for a day before the fire occured: 3 June 2025. We will use the parameters we defined at the beginning to query the STAC collection and retrieve the specific pre-fire images needed for our analysis.\nWith the search() function, you can query a STAC catalog based on given keyword arguments. As a result of the search, you see that one Item is returned from the STAC Catalog.\n\n# Interest timeframe parameters for the filtering\ndate_pre = pre_f + 'T00:00:00Z/' + pre_f + 'T23:59:59.999999Z' # interest period\ns2_col = list(eopf_catalog.search(\n                bbox= search_bbox, # area\n                datetime= date_pre, #time frame\n                collections=def_collection # collection\n                ).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_col]  # stores the available Items URLs\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-2 L2A over Sardinia:  ',len(av_urls))\n\nSearch Results:\nTotal Items Found for Sentinel-2 L2A over Sardinia:   1\n\n\nNow, we can retrieve the item and directly and open it as a xarray.DataTree. In addition, key information from the item‚Äôs properties is also extracted to verify key properties of the item.\n\n# We are interested in the datasets contained in the measurements bands for True Colour and False Colour Composites.\ns2_zarr = xr.open_datatree(\n    av_urls[0], engine=\"zarr\", #we always get the earliest one (the first available item goes last)\n    chunks={},\n    decode_timedelta=False\n    )\n\n# Store interest parameters for further plotting:\ndate = s2_zarr.attrs['stac_discovery']['properties']['start_datetime'][:10]\ntime_zarr = s2_zarr.attrs['stac_discovery']['properties']['start_datetime'][11:19]\n# target_crs = s2_zarr.attrs[\"stac_discovery\"][\"properties\"][\"proj:epsg\"]\n\nprint(f'Item for the {date} at {time_zarr}')\n\nItem for the 2025-06-03 at 10:10:41\n\n\nThe spectral bands we will need for our analysis are found within the /reflectance group, specifically under the r20m subgroup.\nBefore directly processing our assets of interest, we will filter out invalid pixels, such as pixels containing clouds, cloud shadows, or areas with no data. We will use the Scene Classification Layer (SCL) available inside the .zarr item, which is a separate asset located under the /classification/r20m group.\nBy using the pre-defined validate_scl() function, we can create a boolean mask that masks out invalid pixels.\n\n# Extract the resolution group we are interested to analyse over:\nzarr_meas = s2_zarr.measurements.reflectance.r20m\n\n# Extract the Scene Classification Layer at 20m resolution:\nl2a_class_20m = s2_zarr.conditions.mask.l2a_classification.r20m.scl\n\n# Apply the function `validatae_scl` to mask out invalid pixels\nvalid_mask = validate_scl(l2a_class_20m)\n\nThe visualisation we are intending to create covers a larger extent than the specific fire area. This helps us to better understand the event‚Äôs overall spatial extent. For this, we generate a bounding box to visually pinpoint the fire‚Äôs precise location within a wider composite image.\n\n# Defining a larger bounding box for better visualisation:\nbbox_vis = (8.649555,40.073583,9.127893,40.343840)\n\n# A fixed geographic bounding box to highlight the AOI in the map format\nmap_box = search_bbox\n\nIn next step, we need to reproject the area of interest from EPSG: 4326 to UTM coordinates. Once the area is defined, our loaded data (zarr_meas) is masked using the defined bbox_utm. After extracting the area, only the valid pixels are selected.\n\n# A new list with the converted UTM coordinates\nbbox_utm = lat_lon_to_utm_box((bbox_vis[0], bbox_vis[1]),(bbox_vis[2], bbox_vis[3]),transformer)\n\n# Use the box() function to create a polygon from the coordinates\nmap_box = box(map_box[0],map_box[1],map_box[2],map_box[3])\n\n# Boolean mask for the 'x' dimension (longitude/easting)\nx_mask = (zarr_meas['x'] &gt;= bbox_utm[0]) & (zarr_meas['x'] &lt;= bbox_utm[2])\n# Boolean mask for the 'y' dimension (latitude/northing)\ny_mask = (zarr_meas['y'] &gt;= bbox_utm[1]) & (zarr_meas['y'] &lt;= bbox_utm[3])\n\n# Combined mask for the bounding box\nbbox_mask = x_mask & y_mask\n\n# Extract row and column indices where the mask is True\ncols,rows = np.where(bbox_mask)\n\n\nPre-Fire True Colour Image\nOnce we have created the necessary masks, we can proceed to create True Color Image composites. For the composite creation, zarr_meas contains the assets we are interested in. The TCI composite makes use of the red (B04), green (B03), and blue (B02) bands to create a view that looks natural to the human eye.\nxarray‚Äôs where() function allows us to apply the SLC filtering we had previously defined.\n\n# True colour channels we are interested to retrieve composite:\ntc_red  = 'b04'\ntc_green= 'b03'\ntc_blue = 'b02'\n\n# The tc_red, tc_green, and tc_blue variables are inputs specifying the band names\nred = zarr_meas[tc_red].where(valid_mask)\ngre = zarr_meas[tc_green].where(valid_mask)\nblu = zarr_meas[tc_blue].where(valid_mask)\n\n# Visualising the green band:\nplt.imshow(gre)\nplt.title('Green Reflectance (b03)')\n\nText(0.5, 1.0, 'Green Reflectance (b03)')\n\n\n\n\n\n\n\n\n\nThe next step is to clip the retrieved asset to our area of interest which we defined earlier with specific bounding box information. We can apply the mask_sub_utm() function, which will masks the three bands to the defined bounding box.\nIt is important to point out that until now, we have not accessed on disk the data. Once we add the .values argument to the resulting _ from mask_sub_utm(), the data is accessed.\n.zarr contains x and y information for each of the pixels, and storing these values for a further geolocalisation of our item of interest is essential.\nYou can visualise the blue (B02) band to verify the clipped area.\n\n# The mask_sub_utm() function takes the bands and masks them to the valid rows and columns from the bbox_mask\nred = mask_sub_utm(red,rows, cols).values\ngre = mask_sub_utm(gre,rows, cols).values\nblu = mask_sub_utm(blu,rows, cols).values\n\n# The zarr_meas group is the input dataset containing the dimensions\n# by slicing the 'y' dimension array based on the minimum and maximum row indices\ny_zarr = zarr_meas['y'].isel(y=slice(rows.min(), rows.max() + 1)).values\n# also, the same for the 'x' dimension array based on the minimum and maximum column indices\nx_zarr = zarr_meas['x'].isel(x=slice(cols.min(), cols.max() + 1)).values\n\n# We transform the original x,y bbox from our clip to decimal degree coordinates\nmap_ext_deg_pre = list(t_utm_to_deg.transform(np.nanmin(x_zarr),np.nanmin(y_zarr)) + \n                   t_utm_to_deg.transform(np.nanmax(x_zarr),np.nanmax(y_zarr)))\n\n# Visualising the clipped red band:\nplt.imshow(blu)\nplt.title('Clipped Blue Reflectance (b02)')\n\nText(0.5, 1.0, 'Clipped Blue Reflectance (b02)')\n\n\n\n\n\n\n\n\n\nTo create the composite image, we need to normalise each of the input assets. Normalisation ensures that the bands have a consistent and predictable range of values. This supports optimal data processing and removes the influence of external factors (like changing light conditions) allowing for a meaningful comparison among generated composites.\nThe normalisation_str_gm() function achieves this by scaling the reflectance values to a standard range (0-255) using the percentile-based method.\nOnce the values for our three bands have been normalised, they can be stacked in an RGB format to generate the initial True Colour Image (TCI).\n\n# Input: percentile range for contrast stretching\ncontrast_stretch_percentile=(2, 98)\n# Input: gamma correction value\ngamma=1.8\n\n# Apply normalisation to the red, green and blue bands using the specified percentile and gamma values\nred_processed = normalisation_str_gm(red, *contrast_stretch_percentile, gamma)\ngreen_processed = normalisation_str_gm(gre, *contrast_stretch_percentile, gamma)\nblue_processed = normalisation_str_gm(blu, *contrast_stretch_percentile, gamma)\n\n# We stack the processed red, green, and blue arrays\nrgb_composite_sm = np.dstack((red_processed, green_processed, blue_processed)).astype(np.float32)\n\nplt.imshow(rgb_composite_sm)\nplt.title('RGB Composite')\n\nText(0.5, 1.0, 'RGB Composite')\n\n\n\n\n\n\n\n\n\nThe image is currently displayed with a neutral colour ramp and with the non-valid masked pixels. Some of the details can be enhanced based on the information the overall composite contains.\nFor this, we can apply a histogram equalisation. This technique will adjust the brightness and improve the visibility of details within our image.  Through the skimage library, we can apply the exposure.equalize_adapthist() function. This method creates a more natural-looking and visually balanced composite.\n\n#Adding equalisation from skimage:\nfire_tc = exposure.equalize_adapthist(rgb_composite_sm)\n\nplt.imshow(fire_tc)\nplt.title('Equalised Composite') # Add a title for clarity\n\nText(0.5, 1.0, 'Equalised Composite')\n\n\n\n\n\n\n\n\n\n\n\nPre-Fire False Colour Image\nNext, a False Colour Image (FCI) is created to provide a clearer overview of vegetation health.\nThis image uses the Shortwave Infrared (B12), Near-Infrared (B8a), and Blue (B02) bands. This specific combination enhances the distinction between healthy vegetation, which appears green, and damaged or burnt areas, which are shown in vivid, contrasting colours.\nThis False Colour composite will help us to better highlight the full extent of the fire.\n\n# The false colour channels we are interested to retrieve coposite:\nfc_swir = 'b12'\nfc_nir =  'b8a'\nfc_blue = 'b02'\n\nFollowing the same principle as of the creation of the True Colour composite, we can choose the relevant bands and apply the masking and clipping steps.\n\n# The zarr_meas object is the input dataset containing the bands, fc_red, fc_green, fc_blue specify the bands\n# The where() method is used to apply the boolean valid_mask to the bands\nswir = zarr_meas[fc_swir].where(valid_mask)\nnir =  zarr_meas[fc_nir].where(valid_mask)\nblu =  zarr_meas[fc_blue].where(valid_mask)\n\n# The mask_sub_utm() function takes the bands and masks them to the specified rows and columns\nswir = mask_sub_utm(swir,rows, cols).values\nnir = mask_sub_utm(nir,rows, cols).values\nblu = mask_sub_utm(blu,rows, cols).values\n\nThen, we can apply the normalisation function, followed by the stacking of the three bands. The False Colour composite $$$ explain the colouring\n\n# Apply the normalisation function to each band\nswir_processed = normalisation_str_gm(swir, *contrast_stretch_percentile, gamma)\nnir_processed = normalisation_str_gm(nir, *contrast_stretch_percentile, gamma)\nblue_processed = normalisation_str_gm(blu, *contrast_stretch_percentile, gamma)\n\n# Use np.dstack to create a false-colour composite from the processed bands\nfalse_composite= np.dstack((swir_processed, nir_processed, blue_processed)).astype(np.float32)\n\n# Output:\nplt.imshow(false_composite)\nplt.title('False Composite')\n\nText(0.5, 1.0, 'False Composite')\n\n\n\n\n\n\n\n\n\nWe then continue and also apply the equalisation function.\n\n# Apply adaptive histogram equalisation to enhance contrast for fire detection\nfire_fc = exposure.equalize_adapthist(false_composite)\n\n# Create a figure to plot\n\nplt.imshow(fire_fc)\nplt.title('Equalised False Composite')\n\nText(0.5, 1.0, 'Equalised False Composite')",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#post-fire-visualisation",
    "href": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#post-fire-visualisation",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Post-Fire Visualisation",
    "text": "Post-Fire Visualisation\nNow, we will replicate the same visualisation for a specific time after the fire: 10 June 2025. Considering this new date, we will retrieve images from the same collection that correspond to our new timeframe of interest.\n\ndate_post = post_f + 'T00:00:00Z/' + post_f + 'T23:59:59.999999Z' # interest period\n\ns2_post = list(eopf_catalog.search(\n                bbox= search_bbox, \n                datetime= date_post,\n                collections=def_collection).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_post]\nav_urls\n\n['https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:notebook-data/tutorial_data/cpm_v264/S2C_MSIL2A_20250621T100611_N0511_R022_T32TMK_20250623T084315.zarr']\n\n\nWe open again the the retrieved item from our filtered results, followed by the masking and validation steps to ensure a clean, cloud-free composite.\n\npost_zarr = xr.open_datatree(\n    av_urls[0], engine=\"zarr\", #we always get the earliest one (last)\n    chunks={},\n    decode_timedelta=False\n    )\n\nzarr_meas = post_zarr.measurements.reflectance.r20m\n\n# Extractthe cloud free mask at 20m resolution:\nl2a_class_20m = post_zarr.conditions.mask.l2a_classification.r20m.scl\n\nvalid_mask = validate_scl(l2a_class_20m)  # Boolean mask (10980x10980)\n\n\nPost-Fire True Colour Image\nOnce invalid pixels are filtered out, we can generate the corresponding True-Color composite to get a view of our area of interest after the fire event. We again clip the retrieved assets to our specific bounding box.\n\n# Create UTM masks for rows and columns based on the bounding box.\ncols_post, rows_post = zarr_mask_utm(bbox_utm, zarr_meas)\n\n# Select the red, green, and blue bands and apply the valid mask.\nred = zarr_meas[tc_red].where(valid_mask)\ngre =  zarr_meas[tc_green].where(valid_mask)\nblu =  zarr_meas[tc_blue].where(valid_mask)\n\n# Mask and clip the selected bands using the row and column indices.\nred = mask_sub_utm(red,rows_post, cols_post).values\ngre = mask_sub_utm(gre,rows_post, cols_post).values\nblu = mask_sub_utm(blu,rows_post, cols_post).values\n\n# Slice the y-dimension values using the new row indices.\ny_zarr = zarr_meas['y'].isel(y=slice(rows_post.min(), rows_post.max() + 1)).values\n# Slice the x-dimension values using the new column indices.\nx_zarr = zarr_meas['x'].isel(x=slice(cols_post.min(), cols_post.max() + 1)).values\n\n# We transform the original x,y bbox from our clip to decimal degree coordinates\nmap_ext_deg_post = list(t_utm_to_deg.transform(np.nanmin(x_zarr),np.nanmin(y_zarr)) + \n                   t_utm_to_deg.transform(np.nanmax(x_zarr),np.nanmax(y_zarr)))\n\nAnd, once the new area is defined, we normalise, stack and equalize the composite.\n\n# Apply normalisation and gamma correction to the red, green, and blue bands.\nred_processed = normalisation_str_gm(red, *contrast_stretch_percentile, gamma)\ngreen_processed = normalisation_str_gm(gre, *contrast_stretch_percentile, gamma)\nblue_processed = normalisation_str_gm(blu, *contrast_stretch_percentile, gamma)\n\n# Stack the processed bands to create a single true-colour composite image.\nrgb_composite_sm = np.dstack((red_processed, green_processed, blue_processed)).astype(np.float32)\n\n# Apply adaptive histogram equalisation to enhance the composite image.\ntc_post = exposure.equalize_adapthist(rgb_composite_sm)\n\nplt.imshow(tc_post)\nplt.title('Equalised Composite') # Add a title for clarity\n\nText(0.5, 1.0, 'Equalised Composite')\n\n\n\n\n\n\n\n\n\n\n\nPost-Fire False Colour Image\nAnd as the last processing step, we create the False Colour composite for the same day, to clearly visualise the extent of the burn scars and vegetation recovery.\n\n# Select the red, green, and blue bands and apply the valid mask.\n\nswir = zarr_meas[fc_swir].where(valid_mask)\nnir =  zarr_meas[fc_nir].where(valid_mask)\nblu =  zarr_meas[fc_blue].where(valid_mask)\n\n# Mask and clip the selected bands using the row and column indices.\n\nswir = mask_sub_utm(swir,rows_post, cols_post).values\nnir = mask_sub_utm(nir,rows_post, cols_post).values\nblu = mask_sub_utm(blu,rows_post, cols_post).values\n\n# Apply normalisation and gamma correction to the red, green, and blue bands.\n\nswir_processed = normalisation_str_gm(swir, *contrast_stretch_percentile, gamma)\nnir_processed = normalisation_str_gm(nir, *contrast_stretch_percentile, gamma)\nblue_processed = normalisation_str_gm(blu, *contrast_stretch_percentile, gamma)\n\n\n# Stack the processed bands to create a single false-colour composite image.\nfalse_composite= np.dstack((swir_processed, nir_processed, blue_processed)).astype(np.float32)\n\n# Apply adaptive histogram equalisation to enhance the composite image.\nfc_post = exposure.equalize_adapthist(false_composite)\n\nplt.imshow(fc_post)\nplt.title('Equalised Composite') # Add a title for clarity\n\nText(0.5, 1.0, 'Equalised Composite')",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#compare-pre--and-post-fire-composites",
    "href": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#compare-pre--and-post-fire-composites",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Compare pre- and post-fire composites",
    "text": "Compare pre- and post-fire composites\nAs a last step, we will georeference and visualise the created composites together, presenting it in a way that makes it easier to recognise and understand the monitored areas.\nWe will use the cartopy library to pinpoint the location of our georeferenced datasets based on their CRS and geospatial bounding box. The visualisation will be a 2x2 matrix, offering a comprehensive, multi-channel overview.\nFinally, the plot will be enhanced by adding key elements such as grid lines for improved geolocation, a clear title, and a bounding box to highlight the specific area of the fire. This approach allows for a direct visual comparison of the landscape‚Äôs state before and after the event.\n\ndata_ll = ccrs.PlateCarree()\n\nfig, axs = plt.subplots(2, 2, figsize=(15, 9), subplot_kw={'projection': data_ll})\n\n# Pre fire TCI\nax1 = axs[0,0]\nax1.imshow(fire_tc, origin='upper',\n                extent=[map_ext_deg_pre[0],map_ext_deg_pre[2],\n                        map_ext_deg_pre[1],map_ext_deg_pre[3]],  # item\n                transform=data_ll)\nax1.add_geometries(map_box, crs=data_ll, facecolor='none', \n                   edgecolor='yellow', linewidth=2, linestyle='-')\nax1.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # gridlines and labels\nax1.set_title(f'TCI for {pre_f}')\n\n# Pre fire FCI\nax2 = axs[0,1]\nax2.imshow(fire_fc, origin='upper',\n                extent=[map_ext_deg_pre[0],map_ext_deg_pre[2],\n                        map_ext_deg_pre[1],map_ext_deg_pre[3]],  # item\n                transform=data_ll)\nax2.add_geometries(map_box, crs=data_ll, facecolor='none', \n                   edgecolor='yellow', linewidth=2, linestyle='-')\nax2.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # gridlines and labels\nax2.set_title(f'FCI for {pre_f}')\n\n#Post fire TCO\nax3 = axs[1,0]\nax3.imshow(tc_post, origin='upper',\n                extent=[map_ext_deg_post[0],map_ext_deg_post[2],\n                        map_ext_deg_post[1],map_ext_deg_post[3]],  # item\n                transform=data_ll)\nax3.add_geometries(map_box, crs=data_ll, facecolor='none', \n                   edgecolor='yellow', linewidth=2, linestyle='-')\nax3.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # gridlines and labels\nax3.set_title(f'TCI for {post_f}')\n\n# Post fire FCI\nax4 = axs[1,1]\nax4.imshow(fc_post, origin='upper',\n                extent=[map_ext_deg_post[0],map_ext_deg_post[2],\n                        map_ext_deg_post[1],map_ext_deg_post[3]],  # item\n                transform=data_ll)\nax4.add_geometries(map_box, crs=data_ll, facecolor='none', \n                   edgecolor='yellow', linewidth=2, linestyle='-')\nax4.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # gridlines and labels\nax4.set_title(f'FCI for {post_f}')\n\n# Adjust the layout to prevent titles from overlapping\nfig.suptitle(f'Sentinel-2 L2A TCI and FCI', fontsize=16)\n# Display the combined plot\nplt.show()",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#calculating-processing-time",
    "href": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#calculating-processing-time",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Calculating processing time",
    "text": "Calculating processing time\n\net = time.time()\n\ntotal_t = et - st\n\nprint('Total Running Time: ', total_t,' seconds')\n\nTotal Running Time:  62.091012477874756  seconds\n\n\nAs our plots show, the True Colour Image reveals a clear change in the state of the vegetation, with an evident burn scar visible on the ground. The False Colour Image also highlights a significant change in the spectral response, which precisely encloses the spot where the fire occurred.\nIt is important to note the efficiency of this monitoring workflow. The entire process from defining the area of interest to searching, accessing, processing, and visualising the data takes less than a minute, without the need to download data.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#conclusion",
    "href": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#conclusion",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "Conclusion",
    "text": "Conclusion\nHaving processed the key spectral bands, we have successfully established a visual baseline for our monitoring workflow.\nThe generation of these composites allows us to quickly gain an overview of the spatial changes resulting from a fire event, as observed by Sentinel-2 L-2A.\nThis workflow is highly replicable, enabling us to replicate these defined steps at various points in time. This ability to generate consistent visualisations will allow us to understand the full dynamics of a fire‚Äôs event lifecycle over time, from its beginning to the subsequent recovery of the landscape.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#whats-next",
    "href": "06_eopf_zarr_in_action/61_sardinia_s2_tfci.html#whats-next",
    "title": "Fire in Sardinia 2025 - Part 1",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following notebook, we will apply the workflow we have generated to create a True Colour Image from Sentinel-2 L2A data for the day of the fire.\nTo obtain a more detailed overview of the fire‚Äôs state, we will integrate a new dataset into our workflow: Sentinel-3 data. This will enable us to analyse thermal information and pinpoint the active fire‚Äôs location.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/62_sardinia_s3_lst.html",
    "href": "06_eopf_zarr_in_action/62_sardinia_s3_lst.html",
    "title": "Fire in Sardinia 2025 - Part 2",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nOn June 10th, 2025, a significant wildfire in Italy‚Äôs Nuoro Province in Sardinia burned approximately 1000 hectares, a scale that is clearly visible in satellite imagery with a 20-meter resolution. The European Forest Fire Information System (EFFIS) keeps record of these events.\nThis notebook demonstrates how two different .zarr encoded Sentinel Mission products can be combined to provide a compelling and informative overview of an active fire event.\nFirst, we will use reflectance data from Sentinel-2 L2A to locate the area of the fire on the ground. At the same time, we will use data from Sentinel-3 SLSTR Land Surface Temperature (LST) to demonstrate the intense heat emanating from the fire.\nBy combining these two datasets, we will not only be able to see the fire location and its state on the day of the event, but also understand its thermal intensity, providing a more complete perspective on its dynamics.\nThis notebook is the second a series of three notebook:",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/62_sardinia_s3_lst.html#setting-up-the-environment",
    "href": "06_eopf_zarr_in_action/62_sardinia_s3_lst.html#setting-up-the-environment",
    "title": "Fire in Sardinia 2025 - Part 2",
    "section": "Setting up the environment",
    "text": "Setting up the environment\n\nInitiate a Dask cluster\nThe first step is to initiate a virtual Dask cluster. This cluster consists of a scheduler (the ‚Äúbrain‚Äù) and several workers (the ‚Äúhands‚Äù), which enables faster processing of large datasets by breaking down tasks and running them in parallel.\nA client is then created to manage communication between the code and this cluster. For more information, feel free to visit the dask documentation and the tutorial How to use dask.\n\n# we are interested in the performance the code will have\nst = time.time()\n\ncluster = LocalCluster()\nclient = cluster.get_client()\nclient\n\n\n     \n    \n        Client\n        Client-04bd899e-0817-11f1-9bb5-e24da843f2da\n        \n\n\n\nConnection method: Cluster object\nCluster type: distributed.LocalCluster\n\n\nDashboard: http://127.0.0.1:8787/status\n\n\n\n\n\n\n        \n            \n                Launch dashboard in JupyterLab\n            \n        \n\n        \n            \n            Cluster Info\n            \n    \n    \n    \n        LocalCluster\n        ba2aa0ca\n        \n\n\n\nDashboard: http://127.0.0.1:8787/status\nWorkers: 4\n\n\nTotal threads: 8\nTotal memory: 31.35 GiB\n\n\nStatus: running\nUsing processes: True\n\n\n\n\n\n        \n            \n                Scheduler Info\n            \n\n            \n    \n         \n        \n            Scheduler\n            Scheduler-746a21f4-d858-4864-83d3-b5ef566af952\n            \n\n\n\nComm: tcp://127.0.0.1:39781\nWorkers: 0\n\n\nDashboard: http://127.0.0.1:8787/status\nTotal threads: 0\n\n\nStarted: Just now\nTotal memory: 0 B\n\n\n\n\n        \n    \n\n    \n        \n            Workers\n        \n\n        \n        \n             \n            \n            \n                \n                    Worker: 0\n                \n                \n\n\n\nComm: tcp://127.0.0.1:34413\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:33811/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:34831\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-2l2m12v3\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 1\n                \n                \n\n\n\nComm: tcp://127.0.0.1:46429\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:41531/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:35139\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-lbec3jbw\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 2\n                \n                \n\n\n\nComm: tcp://127.0.0.1:38299\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:45399/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:33533\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-ltgcn7g2\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 3\n                \n                \n\n\n\nComm: tcp://127.0.0.1:44907\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:40723/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:37817\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-11wuwqkx\n\n\n\n\n            \n            \n        \n        \n\n    \n\n\n        \n    \n\n            \n        \n\n    \n\n\n\n\n\nEstablish a connection to the EOPF STAC Catalog\nData is retrieved from the EOPF STAC Catalogue endpoint. Once the connection is established, we can query the catalog based on specific search criteria.\n\neopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\" #root starting point\neopf_catalog = Client.open(url=eopf_stac_api_root_endpoint) # calls the selected url\neopf_catalog\n\n\n\n\n\n\n    &lt;Client id=eopf-sample-service-stac-api&gt;\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Catalog\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"eopf-sample-service-stac-api\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"STAC catalog of the EOPF Sentinel Zarr Samples Service\"\n        \n    \n                \n            \n                \n                    \n        links[] 21 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"conformance\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/conformance\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC/OGC conformance classes implemented by this server\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"POST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-2A\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-grd\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 GRD\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l1-rbt\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-1 RBT\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lfr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l2-lst\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-2 LST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l2-frp\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-2 FRP\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lrr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LRR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-efr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 EFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l1c\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-1C\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-slc\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 SLC\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-err\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 ERR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l2-ocn\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-2 OCN\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \n        \n            \n                \n        \n            rel\n            \"service-desc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/vnd.oai.openapi+json;version=3.0\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service description\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \n        \n            \n                \n        \n            rel\n            \"service-doc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api.html\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service documentation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        conformsTo[] 21 items\n        \n            \n        \n            \n                \n        \n            0\n            \"http://www.opengis.net/spec/cql2/1.0/conf/basic-cql2\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-text\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/geojson\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/oas30\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/features-filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \"https://api.stacspec.org/v1.0.0-rc.2/item-search#filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \"https://api.stacspec.org/v1.0.0/collections\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \"https://api.stacspec.org/v1.0.0/collections/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \"https://api.stacspec.org/v1.0.0/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \"https://api.stacspec.org/v1.0.0/item-search\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \"https://api.stacspec.org/v1.0.0/item-search#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \"https://api.stacspec.org/v1.0.0/item-search#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \"https://api.stacspec.org/v1.0.0/item-search#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"\n        \n    \n                \n            \n        \n    \n\n\n\n\n\n\nDefine search paramters\n\n# The timeframe and area of interest for our filtering\nfire_d = '2025-06-11'\nfire_d_s3 = '2025-10-21'\ndef_collection = ''\n\nsearch_bbox = (8.847198,40.193395,8.938865,40.241895)\n\n# Definition of the transformer parameters for reprojection and correct overlay of layers\ntransformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32632\", always_xy=True)\nt_utm_to_deg = Transformer.from_crs(\"EPSG:32632\",\"EPSG:4326\", always_xy=True)\n\n# Defining a larger bounding box for better visualisation:\nbbox_vis = (8.649555,40.073583,9.127893,40.343840)\n\n# A fixed geographic bounding box to highlight the AOI in the map format\nmap_box = search_bbox\n\n# A new list with the converted UTM coordinates\nbbox_utm = lat_lon_to_utm_box((bbox_vis[0], bbox_vis[1]),(bbox_vis[2], bbox_vis[3]), transformer)\n\n# # Convert the coordinates of the map_box\n# map_box = lat_lon_to_utm_box((map_box[0], map_box[1]),(map_box[2], map_box[3]))",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/62_sardinia_s3_lst.html#overview-of-processing-steps",
    "href": "06_eopf_zarr_in_action/62_sardinia_s3_lst.html#overview-of-processing-steps",
    "title": "Fire in Sardinia 2025 - Part 2",
    "section": "Overview of processing steps",
    "text": "Overview of processing steps\nIn the following, we will go through three main processing steps:\n\nStep 1: Retrieving and visualising Land Surface Temperature from Sentinel-3 SLSTR L2 data\nStep 2: Creating a True-Color composite of Sentinel-2 L2A data, and\nStep 3: Overlaying both datasets, the True-Color composite with the Land Surface Temperature information\n\n\nRetrieve Land Surface Temperature (LST) from Sentinel-3 SLSTR L2\nLand Surface Temperature (LST) data, can be retrieved from the Sentinel-3 SLSTR L2 collection. This data helps to identify temperature anomalies over the Earth‚Äôs Surface, which can be a strong indicator of an active fire.\nIn the following, we query the EOPF STAC Catalog to retrieve Land Surface Temperature from Sentinel-3 SLSTR L2 data.\nThe search below introduces a new argument to the search: query. This argument allows us to go into the .zarr attributes metadata and filter based on specific parameters of the items we are interested in. We will filter for ‚ÄúNon-Time Critical‚Äù items.\n\n# Specifying the Sentinel-3 SLSTR L2 LST collection name\ndef_collection = 'sentinel-3-slstr-l2-lst'\n\n# Search the catalog for items matching the criteria:\ns3_l2 = list(eopf_catalog.search(\n                bbox= search_bbox,  # A bounding box input to define the area of interest\n                datetime= fire_d_s3, # A datetime string input to specify the time range\n                collections=def_collection, # The collection name to search within\n                query = {\"product:timeliness_category\": {'eq':'NT'}} # A query to filter by timeliness category\n                                                                     # in the Catalog\n                ).item_collection())\n\n# Extract the URLs for the product assets from the search results\nav_urls = [item.assets[\"product\"].href for item in s3_l2]\n\nprint(\"Search Results:\")\nprint('Total Items Found for Sentinel-3 SLSRT over Sardinia:  ',len(av_urls))\n\nSearch Results:\nTotal Items Found for Sentinel-3 SLSRT over Sardinia:   3\n\n\nAfter filtering the catalog, we open the first available Sentinel-3 SLSTR item, which corresponds to our specific timeframe of the selected day.\nFor optimising the subsequent plotting, we can extract key information from the retrieved item, such as the date and the specific item time. Afterwards, we access the Land Surface Temperature (LST) asset. The LST data is available under the group measurements.\n\n# Open the last item from the list of URLs as a Zarr data tree\nlst_zarr = xr.open_datatree(\n    av_urls[-1], # Input: URL of the last Zarr item in the av_urls list\n    engine=\"zarr\" # Specify the Zarr engine for opening the file\n    )\n\n# Extract the start date and time from the data tree's metadata\ndate_zarr_lst = lst_zarr.attrs['stac_discovery']['properties']['start_datetime'][:10]\ntime_zarr_lst = lst_zarr.attrs['stac_discovery']['properties']['start_datetime'][11:19]\n\n# Access the 'measurements' group within the data tree\nmeas_lst = lst_zarr.measurements\n# The output is the measurements data group\nmeas_lst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataTree 'measurements'&gt;\nGroup: /measurements\n‚îÇ   Dimensions:    (rows: 1200, columns: 1500)\n‚îÇ   Coordinates:\n‚îÇ     * rows       (rows) int64 10kB 0 1 2 3 4 5 6 ... 1194 1195 1196 1197 1198 1199\n‚îÇ     * columns    (columns) int64 12kB 0 1 2 3 4 5 ... 1495 1496 1497 1498 1499\n‚îÇ       latitude   (rows, columns) float64 14MB ...\n‚îÇ       longitude  (rows, columns) float64 14MB ...\n‚îÇ       x          (rows, columns) float64 14MB ...\n‚îÇ       y          (rows, columns) float64 14MB ...\n‚îÇ   Data variables:\n‚îÇ       lst        (rows, columns) float64 14MB ...\n‚îî‚îÄ‚îÄ Group: /measurements/orphan\n        Dimensions:    (rows: 1200, orphan_pixels: 187)\n        Coordinates:\n            latitude   (rows, orphan_pixels) float64 2MB ...\n            longitude  (rows, orphan_pixels) float64 2MB ...\n            x          (rows, orphan_pixels) float64 2MB ...\n            y          (rows, orphan_pixels) float64 2MB ...\n        Dimensions without coordinates: orphan_pixels\n        Data variables:\n            lst        (rows, orphan_pixels) float64 2MB ...xarray.DataTree'measurements'/measurements/orphan(5)Dimensions:rows: 1200columns: 1500orphan_pixels: 187Coordinates: (4)latitude(rows, orphan_pixels)float64...dimensions :['rows', 'orphan_pixels']dtype :&lt;i4eopf_is_masked :Trueeopf_target_dtype :&lt;f8fill_value :-2147483648long_name :latitude of detector FOV centre on the earth's surfacestandard_name :latitudeunits :degrees_northvalid_max :90000000valid_min :-90000000[224400 values with dtype=float64]longitude(rows, orphan_pixels)float64...dimensions :['rows', 'orphan_pixels']dtype :&lt;i4eopf_is_masked :Trueeopf_target_dtype :&lt;f8fill_value :-2147483648long_name :longitude of detector FOV centre on the earth's surfacestandard_name :longitudeunits :degrees_eastvalid_max :180000000valid_min :-180000000[224400 values with dtype=float64]x(rows, orphan_pixels)float64...dimensions :['rows', 'orphan_pixels']dtype :&lt;i4eopf_is_masked :Trueeopf_target_dtype :&lt;f8fill_value :-1000000long_name :geolocated x (across track) coordinate of detector FOV centreunits :mvalid_max :1000000valid_min :-500000[224400 values with dtype=float64]y(rows, orphan_pixels)float64...dimensions :['rows', 'orphan_pixels']dtype :&lt;i4eopf_is_masked :Trueeopf_target_dtype :&lt;f8fill_value :-5000000long_name :geolocated y (along track) coordinate of detector FOV centreunits :mvalid_max :50000000valid_min :-1000000[224400 values with dtype=float64]Data variables: (1)lst(rows, orphan_pixels)float64..._eopf_attrs :{'add_offset': 290.0, 'coordinates': ['x', 'y', 'latitude', 'longitude'], 'dimensions': ['rows', 'orphan_pixels'], 'dtype': '&lt;i2', 'eopf_is_masked': True, 'eopf_target_dtype': '&lt;f4', 'fill_value': -32768, 'long_name': 'ungridded land surface temperature', 'scale_factor': 0.0020000000949949026, 'short_name': 'lst_orphan', 'standard_name': 'surface_temperature', 'units': 'K', 'valid_max': 32767, 'valid_min': -32767}dtype :&lt;i2long_name :ungridded land surface temperaturestandard_name :surface_temperatureunits :K[224400 values with dtype=float64]Dimensions:rows: 1200columns: 1500Coordinates: (6)rows(rows)int640 1 2 3 4 ... 1196 1197 1198 1199dimensions :['rows']dtype :&lt;i8long_name :rows of image nadir viewarray([   0,    1,    2, ..., 1197, 1198, 1199], shape=(1200,))columns(columns)int640 1 2 3 4 ... 1496 1497 1498 1499dimensions :['columns']dtype :&lt;i8long_name :columns of image nadir viewarray([   0,    1,    2, ..., 1497, 1498, 1499], shape=(1500,))latitude(rows, columns)float64...dimensions :['rows', 'columns']dtype :&lt;i4eopf_is_masked :Trueeopf_target_dtype :&lt;f8fill_value :-2147483648long_name :latitude of detector FOV centre on the earth's surfacestandard_name :latitudeunits :degrees_northvalid_max :90000000valid_min :-90000000[1800000 values with dtype=float64]longitude(rows, columns)float64...dimensions :['rows', 'columns']dtype :&lt;i4eopf_is_masked :Trueeopf_target_dtype :&lt;f8fill_value :-2147483648long_name :longitude of detector FOV centre on the earth's surfacestandard_name :longitudeunits :degrees_eastvalid_max :180000000valid_min :-180000000[1800000 values with dtype=float64]x(rows, columns)float64...dimensions :['rows', 'columns']dtype :&lt;i4eopf_is_masked :Trueeopf_target_dtype :&lt;f8fill_value :-1000000long_name :geolocated x (across track) coordinate of detector FOV centreunits :mvalid_max :1000000valid_min :-500000[1800000 values with dtype=float64]y(rows, columns)float64...dimensions :['rows', 'columns']dtype :&lt;i4eopf_is_masked :Trueeopf_target_dtype :&lt;f8fill_value :-5000000long_name :geolocated y (along track) coordinate of detector FOV centreunits :mvalid_max :50000000valid_min :-1000000[1800000 values with dtype=float64]Data variables: (1)lst(rows, columns)float64..._eopf_attrs :{'add_offset': 290.0, 'coordinates': ['rows', 'columns', 'x', 'y', 'latitude', 'longitude'], 'dimensions': ['rows', 'columns'], 'dtype': '&lt;i2', 'eopf_is_masked': True, 'eopf_target_dtype': '&lt;f4', 'fill_value': -32768, 'long_name': 'gridded land surface temperature', 'scale_factor': 0.0020000000949949026, 'short_name': 'lst', 'standard_name': 'surface_temperature', 'units': 'K', 'valid_max': 32767, 'valid_min': -32767}dtype :&lt;i2long_name :gridded land surface temperaturestandard_name :surface_temperatureunits :K[1800000 values with dtype=float64]\n\n\nTo effectively overlay the data, we first need to process the Land Surface Temperature (LST) asset to cover the same area of interest. We can accomplish this by applying our pre-defined masking functions. Since the LST data is presented in EPSG:4326, we will use the zarr_mask_latlon() function to generate the boolean mask of interest over the data, followed by the mask_sub_latlon() function, which clips it to our area of interest.\n\n# The zarr_mask_latlon function is used to create a mask based on a bounding box and the measurements data\ncols_lst , rows_lst = zarr_mask_latlon(\n    bbox_vis, # The input bounding box\n    meas_lst # The measurements group from the zarr data tree\n    )\n# The mask_sub_latlon function then clips the land surface temperature data\nlst_clip = mask_sub_latlon(\n    meas_lst.lst, # The land surface temperature band from the measurements group\n    rows_lst, # The row indices for the mask\n    cols_lst # The column indices for the mask\n    ).values\n\n# The latitude data is clipped using the same mask indices\nlat_lst = mask_sub_latlon(meas_lst['latitude'],rows_lst, cols_lst).values\n# The longitude data is clipped using the same mask indices\nlon_lst = mask_sub_latlon(meas_lst['longitude'],rows_lst, cols_lst).values\n\nAfter clipping the data to our defined area of interest, we apply the temperature threshold to the data, filtering for only those pixels with temperatures above 312 Kelvin. This temperature range is a strong indicator of heat anomalies, which are often associated with active or developing fires.\n\n# To clip the data and prepare the array for an overlay with the TCI:\nlstf_clip = np.where(\n    lst_clip &lt;= 312, # values less than or equal to 312 K\n    np.nan, # The value to assign if the condition is true\n    lst_clip # The value to assign if the condition is false\n    )\n\nCreating a custom colour map that uses shades of red, with the most vibrant red indicating the hottest areas will enhance our visualisation. This colour map is applied to the LST data, allowing us to clearly and intuitively see the heat signatures that correspond with potential fire activity when the two layers are overlayed.\n\n# For colour ramp:\ncol_map = ListedColormap([[1., 140./255., 0],[178./255., 34./255., 34./255.],[1, 0, 0]]) # red composite shades\n# Define the boundaries for each colour in the ramp\nbounds = [300, 305, 310, 315]\n# Calculate the number of colours, which is one less than the number of bounds\nncolors = len(bounds) - 1\n# Create a normalisation object to map data values to colours based on the defined bounds\nnorm = BoundaryNorm(bounds, col_map.N)\n\n# Use the box() function to create a polygon from the coordinates\nmap_box = box(map_box[0],map_box[1],map_box[2],map_box[3])\n\nThe final step of the Sentinel-3 SLSTR data processing is to visualise the temperature anomalies. We will prepare the filtered LST data to be overlaid over the True-Color composite of Sentinel-2 L2 data.\n\n\n# Create a figure to plot\nfig, axs = plt.subplots(1, 2)\naxs[0].imshow(lst_clip)\naxs[0].set_title('Clipped LST')\n# Plot the filtered land surface temperature data on the second subplot\naxs[1].imshow(lstf_clip)\naxs[1].set_title('Filtered LST') # Add a title for clarity\n# Adjust the layout\nfig.tight_layout()\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCreate Sentinel-2 L2A True-Color composite\nFollowing the parameters we defined before and the workflow described in the first part of this notebook series, we will filter the Sentinel-2 L2A data collection to match our event and AOI. This ensures that the visualisations we create are directly relevant to the fire event and set the stage for comparing it with the Land Surface Temperature data from Sentinel-3.\n\n# Interest timeframe parameters for the filtering\ndate_p = fire_d_s3 + 'T00:00:00Z/' + fire_d_s3 + 'T23:59:59.999999Z' # interest period\ndef_collection = 'sentinel-2-l2a' # collection\n\ns2_col = list(eopf_catalog.search(\n                bbox= search_bbox, # area\n                datetime= date_p, #time frame\n                collections=def_collection # collection\n                ).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_col]\n\nprint(av_urls)\n\n['https://objects.eodc.eu:443/e05ab01a9d56408d82ac32d69a5aae2a:202510-s02msil2a-eu/21/products/cpm_v256/S2A_MSIL2A_20251021T101101_N0511_R022_T32TMK_20251021T115713.zarr']\n\n\nAs we can see, there is no capture available for the day on which the fire occurred. This is because Sentinel-2 L2A has a revisit time of five days at the equator, making it possible that, even when the constellation is synchronously retrieving data, the day in question may not be available. In this case, we define the capture date as the one closest to the event, the 11th June 2025.\n\n# Interest timeframe parameters for the filtering\ndate_p = fire_d + 'T00:00:00Z/' + fire_d + 'T23:59:59.999999Z' # interest period\ndef_collection = 'sentinel-2-l2a' # collection\ns2_col = list(eopf_catalog.search(\n                bbox= search_bbox, # area\n                datetime= date_p, #time frame\n                collections=def_collection # collection\n                ).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_col] \nav_urls\n\n['https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:notebook-data/tutorial_data/cpm_v264/S2C_MSIL2A_20250611T101041_N0511_R022_T32TMK_20250611T175918.zarr']\n\n\nOnce we have obtained the available items from the Sentinel-2 L2A collection, we can open the asset as a xarray.DataTree.\nTo prepare the data for further processing, we will extract key metadata like the collection, date, time, and the spectral bands needed for the visualisation (which are conveniently grouped under r20m group).\nThese True-Color composite processing steps include: - Masking of invalid pixels - Clipping to AOI - Band selection - Normalisation - Composite creation - Equalisation\n\nMasking out invalid pixels\n\n# We are interested in the datasets contained in the measurements bands for True Colour and False Colour Composites.\ns2_zarr = xr.open_datatree(\n    av_urls[0], engine=\"zarr\", #we always get the earliest one (the first available item goes last)\n    chunks={},\n    decode_timedelta=False\n    )\n\n# Store interest parameters for further plotting:\ndate = s2_zarr.attrs['stac_discovery']['properties']['start_datetime'][:10]\ntime_zarr = s2_zarr.attrs['stac_discovery']['properties']['start_datetime'][11:19]\n# target_crs = s2_zarr.attrs[\"stac_discovery\"][\"properties\"][\"proj:epsg\"]\n# Extract the resolution group we are interested to analyse over:\nzarr_meas = s2_zarr.measurements.reflectance.r20m\n\n# Extract the cloud free mask at 20m resolution:\nl2a_class_20m = s2_zarr.conditions.mask.l2a_classification.r20m.scl\nvalid_mask = validate_scl(l2a_class_20m)  # Boolean mask (10980x10980)\n\n\n\nClipping to AOI\nIn a next step, we clip the retrieved item to our defined area of interest (AOI).\n\n# True colour channels we are interested to retrieve coposite:\ntc_red  = 'b04'\ntc_green= 'b03'\ntc_blue = 'b02'\n\n# Boolean mask for the 'x' dimension (longitude/easting)\nx_mask = (zarr_meas['x'] &gt;= bbox_utm[0]) & (zarr_meas['x'] &lt;= bbox_utm[2])\n# Boolean mask for the 'y' dimension (latitude/northing)\ny_mask = (zarr_meas['y'] &gt;= bbox_utm[1]) & (zarr_meas['y'] &lt;= bbox_utm[3])\n\n# Combined mask for the bounding box\nbbox_mask = x_mask & y_mask\n\n# Extract row and column indices where the mask is True\ncols, rows = np.where(bbox_mask)\n\n\n\nBand selection, normalisation composite creation and equalisation\nIn the next step, we proceed to select the relevant bands from the item, apply normalisation and equalisation, in order to visualise the True-Color composite of 11 June 2025 over the Nuoto region in Sardinia.\n\n# The tc_red, tc_green, and tc_blue variables are inputs specifying the band names\nred = zarr_meas[tc_red].where(valid_mask)\ngre =  zarr_meas[tc_green].where(valid_mask)\nblu =  zarr_meas[tc_blue].where(valid_mask)\n\n# The mask_sub_utm() function takes the bands and masks them to the valid rows and columns\nred = mask_sub_utm(red,rows, cols).values\ngre = mask_sub_utm(gre,rows, cols).values\nblu = mask_sub_utm(blu,rows, cols).values\n\n# The zarr_meas group is the input dataset containing the dimensions\n# by slicing the 'y' dimension array based on the minimum and maximum row indices\ny_zarr = zarr_meas['y'].isel(y=slice(rows.min(), rows.max() + 1)).values\n# also, the same for the 'x' dimension array based on the minimum and maximum column indices\nx_zarr = zarr_meas['x'].isel(x=slice(cols.min(), cols.max() + 1)).values\n\nmap_ext_deg = list(t_utm_to_deg.transform(np.nanmin(x_zarr),np.nanmin(y_zarr)) + \n                   t_utm_to_deg.transform(np.nanmax(x_zarr),np.nanmax(y_zarr)))\n\n# Input: percentile range for contrast stretching\ncontrast_stretch_percentile=(2, 98)\n# Input: gamma correction value\ngamma=1.8\n\n# Apply normalisation to the red, green and blue bands using the specified percentile and gamma values\nred_processed = normalisation_str_gm(red, *contrast_stretch_percentile, gamma)\ngreen_processed = normalisation_str_gm(gre, *contrast_stretch_percentile, gamma)\nblue_processed = normalisation_str_gm(blu, *contrast_stretch_percentile, gamma)\n\n# We stack the processed red, green, and blue arrays\nrgb_composite_sm = np.dstack((red_processed, green_processed, blue_processed)).astype(np.float32)\n\n#Adding equalisation from skimage:\nfire_tc = exposure.equalize_adapthist(rgb_composite_sm)\n\n\nplt.imshow(fire_tc)\nplt.title('Equalised Composite') # Add a title for clarity\n\nText(0.5, 1.0, 'Equalised Composite')\n\n\n\n\n\n\n\n\n\n\n\n\nOverlay Sentinel-2 True-Color composite with Sentinel-3 LST data\nAnd finally, we can georeference and overlay the two datasets, the True-Color composite from Sentinel-2 as well as the Land Surface Temperature information from Sentinel-3.\n\n#Overlay\nplt.figure(figsize=(14, 8))\n# Define the coordinate reference system (CRS) for latitude/longitude\ndata_ll = ccrs.PlateCarree()\n\nax = plt.axes(projection=data_ll)\n# Display the Sentinel-2 true-colour composite (TCI) image\nimg = ax.imshow(fire_tc, origin='upper',\n                extent=[map_ext_deg[0],map_ext_deg[2],map_ext_deg[1],map_ext_deg[3]],  # item\n                transform=data_ll)\n# Display the land surface temperature (LST) data as an overlay\nim2 = ax.imshow(lstf_clip, origin='upper',\n                extent=[np.nanmin(lon_lst), np.nanmax(lon_lst),\n                        np.nanmin(lat_lst), np.nanmax(lat_lst)],\n                transform=data_ll, # coordinates\n                cmap=col_map,  norm=norm) # The custom colour map for LST\ncbar = plt.colorbar(im2,ticks=bounds, shrink=0.3)\ncbar.set_label(\"Land Surface Temperature (K)\")\n\n\n# features\nax.add_geometries(map_box, crs=data_ll, facecolor='none', edgecolor='yellow', linewidth=2, linestyle='-')\nax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # Add gridlines and labels\n\n# Adjust title and plot parameters for a tight layout\nplt.title(f'Sentinel-2 L2A TCI + LST for the {fire_d_s3}', fontsize=16)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe Sentinel-2 L2A provides the geographical context of the landscape, while the Sentinel-3 SLSTR LST information provides an indication of the hottest areas on that day. This allows for a more accurate and immediate understanding of a fire‚Äôs behaviour during the event. We can see that the hottest detected spot over the area of interest is indeed aligned with the fire event location.\nThe overlay provides additional information, especially in conditions where optical views are limited. For example, during less light hours or through heavy smoke, the thermal data can still reveal the fire‚Äôs true footprint.\n\n\nCalculating processing time\n\net = time.time()\n\ntotal_t = et - st\n\nprint('Total Running Time: ', total_t,' seconds')\n\nTotal Running Time:  29.77818512916565  seconds\n\n\nA significant takeaway from this process is its remarkable speed. The entire workflow, from data access to visualisation, is completed in under two minutes. Here is the key evident advantage of using .zarr encoding for wildfire detection.  EOPF enables us to quickly access and combine Sentinel data directly from the cloud without the need to download large volumes of data.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/62_sardinia_s3_lst.html#conclusion",
    "href": "06_eopf_zarr_in_action/62_sardinia_s3_lst.html#conclusion",
    "title": "Fire in Sardinia 2025 - Part 2",
    "section": "Conclusion",
    "text": "Conclusion\nBy integrating items from Sentinel-2 with critical thermal data from Sentinel-3 through the EOPF STAC Catalog Collections, this notebook has demonstrated a complete and efficient workflow for analysing a real-world wildfire event. \nWe were able to create a powerful overlay that not only shows the geographical context of the burnt area but also precisely identifies the active heat signatures associated with the fire. This approach proves that combining different types of satellite data is essential for gaining a complete understanding of complex environmental events.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/62_sardinia_s3_lst.html#whats-next",
    "href": "06_eopf_zarr_in_action/62_sardinia_s3_lst.html#whats-next",
    "title": "Fire in Sardinia 2025 - Part 2",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nBuilding on our visual analysis, the next notebook will introduce a quantitative method to assess fire severity. We will calculate the Normalised Burn Ratio (NBR) using data from Sentinel-2 satellite imagery.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/63_sardinia_dNBR.html",
    "href": "06_eopf_zarr_in_action/63_sardinia_dNBR.html",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nThis notebook introduces the Normalised Burn Ratio (NBR), a key index used in satellite remote sensing to assess burn severity. The NBR quantifies the severity of damage from wildfires. The NBR is calculated using near-infrared and shortwave infrared bands from Sentinel-2 Level 2 data to highlight vegetation and burned areas.\nBased on the NBR, we can calculate the differenced Normalised Burn Ratio (dNBR) which is a strong indicator of the severity of a fire‚Äôs impact on vegetation. The index can be interpreted as follows:\nTo calculate the dNBR, we will first calculate the NBR before and after a fire event. The post-fire NBR image is then subtracted from the pre-fire NBR image to produce the dNBR image.\nThis notebook is the second a series of three notebooks:",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#setting-up-the-environment",
    "href": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#setting-up-the-environment",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "Setting up the environment",
    "text": "Setting up the environment\n\nInitiate a Dask cluster\nThe first step is to initiate a virtual Dask cluster consisting of a scheduler that manages tasks and multiple workers that process them.\n\ncluster = LocalCluster()\nclient = cluster.get_client()\nclient\n\n\n     \n    \n        Client\n        Client-1c06c7cf-0817-11f1-9c81-e24da843f2da\n        \n\n\n\nConnection method: Cluster object\nCluster type: distributed.LocalCluster\n\n\nDashboard: http://127.0.0.1:8787/status\n\n\n\n\n\n\n        \n            \n                Launch dashboard in JupyterLab\n            \n        \n\n        \n            \n            Cluster Info\n            \n    \n    \n    \n        LocalCluster\n        4dd9f659\n        \n\n\n\nDashboard: http://127.0.0.1:8787/status\nWorkers: 4\n\n\nTotal threads: 8\nTotal memory: 31.35 GiB\n\n\nStatus: running\nUsing processes: True\n\n\n\n\n\n        \n            \n                Scheduler Info\n            \n\n            \n    \n         \n        \n            Scheduler\n            Scheduler-fdff3ffd-ce4e-43f0-82d1-b79201bd7e0c\n            \n\n\n\nComm: tcp://127.0.0.1:46303\nWorkers: 0\n\n\nDashboard: http://127.0.0.1:8787/status\nTotal threads: 0\n\n\nStarted: Just now\nTotal memory: 0 B\n\n\n\n\n        \n    \n\n    \n        \n            Workers\n        \n\n        \n        \n             \n            \n            \n                \n                    Worker: 0\n                \n                \n\n\n\nComm: tcp://127.0.0.1:39601\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:39961/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:37845\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-frjxgp9t\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 1\n                \n                \n\n\n\nComm: tcp://127.0.0.1:41457\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:46205/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:42083\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-avm75pz1\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 2\n                \n                \n\n\n\nComm: tcp://127.0.0.1:37351\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:44223/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:45573\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-dee78j8t\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 3\n                \n                \n\n\n\nComm: tcp://127.0.0.1:46769\nTotal threads: 2\n\n\nDashboard: http://127.0.0.1:39065/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:42297\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-3ijtew9_\n\n\n\n\n            \n            \n        \n        \n\n    \n\n\n        \n    \n\n            \n        \n\n    \n\n\n\n\n\nDefine workflow variables\nFollowing Part 1 of, we need to define the specific spatial and temporal parameters for our analysis. We will set the same area of interest over the Province of Nuoro Sardinia, Italy. We define the dates for our pre-fire and post-fire period.\nAccording to EFFIS‚Äôs definition, the severity for each fire is calculated after 30 days of the date of the fire, and it can be classified as follows:\n\n\n\nClass\ndNBR range (multiplied by 1000)\n\n\n\n\nUnburned or Regrowth\n&lt; 100\n\n\nLow severity\n100 - 270\n\n\nModerate low severity\n270 - 440\n\n\nModerate high severity\n440 - 660\n\n\nHigh severity\n&gt;= 660\n\n\n\nFor the pre-fire state, we will use an image from 3rd of June 2025, and due to data avilability, the closest available image for post fire state is set to 3rd July 2025. Additional information such as CRS and the relevant Sentinel-2 Level 2 bands, Near Infra Red (NIR) (B8a) and Short Wave Infrared (SWIR) (B12), are set.\n\n# Dates of interest\n# Before the fire:\npre_f  = '2025-06-03'\n# After the fire:\npost_f = '2025-07-03'\n\n# The area of interest for our filtering\nbbox = (8.847198,40.193395,\n        8.938865,40.241895)\n\n# Definition of the transformer parameters for reprojection and correct overlay of layers\ntransformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32632\", always_xy=True)\nt_utm_to_deg = Transformer.from_crs(\"EPSG:32632\",\"EPSG:4326\", always_xy=True)\n\n# The false colour channels we are interested to retrieve coposite:\nswir = 'b12'\nnir =  'b8a'\n\n# Defining a larger bounding box for better visualisation:\nbbox_vis = (8.649555,40.073583,\n          9.127893,40.343840)\n\n# A fixed geographic bounding box to highlight the AOI in the map format\nmap_box = bbox\n# A new list with the converted UTM coordinates\nbbox_utm = lat_lon_to_utm_box((bbox_vis[0], bbox_vis[1]),(bbox_vis[2], bbox_vis[3]),transformer)\n\ndef_collection = 'sentinel-2-l2a' #collection\n\n# we are interested in the performance the code will have\nst = time.time()\n\n\n\nEstablish a connection to the EOPF STAC Catalog\nAdditionally, we also need to establish a connection to the EOPF STAC catalog.\n\neopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\" #root starting point\neopf_catalog = Client.open(url=eopf_stac_api_root_endpoint) # calls the selected url\neopf_catalog\n\n\n\n\n\n\n    &lt;Client id=eopf-sample-service-stac-api&gt;\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Catalog\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"eopf-sample-service-stac-api\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"STAC catalog of the EOPF Sentinel Zarr Samples Service\"\n        \n    \n                \n            \n                \n                    \n        links[] 21 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"conformance\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/conformance\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC/OGC conformance classes implemented by this server\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"POST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l2a\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-2A\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-grd\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 GRD\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l1-rbt\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-1 RBT\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lfr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l2-lst\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-2 LST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-slstr-l2-frp\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 SLSTR Level-2 FRP\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l2-lrr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-2 LRR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-efr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 EFR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-2-l1c\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-2 Level-1C\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l1-slc\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-1 SLC\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-3-olci-l1-err\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-3 OLCI Level-1 ERR\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \n        \n            \n                \n        \n            rel\n            \"child\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/collections/sentinel-1-l2-ocn\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sentinel-1 Level-2 OCN\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \n        \n            \n                \n        \n            rel\n            \"service-desc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/vnd.oai.openapi+json;version=3.0\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service description\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \n        \n            \n                \n        \n            rel\n            \"service-doc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.core.eopf.eodc.eu/api.html\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service documentation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        conformsTo[] 21 items\n        \n            \n        \n            \n                \n        \n            0\n            \"http://www.opengis.net/spec/cql2/1.0/conf/basic-cql2\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-text\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/geojson\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/oas30\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/features-filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \"https://api.stacspec.org/v1.0.0-rc.2/item-search#filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \"https://api.stacspec.org/v1.0.0/collections\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \"https://api.stacspec.org/v1.0.0/collections/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \"https://api.stacspec.org/v1.0.0/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \"https://api.stacspec.org/v1.0.0/item-search\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \"https://api.stacspec.org/v1.0.0/item-search#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \"https://api.stacspec.org/v1.0.0/item-search#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \"https://api.stacspec.org/v1.0.0/item-search#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"EOPF Sentinel Zarr Samples Service STAC API\"",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#calculation-of-nbr---pre-fire",
    "href": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#calculation-of-nbr---pre-fire",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "Calculation of NBR - Pre-Fire",
    "text": "Calculation of NBR - Pre-Fire\nNow we can use our defined parameters to query the STAC catalog and to retrieve all available Sentinel-2 imagery that correspond to our query arguments.\n\n# We define the search over the whole day, from 12:00 am to 11:59 pm\ndate_pre = pre_f + 'T00:00:00Z/' + pre_f + 'T23:59:59.999999Z' # interest period\n\ns2_pre = list(eopf_catalog.search(\n                bbox= bbox, \n                datetime= date_pre,\n                collections=def_collection).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_pre]\nav_urls\n\n['https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:notebook-data/tutorial_data/cpm_v264/S2A_MSIL2A_20250603T101041_N0511_R022_T32TMK_20250603T134103.zarr']\n\n\nNow we open the retrieved item as a xarray.DataTree. This image will serve as our baseline for the pre-fire conditions, providing a clean snapshot of the landscape before the event. We extract the r20m group under measurements group, as this is the resolution we will be focusing on. We also mask out all invalid pixels by applying the function validate_scl().\n\n# Open the last Zarr item from the list of URLs as a data tree.\npre_zarr = xr.open_datatree(\n    av_urls[0], engine=\"zarr\",\n    chunks={},\n    )\n\n# Select the 20m reflectance measurements from the data tree.\nzarr_meas_pre = pre_zarr.measurements.reflectance.r20m\n\n# Extractthe cloud free mask at 20m resolution:\nl2a_class_20m_pre = pre_zarr.conditions.mask.l2a_classification.r20m.scl\nvalid_mask_pre = validate_scl_w(l2a_class_20m_pre)  # Boolean mask\n\nTo calculate the Normalised Burn Ratio (NBR), we will access the specific spectral bands we need: the Near-Infrared (NIR) band (B8A) and the Shortwave Infrared (SWIR) band (B12).\nOnce we access them, we need to ensure our data features our area of interest (AOI). We will apply the same masking and clipping functions used in our previous tutorial to clip the imagery to our precise bbox_utm.\n\n# Create UTM masks for rows and columns based on the bounding box.\ncols_pre, rows_pre= zarr_mask_utm (bbox_utm, zarr_meas_pre)\n\n# Extract and slice the y-dimension values from the Zarr measurement.\ny_zarr = zarr_meas_pre['y'].isel(y=slice(rows_pre.min(), rows_pre.max() + 1)).values\n# Extract and slice the x-dimension values from the Zarr measurement.\nx_zarr = zarr_meas_pre['x'].isel(x=slice(cols_pre.min(), cols_pre.max() + 1)).values\n\n# Select the red, green, and blue bands and apply the valid mask.\nswir_pre = zarr_meas_pre[swir].where(valid_mask_pre)\nnir_pre =  zarr_meas_pre[nir].where(valid_mask_pre)\n\n# Mask and clip the selected bands using the row and column indices.\nswir_pre = mask_sub_utm(swir_pre,rows_pre, cols_pre).values\nnir_pre = mask_sub_utm(nir_pre,rows_pre, cols_pre).values\n\nOnce we obtain the masked assets, we can visualise them before calculating the NBR.\n\n# Create a figure to plot\nfig, axs = plt.subplots(1, 2)\naxs[0].imshow(nir_pre)\naxs[0].set_title(f'NIR (b8) for the {pre_f}')\n# Plot the filtered land surface temperature data on the second subplot\naxs[1].imshow(swir_pre)\naxs[1].set_title(f'SWIR (b12) for the {pre_f}') # Add a title for clarity\n# Adjust the layout\nfig.tight_layout()\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nWith our swir_pre and nir_pre bands ready, we can now calculate the pre-fire NBR image. We will apply the following NBR formula:\n\\[\\frac{(NIR - SWIR)} {(NIR + SWIR)}\\]\nAn important consideration for this process is the possibility of division by zero when calculating the composite. To prevent this, we create a mask that assigns a value of 1 to any pixel that is 0, while keeping the original values for all other pixels.\n\n# We calculate the nbr for our pre fire event\npre_difference = nir_pre - swir_pre\n\n# to deal with 0 divisions on the NBR formula\n\npre_addition = nir_pre + swir_pre\n\n# we create a mask to detect possible 0 values\nzero_mask = (pre_addition == 0)\npre_z= pre_addition.copy()\n\npre_z = da.where(pre_addition == 0, 1, pre_z)\n\n\n# Calculatig our NBR for the moment before the fire:\n\nnbr_pre  = da.where(pre_addition == 0, 0, pre_difference / pre_z)\n\nNow, we can visualise the calculated pre-fire NBR image.\n\n# Visualising the clipped red band:\nplt.imshow(nbr_pre, vmin=-1.0, vmax=1.0)\nplt.title(f'NBR from the {pre_f}')\n\nText(0.5, 1.0, 'NBR from the 2025-06-03')",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#calculation-of-nbr---post-fire",
    "href": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#calculation-of-nbr---post-fire",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "Calculation of NBR - Post-Fire",
    "text": "Calculation of NBR - Post-Fire\nThe next step is to repeat the same steps as above and to calculate a post-fire NBR image.\nWe first query the EOPF STAC catalog for items avialble on 3 July 2025, open the retrieved item as xarray.DataTree and mask out invalid pixels.\n\n# We define the search over the whole day, from 12:00 am to 11:59 pm\ndate_post = post_f + 'T00:00:00Z/' + post_f + 'T23:59:59.999999Z' # interest period\n\ns2_post = list(eopf_catalog.search(\n                bbox= bbox, \n                datetime= date_post,\n                collections=def_collection).item_collection())\n\nav_urls = [item.assets[\"product\"].href for item in s2_post]\n\npost_zarr = xr.open_datatree(\n    av_urls[-1], engine=\"zarr\", #we always get the earliest one (last)\n    chunks={},\n    )\n\nzarr_meas_post = post_zarr.measurements.reflectance.r20m\n\n# Extractthe cloud free mask at 20m resolution:\nl2a_class_20m_post = post_zarr.conditions.mask.l2a_classification.r20m.scl\nvalid_mask_post = validate_scl_w(l2a_class_20m_post)  # Boolean mask\n\nIn a next step, we follow the same masking and clipping functions to this new dataset to ensure it is focused on our area of interest.\n\n# Create UTM masks for rows and columns based on the bounding box.\ncols_post, rows_post= zarr_mask_utm(bbox_utm, zarr_meas_post)\n\n# Slice the y-dimension values using the new row indices.\ny_zarr = zarr_meas_post['y'].isel(y=slice(rows_post.min(), rows_post.max() + 1)).values\n# Slice the x-dimension values using the new column indices.\nx_zarr = zarr_meas_post['x'].isel(x=slice(cols_post.min(), cols_post.max() + 1)).values\n\n# define our zarr extracted coordinates\nmap_ext_deg = list(t_utm_to_deg.transform(np.nanmin(x_zarr),np.nanmin(y_zarr)) + \n                   t_utm_to_deg.transform(np.nanmax(x_zarr),np.nanmax(y_zarr)))\n\n# Select the red, green, and blue bands and apply the valid mask.\nswir_post = zarr_meas_post[swir].where(valid_mask_post)\nnir_post =  zarr_meas_post[nir].where(valid_mask_post)\n\n# Mask and clip the selected bands using the row and column indices.\nswir_post = mask_sub_utm(swir_post,rows_post, cols_post).values\nnir_post = mask_sub_utm(nir_post,rows_post, cols_post).values\n\nAfter our masking, we obtain the following bands\n\n# Create a figure to plot\nfig, axs = plt.subplots(1, 2)\naxs[0].imshow(nir_post)\naxs[0].set_title(f'NIR (b8) for the {post_f}')\n# Plot the filtered land surface temperature data on the second subplot\naxs[1].imshow(swir_post)\naxs[1].set_title(f'SWIR (b12) for the {post_f}') # Add a title for clarity\n# Adjust the layout\nfig.tight_layout()\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nWith our post-fire bands, we can now calculate the Post-Fire NBR. We apply the 0 division consideration masking and the NBR formula again to these bands to get the post-fire NBR image.\n\n# We calculate the nbr for our post fire event\npost_difference = nir_post - swir_post\n\n# to deal with 0 divisions on the NBR formula\npost_addition = nir_post + swir_post\n\n# we create a mask to detect possible 0 values\nzero_mask = (post_addition == 0)\npost_z= post_addition.copy()\n\npost_z = da.where(post_addition == 0, 1, post_z)\n\nnbr_post  = da.where(post_addition == 0, 0, post_difference / post_z)\n\n# Visualising the clipped red band:\nplt.imshow(nbr_post, vmin=-1.0, vmax=1.0)\nplt.title(f'NBR from the {post_f}')\n\nText(0.5, 1.0, 'NBR from the 2025-07-03')",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#calculate-differenced-nbr-dnbr",
    "href": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#calculate-differenced-nbr-dnbr",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "Calculate Differenced NBR (dNBR)",
    "text": "Calculate Differenced NBR (dNBR)\nThe last calculation step for our analysis is the delta NBR (dNBR). This index is calculated by subtracting the post-fire NBR from the pre-fire NBR. Higher dNBR values indicate more severe damage, providing a quantitative measure of the fire‚Äôs impact.\n\\[dNBR = prefireNBR - postfireNBR\\]\n\n# Calculate the delta Normalised Burn Ratio (dNBR) by subtracting the post-fire NBR from the pre-fire NBR.\ndNBR = (nbr_pre - nbr_post) * 1000\n\n# bringing the dNBR to memory\ndNBR_c = dNBR.compute()\n\nAs our calculation was based on dask array for a faster computation, we bring it back to memory and multiply it by 1000 to be able to compare it to Key & Benson (2006) severity thresholds, proposed by EFFIS.\n\n# Visualising the clipped red band:\n# plt.imshow(dNBR)\nplt.imshow(dNBR, vmin=-1000.0, vmax=1000.0)\nplt.title(f'Calculated dNBR')\n\nText(0.5, 1.0, 'Calculated dNBR')\n\n\n\n\n\n\n\n\n\nFinally, we will plot our results to visualise the burn severity. Using the cartopy library, we can create a georeferenced map that accurately displays our data based on its CRS and geospatial bounding box.\nThe dNBR data will be presented on this map using a colour scheme that clearly highlights the most affected areas by the fire.\n\n# Creating the Geometry\nmap_box = box(map_box[0],map_box[1],map_box[2],map_box[3])\n\n#Overlay\nplt.figure(figsize=(15, 10))\n# Create a figure with a specified size.\ndata_ll = ccrs.PlateCarree()\n# Set up the plot with a defined projection.\nax = plt.axes(projection=data_ll)\n\n# Display the Differenced Normalised Burn Ratio (dNBR)\nim = ax.imshow(dNBR_c, origin='upper',\n                extent=(bbox_vis[0],bbox_vis[2],\n                        bbox_vis[1],bbox_vis[3]),  # item\n                         vmin=-1000.0, vmax=1000.0,\n                transform=data_ll)\n\n# features\nplt.colorbar(im, ax=ax, label='dNBR Value')\nax.add_geometries([map_box], crs=data_ll, facecolor='none', edgecolor='yellow', linewidth=2, linestyle='-')\nax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False) # Add gridlines and labels\n\n\n# Set the title of the plot.\nplt.title(f'Sentinel-2 L2A Differenced Normalised Burn ratio between {pre_f} and {post_f}', fontsize=16)\n# Adjust plot to ensure all elements fit without overlapping.\nplt.tight_layout()\n# Show the final plot.\nplt.show()\n\n\n\n\n\n\n\n\nAs the plot shows, the burn scar provides a spectral response through dNBR, even after the asset was clipped to remove clouds and water bodies. The severity values are over 750, which classifies this as being in the high-severity range of Key & Benson (2006).\n\n\n\nClass\ndNBR range (multiplied by 1000)\n\n\n\n\nUnburned or Regrowth\n&lt; 100\n\n\nLow severity\n100 - 270\n\n\nModerate low severity\n270 - 440\n\n\nModerate high severity\n440 - 660\n\n\nHigh severity\n&gt;= 660\n\n\n\n\nCalculating processing time\nBesides the asset‚Äôs accessibility, it is important to note the time efficiency of this monitoring workflow. The entire process, from defining the area of interest to searching, accessing, processing, and visualising the data takes less than 30 seconds.\n\net = time.time()\ntotal_t = et - st\nprint('Total Running Time: ', total_t,' seconds')\n\nTotal Running Time:  37.69795894622803  seconds",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#conclusion",
    "href": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#conclusion",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "Conclusion",
    "text": "Conclusion\nThis series of notebooks demonstrated a complete workflow for monitoring fire events using data from the Sentinel-2 and Sentinel-3 missions, providing a comprehensive view of the wildfire stages, before, during and after.\nBy leveraging the cloud-optimised zarr format, we have shown how visual and quantitative composites, plus multisource integration can provide a clear and repeatable method for assessing the severity of a wildfire occurrence.\nUnlike previous workflows, which required the local downloading and processing of large .TIFF images, the .zarr format, available through the EOPF STAC Catalog, enables users to filter and access data without having to manage massive datasets locally. Furthermore, the ability to replicate defined steps at various points in time provides a robust framework for comprehending the entire fire life cycle.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#whats-next",
    "href": "06_eopf_zarr_in_action/63_sardinia_dNBR.html#whats-next",
    "title": "Fire in Sardinia 2025 - Part 3",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following notebook, we will demonstrate how to use Sentinel-1 GRD EOPF zarr data to generate a workflow that maps flood extents over Valencia, Spain.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Fire in Sardinia 2025 - Part 3</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html",
    "href": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nSentinel-1 GRD data is particularly valuable to detect water and underwater areas. Synthetic Aperture Radar (SAR) can capture images day and night, in any weather, a feature especially important for flooding events, where cloudy and rainy weather can persist for weeks. This makes it far more reliable than optical sensors during storms.\nWith its frequent revisits, wide coverage, and free high-resolution data, Sentinel-1 enables the rapid mapping of flood extents, as will be demonstrated in this workflow. VV polarization is preferred for flood mapping due to its sensitivity to water surfaces, which typically appear darker in the images compared to land surfaces.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#data-pre-processing",
    "href": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#data-pre-processing",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "Data pre-processing",
    "text": "Data pre-processing\nTo search and load the data needed for the analysis, we will follow the processes we presented in Sentinel-1 GRD structure tutorial and S1 basic operations tutorial.\nOnce we defined our interest Sentinel-1 GRD items, we can see that they contain both VH and VV polarizations. For this flood mapping context, VV polarization is the choice of interest, as water backscatter is much more visible with it, rather than with VH.\n\nLoading the datatree\nThe list below shows the names of the products we will use for the flood mapping and time series analysis. As we have seen in previous chapters, these names already contain valuable information that can be used to search for specific products within the EOPF STAC catalogue.\n\nscenes = [\"S1A_IW_GRDH_1SDV_20241007T180256_20241007T180321_056000_06D943_D46B\", \n          \"S1A_IW_GRDH_1SDV_20241019T180256_20241019T180321_056175_06E02E_2D52\", \n          \"S1A_IW_GRDH_1SDV_20241031T180256_20241031T180321_056350_06E71E_479F\", \n          \"S1A_IW_GRDH_1SDV_20241112T180255_20241112T180320_056525_06EE16_DC29\", \n          \"S1A_IW_GRDH_1SDV_20241124T180254_20241124T180319_056700_06F516_BA27\", \n          \"S1A_IW_GRDH_1SDV_20241206T180253_20241206T180318_056875_06FBFD_25AD\", \n          \"S1A_IW_GRDH_1SDV_20241218T180252_20241218T180317_057050_0702F2_0BC2\", \n          \"S1A_IW_GRDH_1SDV_20241230T180251_20241230T180316_057225_0709DD_15AC\", \n          \"S1A_IW_GRDH_1SDV_20250111T180250_20250111T180315_057400_0710C7_ADBB\", \n          \"S1A_IW_GRDH_1SDV_20250123T180249_20250123T180314_057575_0717B9_A784\", \n          \"S1A_IW_GRDH_1SDV_20250204T180249_20250204T180314_057750_071EA2_4373\", \n          \"S1A_IW_GRDH_1SDV_20250216T180248_20250216T180313_057925_0725AE_8AC7\", \n          \"S1A_IW_GRDH_1SDV_20250312T180248_20250312T180313_058275_0733E6_4F5B\", \n          \"S1A_IW_GRDH_1SDV_20250324T180248_20250324T180313_058450_073AD0_04B7\", \n          ]\n\nzarr_paths = []\nfor scene in scenes:\n    zarr_paths.append(f\"https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:notebook-data/tutorial_data/cpm_v260/{scene}.zarr\")\n\nNext, we will load all zarr datasets as xarray.Datatrees. Here we are not reading the entire dataset from the store; but, creating a set of references to the data, which enables us to access it efficiently later in the analysis.\n\nclient = Client()  # Set up local cluster on your laptop\nclient\n\n@dask.delayed\ndef load_datatree_delayed(path):\n    return xr.open_datatree(path, consolidated=True, chunks=\"auto\")\n\n# Create delayed objects\ndelayed_datatrees = [load_datatree_delayed(path) for path in zarr_paths]\n# Compute in parallel\ndatatrees = dask.compute(*delayed_datatrees)\n\nEach element inside the datatree list is a datatree and corresponds to a Sentinel-1 GRD scene datatree present on the list above.\n\n# Each element inside the datatree list is a datatree and corresponds to a Sentinel-1 GRD scene datatree present on the list above\ntype(datatrees[0]) \n\nxarray.core.datatree.DataTree\n\n\n\n\nDefining variables\n\n# Number of scenes we are working with for the time series analysis\nDATASET_NUMBER = len(datatrees) \n\nIf we run the following commented out code line we will be able to see how each datatree is organized within its groups and subgroups (as explained in this section). From this datatree, we took the groups and subgroups constant ID numbers used to open specific groups and variables such as: - Measurements group = 7 so, in order to open this group, on the first element of our list of scenes, over the first polarization VV, we do datatrees[0][datatrees[0].groups[7]] - GCP group = 28 so, in order to open this group, on the first element of our list of scenes, over the first polarization VV, we do datatrees[0][datatrees[0].groups[28]] - Calibration group = 33 so, in order to open this group, on the first element of our list of scenes, over the first polarization VV, we do datatrees[0][datatrees[0].groups[33]]\nOver the course of this notebook these IDs will be used to call variables and compute some other functions.\n\n# datatrees[0].groups\n\n\n# Opening the measurements group from the datatree\ndatatrees[0][datatrees[0].groups[7]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataTree 'measurements'&gt;\nGroup: /S01SIWGRD_20241007T180256_0025_A320_D46B_06D943_VV/measurements\n    Dimensions:       (azimuth_time: 16677, ground_range: 26061)\n    Coordinates:\n      * azimuth_time  (azimuth_time) datetime64[ns] 133kB 2024-10-07T18:02:56.455...\n        line          (azimuth_time) int64 133kB dask.array&lt;chunksize=(16677,), meta=np.ndarray&gt;\n      * ground_range  (ground_range) float64 208kB 0.0 10.0 ... 2.606e+05 2.606e+05\n        pixel         (ground_range) int64 208kB dask.array&lt;chunksize=(26061,), meta=np.ndarray&gt;\n    Data variables:\n        grd           (azimuth_time, ground_range) uint16 869MB dask.array&lt;chunksize=(4096, 8192), meta=np.ndarray&gt;xarray.DataTree'measurements'Dimensions:azimuth_time: 16677ground_range: 26061Coordinates: (4)azimuth_time(azimuth_time)datetime64[ns]2024-10-07T18:02:56.455660 ... 2...array(['2024-10-07T18:02:56.455660000', '2024-10-07T18:02:56.457159057',\n       '2024-10-07T18:02:56.458658115', ..., '2024-10-07T18:03:21.450952884',\n       '2024-10-07T18:03:21.452451942', '2024-10-07T18:03:21.453951000'],\n      shape=(16677,), dtype='datetime64[ns]')line(azimuth_time)int64dask.array&lt;chunksize=(16677,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n130.29 kiB\n130.29 kiB\n\n\nShape\n(16677,)\n(16677,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         16677 1\n\n\n\n\nground_range(ground_range)float640.0 10.0 ... 2.606e+05 2.606e+05array([0.0000e+00, 1.0000e+01, 2.0000e+01, ..., 2.6058e+05, 2.6059e+05,\n       2.6060e+05], shape=(26061,))pixel(ground_range)int64dask.array&lt;chunksize=(26061,), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n203.60 kiB\n203.60 kiB\n\n\nShape\n(26061,)\n(26061,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         26061 1\n\n\n\n\nData variables: (1)grd(azimuth_time, ground_range)uint16dask.array&lt;chunksize=(4096, 8192), meta=np.ndarray&gt;_eopf_attrs :{'coordinates': ['azimuth_time', 'line', 'pixel', 'ground_range'], 'dimensions': ['azimuth_time', 'ground_range'], 'dtype': '&lt;u2', 'long_name': 'measurement data set for GRD IW'}dtype :&lt;u2long_name :measurement data set for GRD IW\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n828.97 MiB\n81.01 MiB\n\n\nShape\n(16677, 26061)\n(4389, 9677)\n\n\nDask graph\n12 chunks in 2 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n              26061 16677\n\n\n\n\n\n\n\n\n# Some other important constant ID numbers \nMEASUREMENTS_GROUP_ID = 7\nGCP_GROUP_ID = 28\nCALIBRATION_GROUP_ID = 33\n\nWe now define the thresholds that will be used for the flood mapping analysis. These values are not fixed and they can be calibrated and adjusted to achieve a better fit for different regions or flood events.\nIn SAR imagery, open water surfaces typically appear very dark because they reflect the radar signal away from the sensor. This results in low backscatter values. In our case, pixels with a backscatter lower than approximately ‚Äì15 dB are likely to correspond to water.\n\nWATER_THRESHOLD_DB = -15\n\nIt is interesting to study the flood event over a specific point within the area of interest. Therefore, we are storing the coordinates of an anchor point inside the area which is not usually covered by water. After the heavy rain, it became flooded for a few weeks - this will be the point in which we study the evolution of the flood event.\n\nTARGET_LAT = 39.28\nTARGET_LONG = -0.30\n\n# Define bounding box for Valencia area (min_lon, min_lat, max_lon, max_lat)\nbbox = [-0.45, 39.15, -0.15, 39.40]",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#extracting-information-from-the-.zarr",
    "href": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#extracting-information-from-the-.zarr",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "Extracting information from the .zarr",
    "text": "Extracting information from the .zarr\nAs explained in the S1 basic operations tutorial, we will perform over all the selected data the following operations:\n\nAssigning latitude and longitude coordinates to the dataset\nComputing the backscatter\n\nAlso, we‚Äôll slice the data to meet our area of interest and decimate it!\n\nSlicing and decimating GRD variable\nTo begin with, we access all our .zarr items measurements groups by creating a list storing all of them.\n\nmeasurements = []\n# Looping to populate the measurements list with only the measurements groups of each dataset on the datatree list\nfor i in range(DATASET_NUMBER):\n    measurements.append(datatrees[i][datatrees[i].groups[MEASUREMENTS_GROUP_ID]].to_dataset())\n    # Execute it and store it in variable, instead of being lazy\n\nWe continue by slicing grd‚Äôs data to focus on a specific area (Valencia).\nTo properly slice the data for multiple products that will be combined into a time series, we need to use Ground Control Points (GCPs) to create a spatial mask based on latitude and longitude coordinates. This ensures that pixels across different acquisition dates correspond to the same ground locations. This is essential and speciallly necessary for accurate time series analysis since we‚Äôll need to stack the scenes on top of one another.\n\n# Plotting the first decimated GRD product from our list, corresponding to the whole scene\nmeasurements[0].grd.isel(\n        azimuth_time=slice(None, None, 20),\n        ground_range=slice(None, None, 20)).plot(vmax=300)\nplt.show()\n\n\n\n\n\n\n\n\n\nprint(\"Azimuth time has\", measurements[0].grd.shape[0], \"values.\")\nprint(\"Ground range has\", measurements[0].grd.shape[1], \"values.\")\n\nAzimuth time has 16677 values.\nGround range has 26061 values.\n\n\nWe use GCPs to create a spatial mask based on our bounding box, then use that mask to find the corresponding slice in SAR geometry (azimuth_time and ground_range). This approach ensures that each pixel represents the same ground location across different products, which is crucial for time series analysis.\n\ngrd = []\ngcp = []\n\n# Looping to populate the grd list with GCP-based spatial slicing\nfor i in range(DATASET_NUMBER):\n    # Load GCPs first\n    gcps = datatrees[i][datatrees[i].groups[GCP_GROUP_ID]].to_dataset()[[\"latitude\", \"longitude\"]]\n    \n    # Create spatial mask based on bounding box\n    mask = (\n        (gcps.latitude &lt; bbox[3]) & (gcps.latitude &gt; bbox[1]) &\n        (gcps.longitude &lt; bbox[2]) & (gcps.longitude &gt; bbox[0])\n    )\n    \n    # Find indices where mask is True\n    idx = np.where(mask == 1)\n    \n    if len(idx[0]) == 0 or len(idx[1]) == 0:\n        continue\n    \n    # Build slice with offset to ensure we capture the full area\n    offset = 2\n    i0 = int(min(idx[0]))\n    i1 = int(max(idx[0]))\n    j0 = int(min(idx[1]))\n    j1 = int(max(idx[1]))\n    \n    azimuth_time_slice = slice(max(0, i0 - offset), min(mask.shape[0], i1 + offset + 1))\n    ground_range_slice = slice(max(0, j0 - offset), min(mask.shape[1], j1 + offset + 1))\n    \n    # Slice GCPs\n    gcps_crop = gcps.isel(\n        azimuth_time=azimuth_time_slice,\n        ground_range=ground_range_slice\n    )\n    \n    # Get min/max values from sliced GCPs for SAR geometry slicing\n    azimuth_time_min = gcps_crop.azimuth_time.min().values\n    azimuth_time_max = gcps_crop.azimuth_time.max().values\n    ground_range_min = gcps_crop.ground_range.min().values\n    ground_range_max = gcps_crop.ground_range.max().values\n    \n    # Slice GRD data using SAR geometry coordinates\n    grd_crop = measurements[i].grd.sel(\n        azimuth_time=slice(azimuth_time_min, azimuth_time_max),\n        ground_range=slice(ground_range_min, ground_range_max)\n    )\n    \n    # Decimate if needed (step=10 for faster processing)\n    grd_crop = grd_crop.isel(\n        azimuth_time=slice(None, None, 10),\n        ground_range=slice(None, None, 10)\n    )\n    \n    # Interpolate GCPs to match the sliced and decimated GRD\n    gcps_crop_interp = gcps_crop.interp_like(grd_crop)\n    \n    # Create final mask on interpolated coordinates\n    mask_2 = (\n        (gcps_crop_interp.latitude &lt; bbox[3]) & (gcps_crop_interp.latitude &gt; bbox[1]) &\n        (gcps_crop_interp.longitude &lt; bbox[2]) & (gcps_crop_interp.longitude &gt; bbox[0])\n    )\n    \n    # Apply mask and drop masked values\n    grd_crop = grd_crop.where(mask_2.compute(), drop=True)\n    \n    # We load all the variables already because we will use them in lots of future computations\n    grd.append(grd_crop.load())\n    gcp.append(gcps_crop_interp.load())\n\n\n# Plotting the first sliced and decimated GRD product from our list \ngrd[0].plot(vmax=300)\nplt.title(\"Sliced GRD product for the area of interest\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAssigning latitude and longitude coordinates\nWe will execute the following step to assign latitude and longitude coordinates to our datasets: 1. Creating a gcp dataset interpolated with the grd dataset; 2. Assigning the latitude and longitude coordinates to the grd dataset;\nThese steps are very important because we are computing a georeferenced image, which allows direct comparison with other spatial datasets. Until now, the image coordinates were expressed in azimuth_time and ground_range, which makes sense in a SAR context but not for geographical analyses.\n\n# GCPs are now loaded and interpolated during the slicing step above\n# Looping to assign the latitude and longitude coordinates to grd \nfor i in range(DATASET_NUMBER):\n    grd[i] = grd[i].assign_coords({\"latitude\": gcp[i].latitude, \n                                   \"longitude\": gcp[i].longitude})\n\n\n# Plotting the third sliced and decimated GRD product from our list with latitude and longitude coordinates\ngrd[0].plot(x=\"longitude\", y=\"latitude\", vmax=300)\nplt.title(\"GRD product with latitude and longitude coordinates\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nComputing backscatter\nAgain, the following steps are just recreating what was done before, but this time over more datasets. For further detailed information, take a look at this chapter.\nFirstly we access the variables concerning the calibration values. These are the values that are going to be used for the backscatter computation.\nWe use manual calibration with sigma_nought instead of xarray_sentinel.calibrate_intensity() because of known issues with the product format (see forum discussion and GitLab issue). A function is created to make all the steps more automatic but you‚Äôll see that all the procedures done inside the intensity_calibration were already explained on the previous tutorial. The manual approach uses line and pixel dimensions for interpolation, which correctly handles the calibration coefficients.\n\ncalibration = []\n# Looping to populate the calibration list with only the calibration groups of each dataset on the datatree list\nfor i in range(DATASET_NUMBER):\n    calibration.append(datatrees[i][datatrees[i].groups[CALIBRATION_GROUP_ID]].to_dataset())\n\n\ndef intensity_calibration(calibration, grd):\n    \"\"\"\n    Computes the calibrated backscatter intensity from the GRD data and the calibration information.\n    \n    Parameters\n    ----------\n    calibration : xarray.Dataset\n        Calibration data (e.g., sigma_nought).\n    grd : xarray.DataArray\n        GRD data to be calibrated.\n    \n    Returns\n    -------\n    calibrated_intensity : xarray.DataArray\n        Calibrated backscatter intensity in dB.\n    \"\"\"\n    # Accessing the sigma_nought values\n    sigma_nought = calibration.sigma_nought \n\n    # we reacreate the sigma_nought array with line and pixel dimensions for easier interpolation\n    sigma_nought_line_pixel = xr.DataArray(\n        data=sigma_nought.data,\n        dims=[\"line\", \"pixel\"],\n        coords=dict(\n            line=([\"line\"], sigma_nought.line.values),\n            pixel=([\"pixel\"], sigma_nought.pixel.values),\n        ),\n    )\n\n    # just like for the sigma_nought, we reacreate the grd array with line and pixel dimensions for easier interpolation\n    grd_line_pixel = xr.DataArray(\n        data=grd.data,\n        dims=[\"line\", \"pixel\"],\n        coords=dict(\n            line=([\"line\"], grd.line.values),\n            pixel=([\"pixel\"], grd.pixel.values),\n        ),\n    )\n\n    # we interpolate the sigma_nought with the grd geometry\n    sigma_nought_interp_line_pixel = sigma_nought_line_pixel.interp_like(grd_line_pixel, method=\"linear\")\n\n    sigma_nought_interp = xr.DataArray(\n        data=sigma_nought_interp_line_pixel.data,\n        dims=[\"azimuth_time\", \"ground_range\"],\n        coords=dict(\n            azimuth_time=([\"azimuth_time\"], grd.azimuth_time.values),\n            ground_range=([\"ground_range\"], grd.ground_range.values),\n        ),\n    )\n    intensity = 10 * np.log10(np.maximum(((abs(grd.astype(np.float32)) ** 2) / (sigma_nought_interp**2)), 1e-10))\n    return intensity\n\n\nintensity = []\n# Looping to populate the calibration list with only the calibration groups of each dataset on the datatree list\nfor i in range(DATASET_NUMBER):\n    intensity.append(intensity_calibration(calibration[i], grd[i]).load())\n\nIn case we prefer to keep it more simple and calculate the intensity values with xarray_sentinel we can just uncomment the following cell and run it.\n\n# intensity = []\n# # Looping to populate the intensity list with the calibrated intensity array originated from xarray_sentinel.calibrate_intensity function\n# for i in range(DATASET_NUMBER):\n#     intensity.append(xarray_sentinel.calibrate_intensity(\n#         grd[i], \n#         calibration[i].beta_nought, \n#         as_db=True))\n\n\n# Plotting the backscatter intensity for the first dataset on the list\nintensity[0].plot(x=\"longitude\", y=\"latitude\", vmin=-25, vmax=5)\nplt.title(\"Computed backscatter intensity\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCreate a datacube to prepare for time series analysis\nSince we are performing a time series with .zarr, instead of analysing individual items stored in a list, we can create a combined dataset, containing all the data, stacked together by a new dimension time. Through the stacking, we are building a three-dimensional datacube.\nTo get values for the new dimension time, we need to extract the acquisiton dates for each product.\n\ndata = []\n# Looping to populate the data list with all the acquisition dates from the datatree\nfor i in range(len(intensity)):\n    data.append(intensity[i].azimuth_time.values[1].astype('datetime64[D]'))\ndata\n\n[np.datetime64('2024-10-07'),\n np.datetime64('2024-10-19'),\n np.datetime64('2024-10-31'),\n np.datetime64('2024-11-12'),\n np.datetime64('2024-11-24'),\n np.datetime64('2024-12-06'),\n np.datetime64('2024-12-18'),\n np.datetime64('2024-12-30'),\n np.datetime64('2025-01-11'),\n np.datetime64('2025-01-23'),\n np.datetime64('2025-02-04'),\n np.datetime64('2025-02-16'),\n np.datetime64('2025-03-12'),\n np.datetime64('2025-03-24')]\n\n\n\n\nGeocoding onto regular grid\nIn order to stack data into a time series datacube, we need to ensure that pixels across different acquisition dates correspond to the exact same ground locations. Since each Sentinel-1 GRD product has lat/lon coordinates on an irregular grid (due to SAR geometry), we need to geocode all products onto a common regular grid.\nThis process involves: 1. Creating a regular coordinate grid that covers all products 2. Interpolating each product‚Äôs backscatter values from its irregular lat/lon coordinates to the common regular grid 3. Stacking the geocoded products into a time series datacube\nThis ensures proper alignment for accurate time series analysis, where each pixel represents the same ground location across all dates.\n\ndef create_regular_grid(min_x, max_x, min_y, max_y, spatialres):\n    \"\"\"\n    Create a regular coordinate grid given bounding box limits.\n    \n    Parameters\n    ----------\n    min_x, max_x : float\n        Minimum and maximum X coordinates (e.g., longitude).\n    min_y, max_y : float\n        Minimum and maximum Y coordinates (e.g., latitude).\n    spatialres : float\n        Desired spatial resolution (in same units as x/y).\n    \n    Returns\n    -------\n    grid_x_regular : ndarray\n        2D array of regularly spaced X coordinates.\n    grid_y_regular : ndarray\n        2D array of regularly spaced Y coordinates.\n    \"\"\"\n    # Ensure positive dimensions and consistent spacing\n    width = int(np.ceil((max_x - min_x) / spatialres))\n    height = int(np.ceil((max_y - min_y) / spatialres))\n    \n    # Compute grid centers (half-pixel offset)\n    half_pixel = spatialres / 2.0\n    x_regular = np.linspace(\n        min_x + half_pixel, max_x - half_pixel, width, dtype=np.float32\n    )\n    y_regular = np.linspace(\n        min_y + half_pixel, max_y - half_pixel, height, dtype=np.float32\n    )\n    \n    grid_x_regular, grid_y_regular = np.meshgrid(x_regular, y_regular)\n    return grid_x_regular, grid_y_regular\n\n\ndef geocode_grd(sigma_0, grid_x_regular, grid_y_regular, time_val):\n    \"\"\"\n    Geocode GRD backscatter from irregular lat/lon grid to regular grid.\n    \n    Parameters\n    ----------\n    sigma_0 : xarray.DataArray\n        Backscatter intensity with latitude and longitude coordinates.\n    grid_x_regular : ndarray\n        2D array of regular X (longitude) coordinates.\n    grid_y_regular : ndarray\n        2D array of regular Y (latitude) coordinates.\n    time_val : datetime64\n        Time value for this product.\n    \n    Returns\n    -------\n    ds : xarray.Dataset\n        Geocoded dataset with regular x and y coordinates.\n    \"\"\"\n    grid_lat = sigma_0.latitude.values\n    grid_lon = sigma_0.longitude.values\n    \n    # Set border values to zero to avoid border artifacts with nearest interpolator\n    sigma_0_data = sigma_0.data.copy()\n    sigma_0_data[[0, -1], :] = 0\n    sigma_0_data[:, [0, -1]] = 0\n    \n    # Interpolate from irregular to regular grid\n    interpolated_values = griddata(\n        (grid_lon.flatten(), grid_lat.flatten()),\n        sigma_0_data.flatten(),\n        (grid_x_regular, grid_y_regular),\n        method=\"nearest\",\n    )\n    \n    # Create xarray Dataset with regular coordinates\n    ds = xr.Dataset(\n        coords=dict(\n            time=([\"time\"], [time_val]),\n            y=([\"y\"], grid_y_regular[:, 0]),\n            x=([\"x\"], grid_x_regular[0, :]),\n        )\n    )\n    ds[\"intensity\"] = ((\"time\", \"y\", \"x\"), np.expand_dims(interpolated_values, 0))\n    ds = ds.where(ds != 0)\n    \n    return ds\n\n\n# Extract bounds from all intensity products to create common regular grid\nmin_lat = min([i.latitude.min().values.item() for i in intensity])\nmax_lat = max([i.latitude.max().values.item() for i in intensity])\nmin_lon = min([i.longitude.min().values.item() for i in intensity])\nmax_lon = max([i.longitude.max().values.item() for i in intensity])\n\n# Create common regular grid (resolution: 0.0001 degrees ‚âà 11 meters)\ngrid_x_regular, grid_y_regular = create_regular_grid(\n    min_lon, max_lon, min_lat, max_lat, 0.0001\n)\n\nNow we geocode all products onto the common regular grid and stack them into a time series datacube. Each pixel now corresponds to the exact same ground location across all acquisition dates, enabling accurate time series analysis.\n\n# Geocode all products onto the common regular grid\ngeocoded = []\nfor i in range(len(intensity)):\n    geocoded.append(geocode_grd(intensity[i], grid_x_regular, grid_y_regular, data[i]))\n\n# Create the data cube by stacking all geocoded products\nintensity_data_cube = xr.concat(geocoded, dim=\"time\").sortby(\"time\")\n\n# There is a new dimension coordinate (time) \nintensity_data_cube\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1GB\nDimensions:    (time: 14, y: 3239, x: 4047)\nCoordinates:\n  * time       (time) datetime64[s] 112B 2024-10-07 2024-10-19 ... 2025-03-24\n  * y          (y) float32 13kB 39.11 39.11 39.11 39.11 ... 39.44 39.44 39.44\n  * x          (x) float32 16kB -0.5029 -0.5028 -0.5027 ... -0.09841 -0.09831\nData variables:\n    intensity  (time, y, x) float64 1GB nan nan nan nan nan ... nan nan nan nanxarray.DatasetDimensions:time: 14y: 3239x: 4047Coordinates: (3)time(time)datetime64[s]2024-10-07 ... 2025-03-24array(['2024-10-07T00:00:00', '2024-10-19T00:00:00', '2024-10-31T00:00:00',\n       '2024-11-12T00:00:00', '2024-11-24T00:00:00', '2024-12-06T00:00:00',\n       '2024-12-18T00:00:00', '2024-12-30T00:00:00', '2025-01-11T00:00:00',\n       '2025-01-23T00:00:00', '2025-02-04T00:00:00', '2025-02-16T00:00:00',\n       '2025-03-12T00:00:00', '2025-03-24T00:00:00'], dtype='datetime64[s]')y(y)float3239.11 39.11 39.11 ... 39.44 39.44array([39.11285 , 39.11295 , 39.11305 , ..., 39.436386, 39.436485, 39.436584],\n      shape=(3239,), dtype=float32)x(x)float32-0.5029 -0.5028 ... -0.09831array([-0.502901, -0.502801, -0.502701, ..., -0.098507, -0.098407, -0.098307],\n      shape=(4047,), dtype=float32)Data variables: (1)intensity(time, y, x)float64nan nan nan nan ... nan nan nan nanarray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]], shape=(14, 3239, 4047))",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#flood-mapping-and-time-series-analysis",
    "href": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#flood-mapping-and-time-series-analysis",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "Flood mapping and time series analysis",
    "text": "Flood mapping and time series analysis\nThe last step is to perform the time series and flood mapping analysis.\n\nSimple visualisation of all datasets selected\nFirst, we can plot all the datasets simply to create a visualisation of the flood. In addition to these plots, we are also plotting a chosen latitude and longitude point (as defined at beginning of this tutorial). The coordinate serves as a measure of comparison between all the datasets and from within different analysis methods.\nWhen we look over all the items plotted, we can clearly see that the significant flood event happened between the 19th and the 31st of October (it occurred on the 29th of October 2024).\nAdditionally, we can see that the backscatter displaying the water presence was only going back to normal ranges around mid-February 2025.\n\ncols = 4    # setting up column number\nrows = int(np.ceil(len(geocoded) / cols))  # setting up row number according to column number\nfig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))  \naxes = axes.flatten()  \n\nfor i in range(len(geocoded)):\n    ax = axes[i]\n    intensity_data_cube.isel(time=i).intensity.plot(    # plotting all the datasets stored in the data cube\n        x=\"x\", y=\"y\",\n        vmin=-25, vmax=5,\n        ax=ax,  \n        add_colorbar=False  \n    )\n    ax.scatter(TARGET_LONG, TARGET_LAT, color=\"red\", marker=\"o\", s=10, label=\"Selected Point\")  # also plotting the known point defined before\n    ax.legend(loc=\"upper right\")\n\nfor j in range(i+1, len(axes)):\n    axes[j].axis('off')     # to avoid having empty cells\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCreate a flood map based on threshold values\nIt is known through literature and other sources that water appears as darker pixels, typically with values lower than -15 dB. This is a very good method for identifying water because separating the pixels within this threshold value will give us almost a True and False map for pixels which are greater or smaller than the defined threshold.\nIn the plots below, we classify the pixels with backscatter values equal to or lower than -15 in yellow. Conversely, in purple, we see the pixels that have backscatter values greater than -15.\nThis type of visualisation allows us to easily identify flooded and non-flooded areas.\n\nfig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))  \naxes = axes.flatten()  \n\nfor i in range(len(geocoded)):\n    ax = axes[i]\n    water_mask = (intensity_data_cube.isel(time=i).intensity &lt;= WATER_THRESHOLD_DB)     # defining the water mask from the threshold\n    water_mask.plot(        # plotting all the water masks \n        x=\"x\", y=\"y\",\n        ax=ax,  \n        add_colorbar=False  \n    )\n    ax.scatter(TARGET_LONG, TARGET_LAT, color=\"red\", marker=\"o\", s=10, label=\"Selected Point\") # again plotting the known point defined before\n    ax.legend(loc=\"upper right\")\n\nfor j in range(i+1, len(axes)):\n    axes[j].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCreate a map showing differences between two images\nKnowing the exact flood date, which we have, and from the images plotted previously, we can easily see that the second image is the one right before the flood event and that the third image is the one directly after it. These two images show significant differences in the flooded areas and backscatter values, ranging from -5 dB (in the image before the event) to -20 dB (in the image directly after the event).\nFor this reason, when we compute the difference between the two images, we will mostly get: - Values around 0 dB for areas that did not change - Values ranging from -15 dB to -20 dB in the precise flooded areas.\nThis is an excellent way to determine precisely which areas were flooded. As we are comparing an image from before the event with another one taken at the highest possible flooding point, the differences between them will be extreme.\n\ndif = (intensity_data_cube.isel(time=1).intensity - intensity_data_cube.isel(time=2).intensity)   # computing the difference between third and second dataset\ndif.plot(x=\"x\", y=\"y\", vmin=-10, vmax=20)\nplt.title(\"Flooded area right after the heavy rains\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCreate a time-series plot of one location within the flood\nTaking advantage of the data cube we have created over a new time dimension, it is much easier to plot the data over this new dimension, as in a time series plot. As our data now shares same dimensions and shape, we can choose to plot a backscatter analysis over the specific latitude and longitude point we defined earlier.\nAs these coordinates might not be exactly the ones shown on the dimension values, we need to perform some operations to find the closest values to the desired coordinates. We will now change the latitude and longitude coordinate values and see how the corresponding azimuth_time and ground_range values and indexes change.\n\n# Find how far each pixel's coordinates are from the target point\nabs_error = np.abs(intensity_data_cube.y - TARGET_LAT) + np.abs(intensity_data_cube.x - TARGET_LONG)  \n\n# Get the indexes of the closest point\ni, j = np.unravel_index(np.argmin(abs_error.values), abs_error.shape)\ny_index = i\nx_index = j\n\n# Get the coordinate values of the closest point\ny_value = intensity_data_cube.y[i].values\nx_value = intensity_data_cube.x[j].values\n\nprint(\"Nearest y (latitude):\", y_value, \", with index:\", y_index)\nprint(\"Nearest x (longitude):\", x_value, \", with index:\", x_index)\n\n# Slice the data cube in order to get only the pixel that corresponds to the target point\ntarget_point = intensity_data_cube.isel(y=y_index, x=x_index).intensity\n\nNearest y (latitude): 39.280018 , with index: 1672\nNearest x (longitude): -0.3000041 , with index: 2029\n\n\nNow we can plot the data cube, showing the backscatter intensity over the target point we defined earlier. Since the datasets are stacked along the time dimension, it becomes much easier to plot the evolution of water backscatter at a specific location. This provides an effective way to monitor the flooding status at that point.\nWe can also add a line representing the water threshold we defined. Any point with a backscatter value below this threshold will be classified as water, thus flooded.\n\n# Plot the sliced data cube\ntarget_point.plot(label='Time series backscatter') \n\nx = target_point[target_point.dims[0]].values   # getting the x axis values (time)\ny = target_point.values                         # getting the y axis values (backscatter intensity)\n\n# Creating the trend line\nx_num = np.arange(len(x))   \nz = np.polyfit(x_num, y, 6)\np = np.poly1d(z)\n\nplt.plot(x, p(x_num), 'r--', label='Trend line')\nplt.plot(x, [-15] * len(x), 'g--', label='Flood threshold')\nplt.legend()\nplt.show()",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#challenges",
    "href": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#challenges",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "Challenges",
    "text": "Challenges\nWhile using the optimised .zarr format saves a lot of time and makes creating workflows relatively simple and achievable, there are still a few challenges to handle and to keep in mind:\n\nSentinel-1 GRD Data Availability: For Sentinel-1 GRD, most of the datasets are not yet available on the STAC catalogue. This makes searching and data handling harder because, in the end, only a few products are correctly converted.\nBackscatter Computation: The xarray_sentinel library has known issues with certain product formats, requiring manual calibration using sigma_nought with line and pixel dimension interpolation. This tutorial demonstrates the correct manual calibration approach.\nGeocoding: Proper geocoding onto a regular grid is essential for accurate time series analysis. This tutorial uses scipy.interpolate.griddata to geocode products from irregular SAR geometry coordinates to a common regular grid, ensuring pixels correspond to the same ground locations across all dates.\nTerrain Correction: With the available libraries, it is very difficult to perform geometric and radiometric terrain correction. The existing tools that support the .zarr format are not yet fully operational and do not accept the format as it is.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#conclusion",
    "href": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#conclusion",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "Conclusion",
    "text": "Conclusion\nThe .zarr format is particularly well suited for hazard analysis because it enables multiple datasets to be combined into a single structure, either as a data cube or as a list of datatrees. This makes it ideal for rapid, multi-temporal, and multi-spatial monitoring. Unlike the .SAFE format, which required downloading entire products, .zarr only loads the specific groups needed, while the rest is accessed on the fly. As a result, both data handling and subsequent operations are much faster and more efficient. The .load() helps a lot on these situations.\nAlthough the ecosystem for .zarr is still evolving, there are already promising developments. In the past, .SAFE products could be fully processed on applications like SNAP, but similar completeness has not yet been reached for .zarr. Nevertheless, libraries such as xarray_sentinel and are beginning to cover essential SAR operations. This potential is illustrated in the Valencia flood case study, where Sentinel-1 backscatter sensitivity to water enabled clear mapping of flood extent and duration. The same workflow can be adapted to other flood events by adjusting the relevant thresholds and parameters to match local conditions.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#whats-next",
    "href": "06_eopf_zarr_in_action/64_flood_mapping_valencia.html#whats-next",
    "title": "Flood Mapping - Time Series Analysis in Valencia",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following notebook we will explore a new approach to the EOPF Zarr format. We will follow step by step the creation of Overviews, taking as a starting point the existing EOPF Zarr format structure and taking it to the next level!",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Flood Mapping - Time Series Analysis in Valencia</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/65_create_overviews.html",
    "href": "06_eopf_zarr_in_action/65_create_overviews.html",
    "title": "Create and Visualise Multiscale Pyramids - Part 1",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nLarge satellite products, such as Sentinel-2 Level-2A scenes, contain tens of millions of pixels per band. Accessing or visualising them at full resolution is often unnecessary, especially for exploratory analysis, map rendering, or quality checks. Multiscale pyramids address this by providing progressively coarser versions of the original data, allowing client applications to request only the level of detail required. This approach reduces computational load, improves user experience, and aligns with modern cloud-native geospatial workflows.\nOur approach consist of two notebooks:\nIn this notebook, we will demonstrate how to create overviews (also called multiscale pyramids) for large Earth Observation datasets stored in Zarr format. Overviews are downscaled representations of gridded data that support efficient visualisation and scalable access to high-resolution datasets. They enable fast inspection at multiple zoom levels, reduce data transfer volumes, and improve performance when working with cloud-optimised storage.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/65_create_overviews.html#copy-remote-dataset-to-local-storage",
    "href": "06_eopf_zarr_in_action/65_create_overviews.html#copy-remote-dataset-to-local-storage",
    "title": "Create and Visualise Multiscale Pyramids - Part 1",
    "section": "Copy Remote Dataset to Local Storage",
    "text": "Copy Remote Dataset to Local Storage\nThe starting point for our overviews starts with the ‚Äúlocal‚Äù access to the STAC zarr item we are interested in. We do this based on two main reasons:\n\nThe remote dataset is read-only (object storage) and we need a writable local copy to add new groups (L1-L5)\nThis preserves the complete original structure\n\nTo make sure that we use a convenient scene, we select a source URL from the STAC catalogue.\n\nremote_url = (\"https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:202601-s02msil2a-eu/30/products/cpm_v262/S2C_MSIL2A_20260130T102251_N0511_R065_T32TQT_20260130T142716.zarr\")\nstore_path = (\"S2C_MSIL2A_20260130T102251_N0511_R065_T32TQT_20260130T142716.zarr\")\nbase_store = fs.get_mapper(f\"{bucket}/{store_path}\")\n\nAs a first step, we download the remote Zarr dataset and saves it as a Zarr copy ready on a S3 bucket for exploration. Chunking helps large datasets load faster especially when used in visualisation tools that read data in small spatial tiles.\n\nprint(f\"Copying remote Zarr to local storage... (may take several minutes)\")\ntry:\n    s2l2a_remote = xr.open_datatree(remote_url, engine=\"zarr\")\nexcept Exception as e:\n    raise RuntimeError(f\"Failed to open remote dataset: {e}\\nCheck network connectivity and URL\")\nprint(f\"Copying to s3://{base_store} ...\")\ns2l2a_remote.to_zarr(\n    store=base_store,\n    mode=\"w\",\n    consolidated=False,\n    zarr_version=2,\n    compute=True,\n)\n\nCopying remote Zarr to local storage... (may take several minutes)\nCopying to s3://&lt;fsspec.mapping.FSMap object at 0x7f244f1dc410&gt; ...\n\n\n&lt;xarray.backends.zarr.ZarrStore at 0x7f244ecef380&gt;\n\n\nThen, we can access the dataset from the S3 bucket and look inside the group that contains the 10-metre reflectance data to understand which variables, dimensions, and coordinates it contains.\n\n# --- Load Local Dataset and Inspect Structure ---\nvariable_group_path = \"measurements/reflectance/r10m\"\nr10m_store = fs.get_mapper(\n    f\"{bucket}/{store_path}/{variable_group_path}\"\n)\ndataset = xr.open_dataset(r10m_store, engine=\"zarr\")\ndataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:  (y: 10980, x: 10980)\nCoordinates:\n  * y        (y) float32 44kB 5.3e+06 5.3e+06 5.3e+06 ... 5.19e+06 5.19e+06\n  * x        (x) float32 44kB 7e+05 7e+05 7e+05 ... 8.097e+05 8.098e+05\nData variables:\n    b03      (y, x) float64 964MB ...\n    b04      (y, x) float64 964MB ...\n    b02      (y, x) float64 964MB ...\n    b08      (y, x) float64 964MB ...xarray.DatasetDimensions:y: 10980x: 10980Coordinates: (2)y(y)float325.3e+06 5.3e+06 ... 5.19e+06dimensions :['y']dtype :&lt;f4long_name :y coordinates of the image at 10m in meters from up-left pixelunits :marray([5.300035e+06, 5.300025e+06, 5.300015e+06, ..., 5.190265e+06,\n       5.190255e+06, 5.190245e+06], shape=(10980,), dtype=float32)x(x)float327e+05 7e+05 ... 8.097e+05 8.098e+05dimensions :['x']dtype :&lt;f4long_name :x coordinates of the image at 10m in meters from up-left pixelunits :marray([699965., 699975., 699985., ..., 809735., 809745., 809755.],\n      shape=(10980,), dtype=float32)Data variables: (4)b03(y, x)float64..._eopf_attrs :{'add_offset': -0.1, 'coordinates': ['y', 'x'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'eopf_is_masked': True, 'eopf_target_dtype': '&lt;f8', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band 03 560 nm', 'scale_factor': 0.0001, 'short_name': 'b03_r10m', 'units': 'digital_counts', 'valid_max': 65535, 'valid_min': 1}dtype :&lt;u2long_name :BOA reflectance from MSI acquisition at spectral band 03 560 nmunits :digital_counts[120560400 values with dtype=float64]b04(y, x)float64..._eopf_attrs :{'add_offset': -0.1, 'coordinates': ['y', 'x'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'eopf_is_masked': True, 'eopf_target_dtype': '&lt;f8', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band 04 665 nm', 'scale_factor': 0.0001, 'short_name': 'b04_r10m', 'units': 'digital_counts', 'valid_max': 65535, 'valid_min': 1}dtype :&lt;u2long_name :BOA reflectance from MSI acquisition at spectral band 04 665 nmunits :digital_counts[120560400 values with dtype=float64]b02(y, x)float64..._eopf_attrs :{'add_offset': -0.1, 'coordinates': ['y', 'x'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'eopf_is_masked': True, 'eopf_target_dtype': '&lt;f8', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band 02 490 nm', 'scale_factor': 0.0001, 'short_name': 'b02_10m', 'units': 'digital_counts', 'valid_max': 65535, 'valid_min': 1}dtype :&lt;u2long_name :BOA reflectance from MSI acquisition at spectral band 02 490 nmunits :digital_counts[120560400 values with dtype=float64]b08(y, x)float64..._eopf_attrs :{'add_offset': -0.1, 'coordinates': ['y', 'x'], 'dimensions': ['y', 'x'], 'dtype': '&lt;u2', 'eopf_is_masked': True, 'eopf_target_dtype': '&lt;f8', 'fill_value': 0, 'long_name': 'BOA reflectance from MSI acquisition at spectral band 08 842 nm', 'scale_factor': 0.0001, 'short_name': 'b08_r10m', 'units': 'digital_counts', 'valid_max': 65535, 'valid_min': 1}dtype :&lt;u2long_name :BOA reflectance from MSI acquisition at spectral band 08 842 nmunits :digital_counts[120560400 values with dtype=float64]",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/65_create_overviews.html#compute-overviews-in-memory",
    "href": "06_eopf_zarr_in_action/65_create_overviews.html#compute-overviews-in-memory",
    "title": "Create and Visualise Multiscale Pyramids - Part 1",
    "section": "Compute Overviews (In-Memory)",
    "text": "Compute Overviews (In-Memory)\nNow we compute the overview levels in memory only - no data is written to disk at this stage.\nWe extract the reflectance group at 10m resolution and automatically discover variables and dimensions.\nKey operations: - Open the local Zarr dataset as a datatree - Extract the reflectance group and convert to an xarray Dataset - Automatically discover all variables and dimensions - Identify spatial coordinate names (x, y)\nIn this step, we identify the spatial dimensions and variables in the dataset and define the scale levels that will be used to generate lower-resolution overviews.\n\nscales = [2, 4, 8, 16, 32, 64, 128]  # Scale factors for each level\nvariables = [var for var in dataset.data_vars]  # Discover variables\nspatial_dims = [dim for dim in dataset.dims]  # Discover dimensions\nx_dim = next((d for d in spatial_dims if d in ['x', 'X', 'lon', 'longitude']), 'x')  # Identify x dimension\ny_dim = next((d for d in spatial_dims if d in ['y', 'Y', 'lat', 'latitude']), 'y')  # Identify y dimension\nprint(f\"Variables: {variables} | Dims: {spatial_dims} | Shape: {dataset[variables[0]].shape} | Using: x_dim='{x_dim}', y_dim='{y_dim}'\\n\")\n\nVariables: ['b03', 'b04', 'b02', 'b08'] | Dims: ['y', 'x'] | Shape: (10980, 10980) | Using: x_dim='x', y_dim='y'\n\n\n\nAccessing such information allows us to generate a series of lower-resolution overview datasets directly in memory.\nFor each scale factor, we use xarray‚Äôs coarsen() function to average groups of pixels along the spatial dimensions (x, y). Each coarsened version is stored under a level name like L1, L2, etc., representing progressively coarser spatial resolutions.\n\noverviews = {}  # Generate in-memory overview datasets\nfor i, factor in enumerate(scales):\n    level_id = f\"L{i+1}\"\n    coarsened = dataset.coarsen({x_dim: factor, y_dim: factor}, boundary=\"trim\").mean()\n    overviews[level_id] = coarsened[variables]\n\nprint(f\"Created {len(overviews)} overview levels:\")\nfor level_id, level_ds in overviews.items():\n    print(f\"  {level_id}: shape {level_ds[variables[0]].shape}, dims {dict(level_ds.dims)}\")\nprint(\"\\nOverview datasets created successfully (in memory only, not written to disk)\")\n\nCreated 7 overview levels:\n  L1: shape (5490, 5490), dims {'y': 5490, 'x': 5490}\n  L2: shape (2745, 2745), dims {'y': 2745, 'x': 2745}\n  L3: shape (1372, 1372), dims {'y': 1372, 'x': 1372}\n  L4: shape (686, 686), dims {'y': 686, 'x': 686}\n  L5: shape (343, 343), dims {'y': 343, 'x': 343}\n  L6: shape (171, 171), dims {'y': 171, 'x': 171}\n  L7: shape (85, 85), dims {'y': 85, 'x': 85}\n\nOverview datasets created successfully (in memory only, not written to disk)",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/65_create_overviews.html#attach-multiscales-metadata",
    "href": "06_eopf_zarr_in_action/65_create_overviews.html#attach-multiscales-metadata",
    "title": "Create and Visualise Multiscale Pyramids - Part 1",
    "section": "Attach Multiscales Metadata",
    "text": "Attach Multiscales Metadata\nOnce the data has been processed, relating it with the GeoZarr-compliant metadata will enhance the application and self description:\n\nVersion: Schema version (‚Äú1.0‚Äù)\nResampling method: How data was aggregated (‚Äúaverage‚Äù)\nVariables: Which bands have overviews\nLayout: The complete hierarchy including L0 (base) and all derived levels\n\nThe metadata is stored in dataset.attrs[\"multiscales\"] following the GeoZarr Overviews specification. This ensures interoperability with GeoZarr-aware tools and libraries.\nHere we prepare the information needed to describe the overview hierarchy in the GeoZarr metadata. We set overview_path to indicate where the overview groups will be stored, record the resampling_method(\"average\") used to create them, and compute the base spatial resolutions (x_res and y_res) from the coordinate spacing.\n\noverview_path = \"overviews\"  # Where overviews are written (\".\" for direct children)\nresampling_method = \"average\"\nx_res = abs(float(dataset['x'].values[1] - dataset['x'].values[0]))\ny_res = abs(float(dataset['y'].values[1] - dataset['y'].values[0]))\n\nNow, we build the multiscales layout metadata that describes how all overview levels relate to the base dataset.\nThe first entry (L0) represents the original data, including its spatial resolution (cell_size). Each subsequent level (L1, L2, ‚Ä¶) is added to the layout with information about its path, the level it was derived from, the scale factors applied, the resampling method, and its corresponding cell size.\nFinally, this complete structure is stored in dataset.attrs[\"multiscales\"] following the GeoZarr Overviews specification (draft). The printed JSON summary shows the final metadata layout that GeoZarr-aware tools can use to identify and navigate between resolution levels.\n\nlayout = [{\"id\": \"L0\", \"path\": \".\", \"cell_size\": [x_res, y_res]}]  # Base level (native data at current group)\nfor i, factor in enumerate(scales):\n    level_id = f\"L{i+1}\"\n    level_path = level_id if overview_path == \".\" else f\"{overview_path}/{level_id}\"\n    level_cell_size = [x_res * factor, y_res * factor]\n    layout.append({\"id\": level_id, \"path\": level_path, \"derived_from\": \"L0\" if i == 0 else f\"L{i}\", \"factors\": [factor, factor], \"resampling_method\": resampling_method, \"cell_size\": level_cell_size})\ndataset.attrs[\"multiscales\"] = {\"version\": \"1.0\", \"resampling_method\": resampling_method, \"variables\": variables, \"layout\": layout}\nprint(\"Metadata structure:\")\nprint(json.dumps(dataset.attrs[\"multiscales\"], indent=2))\n\nMetadata structure:\n{\n  \"version\": \"1.0\",\n  \"resampling_method\": \"average\",\n  \"variables\": [\n    \"b03\",\n    \"b04\",\n    \"b02\",\n    \"b08\"\n  ],\n  \"layout\": [\n    {\n      \"id\": \"L0\",\n      \"path\": \".\",\n      \"cell_size\": [\n        10.0,\n        10.0\n      ]\n    },\n    {\n      \"id\": \"L1\",\n      \"path\": \"overviews/L1\",\n      \"derived_from\": \"L0\",\n      \"factors\": [\n        2,\n        2\n      ],\n      \"resampling_method\": \"average\",\n      \"cell_size\": [\n        20.0,\n        20.0\n      ]\n    },\n    {\n      \"id\": \"L2\",\n      \"path\": \"overviews/L2\",\n      \"derived_from\": \"L1\",\n      \"factors\": [\n        4,\n        4\n      ],\n      \"resampling_method\": \"average\",\n      \"cell_size\": [\n        40.0,\n        40.0\n      ]\n    },\n    {\n      \"id\": \"L3\",\n      \"path\": \"overviews/L3\",\n      \"derived_from\": \"L2\",\n      \"factors\": [\n        8,\n        8\n      ],\n      \"resampling_method\": \"average\",\n      \"cell_size\": [\n        80.0,\n        80.0\n      ]\n    },\n    {\n      \"id\": \"L4\",\n      \"path\": \"overviews/L4\",\n      \"derived_from\": \"L3\",\n      \"factors\": [\n        16,\n        16\n      ],\n      \"resampling_method\": \"average\",\n      \"cell_size\": [\n        160.0,\n        160.0\n      ]\n    },\n    {\n      \"id\": \"L5\",\n      \"path\": \"overviews/L5\",\n      \"derived_from\": \"L4\",\n      \"factors\": [\n        32,\n        32\n      ],\n      \"resampling_method\": \"average\",\n      \"cell_size\": [\n        320.0,\n        320.0\n      ]\n    },\n    {\n      \"id\": \"L6\",\n      \"path\": \"overviews/L6\",\n      \"derived_from\": \"L5\",\n      \"factors\": [\n        64,\n        64\n      ],\n      \"resampling_method\": \"average\",\n      \"cell_size\": [\n        640.0,\n        640.0\n      ]\n    },\n    {\n      \"id\": \"L7\",\n      \"path\": \"overviews/L7\",\n      \"derived_from\": \"L6\",\n      \"factors\": [\n        128,\n        128\n      ],\n      \"resampling_method\": \"average\",\n      \"cell_size\": [\n        1280.0,\n        1280.0\n      ]\n    }\n  ]\n}\n\n\n\nnew_attrs = dataset.attrs.copy()   # includes your multiscales metadata\njson_bytes = json.dumps(new_attrs).encode(\"utf-8\")\n# FSMap stores values as bytes\nr10m_store['.zattrs'] = json_bytes\n\n\nWrite Overviews to Local Zarr Store\nThe final step consists of adding the computed overviews to the Zarr store copy.\nOverview path options: - overview_path=\".\" - Write overviews as direct children (L1, L2, L3, ‚Ä¶) - overview_path=\"overviews\" - Write overviews in a subfolder (overviews/L1, overviews/L2, ‚Ä¶)\nWrite operations: 1. Write L1-L5 - Add overview levels as subgroups 2. Add metadata - Update group attributes with multiscales metadata\nKey point: Native data stays at the group level. The multiscales metadata uses path: \".\" for L0 to reference the existing native data without duplication.\nResult with overview_path=\".\":\nmeasurements/reflectance/r10m/\n‚îú‚îÄ‚îÄ b02, b03, b04, b08  # Native data (L0 via path=\".\")\n‚îú‚îÄ‚îÄ x, y                # Coordinates\n‚îú‚îÄ‚îÄ L1/                 # Overview levels (direct children)\n‚îú‚îÄ‚îÄ L2/\n‚îú‚îÄ‚îÄ L3/\n‚îú‚îÄ‚îÄ L4/\n‚îú‚îÄ‚îÄ L5/\n‚îî‚îÄ‚îÄ .zattrs             # multiscales metadata\nAlternative with overview_path=\"overviews\":\nmeasurements/reflectance/r10m/\n‚îú‚îÄ‚îÄ b02, b03, b04, b08  # Native data (L0 via path=\".\")\n‚îú‚îÄ‚îÄ x, y                # Coordinates\n‚îú‚îÄ‚îÄ overviews/          # Overview levels in subfolder\n‚îÇ   ‚îú‚îÄ‚îÄ L1/\n‚îÇ   ‚îú‚îÄ‚îÄ L2/\n‚îÇ   ‚îú‚îÄ‚îÄ L3/\n‚îÇ   ‚îú‚îÄ‚îÄ L4/\n‚îÇ   ‚îî‚îÄ‚îÄ L5/\n‚îî‚îÄ‚îÄ .zattrs             # multiscales metadata\n\nprint(f\"Adding overviews to {variable_group_path} | Variables: {variables} | Path: '{overview_path}'\\n\")\n\n# Create the overview group folder on S3\nzarr.open_group(store=base_store, mode=\"a\", zarr_version=2)\n\nprint(f\"Writing {len(overviews)} overview levels...\")\nfor level_id, level_dataset in overviews.items():\n\n    level_store = fs.get_mapper(\n        f\"{bucket}/{store_path}/\"\n        f\"{variable_group_path}/{overview_path}/{level_id}\"\n    )\n\n    level_dataset.to_zarr(\n        store=level_store,\n        mode=\"a\",\n        zarr_version=2,\n    )\n\n# Write coordinates + attrs into r10m group\ncoords_only = xr.Dataset(coords=dataset.coords, attrs=dataset.attrs)\ncoords_only.to_zarr(\n    store=r10m_store,\n    mode=\"a\",\n    zarr_version=2,\n)\n\nprint(f\"Generating consolidated metadata for {overview_path}/\")\nzarr.consolidate_metadata(store=base_store)\n\nprint(f\"\\nSuccessfully added overviews to {variable_group_path}\\n\")\nprint(f\"Final structure:\\n  {variable_group_path}/\")\nprint(f\"    ‚îú‚îÄ‚îÄ {', '.join(variables)}\")\nprint(f\"    ‚îú‚îÄ‚îÄ {x_dim}, {y_dim}\")\nprint(f\"    ‚îú‚îÄ‚îÄ {overview_path}/\")\nfor level_id in overviews.keys():\n    print(f\"    ‚îÇ   ‚îú‚îÄ‚îÄ {level_id}/\")\nprint(f\"    ‚îî‚îÄ‚îÄ .zattrs\")\n\nAdding overviews to measurements/reflectance/r10m | Variables: ['b03', 'b04', 'b02', 'b08'] | Path: 'overviews'\n\nWriting 7 overview levels...\nGenerating consolidated metadata for overviews/\n\nSuccessfully added overviews to measurements/reflectance/r10m\n\nFinal structure:\n  measurements/reflectance/r10m/\n    ‚îú‚îÄ‚îÄ b03, b04, b02, b08\n    ‚îú‚îÄ‚îÄ x, y\n    ‚îú‚îÄ‚îÄ overviews/\n    ‚îÇ   ‚îú‚îÄ‚îÄ L1/\n    ‚îÇ   ‚îú‚îÄ‚îÄ L2/\n    ‚îÇ   ‚îú‚îÄ‚îÄ L3/\n    ‚îÇ   ‚îú‚îÄ‚îÄ L4/\n    ‚îÇ   ‚îú‚îÄ‚îÄ L5/\n    ‚îÇ   ‚îú‚îÄ‚îÄ L6/\n    ‚îÇ   ‚îú‚îÄ‚îÄ L7/\n    ‚îî‚îÄ‚îÄ .zattrs",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/65_create_overviews.html#now-it-is-your-turn",
    "href": "06_eopf_zarr_in_action/65_create_overviews.html#now-it-is-your-turn",
    "title": "Create and Visualise Multiscale Pyramids - Part 1",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nWith everything we have learnt so far, you are now able to create multiscale overviews for your own datasets.\n\nTask 1: Experiment With Different Scale Factors\nTry modifying the scales list to create different pyramid structures. For example: - Fewer levels: scales = [2, 4, 8] for a smaller pyramid - More aggressive downsampling: scales = [4, 16, 64] for rapid zoom levels - Fine-grained levels: scales = [2, 3, 4, 6, 8] for smoother transitions\n\n\nTask 2: Apply To Your Own Dataset\nUse this notebook as a template for your own Earth Observation data: 1. Replace the URL with your own Zarr dataset 2. Let the code discover variables and dimensions automatically 3. Adjust scale factors based on your data resolution 4. Validate and write the results",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/65_create_overviews.html#conclusion",
    "href": "06_eopf_zarr_in_action/65_create_overviews.html#conclusion",
    "title": "Create and Visualise Multiscale Pyramids - Part 1",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial demonstrated the complete workflow for creating GeoZarr-compliant multiscale overviews:\n\n‚úÖ Load and discover dataset structure automatically\n‚úÖ Compute overview levels in memory (no disk I/O)\n‚úÖ Attach specification-compliant metadata\n‚úÖ Write to Zarr storage\n\nKey takeaways: - The compute-then-write pattern separates computation from I/O - Dynamic discovery makes code adaptable to different datasets",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/65_create_overviews.html#whats-next",
    "href": "06_eopf_zarr_in_action/65_create_overviews.html#whats-next",
    "title": "Create and Visualise Multiscale Pyramids - Part 1",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the next notebook we will focus on the second part of this workflow and, visualise the generated overviews with the help of matplotlib and ipyleaflet for progressive rendering and web mapping.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 1</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/66_use_overviews.html",
    "href": "06_eopf_zarr_in_action/66_use_overviews.html",
    "title": "Create and Visualise Multiscale Pyramids - Part 2",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nOverviews enable efficient visualisation by providing progressively coarser representations of the data, allowing us to quickly navigate and explore large satellite images without loading the full-resolution dataset every time.\nOur approach consists of two notebooks:\nIn this notebook, we will explore and visualise the multiscale overview pyramid created in the previous tutorial. Building upon what we learned about creating overviews, we will now focus on how to use them effectively for interactive visualisation and exploration of large Earth Observation datasets.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/66_use_overviews.html#understanding-the-overview-hierarchy",
    "href": "06_eopf_zarr_in_action/66_use_overviews.html#understanding-the-overview-hierarchy",
    "title": "Create and Visualise Multiscale Pyramids - Part 2",
    "section": "Understanding the Overview Hierarchy",
    "text": "Understanding the Overview Hierarchy\nThe first step in working with overviews is to understand their structure. In the previous tutorial, we created a multiscale pyramid with several levels (L0 through L7), where each level represents the data at a different resolution.\nLet‚Äôs load the dataset and examine the multiscales metadata that describes this hierarchy. This metadata follows the GeoZarr Overviews specification and contains information about: - Which levels exist and where they are stored in the Zarr hierarchy - How each level relates to others (parent-child relationships through derived_from) - The spatial resolution (cell_size) of each level in meters - What resampling method was used to create each level\n\nOpening the dataset\nWe start by opening the dataset at the group level where our overviews are stored on S3. This is the same path we used in the previous tutorial when creating the overviews (measurements/reflectance/r10m).\n\n# S3 path configuration\ns3_zarr_name = \"S2A_MSIL2A_20250831T135741_N0511_R010_T26WPD_20250831T185012.zarr\"\nvariable_group_path = \"measurements/reflectance/r10m\"\n# Open dataset from S3 using fs.get_mapper()\nr10m_store = fs.get_mapper(f\"{bucket}/{s3_zarr_name}/{variable_group_path}\")\ndataset = xr.open_dataset(r10m_store, engine=\"zarr\")  # Load dataset\nprint(f\"Dataset: {dict(dataset.dims)} | Variables: {list(dataset.data_vars)} | Multiscales: {'multiscales' in dataset.attrs}\\n\")\n\nDataset: {'y': 10980, 'x': 10980} | Variables: ['b02', 'b03', 'b04', 'b08'] | Multiscales: True\n\n\n\nThe output confirms that our dataset has dimensions of 10,980 √ó 10,980 pixels and contains four spectral bands (b02, b03, b04, b08), along with the multiscales metadata we created in the previous tutorial.\n\n\nParsing the multiscales metadata\nThe multiscales attribute contains all the information about our overview pyramid. Let‚Äôs parse it into a table format using pandas to make it easier to understand.\nEach row in the table represents one resolution level:\n\nid: Level identifier (L0, L1, L2, etc.)\npath: Where this level is stored in the Zarr hierarchy (. means current group, overviews/L* means subfolder)\ncell_size: Spatial resolution in metres as [x_res, y_res]\nderived_from: Which parent level this was created from\nfactors: Downsampling factors applied as [y_factor, x_factor]\nresampling_method: How pixels were aggregated (average, nearest, etc.)\n\n\n# Parse multiscales metadata\nmultiscales= dataset.attrs[\"multiscales\"]\nlayout_df = pd.DataFrame(multiscales[\"layout\"])\nprint(\"Overview Level Hierarchy:\")\ndisplay(layout_df)\n\nOverview Level Hierarchy:\n\n\n\n\n\n\n\n\n\nid\npath\ncell_size\nderived_from\nfactors\nresampling_method\n\n\n\n\n0\nL0\n.\n[10.0, 10.0]\nNaN\nNaN\nNaN\n\n\n1\nL1\noverviews/L1\n[20.0, 20.0]\nL0\n[2, 2]\naverage\n\n\n2\nL2\noverviews/L2\n[40.0, 40.0]\nL1\n[4, 4]\naverage\n\n\n3\nL3\noverviews/L3\n[80.0, 80.0]\nL2\n[8, 8]\naverage\n\n\n4\nL4\noverviews/L4\n[160.0, 160.0]\nL3\n[16, 16]\naverage\n\n\n5\nL5\noverviews/L5\n[320.0, 320.0]\nL4\n[32, 32]\naverage\n\n\n6\nL6\noverviews/L6\n[640.0, 640.0]\nL5\n[64, 64]\naverage\n\n\n7\nL7\noverviews/L7\n[1280.0, 1280.0]\nL6\n[128, 128]\naverage\n\n\n\n\n\n\n\nNotice the hierarchical structure:\n\nL0 has path=\".\", meaning it references the native data at the current group level (no data duplication).\nL1-L7 have path=\"overviews/L*\", stored in the overviews/ subfolder we created.\nEach level is progressively coarser: L1 is 2√ó downsampled, L2 is 4√ó, L3 is 8√ó, and so on.\nThe cell_size doubles at each level: 10m ‚Üí 20m ‚Üí 40m ‚Üí 80m ‚Üí 160m ‚Üí 320m ‚Üí 640m ‚Üí 1280m.\nAll levels use average resampling, which is appropriate for continuous reflectance data.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/66_use_overviews.html#loading-overview-levels",
    "href": "06_eopf_zarr_in_action/66_use_overviews.html#loading-overview-levels",
    "title": "Create and Visualise Multiscale Pyramids - Part 2",
    "section": "Loading Overview Levels",
    "text": "Loading Overview Levels\nNow that we understand the structure from the metadata, let‚Äôs load each overview level into memory. We‚Äôll iterate through the layout array from the multiscales metadata and open each level as a separate xarray Dataset.\nThe code below:\n\nCreates an empty dictionary to store all overview datasets\nLoops through each entry in the layout metadata\nConstructs the full path by joining the base path with the level‚Äôs relative path\nOpens each level using xr.open_dataset() with the Zarr engine\nDisplays the dimensions and downsampling factor for each level\n\n\noverview_datasets = {}  # Dictionary to store all levels\nfor entry in multiscales[\"layout\"]:\n    level_id, level_path = entry[\"id\"], entry[\"path\"]\n    # Construct S3 path for each level\n    if level_path == \".\":\n        # L0 references the base dataset\n        level_store = fs.get_mapper(f\"{bucket}/{s3_zarr_name}/{variable_group_path}\")\n    else:\n        # L1-L7 are in the overviews subfolder\n        level_store = fs.get_mapper(f\"{bucket}/{s3_zarr_name}/{variable_group_path}/{level_path}\")\n    \n    overview_datasets[level_id] = xr.open_dataset(level_store, engine=\"zarr\")\n    print(f\"Loaded  {level_id}: {overview_datasets[level_id]['b02'].shape[0]:5d} √ó {overview_datasets[level_id]['b02'].shape[1]:5d} pixels\")\n\nLoaded  L0: 10980 √ó 10980 pixels\nLoaded  L1:  5490 √ó  5490 pixels\nLoaded  L2:  2745 √ó  2745 pixels\nLoaded  L3:  1372 √ó  1372 pixels\nLoaded  L4:   686 √ó   686 pixels\nLoaded  L5:   343 √ó   343 pixels\nLoaded  L6:   171 √ó   171 pixels\nLoaded  L7:    85 √ó    85 pixels\n\n\nObserve how the dimensions decrease at each level:\n\nL0: 10,980 √ó 10,980 pixels (full resolution, ~121 megapixels)\nL1: 5,490 √ó 5,490 pixels (half resolution, ~30 megapixels)\nL2: 2,745 √ó 2,745 pixels (quarter resolution, ~7.5 megapixels)\nL7: 85 √ó 85 pixels (128√ó downsampled, ~7 kilopixels)\n\nLower resolution levels are much faster to load and visualise, making them ideal for quick previews, thumbnails, or zoomed-out views. This is the key benefit of the overview pyramid structure.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/66_use_overviews.html#visualization-of-overviews",
    "href": "06_eopf_zarr_in_action/66_use_overviews.html#visualization-of-overviews",
    "title": "Create and Visualise Multiscale Pyramids - Part 2",
    "section": "Visualization of Overviews",
    "text": "Visualization of Overviews\n\nCreating RGB Composites\nTo visualise our Sentinel-2 data, we‚Äôll create RGB true-colour composites by combining three spectral bands:\n\nRed channel: Band 4 (b04) at 664 nm - sensitive to red wavelengths\nGreen channel: Band 3 (b03) at 560 nm - sensitive to green wavelengths\nBlue channel: Band 2 (b02) at 490 nm - sensitive to blue wavelengths\n\nHowever, raw reflectance values (typically ranging from 0 to ~0.4) don‚Äôt display well directly. We need to apply contrast enhancement through percentile stretching to make features visible and create visually appealing images.\n\n\nPercentile stretching for contrast enhancement\nThe normalise() helper function below performs percentile-based contrast stretching, a standard technique in remote sensing visualisation. It works by:\n\nFiltering out NaN (fill) values, which are common in Earth Observation data due to clouds, partial coverage, or sensor issues\nComputing the 2nd and 98th percentile values of the valid data\nLinearly mapping these percentile values to 0 and 1 respectively\nClipping any values outside this range\n\nThis approach is robust to outliers (very bright or dark pixels) and produces visually balanced images. Critical note: Proper NaN handling is essential - if NaN values aren‚Äôt filtered out, np.percentile() returns NaN, causing the entire image to display as white or blank.\n\n    # Normalize each channel using percentile stretch (2% - 98%)\ndef normalize(band):\n    valid_pixels = band[~np.isnan(band)]  # ‚Üê ADD THIS LINE\n    if len(valid_pixels) == 0:\n        return np.zeros_like(band)\n    p2, p98 = np.percentile(valid_pixels, [2, 98])  # ‚Üê USE valid_pixels\n    if p98 == p2:\n        return np.zeros_like(band)\n    normalized = (band - p2) / (p98 - p2)\n    return np.clip(normalized, 0, 1)\n\n\n\nInteractive visualization with zoom levels\nNow let‚Äôs create an interactive visualisation that demonstrates the power of overviews. The widget below allows you to:\n\nMove the slider to switch between zoom levels (0 = highest resolution L0, 7 = lowest resolution L7)\nObserve the performance difference: Lower resolution levels (L5-L7) display almost instantly, while higher resolution levels take longer\nNotice the quality tradeoff: Higher levels show more detail but require more time to load and render\n\nThe function crops each image to the top-left quarter to make the display more responsive. Even with this cropping, L0 at full resolution would be 2,745 √ó 2,745 pixels, which is still quite large. This demonstrates why overviews are so valuable for interactive applications.\n\n\ndef visualize_level(i):\n    \"\"\"Show RGB composite for overview level (cropped top-left).\"\"\"\n    ds = overview_datasets[f\"L{i}\"]                         # Select overview level\n    r, g, b = [ds[b].values for b in ('b04', 'b03', 'b02')] # Extract RGB bands\n    h, w = r.shape\n    rgb = np.dstack([r, g, b])[:h//4, :w//4]                # Crop top-left quarter\n    img = np.dstack([normalize(rgb[..., j]) for j in range(3)]) # Normalise bands\n    fig, ax = plt.subplots(figsize=(4.5, 4.5))               # Set figure size\n    ax.imshow(img)                                           # Display RGB image\n    plt.show()\ninteract(visualize_level, i=IntSlider(min=0, max=7, value=4, description='Zoom Level')); # Interactive slider",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/66_use_overviews.html#comparing-multiple-resolution-levels",
    "href": "06_eopf_zarr_in_action/66_use_overviews.html#comparing-multiple-resolution-levels",
    "title": "Create and Visualise Multiscale Pyramids - Part 2",
    "section": "Comparing Multiple Resolution Levels",
    "text": "Comparing Multiple Resolution Levels\nTo better understand the effect of downsampling, let‚Äôs compare multiple overview levels side by side. This visual comparison helps us see:\n\nHow much spatial detail is lost at each downsampling level\nThe tradeoff between image quality and file size/performance - L2 is 16√ó smaller than L0 but still retains good detail\nWhich level is appropriate for different use cases: L2 for regional analysis, L5 for quick previews, L7 for thumbnails\n\nThe function below displays three different levels (L2, L5, and L7) to show this progression from medium to very coarse resolution.\n\ndef show_levels(levels=(2, 5, 7)):\n    \"\"\"Display RGB composites for selected overview levels.\"\"\"\n    fig, axes = plt.subplots(1, len(levels), figsize=(12, 4))\n    for ax, i in zip(axes, levels):\n        ds = overview_datasets[f\"L{i}\"]                              # Select overview level\n        rgb = np.dstack([ds[b].values for b in ('b04', 'b03', 'b02')]) # Stack RGB bands\n        img = np.dstack([normalize(rgb[..., j]) for j in range(3)])     # Normalise\n        ax.imshow(img); ax.axis(\"off\")\n        ax.set_title(f\"L{i} | {rgb.shape[0]}√ó{rgb.shape[1]} | √ó{2**i}\", fontsize=10)\n    plt.tight_layout(); plt.show()\n\nshow_levels()\n\n\n\n\n\n\n\n\nNotice the progressive loss of detail:\n\nL2 (4√ó downsampled, 2745√ó2745 px): Retains good spatial detail, suitable for regional-scale visualisation and analysis\nL5 (32√ó downsampled, 343√ó343 px): Shows general patterns and major features but loses fine details like small fields or roads\nL7 (128√ó downsampled, 85√ó85 px): Provides only a coarse overview showing large-scale patterns, useful for thumbnails or global context\n\nThis demonstrates why overviews are essential for progressive rendering in web mapping applications: the application can display L7 instantly for context, then progressively load L5, L3, L1 as the user waits, and finally load L0 when zoomed in for detailed analysis.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/66_use_overviews.html#interactive-web-map-with-automatic-level-selection",
    "href": "06_eopf_zarr_in_action/66_use_overviews.html#interactive-web-map-with-automatic-level-selection",
    "title": "Create and Visualise Multiscale Pyramids - Part 2",
    "section": "Interactive Web Map with Automatic Level Selection",
    "text": "Interactive Web Map with Automatic Level Selection\nNow let‚Äôs put everything together by creating a professional-like interactive web map using ipyleaflet. This demonstrates a real-world application of overviews for geospatial visualisation.\nKey features:\n\nAutomatic level selection: As you zoom in or out, the map automatically switches to the most appropriate overview level based on the current zoom level and ground resolution\nManual override: Use the slider to manually select a specific level if you want to compare quality at different resolutions\nStandard map controls: Pan by clicking and dragging, zoom with mouse wheel or +/- buttons, switch basemap layers\nReal-time information: The label shows which level is displayed, its dimensions, cell size, and current ground resolution\n\nThe automatic selection algorithm works by:\n\nCalculating the ground resolution (metres per pixel) at the current Web Mercator zoom level\nComparing it to the cell_size metadata of each overview level\nSelecting the level whose cell_size is closest to the ground resolution\n\nThis ensures you always see the optimal balance between image quality and loading performance for your current view.\n\n# Create Interactive Map with Smart Overview Level Selection\nfrom ipyleaflet_multiscales import create_interactive_map\n\n# Get metadata from the base level (L0)\nmetadata = overview_datasets[\"L0\"].b02.attrs\n\n# Define RGB band names (Sentinel-2: R=b04, G=b03, B=b02)\nband_names = {\"r\": \"b04\", \"g\": \"b03\", \"b\": \"b02\"}\n\n# Create the interactive map\n# - initial_level=4: Start with L4 (good balance between quality and performance)\n# - initial_zoom=10: Start zoomed to show the full area\n# - band_names: Specify which bands to use for RGB composite\nmap_widget = create_interactive_map(\n    overview_datasets=overview_datasets,\n    multiscales=multiscales,\n    metadata=metadata,\n    initial_level=5,\n    initial_zoom=7,\n    band_names=band_names\n)\n\n# Display the map\n# The label now shows: Level | Pixel dimensions | Cell size | Zoom | Ground resolution\ndisplay(map_widget)\n\nüó∫Ô∏è  Creating interactive map with overview levels...\n   Center: [70.6556, -22.7698] (lat/lon)\n   Bounds: [[70.1988, -24.3543], [71.1124, -21.1852]]\n\n\n\n\n    \n    \n\n\nCreating initial overlay for L5...\n   Image shape: (343, 343, 3)\n‚úì Map created successfully!\n   - Zoom in/out to automatically switch overview levels (smart selection based on cell_size)\n   - Or use the slider to manually select a level\n\n\n\n\n\n\nHow to use the interactive map:\n\nZoom in/out using the +/- buttons, mouse wheel, or double-click - watch as the overview level automatically adjusts to match your zoom level\nPan the map by clicking and dragging to explore different areas\nUse the slider to manually select a specific overview level if you want to compare quality\nMonitor the label which shows:\n\nLevel ID and dimensions: e.g.¬†‚ÄúL5 (343√ó343 px)‚Äù\nDownsampling factor: e.g.¬†‚Äú32√ó downsampled‚Äù\nCell size: The spatial resolution in metres (e.g.¬†‚Äú320.0m‚Äù means each pixel represents 320m on the ground)\nCurrent zoom: The Web Mercator zoom level (typically 1-18)\nGround resolution: The actual pixel size at the current zoom level (e.g.¬†‚Äú84.5m/px‚Äù)\n\n\nTry zooming in and out to see how the system automatically switches between levels to maintain both visual quality and responsiveness!",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/66_use_overviews.html#now-it-is-your-turn",
    "href": "06_eopf_zarr_in_action/66_use_overviews.html#now-it-is-your-turn",
    "title": "Create and Visualise Multiscale Pyramids - Part 2",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nNow that you‚Äôve learned how to visualise and interact with multiscale overviews, try these exercises to deepen your understanding:\n\nTask 1: Experiment with different band combinations\nInstead of true colour RGB (b04, b03, b02), try creating false colour composites that highlight different features:\n\nColour infrared (CIR): {\"r\": \"b08\", \"g\": \"b04\", \"b\": \"b03\"} - highlights vegetation in red tones\nAgriculture composite: {\"r\": \"b08\", \"g\": \"b03\", \"b\": \"b02\"} - emphasises crop health and vigour\nUrban analysis: {\"r\": \"b08\", \"g\": \"b04\", \"b\": \"b02\"} - distinguishes urban areas from vegetation\n\nModify the band_names dictionary in the map creation code above and re-run the cell to see how different band combinations reveal different information about the landscape.\n\n\nTask 2: Apply this workflow to a different area\nGo back to the previous tutorial (65_create_overviews.ipynb) and create overviews for a different Sentinel-2 scene from your region of interest. Then return to this notebook and update the s3_zarr_name variable to visualise your new dataset. Compare how the overview structure works for different landscapes (urban vs rural, mountainous vs flat, etc.).\n\n\nTask 3: Analyse the performance tradeoff\nMeasure how long it takes to load and display different overview levels. Add timing code like:\nimport time\nstart = time.time()\nvisualize_level(0)  # L0 - full resolution\nprint(f\"L0 took {time.time()-start:.2f} seconds\")\n\nstart = time.time()\nvisualize_level(5)  # L5 - much coarser\nprint(f\"L5 took {time.time()-start:.2f} seconds\")\nHow much faster is L5 compared to L0? What about L7? At what level do you think the quality becomes too low for useful analysis?\nNow that you‚Äôve mastered creating and visualising GeoZarr overviews through tutorials 65 and 66, you can:\n\nApply these techniques to your own datasets: Use the complete workflow on your Earth Observation data from any source (Sentinel-2, Landsat, commercial satellites, etc.)\nBuild custom web applications: The ipyleaflet_multiscales module provides a foundation for developing interactive mapping tools tailored to specific needs\nOptimise for your use case: Test different chunk sizes, compression algorithms, and scale factors to find the best balance between file size and access performance\nScale to cloud platforms: The workflow demonstrated here already uses S3 cloud object storage, which enables web-scale access and can be adapted to other cloud providers (Azure Blob, Google Cloud Storage)\n\nFurther resources:\n\nGeoZarr Specification - Full technical specification for GeoZarr extensions\nxarray documentation - Comprehensive guide to working with labelled multi-dimensional arrays",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/66_use_overviews.html#conclusion",
    "href": "06_eopf_zarr_in_action/66_use_overviews.html#conclusion",
    "title": "Create and Visualise Multiscale Pyramids - Part 2",
    "section": "Conclusion",
    "text": "Conclusion\nIn this tutorial, we‚Äôve learned how to visualise and interact with multiscale overview pyramids for GeoZarr datasets. We covered:\n\nUnderstanding the hierarchy: How to parse and inspect multiscales metadata following the GeoZarr specification\nLoading levels dynamically: How to iterate through the layout metadata and load different resolution levels\nCreating RGB composites: How to combine spectral bands with proper contrast enhancement and NaN handling\nInteractive exploration: How to build responsive widgets for exploring different zoom levels\nProfessional web mapping: How to create maps with automatic level selection based on zoom and ground resolution\n\nKey takeaways:\n\nOverviews enable efficient multi-scale visualisation by providing progressively coarser representations of large datasets\nAutomatic level selection ensures optimal performance while maintaining visual quality appropriate for the current view\nProper NaN handling is critical - failing to filter NaN values before percentile calculations causes white or blank displays\nThe cell_size metadata enables intelligent zoom-aware rendering by matching overview resolution to ground resolution\n\nThese techniques are essential for building interactive Earth Observation applications that remain responsive even when working with very large satellite imagery datasets.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/66_use_overviews.html#whats-next",
    "href": "06_eopf_zarr_in_action/66_use_overviews.html#whats-next",
    "title": "Create and Visualise Multiscale Pyramids - Part 2",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following notebook, we will go South and showcase the application of Sentinel 2 L1C data, focusing on Water Reservoirs. We will implement parts of the GWW algorithms to estimate water surface area for a single reservoir: Mita Hills in Zambia.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Create and Visualise Multiscale Pyramids - Part 2</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html",
    "href": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html",
    "title": "Reservoir Surface Monitoring",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nWater reservoirs are essential for water supply, energy production, and irrigation. However, population growth, economic expansion, and climate change are increasing pressure on these resources, affecting water availability and raising the risk of droughts and floods. Reliable monitoring of reservoirs is critical to ensure sustainable water management and water security. This is especially important in transboundary basins, where upstream reservoirs can significantly influence water availability for downstream countries.\nThe Global Water Watch (GWW) is a platform developed by Deltares with support from Google.org, the Water, Peace, and Security Partnership, and the European Space Agency (ESA). It provides near-real-time (NRT), globally accessible information on reservoirs using Earth Observation data, helping stakeholders monitor changes in water extent and manage resources more effectively. A detailed description of the GWW methods is available under High-resolution surface water dynamics in Earth‚Äôs small and medium-sized reservoirs by Donchyts et al., here.\nIn this notebook, we implement parts of the GWW algorithms to estimate water surface area for a single reservoir: Mita Hills in Zambia. Although the original GWW algorithm uses Landsat 7 & 8 as well as Sentinel-2, we focus only on Sentinel-2 (L1C) imagery here for simplicity. For the purpose of this resource, we use Sentinel-2 (L1C) imagery available through the EOPF STAC Catalog.\nSection 1 focuses on preparing and preprocessing the Sentinel-2 data, while Section 2 covers the steps required to estimate reservoir surface area using the GWW methodology.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Reservoir Surface Monitoring</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html#section-1---data-preparation",
    "href": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html#section-1---data-preparation",
    "title": "Reservoir Surface Monitoring",
    "section": "Section 1 - Data Preparation",
    "text": "Section 1 - Data Preparation\nOverview of Section 1:\n1.1 - Initial settings and data connection\n1.2 - Load and preprocess data\n1.3 - Filtering data\n\n1.1 - Initial settings and data connection\nInitiate dask client for parallel processing\n\n# Start dask client \nclient = Client()  # local cluster, can monitor dashboard\nprint(client)\nprint(client.dashboard_link)\n\n&lt;Client: 'tcp://127.0.0.1:42001' processes=4 threads=8, memory=31.35 GiB&gt;\nhttp://127.0.0.1:8787/status\n\n\nDefine the settings and retrieve Sentinel-2 L1C data from the EOPF STAC Catalog. In this example, we will use the bounding box covering Mita Hills, apply a 30% cloud cover cutoff for the query, and select a period from August 2022 to December 2024. This relatively long period ensures a sufficient number of scenes, covering both dry and wet conditions.\n\n# Define AOI bbox coordinates (minx, miny, maxx, maxy) in EPSG:4326 (WGS 84)\nminx, miny, maxx, maxy = 28.99253107, -14.2426452, 29.17046702, -13.95317373\n\n# Define time range\nstart_date = \"2022-08-01\" \nend_date = \"2024-12-01\"\n\n# Define cloud cover cutoff percentile\ncloud_cutoff_percentile = 30  # e.g., 30%\n\n# Define collection\ncollection = \"sentinel-2-l1c\"\n\n# Connect to EOPF STAC Catalog\neopf_stac_api_root_endpoint = \"https://stac.core.eopf.eodc.eu/\"\neopf_catalog = StacClient.open(url=eopf_stac_api_root_endpoint)\n\n# Start a search\ns2_collection = eopf_catalog.search(\n    collections=collection,\n    bbox=(minx, miny, maxx, maxy),\n    datetime=f\"{start_date}T00:00:00Z/{end_date}T23:59:59Z\",\n    query = {'eo:cloud_cover': {'lte': cloud_cutoff_percentile}}\n)\n\n# List found scenes\nscenes = list_found_elements(s2_collection)\nprint(f\"Total items found for collection {collection} over AOI:\", len(scenes[0]))\n\nif len(scenes[0]) == 0:\n    raise ValueError(\"No scenes found for the specified AOI and time range. Please adjust your search parameters.\")\n\n# Retrieve ZARR URLs/paths\nS2l1c_coll = eopf_catalog.get_collection(collection)\nitems_loc_url = []\n\nfor item_id in scenes[0]:\n    item = S2l1c_coll.get_item(id=item_id)\n    item_assets = item.get_assets(media_type=MediaType.ZARR)\n    cloud_storage_url = item_assets['product'].href\n    items_loc_url.append(cloud_storage_url)\n\nTotal items found for collection sentinel-2-l1c over AOI: 115\n\n\n\n\n1.2 - Load and preprocess data\nFirst we load the datasets using the load_datatrees function. Note that in the following cell loading is done lazily using dask.delayed, which builds a Dask task graph. Execution of this graph triggers parallel processing of all dataset loading tasks, improving efficiency and reducing memory usage.\n\n# Load datatrees in parallel using dask.delayed\ndelayed_datatrees = [dask.delayed(load_datatrees)(path) for path in items_loc_url]\ndatatrees = dask.compute(*delayed_datatrees)\n\nThe obtained datatrees contain the full set of source bands (at all available resolutions) as well as useful metadata for every retrieved scene. Some preprocessing is necessary. This is handled by the preprocess_datatree function, which extracts only the bands of interest, i.e.¬†green (b03) and NIR (b08), clips the tile to the AOI, merges the two bands into a single dataset, and finally adds a time dimension derived from the datatree attributes (‚Äústac_discovery‚Äù / ‚Äúproperties‚Äù / ‚Äústart_datetime‚Äù).\nAlthough the search coordinates are given in geographic coordinates (EPSG:4326), the data retrieved from the EOPF STAC API is provided in UTM coordinates. Therefore, we need to convert the AOI coordinates to UTM as well, to ensure that the clipping is performed correctly. The image CRS code is also available in the datatree attributes.\n\n# get the scenes crs from the attributes of the first datatree\ncrs_code = datatrees[0].attrs[\"other_metadata\"][\"horizontal_CRS_code\"]  \nprint(\"Scene CRS code:\", crs_code)\n\n# Build CRS object and transformer from WGS84\nscene_crs = CRS.from_user_input(crs_code)\nproject_to_scene = Transformer.from_crs(\"EPSG:4326\", scene_crs, always_xy=True)\n\n# Transform bounding box to scene CRS \nminx_utm, miny_utm = project_to_scene.transform(minx, miny)\nmaxx_utm, maxy_utm = project_to_scene.transform(maxx, maxy)\n\nScene CRS code: EPSG:32735\n\n\nApply the preprocessing and compute the datasets\n\n# Preprocess datatrees in parallel using dask.delayed\ndelayed_datasets = [\n    dask.delayed(preprocess_datatree)(\n        dtree,\n        minx_utm,\n        miny_utm,\n        maxx_utm,\n        maxy_utm,\n    )\n    for dtree in datatrees\n]\n\ndatasets = dask.compute(*delayed_datasets)\n\nCreate a datacube with all datasets along time dimension\n\n# ignore some warnings\nwarnings.filterwarnings(\"ignore\", message=\"Converting non-nanosecond precision\")\n\n# Combine all datasets along time dimension\ndata_cube = xr.concat(datasets, dim=\"time\")\n# Sort by time\ndata_cube = data_cube.sortby(\"time\")\n\n\n\n1.3 - Filtering data\nAlthough we selected scenes with less than 30% cloud coverage in our query, this threshold applies to the entire tile, meaning some clouds may still be present in the clipped data_cube.\nTo address this, we first assign a quality score to each image using the green band by computing the 75th percentile (default in GWW) over the AOI (clouds have high reflectance so the lower the score the cleaner).\nWe then keep only the cleanest scenes based on a chosen percentage of the total images (in our case 75%).\nNotes to consider:\n\nThis step requires a long time series with a relatively large number of images (for example, in this notebook we use a period with around 100 images). If you are focusing on a shorter period, you can skip this subsection and move directly to Section 2.\nSelecting scenes with less than 30% cloud coverage can be somewhat arbitrary. A more accurate estimate could be obtained from climatology data, for example using the MODIS cloud occurrence dataset.\nKeeping the top 75% of the cleanest images is also somewhat arbitrary.\nAll of the above filtering settings may reduce the number of final cleaned images compared to the number used/provided by the official GWW algorithm over the same period, although only minor differences are expected.\n\n\n# Compute quality scores based on green band 75th percentile\nquality_scores = data_cube[\"green\"].quantile(\n    q=0.75,\n    dim=(\"y\", \"x\"),\n    skipna=True\n)\n# Store quality scores in data cube\ndata_cube[\"quality_score\"] = quality_scores\n\n\n# Keep the 75% cleanest scenes based on quality scores\nkeep_fraction = 0.75\n\n# Only compute the quality_score array\nqs = data_cube[\"quality_score\"].compute().values \nn_keep = max(int(len(qs) * keep_fraction), 1)\n\n# Indices of the n_keep smallest values\nsorted_idx = qs.argsort()[:n_keep]\n\n# Select those scenes from dataset \ndata_cube = data_cube.isel(time=sorted_idx).sortby(\"time\")\n\nFinally, we have a clipped and cleaned data_cube containing all scenes, including a time dimension for the relevant bands as data variables (time, lat, lon). We will use this dataset in Section 2 to perform time series analysis, namely to derive water extents and calculate the area for each scene.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Reservoir Surface Monitoring</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html#section-2---reservoir-water-surface-estimation",
    "href": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html#section-2---reservoir-water-surface-estimation",
    "title": "Reservoir Surface Monitoring",
    "section": "Section 2 - Reservoir Water Surface Estimation",
    "text": "Section 2 - Reservoir Water Surface Estimation\nOverview of Section 2:\n2.1 - Compute Normalized Difference Water Index (NDWI)\n2.2 - Integrate Water Occurrence (WO) data\n2.3 - Generate water extents (core GWW algorithm)\n2.4 - Extract Largest Connected Component\n2.5 - Compute reservoir area\n\n2.1 - Compute Normalized Difference Water Index (NDWI)\nOnce we have preprocessed and prepared the data for our AOI, we can start by computing the Normalized Difference Water Index (NDWI) using the green (b03) and NIR (b08) bands. The NDWI highlights water features by producing high positive values for water pixels and lower or negative values for land and vegetation. This provides an initial indication of where water is located, although simple thresholding at this stage can be unreliable, particularly near shorelines or in areas with shallow water or vegetation.\n\n# calculate NDWI\ngreen = data_cube['green']\nnir = data_cube['nir']\nndwi = (green - nir) / (green + nir)\n\nVisualize example output from Subsection 2.1\n\n# Plot NDWI for a specific date as an example\nplt.figure(figsize=(5, 5))\nplt.imshow(ndwi.sel(time='2024-05-23'), vmin=-0.5, vmax=0.5, cmap='managua')\nplt.colorbar(label='NDWI', shrink=0.7)\nplt.title('NDWI on 2024-05-23');\n\n\n\n\n\n\n\n\nAs shown in the plot, the water body area is visible, with high values represented by the deep sky-blue color. However, clouds are present within the water body area.\n\n\n2.2 - Integrate Water Occurrence (WO) data\nThe Global Surface Water Explorer (GSWE) dataset from the European Commission‚Äôs Joint Research Centre is also used here. This dataset maps the location and temporal distribution of water surfaces at the global scale over the past 32 years, providing statistics on the extent and change of those water surfaces, namely water occurrence (WO) probabilities per pixel. WO represents the fraction of time a given pixel was observed as water over the study period. The table below shows the range of values and their interpretation.\n\n\nInterpretation of Pixel Values in GSWE (Water Occurrence Layer)\n\n\n\n\n\n\n\n\nPixel Value (range)\nInterpretation\nTypical Environment\n\n\n\n\n0.0\nNever detected as water during the observation period\nLand, desert, urban area\n\n\n0.1 ‚Äì 0.5\nOccasionally detected as water (intermittent presence)\nSeasonal ponds, floodplains, agricultural fields\n\n\n0.5 ‚Äì 0.9\nFrequently water but not permanent\nWetlands, seasonal lakes, riverbanks\n\n\n~1.0\nAlmost always water (permanent presence)\nLakes, large rivers, reservoirs\n\n\n\nFor more information the user is referred to the associated journal article and the online Data Users Guide.\nThe WO dataset is static. For this exercise, we have stored a subset over our AOI (under the data folder), which we will read. In general, the dataset can be downloaded here or accessed through Google Earth Engine. At the end of this notebook, in the example tasks, a code snippet is provided showing how the WO dataset can be downloaded and processed using ee and/or geemap.\nThe GSWE will be used in the next step to perform some filling over the initially classified water areas.\n\nds_wo = rioxarray.open_rasterio(\"data/water_occurrence_utm35_v14.tif\")\nndwi.rio.write_crs(crs_code, inplace=True)\n\n# resample it to match ndwi as it is on a 30m resolution\nds_wo_matched = ds_wo.rio.reproject_match(\n    ndwi,\n    resampling=Resampling.nearest\n)\nds_wo_matched = ds_wo_matched[0]\n\nVisualize example output from Subsection 2.2\n\n# Plot WO\nplt.figure(figsize=(5, 5))\nplt.imshow(ds_wo_matched, vmin=0, vmax=1, cmap='managua')\nplt.colorbar(label='Probability of Water Occurrence', shrink=0.7)\nplt.title('Water Occurrence');\n\n\n\n\n\n\n\n\nAs shown in the plot, the main water body has very high probability values, close to one, indicating that these pixels were almost always water during the observation period, representing the permanent water areas of the reservoir. Lower values appear near the edges of the reservoir, which are the most challenging areas to detect. These lower probabilities typically indicate that water was present frequently but not permanently (values around 0.5‚Äì0.9) or only occasionally (values around 0.1‚Äì0.5). In the next subsection, we will focus on detecting these variable water areas in each image.\n\n\n2.3 - Generate water extents (core GWW algorithm)\nTo detect water more reliably, we combine the following two datasets: the NDWI index and the Water Occurrence (WO).\nFirst, we identify edges in the NDWI image using the Canny, which highlights sharp transitions between water and land. After that, we apply a morphological dilation to the edges, and using only these dilated edge pixels, we apply Otsu thresholding to determine a robust cutoff value that separates water from land. This avoids biases from large uniform land areas and ensures the threshold is focused on transition zones. For more details on the Canny edge detector and Otsu thresholding see this publication.\nNext, we use the WO dataset to fill in water areas that NDWI might miss, such as shallow, turbid zones etc. The 80th percentile of the WO values is computed only on the edge pixels, making the filling threshold context-aware. This filling also helps recover water in pixels obscured by clouds or shadows in the current image. Water is added in areas that are classified as non-water (NDWI&lt;0 here, -0.15 in raw GWW) but exceed the WO threshold.\nFinally, the water mask from NDWI and the filled water mask from WO are combined to produce the total water mask.\nThe code for the steps described above can be found in the gww function.\n\nwater_mask_da, water_fill_da, total_water_da = xr.apply_ufunc(\n    gww,\n    ndwi,              # NDWI array\n    ds_wo_matched,     # Water occurrence array\n    input_core_dims=[[\"y\", \"x\"], [\"y\", \"x\"]],\n    output_core_dims=[[\"y\", \"x\"], [\"y\", \"x\"], [\"y\", \"x\"]],\n    vectorize=True,\n    dask=\"parallelized\",\n    output_dtypes=[bool, bool, bool],\n    dask_gufunc_kwargs={\"allow_rechunk\": True},\n    kwargs={\n        \"canny_sigma\": 0.7,        # Sigma for Canny edge detector\n        \"canny_low\": 0.5,          # Canny low threshold\n        \"canny_high\": 1.0,         # Canny high threshold\n        \"nonwater_thresh\": 0       # NDWI non-water threshold, used to fill water pixels from WO\n    }\n)\n\nVisualize example output from Subsection 2.3\n\nplt.figure(figsize=(10, 10))\n\nplt.subplot(1, 3, 1)\nplt.imshow(water_mask_da.sel(time=\"2024-05-23\").compute(), cmap='Blues')\nplt.title('Water Mask')\n# plt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.imshow(water_fill_da.sel(time=\"2024-05-23\").compute(), cmap='Blues')\nplt.title('Water Fill')\n# plt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.imshow(total_water_da.sel(time=\"2024-05-23\").compute(), cmap='Blues')\nplt.title('Total Water')\n# plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIn the example scene from 2024-05-23 shown in the figure above, the left panel displays the initial water detected using Otsu, the middle panel shows the water filling based on the WO dataset, and the right panel presents the total detected water produced by our algorithm.\n\n\n2.4 - Extract Largest Connected Component\nEven after thresholding, small water patches or noise may appear in the mask. Since we are interested in the main reservoir, we extract the largest connected component from the binary water mask. This isolates the primary water body while ignoring smaller, isolated water regions, giving a clean representation of the reservoir. For this we are using the largest_connected_component function. (Note that the largest connected component is not extracted in the original GWW algorithm)\n\n# Largest Connected Component (LCC) filtering on Total Water\nlcc_da = xr.apply_ufunc(\n    largest_connected_component,\n    total_water_da,\n    input_core_dims=[[\"y\", \"x\"]],\n    output_core_dims=[[\"y\", \"x\"]],\n    vectorize=True,  # applies function to each 2D slice\n    dask=\"parallelized\",\n    output_dtypes=[bool],\n)\n\n\n\n2.5 - Compute reservoir area\nAs a last step, we can calculate the reservoir area by counting the number of pixels in the largest water body and converting this count to square kilometers using the pixel size (10 m for our case; see the compute_area_km2 function).\n\n# Compute area in km¬≤ of LCC water bodies\narea_da = xr.apply_ufunc(\n    compute_area_km2,\n    lcc_da,\n    input_core_dims=[[\"y\", \"x\"]],\n    output_core_dims=[[]],  # scalar per time\n    vectorize=True,\n    dask=\"parallelized\",\n    kwargs={\"pixel_size\": 10.0},\n    output_dtypes=[float],\n)\n\nVisualize example output from Subsections 2.4 and 2.5\n\nplt.figure(figsize=(5, 5))\nplt.imshow(lcc_da.sel(time=\"2024-05-23\").compute(), cmap='Blues')\nplt.title(f'Largest Connected Component on 2024-05-23 \\n Calculated Area: {area_da.sel(time=\"2024-05-23\").compute():.2f} km¬≤');\n\n\n\n\n\n\n\n\nCompute and visualize the estimated areas over time. (Note that the final surface water area time series in the raw GWW algorithm are post-processed with a temporal quantile-based filter)\n\n# Compute area time series\narea_da = area_da.compute()\n\nPlotting the entire time series\n\nplt.figure(figsize=(10, 5))\n\narea_da.to_pandas().plot(\n    marker='x', \n    ms=4,                \n    markeredgewidth=3,     \n    linestyle=' ', \n    color='darkorange', \n    label=\"Computed\"\n)\n\nplt.ylabel('Surface Area (km¬≤)')\nplt.grid()\nplt.legend();",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Reservoir Surface Monitoring</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html#conclusion",
    "href": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html#conclusion",
    "title": "Reservoir Surface Monitoring",
    "section": "Conclusion",
    "text": "Conclusion\nIn this notebook, we demonstrated how Sentinel-2 L1C data can be accessed and processed to monitor reservoir water surface area over a historical time series using Earth Observation techniques. To achieve this, we applied parts of the Global Water Watch (GWW) algorithms (detailed description here) to filter images, derive water masks, fill gaps and estimate reservoir surface.\nThe workflow relied on the .zarr data format from the EOPF STAC Catalog, which enables fast, efficient, and scalable data access directly from the cloud, using standard Python tools. Compared to the traditional .safe files/workflows, this approach reduces overhead, allowing us to produce reservoir time series in just a few minutes.\nOverall, this demonstrates the strong potential of this catalog not only for retrospective reservoir monitoring but also for near-real-time operational applications.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Reservoir Surface Monitoring</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html#now-it-is-your-turn",
    "href": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html#now-it-is-your-turn",
    "title": "Reservoir Surface Monitoring",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nNow that you‚Äôre familiar our reservoir detection workflow, based on the zarr format provided by the EOPF Sentinel STAC Catalog, it‚Äôs time to put your skills into practice! Below are suggested exercises that scale from replication to comparison and finally to an advanced extension using a different sensor.\nOverview of tasks: 1. Try another reservoir ‚Äì replicate the workflow for a different reservoir.\n2. Compare with the official GWW algorithm ‚Äì analyze differences between our implementation and the GWW API results.\n3. Explore SAR-based water extent estimation ‚Äì extend the workflow to Sentinel-1 SAR data and compare with optical results.\n\nTask 1: Try Another Reservoir\nGoal: test how well the workflow generalizes to a different reservoir.\nSteps: 1. Visit the Global Water Watch (GWW) interactive viewer and explore reservoirs.\n2. Pick a reservoir you find interesting and click DOWNLOAD.GEOJSON (bottom of the panel) to download its boundary polygon.\n3. Use GeoPandas to load the GeoJSON and compute the bounding box (bbox) for your new study area.\n4. Re-run this notebook‚Äôs processing pipeline using that bounding box.\nTips & ideas: - Choose reservoirs in different climates (e.g., semi-arid vs.¬†humid tropical) to observe how clouds, vegetation and seasonal changes affect detection. - Try several sizes: small vs.¬†large reservoirs to see how morphological operations and the largest connected component step behave. Note that usually very large reservoirs are well measured using in-situ measurements and partial observations of surface area are less indicative of the state of the full reservoir.\nYou can use the following code snippet to get the WO dataset directly into a data array for your AOI\nimport ee\nimport geemap\n\nee.Authenticate()\nee.Initialize()\n\naoi = ee.Geometry.Rectangle([minx, miny, maxx, maxy])\n\n# Load and process image\nwater_occurrence = (\n    ee.Image(\"JRC/GSW1_4/GlobalSurfaceWater\")\n    .select(\"occurrence\")\n    .unmask(0)\n    .divide(100)\n)\n\nds = geemap.ee_to_xarray(\n    water_occurrence,\n    geometry=aoi,\n    scale=30,\n    crs=crs_code,)\n\nda = ds[\"occurrence\"].isel(time=0).transpose(\"Y\", \"X\").sortby(\"Y\", ascending=False).drop_vars(\"time\")\n\n\nTask 2: Compare with the official GWW algorithm\nGoal: explore differences between the current implementation and the official GWW outputs.\nAs described earlier in this notebook the GWW algorithm is more complex combining many satellite sources and parts of the classification/filtering techniques/settings are different, for example the largest connected components is not extracted. In addition the resulting surface water area time series in GWW are post-processed with a temporal outlier filtering (quantile-based) to remove the remaining errors. Also one major difference is that in the raw algorithm a long archive is exploited.\nSteps: 1. Read the GWW API docs: https://api.globalwaterwatch.earth/docs.\n2. Install the API:\nbash    pip install gwwapi 3. Download timeseries for Mita Hills (reservoir id 88643) using the API (or the website) 4. Compare GWW‚Äôs reported water area time series with your own estimates extracted from Sentinel-2 in this notebook.\nYou can use the following helper function to query the GWW API:\nimport requests\n\ndef get_reservoir_ts_gww(reservoir_id, start_date, end_date):\n    \"\"\"\n    Retrieve time series data for a given reservoir ID from the GWW API.\n    start_date and end_date are strings in 'YYYY-MM-DD' format.\n    \"\"\"\n    base_url = \"https://api.globalwaterwatch.earth/v1\"\n    url = f\"{base_url}/reservoir/{reservoir_id}/ts\"\n\n    params = {\n        \"start\": f\"{start_date}T00:00:00\",\n        \"stop\": f\"{end_date}T23:59:59\"\n    }\n\n    resp = requests.get(url, params=params)\n    resp.raise_for_status()\n    return resp.json()\n\n\nTask 3 (advanced): Explore water extent estimation with SAR Sentinel-1 Level-1 GRD\nGoal:\nAdapt the detection workflow you developed for Sentinel-2 optical data to Sentinel-1 SAR data, and compare how it performs for the same reservoir.\nReasoning:\nIn this notebook, we used Sentinel-2 L1C optical data to estimate reservoir surface area. The same logic - Otsu thresholding, edge detection, morphological filtering, and largest connected component extraction - can also be applied to Sentinel-1 SAR data. Since SAR measures backscatter instead of reflectance, we can‚Äôt compute spectral indices like NDWI. Instead, we use the backscatter values directly to separate wet and dry pixels: water usually appears dark (e.g.¬†&lt; ‚àí16 dB). SAR has the advantage of being cloud-independent, but can sometimes overestimate water, especially when dry soil also produces low backscatter. Also note that SAR requires preprocessing before using it like orbit correction, thermal noise removal, calibration, speckle filtering, terrain correction, conversion to dB etc.\nSteps:\n\nDownload and preprocess Sentinel-1 GRD data (see the Flood Mapping - Time Series Analysis in Valencia example).\n\nAdjust the gww function to work with SAR, e.g.¬†apply a simple mask (e.g.¬†backscatter &lt; -16), refine with Otsu thresholding, use existing morphological steps to clean the result and extract the reservoir (you can skip the water occurrence filling).\nCompare the SAR-based water area with your Sentinel-2 estimates.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Reservoir Surface Monitoring</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html#whats-next",
    "href": "06_eopf_zarr_in_action/67_reservoir_surface_monitoring.html#whats-next",
    "title": "Reservoir Surface Monitoring",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nIn the following notebook, we will explore the application of Sentinel 2 L2A data for analysing vegetation anomalies in German forests.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Reservoir Surface Monitoring</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/68_vegetation_anomalies.html",
    "href": "06_eopf_zarr_in_action/68_vegetation_anomalies.html",
    "title": "Analyzing Forest Vegetation Anomalies Using Sentinel-2 Zarr Data Cubes",
    "section": "",
    "text": "Introduction\nüöÄ Launch this notebook in JupyterLab\nForests are the largest terrestrial carbon sinks, playing a critical role in regulating the global carbon cycle through sustained CO\\(_2\\) uptake. However, extreme climate events (such as heatwaves and droughts) can disrupt forest functioning, reducing photosynthetic activity and, in severe cases, causing tree mortality.\nWhile in situ measurements provide valuable information on forest health, collecting such data over large areas is costly, time-consuming, and logistically challenging. Scalable and continuous monitoring therefore requires more efficient approaches.\nIn this case study, we will explore how to use Sentinel-2 L2A data stored as Zarr data cubes to analyze vegetation anomalies in forest ecosystems in Germany. Specifically, we will focus on two ICOS sites affected by the drought of 2018: DE-Hai and DE-Tha, with DE-Tha left for learners to explore on their own.\nBy leveraging spatiotemporal data cubes, we will compute spectral indices and derive anomaly time series to evaluate forest responses to extreme events in CO\\(_2\\) uptake (Gross Primary Production, GPP, from ICOS). This notebook will guide you through a modular workflow for:\nThrough this study case, you will see the potential of Zarr-based data cubes for scalable forest monitoring.",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Analyzing Forest Vegetation Anomalies Using Sentinel-2 Zarr Data Cubes</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/68_vegetation_anomalies.html#vegetation-anomalies-in-the-hainich-national-park",
    "href": "06_eopf_zarr_in_action/68_vegetation_anomalies.html#vegetation-anomalies-in-the-hainich-national-park",
    "title": "Analyzing Forest Vegetation Anomalies Using Sentinel-2 Zarr Data Cubes",
    "section": "Vegetation Anomalies in the Hainich National Park",
    "text": "Vegetation Anomalies in the Hainich National Park\nWe will start the notebook with a forest ecosystem that was severely affacted by the drought of 2018: DE-Hai.\n\n# DE-Hai Coordinates\nHAI_LAT = 51.079212\nHAI_LON = 10.452168\n\nInitialize a Dask distributed client to enable parallel and delayed computation. This will manage the execution of tasks, such as loading and processing large Sentinel-2 Zarr datasets, efficiently.\n\nclient = Client()\nclient\n\n\nLoad the GPP data\nLoad the GPP time series for the DE-Hai site and compute weekly anomalies, identifying extreme low-GPP events.\n\nThe following helper function just needs one of two possible inputs: ‚ÄúDE-Hai‚Äù (this example), or ‚ÄúDE-Tha‚Äù (for learners to explore).\n\nThe obtained dataframe contains the following columns:\n\nGPP_NT_VUT_REF: Gross Primary Production (GPP) values per week.\nweekofyear: Number of the week of the year [1-53].\nanomaly: GPP anomalies, computed as the deviation from the mean seasonal cycle.\nextreme: Whether the specific value was a extreme or not (1 = extreme, 0 = normal).\n\n\nHAI_df = curate_gpp(\"DE-Hai\")\n\n\n\nCreate the Sentinel-2 L2A Data Cube\nFirst, query the EOPF STAC API to retrieve Sentinel-2 L2A items for the DE-Hai site.\n\nWe specify for the following helper function the coordinates of the site (lat, lon), and we set return_as_dicts to True to avoid ocnflicts when a href link is not present in an asset of the retrieved items.\n\n\n# Get all items as a list of dicts\nHAI_items = get_items(HAI_LAT,HAI_LON,return_as_dicts=True)\n\nFor each item, open and curate the data by subsetting around the site coordinates and selecting the relevant bands:\n\nThe item parameter is a dictionary obtained from each item in HAI_items.\nWe specify the coordinates of the site (lat, lon).\nThe bands parameter is a list of the bands you want to retrive, in this case we just want the red and near-infrared bands (b04 and b8a).\nThe resolution we will use is 20 m: This must be one of 10, 20 or 60.\nThe buffer parameter us set to 500 m (a bounding box is constructed from this parameter as well as from the lat, lon parameters).\nFinally, items_as_dicts is set to True since we defined it in the previous code cell.\n\nAfter this, datasets are computed in parallel with Dask.\n\n# Create the delayed Dask objects\nHAI_ds = [open_and_curate_data(item,lat=HAI_LAT,lon=HAI_LON,bands=[\"b04\",\"b8a\"],resolution=20,buffer=500,items_as_dicts=True) for item in HAI_items]\n\n# Compute the delayed objects in parallel. This outputs a list of xarray.Dataset objects\nHAI_data = dask.compute(*HAI_ds)\n\nAfter computed, datasets are concatenated along the time dimension, sorted by time, and finally loaded into memory as a single xarray.Dataset.\n\n# Concatenate the previous list using the time dimension and sort it\nHAI_ds = xr.concat(HAI_data,dim=\"time\").sortby(\"time\")\n\n# Load it into memory\nHAI_ds = HAI_ds.compute()\n\n\n\nCompute Vegetation Indices\nCompute spectral indices for the DE-Hai dataset using the spyndex package. In this example, we calculate NDVI and kernel NDVI (kNDVI).\n\nNDVI (Normalized Difference Vegetation Index) is a widely used index to monitor vegetation health and greenness. It is calculated as:\n\n\\[\\text{NDVI} = \\frac{N - R}{N + R}\\]\nwhere N is the near-infrared band (B8A) and R is the red band (B04).\n\nkNDVI (Kernel NDVI) is a kernelized version of NDVI. Here, an RBF (Radial Basis Function) kernel is applied:\n\n\\[\\text{kNDVI} = \\frac{k(N,N) - k(N,R)}{k(N,N) + k(N,R)}\\]\nwhere \\(k(a,b)\\) is the RBF kernel:\n\\[k(N,N) = 1\\]\n\\[k(N,R) = \\exp\\left(-\\frac{(N-R)^2}{2 \\sigma^2}\\right)\\]\nHere, \\(\\sigma\\) is claculated as the median in the time dimension of \\(0.5(N+R)\\).\nThe spyndex.computeIndex function computes both indices across the time series and stores them in an xarray.Dataset named idx for subsequent anomaly analysis.\nThe spyndex.computeKernel function computes the kernel for the kNDVI.\nNote that in both cases spyndex just requires the data for computing the indices without the need of hard-coding the formulas.\n\nidx = spyndex.computeIndex(\n    [\"NDVI\",\"kNDVI\"], # Indices to compute\n    N = HAI_ds[\"b8a\"], # NIR band\n    R = HAI_ds[\"b04\"], # Red band\n    kNN = 1.0,\n    kNR = spyndex.computeKernel(\n        \"RBF\", # RBF kernel\n        a = HAI_ds[\"b8a\"],\n        b = HAI_ds[\"b04\"],\n        sigma = ((HAI_ds[\"b8a\"] + HAI_ds[\"b04\"])/2.0).median(\"time\")\n    )\n).to_dataset(\"index\")\n\nAdd the name and units of each index to the attributes according to the CF conventions.\n\nidx.NDVI.attrs[\"long_name\"] = spyndex.indices.NDVI.long_name\nidx.NDVI.attrs[\"units\"] = \"1\"\n\nidx.kNDVI.attrs[\"long_name\"] = spyndex.indices.kNDVI.long_name\nidx.kNDVI.attrs[\"units\"] = \"1\"\n\nResample the NDVI and kNDVI time series to weekly frequency, taking the median within each week. After resampling, fill temporal gaps by applying cubic interpolation along the time dimension. This produces smooth, continuous weekly index time series suitable for anomaly computation.\n\nidx = idx.resample(time=\"1W\").median().interpolate_na(dim=\"time\",method=\"cubic\")\n\n\n\nCalculate Vegetation Anomalies\nCompute the median seasonal cycle (MSC) for NDVI and kNDVI.\nBy grouping the time series by weekofyear and taking the median across years, this step produces a climatological baseline that represents the typical vegetation state for each week of the year.\nThe MSC will be used later to derive vegetation anomalies.\n\nmsc = idx.groupby(\"time.weekofyear\").median(\"time\")\n\nPlot the MSC of the NDVI.\n\nmsc.NDVI.plot.imshow(col = \"weekofyear\",cmap = \"viridis\",col_wrap = 8,vmin=0,vmax=1)\n\nPlot the MSC of the kNDVI.\n\nmsc.kNDVI.plot.imshow(col = \"weekofyear\",cmap = \"viridis\",col_wrap = 8,vmin=0,vmax=1)\n\nCompute vegetation anomalies by subtracting the median seasonal cycle (MSC) from the weekly NDVI and kNDVI values. This step isolates deviations from the expected seasonal pattern, allowing us to identify abnormal vegetation conditions potentially linked to stress or extreme events.\n\nidx_anomalies = idx.groupby(\"time.weekofyear\") - msc\n\nAdd the name and units of each index anomaly to the attributes according to the CF conventions.\n\nidx_anomalies.NDVI.attrs[\"long_name\"] = spyndex.indices.NDVI.long_name + \" Anomaly\"\nidx_anomalies.NDVI.attrs[\"units\"] = \"1\"\n\nidx_anomalies.kNDVI.attrs[\"long_name\"] = spyndex.indices.kNDVI.long_name + \" Anomaly\"\nidx_anomalies.kNDVI.attrs[\"units\"] = \"1\"\n\n\n\nVisualize Time Series\nWe will use time series for visualization. Let‚Äôs first aggregate the indices in space using the median to produce a time series.\n\nidx_agg = idx.median([\"x\",\"y\"])\n\nHere, we defined the colors to use for our indices.\n\n# Colors for indices\nNDVI_COLOR = 'limegreen'\nkNDVI_COLOR = 'darkviolet'\n\n# Color for zero line in anomalies\nZERO_COLOR = 'red'\n\nNow, we will plot the NDVI and kNDVI time series together with the GPP measurements for the DE-Hai site. A secondary axis will be used to display GPP, allowing direct visual comparison between vegetation dynamics and ecosystem productivity. Extreme low-GPP events are highlighted as shaded red intervals: These events are defined as periods of at least two consecutive days in which GPP anomalies fall below the 10th percentile of the lower tail of the distribution. This information is contained in the HAI_df dataframe created via curate_gpp helper function.\nThis visualization helps link vegetation index to observed reductions in carbon uptake, revealing how forest canopy responses relate to ecosystem-scale stress signals.\n\nfig, ax = plt.subplots(figsize=(15, 3))\n\nax.plot(idx_agg.time, idx_agg[\"NDVI\"],  color=NDVI_COLOR,  label=\"NDVI\")\nax.plot(idx_agg.time, idx_agg[\"kNDVI\"], color=kNDVI_COLOR, label=\"kNDVI\")\nax.set_ylim([-0.15,1.2])\nax.set_ylabel(\"VI\")\nax.legend(loc=\"upper left\")\n\nax2 = ax.twinx()\nax2.scatter(df.index, df[\"GPP_NT_VUT_REF\"], \n            s=20, color=\"grey\", alpha=0.6, label=\"GPP\")\nax2.set_ylim([-3.5,17.5])\nax2.set_ylabel(\"GPP\")\nax2.legend(loc=\"upper right\")\n\nextreme_mask = df[\"extreme\"] == 1\ngroups = (extreme_mask != extreme_mask.shift()).cumsum()\n\nfor _, group in df[extreme_mask].groupby(groups):\n    start = group.index.min()\n    end   = group.index.max()\n    ax.axvspan(start, end, color=\"red\", alpha=0.15)\n\nplt.title(\"NDVI, kNDVI, GPP and Extreme Events\")\nplt.tight_layout()\nplt.show()\n\nNow, let‚Äôs do the same for the anomalies by aggregating the anomalies of the indices in space using the median to produce a time series.\n\nidx_anomalies_agg = idx_anomalies.median([\"x\",\"y\"])\n\nNow we can visualize the anomaly time series of NDVI, kNDVI, and GPP for the DE-Hai site. Here, both vegetation indices and GPP have been transformed into weekly anomalies, representing deviations from their typical seasonal cycles. A horizontal line at zero indicates the expected baseline. A secondary axis displays GPP anomalies, allowing direct comparison between canopy-level spectral responses and ecosystem-level carbon uptake changes. Extreme low-GPP events are shown as shaded red intervals.\nThis plot highlights how vegetation index anomalies co-occur with (e.g.¬†2021) or diverge (e.g.¬†2018) from carbon uptake anomalies, offering insight into forest responses to stress events.\n\nfig, ax = plt.subplots(figsize=(15, 3))\n\nax.plot(idx_anomalies_agg.time, idx_anomalies_agg[\"NDVI\"],  color=NDVI_COLOR,  label=\"NDVI\")\nax.plot(idx_anomalies_agg.time, idx_anomalies_agg[\"kNDVI\"], color=kNDVI_COLOR, label=\"kNDVI\")\nax.axhline(0, color=ZERO_COLOR, linewidth=1)\nax.set_ylim([-0.45,0.45])\nax.set_ylabel(\"VI Anomaly\")\nax.legend(loc=\"upper left\")\n\nax2 = ax.twinx()\nax2.scatter(df.index, df[\"anomaly\"], \n            s=20, color=\"grey\", alpha=0.6, label=\"GPP\")\nax2.set_ylim([-6.5,6.5])\nax2.set_ylabel(\"GPP Anomaly\")\nax2.legend(loc=\"upper right\")\n\nextreme_mask = df[\"extreme\"] == 1\ngroups = (extreme_mask != extreme_mask.shift()).cumsum()\n\nfor _, group in df[extreme_mask].groupby(groups):\n    start = group.index.min()\n    end   = group.index.max()\n    ax.axvspan(start, end, color=\"red\", alpha=0.15)\n\nplt.title(\"NDVI, kNDVI, GPP Anomalies and Extreme Events\")\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Analyzing Forest Vegetation Anomalies Using Sentinel-2 Zarr Data Cubes</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/68_vegetation_anomalies.html#now-it-is-your-turn",
    "href": "06_eopf_zarr_in_action/68_vegetation_anomalies.html#now-it-is-your-turn",
    "title": "Analyzing Forest Vegetation Anomalies Using Sentinel-2 Zarr Data Cubes",
    "section": "üí™ Now it is your turn",
    "text": "üí™ Now it is your turn\nThe following exercises will help you reproduce the previous workflow for another dataset.\n\nTask 1: Create a data cube for DE-Tha\n\nUse the coordinates of DE-Tha (provided in the cell below) to create a data cube for this site.\nRetrieve the red edge bands in addition to the NIR and red bands.\nModify the code as you need.\n\n\n# DE-Tha Coordinates\nTHA_LAT = 50.9625\nTHA_LON = 13.56515\n\n# Get all items as a list of dicts\n# THA_items = get_items(THA_LAT,THA_LON,return_as_dicts=True)\n\n# Create the delayed Dask objects\n# THA_ds = [open_and_curate_data(..., bands=[\"b04\", \"b05\", \"b06\", \"b07\", \"b8a\"]) for ...]\n\n# ...\n\n\n\nTask 2: Compute Vegetation Indices\n\nSelect a vegetation index from Awesome Spectral Indices that uses the Red Edge bands.\nModify the code as you need.\n\n\n# Indices that include any of the red edge bands\nfor idx, attrs in spyndex.indices.items():\n    if any(item in [\"RE1\",\"RE2\",\"RE3\"] for item in attrs.bands):\n        print(idx)\n\n\n\nTask 3: Calculate Vegetation Anomalies\n\nCalculate anomalies for the selected index and compare them against the GPP anomalies of DE-Tha.\n\n\nTHA_df = curate_gpp(\"DE-Tha\")\n\n# THA_df[\"GPP_NT_VUT_REF\"] -&gt; GPP values\n# THA_df[\"time\"] -&gt; time simension\n# THA_df[\"anomaly\"] -&gt; Anomalies\n# THA_df[\"extreme\"] -&gt; Extreme = 1, Normal condition = 0",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Analyzing Forest Vegetation Anomalies Using Sentinel-2 Zarr Data Cubes</span>"
    ]
  },
  {
    "objectID": "06_eopf_zarr_in_action/68_vegetation_anomalies.html#conclusion",
    "href": "06_eopf_zarr_in_action/68_vegetation_anomalies.html#conclusion",
    "title": "Analyzing Forest Vegetation Anomalies Using Sentinel-2 Zarr Data Cubes",
    "section": "Conclusion",
    "text": "Conclusion\nIn this notebook, we explored how Sentinel-2 L2A Zarr data cubes can be used to monitor forest vegetation dynamics and detect anomalous behavior linked to ecosystem stress. By leveraging Zarr, STAC-based discovery, and xarray/Dask for scalable computation, we built an end-to-end workflow that included:\n\nAccessing Sentinel-2 data from the EOPF Zarr STAC\n\nCreating spatiotemporal data cubes centered on forest monitoring sites\n\nComputing spectral indices (NDVI, kNDVI) using the Awesome Spectral Indices catalogue\n\nConstructing weekly time series and climatological baselines\n\nDeriving vegetation anomalies and comparing them with GPP anomalies from ICOS\n\nIdentifying and visualizing extreme low-GPP events\n\nThrough the joint analysis of spectral indices and ecosystem productivity, we demonstrated how remote sensing can reveal (or not) signals of forest stress and complement flux tower observations. This workflow illustrates the value of Zarr-based EO data, open standards (STAC), and modern geospatial Python tools for reproducible and scalable environmental monitoring.\n\nAcknowledgements\nWe would like to thank ICOS for providing the data on the Ecosystem stations DE-Hai [1] and DE-Tha [2].\n\n\nReferences\n[1] Knohl, A., Schulze, E.-D., Kolle, O., & Buchmann, N. (2003). Large carbon uptake by an unmanaged 250-year-old deciduous forest in Central Germany. Agricultural and Forest Meteorology, 118(3‚Äì4), 151‚Äì167. https://doi.org/10.1016/s0168-1923(03)00115-1\n[2] Gr√ºnwald, T., & Bernhofer, C. (2007). A decade of carbon, water and energy flux measurements of an old spruce forest at the Anchor Station Tharandt. Tellus B: Chemical and Physical Meteorology, 59(3), 387. https://doi.org/10.1111/j.1600-0889.2007.00259.x",
    "crumbs": [
      "**EOPF Zarr in Action**",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Analyzing Forest Vegetation Anomalies Using Sentinel-2 Zarr Data Cubes</span>"
    ]
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "Here we introduce some helpful terms that are mentioned throughout the EOPF 101.\n\n\n\n\n\n\n\nAcronym\nDefinition\n\n\n\n\nEOPF\nEarth Observation Processing Framework\n\n\nCDSE\nCopernicus Data Space Ecosystem\n\n\nCOG\nCloud Optimised GeoTIFF\n\n\nCMP\nCore Python Modules\n\n\nCRS\nCoordinate Reference System\n\n\ndNBR\nDelta Normalized Burn Ratio\n\n\nDN\nDigital Number\n\n\nEO\nEarth Observation\n\n\nEFFIS\nEuropean Forest Fire Information System\n\n\nEPSG\nEuropean Petroleum Survey Group\n\n\nFCI\nFalse Colour Image\n\n\nGCP\nGround Control Points\n\n\nGRD\nGround Range Detected\n\n\nHEALPix\nHierarchical Equal Area isoLatitude Pixelation\n\n\nLST\nLand Surface Temperature\n\n\nNBR\nNormalized Burnt Ratio\n\n\nNIR\nNear-Infrared\n\n\nNRB\nNormalized Radar Backscatter\n\n\nSAFE\nStandard Archive Format for Europe\n\n\nSAR\nSynthetic Aperture Radar\n\n\nSCL\nScene Classification Layer\n\n\nSLC\nSingle Look Complex\n\n\nSLSTR\nSea and Land Surface Temperature Radiometer\n\n\nSNAP\nSentinel Application Platform\n\n\nSTAC\nSpatio Temporal Asset Catalog\n\n\nSWIR\nShort-Wave Infrared\n\n\nTCI\nTrue Colour Image\n\n\nZarr\nCloud-optimised version for netCDF and HDF5 formats, specifically designed for storing and accessing large n-dimensional arrays",
    "crumbs": [
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>**Glossary**</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "The table below provides a categorized overview of key resources used during the development of the EOPF 101 book.\n\n\n\nCategory\nResource Title\nDescription & Context\nLink\n\n\n\n\nSentinel Mission & Product Specifications\nSentinel-1 Level 1 Product Specification\nDetailed specifications for Sentinel-1 Level 1 products.\nAvailable here\n\n\n\nSentinel-2 - MSI - Level 2A Products\nAuxiliary and data product specifications for Sentinel-2 MSI Level 2A products.\nAvailable here\n\n\n\nSentinel-3 ‚Äì Documentation (via CDSE)\nComprehensive documentation for Sentinel-3 data products and mission.\nAvailable here\n\n\nEOPF Platform & Modules\nSupported Products Formats ‚Äî EOPF - Core Python Modules\nGuide to the product formats supported by the Earth Observation Processing Framework‚Äôs (EOPF) Core Python Modules.\nAvailable here\n\n\n\nEOPF Sentinel Zarr Samples Service STAC Catalog\nA STAC (Spatio Temporal Asset Catalog) for accessing Sentinel Zarr samples hosted by EOPF.\nAvailable here\n\n\n\nEOPF Sentinel Zarr Samples\nDirect access to Sentinel data samples stored in Zarr format within the EOPF ecosystem.\nAvailable here\n\n\nData Formats & Standards\nZarr Documentation\nOfficial documentation for the Zarr format, a cloud-optimised standard for n-dimensional arrays.\nAvailable here\n\n\n\nIntroduction to the Zarr Format | Copernicus Marine Help Center\nAn introductory guide to the Zarr format, provided by the Copernicus Marine Help Center.\nAvailable here\n\n\n\nZarr + STAC\nArticle discussing the integration and benefits of combining Zarr data with STAC catalogs.\nAvailable here\n\n\n\nIs Zarr the new COG?\nAn insightful discussion comparing Zarr with Cloud Optimised GeoTIFF (COG) for cloud-native geospatial data.\nAvailable here\n\n\n\nAbout STAC\nGeneral information and principles behind the Spatio Temporal Asset Catalog (STAC) specification.\nAvailable here\n\n\nCloud-Native Geospatial Initiatives\nCloud-Native Geospatial Forum (CNG)\nThe official website for the Cloud-Native Geospatial Forum, promoting cloud-native approaches in geospatial.\nAvailable here\n\n\n\nCloud-Optimized Geospatial Formats Guide - Zarr\nCloud Native Geo‚Äôs comprehensive Zarr guide\nAvailable here\n\n\n\nCloud Native Geospatial Formats Explained\nMatt Forrest‚Äôs overview of modern formats\nAvailable here\n\n\n\nZarr Takes Cloud-Native Geospatial by Storm\nEarthmover‚Äôs analysis of Zarr adoption\nAvailable here\n\n\nChunking Strategy Guides\nTo Compress or Not to Compress ‚Äî A Zarr Question\nAriel Lubonja‚Äôs compression analysis\nAvailable here\n\n\n\nDask Array Best Practices\nOfficial Dask chunking guidelines\nAvailable here\n\n\n\nChoosing Good Chunk Sizes in Dask\nDask team‚Äôs chunking recommendations\nAvailable here\n\n\n\nFederated and Reusable Processing of Earth Observation Data\nNature Scientific Data paper\nAvailable here",
    "crumbs": [
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>**References**</span>"
    ]
  }
]